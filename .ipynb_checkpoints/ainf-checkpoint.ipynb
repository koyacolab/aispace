{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1698373996251,
     "user": {
      "displayName": "Koyaua Uvarov",
      "userId": "04551130653342672393"
     },
     "user_tz": -180
    },
    "id": "Qj506dTf0hD4"
   },
   "outputs": [],
   "source": [
    "# # This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# # For example, here's several helpful packages to load\n",
    "\n",
    "# import numpy as np # linear algebra\n",
    "# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# # Input data files are available in the read-only \"../input/\" directory\n",
    "# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
    "# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22764,
     "status": "ok",
     "timestamp": 1698374019009,
     "user": {
      "displayName": "Koyaua Uvarov",
      "userId": "04551130653342672393"
     },
     "user_tz": -180
    },
    "id": "tkYBYiue0lS7",
    "outputId": "6afc71ac-0294-4947-8757-067dff387555"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive/')\n",
    "\n",
    "# import os\n",
    "\n",
    "# # !pip install fire\n",
    "# # !pip install tqdm\n",
    "\n",
    "# home_dir = '/content/gdrive/My Drive/A0/aispace'\n",
    "# os.chdir(home_dir)\n",
    "# !pwd\n",
    "\n",
    "# import os\n",
    "# # Get the current working directory\n",
    "# current_directory = os.getcwd()\n",
    "# print(current_directory)\n",
    "\n",
    "# import shutil\n",
    "# import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42824,
     "status": "ok",
     "timestamp": 1698374061828,
     "user": {
      "displayName": "Koyaua Uvarov",
      "userId": "04551130653342672393"
     },
     "user_tz": -180
    },
    "id": "pEOnhw3U0hD6",
    "outputId": "33c8cc60-24a7-4ff8-9fcb-fc884c7a24ba"
   },
   "outputs": [],
   "source": [
    "# !pip install rasterio\n",
    "# !pip install accelerate\n",
    "# !pip install peft\n",
    "# !pip install transformers\n",
    "# # !pip install transformers==4.34.0\n",
    "# !pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1698374061829,
     "user": {
      "displayName": "Koyaua Uvarov",
      "userId": "04551130653342672393"
     },
     "user_tz": -180
    },
    "id": "3_zkf2dM0hD6"
   },
   "outputs": [],
   "source": [
    "KAGGLE = False\n",
    "if KAGGLE == True:\n",
    "    # Define the input and output directories\n",
    "    input_directory  = '/kaggle/input/begreat'  # Replace with the path to your input directory\n",
    "    output_directory = '/kaggle/working'  # Replace with the path to your output directory\n",
    "\n",
    "    def input_copy(input_directory, output_directory):\n",
    "        # Get a list of files in the input directory\n",
    "        files_to_copy = os.listdir(input_directory)\n",
    "        # Iterate through the files and copy them to the output directory\n",
    "        for file_name in files_to_copy:\n",
    "            # Create the full paths for the source and destination\n",
    "            source_file = os.path.join(input_directory, file_name)\n",
    "            destination_file = os.path.join(output_directory, file_name)\n",
    "\n",
    "            # Copy the file from the source to the destination\n",
    "            shutil.copy(source_file, destination_file)\n",
    "\n",
    "        # Get a list of files in the input directory\n",
    "        files = os.listdir(output_directory)\n",
    "        print(files)\n",
    "\n",
    "    input_copy(input_directory, output_directory)\n",
    "\n",
    "    source_directory  = '/kaggle/input/'  # Replace with the path to your input directory\n",
    "    destination_directory = '/kaggle/working/input'  # Replace with the path to your output directory\n",
    "\n",
    "    # Copy the source directory to the destination directory\n",
    "    shutil.copytree(source_directory, destination_directory)\n",
    "\n",
    "    input_copy(input_directory, output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 22684,
     "status": "ok",
     "timestamp": 1698374084509,
     "user": {
      "displayName": "Koyaua Uvarov",
      "userId": "04551130653342672393"
     },
     "user_tz": -180
    },
    "id": "REzgouGF0hD7"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import great\n",
    "from great import GReaT\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "################################\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# all imports should go here\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio as rio\n",
    "from rasterio.plot import show\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import skimage.exposure\n",
    "\n",
    "# access package for AWS access\n",
    "# import boto3\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "import datetime\n",
    "import platform\n",
    "import datetime\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# import ee\n",
    "import h5py\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta  # Import timedelta here\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "import rasterio as rio\n",
    "################################\n",
    "\n",
    "from hlsdataset import HLSDataSet\n",
    "\n",
    "import shutil\n",
    "\n",
    "# Execute only once!\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1698374084510,
     "user": {
      "displayName": "Koyaua Uvarov",
      "userId": "04551130653342672393"
     },
     "user_tz": -180
    },
    "id": "1ymo4JOO2iK9"
   },
   "outputs": [],
   "source": [
    "class HLSInference(HLSDataSet):\n",
    "    def __init__(self, doy=211, table_dtype = 'float16', path='./aispace/data/L8-100x100'):\n",
    "        super().__init__(table_dtype = table_dtype, path=path)\n",
    "        # self.model = model\n",
    "        self.doy_to_impute = doy\n",
    "\n",
    "        self.imputed_data = None\n",
    "        self.recovered_data = None\n",
    "\n",
    "        self.imputed_file = ''\n",
    "\n",
    "        # self.nan_data = self.to_impute #.copy()    # to_impute.copy()\n",
    "        # display(self.nan_data)\n",
    "        #### for only one day processing ###########################\n",
    "        self.nan_data_doy = None # self.nan_data.loc[(self.nan_data['DOY'] == doy)]\n",
    "        self.nan_data_doy = None #  self.nan_data_doy.reset_index(drop=True)\n",
    "\n",
    "        self.data_doy = None #  self.clear_data.loc[(self.clear_data['DOY'] == doy)]\n",
    "        self.data_doy = None #  self.data_doy.reset_index(drop=True)\n",
    "\n",
    "        # self.nan_data_resid  = self.nan_data.loc[(nan_data['DOY'] != doy)]\n",
    "        # self.nan_data_resid  = self.nan_data_resid.reset_index(drop=True)\n",
    "\n",
    "    def _impute(self, model, columns_impute=['B02', 'B03', 'B04', 'PID', 'DOY'], device='cuda', k=400, max_length=1000, temperature=0.01):\n",
    "\n",
    "        self.nan_data_doy = self.to_impute.loc[(self.to_impute['DOY'] == self.doy_to_impute)]\n",
    "        self.nan_data_doy = self.nan_data_doy.reset_index(drop=True)\n",
    "\n",
    "        self.data_doy = self.clear_data.loc[(self.clear_data['DOY'] == self.doy_to_impute)]\n",
    "        self.data_doy = self.data_doy.reset_index(drop=True)\n",
    "\n",
    "        # print(f'to impute data:')\n",
    "        # display(self.nan_data_doy)\n",
    "        print(f'to impute data:')\n",
    "        display(self.nan_data_doy)\n",
    "        display(self.data_doy)\n",
    "\n",
    "        # fn\n",
    "\n",
    "        print(f'NumPy version:{np.__version__}')\n",
    "        np.float = float\n",
    "\n",
    "        # Get the DataFrame with columns in reverse order\n",
    "        # self.nan_data_doy = self.nan_data_doy[self.nan_data_doy.columns[::-1]].copy()\n",
    "\n",
    "        _impute = self.nan_data_doy[columns_impute].copy()\n",
    "        print('IMPUTE:')\n",
    "        display(_impute)\n",
    "        # self.imputed_data = pd.read_csv('imputed.csv')\n",
    "        self.imputed_data = model.impute(_impute, k=k, max_length=max_length, temperature=temperature, device=device)\n",
    "        self.imputed_data.to_csv('imputed2.csv')\n",
    "\n",
    "        print('IMPUTED:')\n",
    "        display(self.imputed_data)\n",
    "        \n",
    "        # imputed_file = f'A0[optim_sophia]/imputed_output_run[3].csv'\n",
    "        # self.imputed_data = pd.read_csv(imputed_file)\n",
    "        # self.imputed_data = self.nan_data_doy.copy()\n",
    "\n",
    "        print(self.nan_data_doy.columns, self.imputed_data.columns)\n",
    "        print(self.nan_data_doy.shape, self.imputed_data.shape)\n",
    "\n",
    "        # Merge the dataframes by X and Y columns and replace B3 in df1 with B3 from df2\n",
    "        merged_df = self.nan_data_doy.merge(self.imputed_data, on=['PID', 'DOY'], suffixes=('', '_df2'), how='left')  \n",
    "        # Replace the original B3 column with B3 from df2\n",
    "        merged_df['B02'] = merged_df['B02_df2']\n",
    "        merged_df['B03'] = merged_df['B03_df2']\n",
    "        merged_df['B04'] = merged_df['B04_df2']\n",
    "        \n",
    "        # Drop the additional B3_df2 column\n",
    "        merged_df = merged_df.drop('B02_df2', axis=1)\n",
    "        merged_df = merged_df.drop('B03_df2', axis=1)\n",
    "        merged_df = merged_df.drop('B04_df2', axis=1)\n",
    "\n",
    "        self.imputed_data = merged_df.copy()\n",
    "        \n",
    "        print(self.nan_data_doy.columns, self.imputed_data.columns)\n",
    "        print(self.nan_data_doy.shape, self.imputed_data.shape)\n",
    "        # fn\n",
    "        # cols = self.nan_data_doy.columns \n",
    "        # self.imputed_data\n",
    "\n",
    "        # Get the DataFrame with columns in reverse order\n",
    "        self.imputed_data = self.imputed_data[self.imputed_data.columns[::-1]].copy()\n",
    "\n",
    "        if len(self.imputed_data) != len(self.nan_data_doy):\n",
    "            print('len(self.imputed_data) != len(self.nan_data_doy)')\n",
    "            # Use the merge function with indicator=True\n",
    "            original_df = self.nan_data_doy\n",
    "            subset_df = self.imputed_data\n",
    "\n",
    "            merged_df = pd.merge(original_df, subset_df, on=['PID', 'DOY'], how='left', indicator=True)\n",
    "\n",
    "            # Find the rows in original_df that are not in subset_df\n",
    "            missing_rows = original_df[merged_df['_merge'] == 'left_only']\n",
    "\n",
    "            # Display the missing rows\n",
    "            # display(missing_rows)\n",
    "\n",
    "            self.imputed_data = pd.concat([self.imputed_data, missing_rows], axis=0)\n",
    "\n",
    "        self.recovered_data = pd.concat([self.imputed_data, self.data_doy], axis=0)\n",
    "        self.recovered_data = self.recovered_data.reset_index(drop=True)\n",
    "\n",
    "        print('imputed_data')\n",
    "        display(self.imputed_data)\n",
    "\n",
    "        print('recovered_data')\n",
    "        display(self.recovered_data)\n",
    "\n",
    "        return self.recovered_data\n",
    "\n",
    "    def _set_inference_recovered(self,):\n",
    "       self.inference_data = self.recovered_data\n",
    "       self.inference_data = self.inference_data.sort_values(by=['Y', 'X', 'DOY', ])\n",
    "\n",
    "       return self.inference_data\n",
    "\n",
    "    def _save_recovered(self, imputed_file=f'recovered_output.csv'):\n",
    "        self.imputed_file = imputed_file\n",
    "        print(imputed_file)\n",
    "        self.recovered_data.to_csv(self.imputed_file)\n",
    "\n",
    "    def _read_recovered(self, imputed_file=f'recovered_output.csv'):\n",
    "        self.imputed_file = imputed_file\n",
    "        print(imputed_file)\n",
    "        self.recovered_data = pd.read_csv(self.imputed_file)\n",
    "        # display(self.imputed_data)\n",
    "        # ######### CLEAR UNNAMED COLUMNS FROM DATASETS #######################################\n",
    "        self.recovered_data = self.recovered_data.loc[:, ~self.recovered_data.columns.str.contains('^Unnamed')]\n",
    "        return self.recovered_data\n",
    "\n",
    "    def _save_imputed(self, imputed_file=f'imputed_output.csv'):\n",
    "        self.imputed_file = imputed_file\n",
    "        print(imputed_file)\n",
    "        self.imputed_data.to_csv(self.imputed_file)\n",
    "\n",
    "    def _read_imputed(self, imputed_file=f'imputed_output.csv'):\n",
    "        self.imputed_file = imputed_file\n",
    "        print(imputed_file)\n",
    "        self.imputed_data = pd.read_csv(self.imputed_file)\n",
    "        # display(self.imputed_data)\n",
    "        # ######### CLEAR UNNAMED COLUMNS FROM DATASETS #######################################\n",
    "        self.imputed_data = self.recovered_data.loc[:, ~self.recovered_data.columns.str.contains('^Unnamed')]\n",
    "        return self.imputed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 6340,
     "status": "ok",
     "timestamp": 1698374090824,
     "user": {
      "displayName": "Koyaua Uvarov",
      "userId": "04551130653342672393"
     },
     "user_tz": -180
    },
    "id": "XtgFFiGF0hD7",
    "outputId": "88ed53ad-c5e5-4cad-aee3-549565495720"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home\n",
      "NumPy version:1.26.1\n",
      "<class 'float'>\n",
      "PIDs is  9999\n",
      "[203]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/hlsdataset.py:210: RuntimeWarning: invalid value encountered in cast\n",
      "  normalized_band = ((band - min_val) / (max_val - min_val) * 255).astype(np.uint8)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABv0AAAEDCAYAAAAWb8hiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABjZ0lEQVR4nO3de5AdZ33n/2/3uc19ZMm2ZGErMQuLQ7w4hblYla2QYLFeKkXBYmrhV9SGJVSlwsoUxH/sxlsLqVSlylT4FRA2QMhuCtj81ksCWQiXACEGy1wEGIM3NhetASdWsCXhi2akuZxb9+8PofF8P8+j02ekM5rT0+9X1VTp6dP99NNP93cMenT6k+R5nhsAAAAAAAAAAACA0kq3egAAAAAAAAAAAAAALgyLfgAAAAAAAAAAAEDJsegHAAAAAAAAAAAAlByLfgAAAAAAAAAAAEDJsegHAAAAAAAAAAAAlByLfgAAAAAAAAAAAEDJsegHAAAAAAAAAAAAlByLfgAAAAAAAAAAAEDJsegHAAAAAAAAAAAAlByLfgAAAAAAAAAAAEDJbdqi33vf+177+Z//eZuYmLAXvvCF9s1vfnOzTgVgjFD7QDVR+0A1UftANVH7QDVR+0A1UftAuSR5nuej7vQv/uIv7Dd+4zfsT/7kT+yFL3yhvfvd77aPfvSjduTIEbv88ssHHptlmT3yyCM2OztrSZKMemhA5eR5bqdOnbK9e/damm7ul3upfWB8UPtANVH7QDVR+0A1UftANVH7QDUNXfv5JnjBC16QHzx4cK3d7/fzvXv35rfffnvhsUePHs3NjB9++Bnxz9GjRzej3B1qnx9+xu+H2ueHn2r+UPv88FPNH2qfH36q+UPt88NPNX+ofX74qeZPUe3XbcQ6nY7de++9dtttt61tS9PUDhw4YIcPHw72b7fb1m6319r5z754+PyX7LV648xq5aWTlwTHze/Y5drTszt8v91ucB6145J5155szrr2Y48/4dpPLD4W9JH1M9cOV1j9v2Lox75Ymft96sngf6GRZeG2vvmNmUXOs/6UkW161lT/AcbgLn+2i+ykfUT+VUev48feacucSieXNKeCPiZrNdde7vn7v5x1/Dn6vaCPdmfVnzf3x0zW/DE/ebgZ9DEK7/5/3+zaN/zL/+eC+ltcXLSrrrrKZmdni3e+AKOq/aNHj9rc3JyZmf34xz8Ojjt27JhrLy0tufbMzIxrT05OBn089piv5ZWVFde+9NJLXXvPnj1BH/W6//XZ6/nnQ/8FU6PRCPrI5fdB7PfUerF/wdFs+udQxzXMv/jSsff7/cJjlF5vTWoyRvfRses4Yq+P0G3/4l/8C9d+xjOe4dq7d+8O+pif9/8t0Ofh8ccfd+1nPvOZQR+j8NrXvta1jx496tr6fMT+ldz6Oez3+/a9732vlLU/DL1vqJaFhYWtHsLYKtt/94tcjHvN75PBxrneLsa926zr36yxb5faB7Yate9R+6gKat+j9lEV2632R77o99hjj1m/3w/+YnX37t32gx/8INj/9ttvt9///d8PB9ZI1xb9Go3wL4+bTT/0Vsv/hXouf8+d5+FfYusxrZb/y/OmfN5ohtO10UW/dJMW/dJ8BIt+yeB2cFDsUnRjMB2Rr3Lr2LPBi36NRngfmjW/rZv4cTSkzywyxf3cP2eptOs13+cwixrnY3raL1Jt5C/BB9nsr9GPqvbn5ubWrjn2C+zUqVMDxzE9Pe3aU1PhIrEu6ujcaB+xcWzGol9sn/Viz9x2WvTT69dxxe5lq9UauI8uAsfupdaYjkMX20ZVk0rPq/Oj7VhNx+a9jLUPFOFZKVaW2i/Cvd56Vb8HZbv+7VL7wFaj9j1qH1VB7XvUPqpiu9X+yBf9Nuq2226zW2+9da199l8n/8K+vdZsnRne8tJKcFyW+78MPr1y0rV7ff8trYlW+Be93bbfZ3HxUd/nsv8GUfi1NbMkWKArmvDwL2Rrqd/WlwWqrixYBgtrFq6lpbIwGKwTxoYZfEnP75TrMUlkHLJTP/P7rK6E37DLOrI40vKPZa3pP+/VIquecp6dDb8QMpfKomAWLmp0ZfFAJ6khiyf/ZMfDcYzA4z/1i1o/+t7XXXtm2i9iPPKTfwz6+IcfP7j25+WV1eDzcXCu2v/yl7+8tug2MTERHKfbdNFLF4GWl5eDPvSYHTt2uLb+K4zYL1JdnNZ9dEFvdTW8D7pNF310gSo2Dl0Y68q3nHURMLYopNeifWofw/yPymEWPZUuNuqC5T//5/88OOa73/2ua3/gAx9w7RtuuMG1r7zyyqAP/Q+7zuHi4qJrP+tZzwr6GAV9dvXd+Lr4WPTNz263a/fff/8IRzga56p9ANsbtY/NoP97i6yY8UPtA9VE7QPVRO0D42Hki36XXnqp1Wo1O37cL4gcP348+oq8VqsV/EUngPKh9oFqovaBaqL2gWqi9oFqovaBaqL2gXIqfu/bBjWbTbv++uvtzjvvXNuWZZndeeedtn///lGfDsCYoPaBaqL2gWqi9oFqovaBaqL2gWqi9oFy2pTXe9566632ute9zp73vOfZC17wAnv3u99tS0tL9vrXv34zTgdgTFD7QDVR+0A1UftANVH7QDVR+0A1UftA+WzKot+rX/1q++lPf2pve9vb7NixY/ZLv/RL9rnPfS4I/QSwvVD7QDVR+0A1UftANVH7QDVR+0A1UftA+SS5pp9vscXFRZufn7fb3nazTUw0zMzsR0cfCvbrZ369cnpqxrVPn37S729hqPv05CWuvbqaufap5VOunaSNoI9Uw+KD6fSf16PrrH6fTtZz7cz8uKL59Jm0ZRi5HJTpDha+67WmcyY75JE+Op2+b7d9O++Gb5Rttvy8Nqb9Pnniz9PP9GLNZnI/r7vTCdeeavjP88gcLne6rt3L/Hmnmv6d1L1IJwttf++6/Y5rLy3753Klsxj0sWvHpa49O+Of07nJpm9PTAZ95Oumvd3u2tvf/5e2sLBgc3Nzwb7j4mzt/+mf/qlNTp65pmc/+9nBfo2Gf14WFhZce8eOHa5dq9WCPk6fPu3aZ893rj5i9Fdnv98f+Hm73S7sY3p62rXrdf/cZpFnf6OazWawrdfzz62OVecwTSN1LP3qMbH/1Oh59Xr1PLHz/vCHP3TtP/iDP3DtI0eOuPYVV1wR9KH/Q1WfhxMnTgTHqOc+97muvXfvXte+8sorXXt2djbo4+6773btbtf/Tlpc9L8v/umf/inoY319dLtd+6u/+qvS1P5Gx5lE/2OIqhqz/zm7pc63pi62s+MscjHuLb9PNm471dx2u//bpfYBbAy1D1QTtQ9UU1HtjzzTDwAAAAAAAAAAAMDFxaIfAAAAAAAAAAAAUHIs+gEAAAAAAAAAAAAlFwuYGwt53rAsP5MRlfdjWXq+PT3t32G6tLLq2t22z/AyM+vnPh+rn/lMLs2PiiVXBAkQuT+mL3kX3cRnWJmZ5ZINpxkZQc5ELENDByLtRI4JU84sCAvUHMBc5qu9El6LbkvkRk1Oh49cvennLMgblLGnkctfNX/eU7nP0mtk/hz1WrjeXZPrTWSXes2fOExGCwsqk6zB5ZrPnvzhMZ8baWb29w/+g2tP1I+59mXzPvft6Vf4rDAzs0vW5YV1uuF9Gme1Wm0t2y2W4abZeUtLS66teXwTEz7f0cxsddX/fijKzouNQ/PotN1q+QzI2DiKMuuGyfArOkZ/n3Q6vjZiNDdRxa5Fr1fnY2VlJTim6PqLchPNzPbs2ePar3nNa1z7T//0T107dv36PGg+oT4fjz/+eNCH5vFNTU259rXXXuvar3/964M+3va2t7n2k0/6DNDPfe5zA89pZnbs2FO/LzQTENjOzieTaztlkm0X3JPy0Jor8707n7FvtxxAAAAAANsH3/QDAAAAAAAAAAAASo5FPwAAAAAAAAAAAKDkWPQDAAAAAAAAAAAASm5sM/163Z7VameyEvIszHGq1Xzm0vKKz+xrd9v+gDzMqOp2JC8rHZzjleRhEl5T9ulJnlYvk4yIWCCdZthpHp/uPkyEhEaBaZ+RHAodmV7L8pLPh8pWw7yxesPPUX1S5izyxPXk/gYjSzXjMOxDp/mUZPw1Mj/22Ugi34SMXbMF89yPs1YLn4eppt/Wl7zGem3StX9+99OCPqZnl117ue3P25ewwceWwqy0/ro8tbJl+qVpulZ7sYwVzaybnvYZh5qlFlOU4adZaLFxnD7tf+don5p7p5+fq9+N0rFrlp7+Hovl4unYhskjVLF+1yvKCYz1MUxejo71ec97nmsfP37ctf/8z/886OPkyZOurfdF53BmxmdzmoXzrvflyJEjrv3Zz3426OPLX/6yaz/wwAPBPuv93M/9XLBtfXbiMPmNZUJ+EkZto89UmTPLAIxWYQY7AAAAAGwRvukHAAAAAAAAAAAAlByLfgAAAAAAAAAAAEDJsegHAAAAAAAAAAAAlNzYZvqdePxxazbPDK+WhPlrufnstMVTC66d9XyeUrMR5nxdfule6dNnMzx89B+lzzCzKmv6/IaehOkNE++g51VJ6juJdZlLvF4uJ9ZxxM7Y7UqG37LPg+qu+qMmJsKMrokZycXTwQ6O/TIzs0Qz/IoPCa6vk/hrOZn5a6nl4Xr3XOrLIdc5k0nLNEjQzCzx2/oa15j4+dk56fPozMzmJn3u34mlJdd+5EmfJXfsiVNBH+2pp3LOuiXL9NuzZ89aTl8sk0zz53bs2OHamqmi2XtmZj/+8Y9dW/PXnv70p7t2sxn+DtJxTMp9Gyb7ScdalL8Xy83TY7StYteieXt6LZrpF5tTzbSLZV4qnSO9vqJsvdg+c3Nzrv2rv/qrrn3s2LGgjy996UsD+1Cx3J6iTEeds0996lNBH5rh96IXvci1r7nmGtd+8skngz527dq19ud2ux18DuD8RfOQyfkDzCysj6rVxjhc7+Lios3Pz2/1MAAAAABsMb7pBwAAAAAAAAAAAJQci34AAAAAAAAAAABAybHoBwAAAAAAAAAAAJQci34AAAAAAAAAAABAydW3egDncvL0sjWaZ4aXSjC8mVmWdVw7Sf0+l8zvce3Ldvm2mdn87C5/zpNPuHbNaq690msHfeS1zLdlHTWVceUWXkuQ+57IhmFy4YNu/YYs9+12uxd00V7p+tNm/sQTk/5xaU76+TEzk9MElxJuCIeut1vvfx6ZEJ3D1N8Wayd9117I/fNjZpb6y7eJmr+XNWn3YvdFJ0D2aff9ODp5eB9aqT/PXMPP++pMy7WfPC0DN7MnV5/a1uv1g8/H2e7du21mZsbMzPr9cOy1mn/usszf7EcffdS1H3nkkaCPn/70p67davk5PXXqlGvv2RP+/piennbtRJ7TXq838HMzs3rd31u9llwebG3HjtH5Uc1mM9g2MTEx8Jjl5eWB5zQLr0/vXez6i65P5zBNi/+dip738ssvd+2XvexlwTH6zDz44IOuvXPnTtduNBpBH92ur8MTJ0649r59+1z7uuuuC/p4+OGHXfv//J//49rz8/Oufc011wR9PO1pT1v78/Lysv3xH/9xsA+A0Yn9bgMAAAAAANgqfNMPAAAAAAAAAAAAKDkW/QAAAAAAAAAAAICSY9EPAAAAAAAAAAAAKLmxzfTr5jWz/Ew2VdYPc89qkp02WZ9y7T2XX+XaP7fvyqCPf/qnf3Ltxx73OV+Tkz7nqputBn30NXOq5rOe+v3iQL607tdegyM0xysSH5Mkvg89b3tZssLCGDhrpD4LLGn5dq3hzxGLsUk0006uJjobuvRcEI+TxHYoiEHMZVwreZgV1zR/L+uJv5cyxUGfZma5RJ11JftsQbIol5IwW3Ay9/O+s+bz5vZMz7r2VCvs48mlp57VbrdceUOtVmstYy6WT9fp+OvV/D2t66NHjwZ9XHbZZa591VVXBfusF8vSK8rwO588Pu2z6HOzMOdO99E51PmLja0oazCW6adZekXjim3TtvYxzH1Qev179+4N9jlw4IBr/+QnP3HtlZUV145l+j322GOu/c/+2T9z7de+9rWu/exnPzvoQ/Mn/+zP/sy1P/nJT7r2DTfcEPSx/tmOZWICwLhZWFiwubm5rR4GRmyYLF8AAAAAwOjxTT8AAAAAAAAAAACg5Fj0AwAAAAAAAAAAAEqORT8AAAAAAAAAAACg5MY2069mdaudHZ6GqZlZWvOZEFPTO1x7TtqrK6eDPk484bO/FpZ9Ntj0hM9tatTDbIpeT7KtJKsik0ilLJJlIVF5lqSDc64iUXLWlXEsn5Z8sa4/ycxkM+gjafqx9UzzxPznsRXjpCBbL5a+pf3qXkNEGoaDkduS6G2KdLKc+JvVzCSTTLLxYqkkK3LDFzMfntiu+c/7adhLLoOfksHP1v1zOdH0eZZmZpPrMtk6nTATc5x1Op213LlmM3xONQ/m9Glf2wsLC64d62Pfvn2ufcUVV7j24uKia3e7YQjm5OSkaxfl8Wk+XWyfoqwbzdqLbZuennZtzXV78skngz50n7OZiucal+YXxvooyhaMKcrnK/rcLJxnzTCMzeEv/dIvubbmQn74wx927UsvvTTo4+Uvf7lrv+QlL3FtzRLUOTYLn8tf+7Vfc+0PfvCDrn3ixImgj1/8xV9c+3O73Q4+L4th7jUAoFw2+rudDEAAAAAA2Di+6QcAAAAAAAAAAACUHIt+AAAAAAAAAAAAQMmx6AcAAAAAAAAAAACU3Nhm+tWTMz9mZv1InoNuakn+Xru94to/eTTMPnrsiZOurZlUp1d8blWWRbIF65q/5/dpNP3nfc0ANLM8k6y8mu+jL4e0V8L56LYlG6zvz9ua9Lc6aQVdBGppQb5WLBhP8/eCXcJjinIAgzyPyLjywvTA4kyQtvn7vyCHaD5jHmQRmi0mPkNrJfFZcGnu720tj+ScyWO2LDmALemj1Q+fy5l1+WntWvjMjbNOp7OWRRbL49NsuJUVX+t6jOakmZldeeWVA/vcsWOHa8cyaIpyZobJodH8Of0dpPlzrVZYuLGswI30GRPL7FtPswjNwusNskgj8zFM7uF6sVxA3aZjLxqXmdnOnTtd+8CBA669urrq2rFMvxtvvNG1L7/8ctfW+xDL29PrX5/PZ2b2K7/yK679yU9+MuhjvVgWJQCA3NCyOJ/7RA4gAAAAgKrjm34AAAAAAAAAAABAybHoBwAAAAAAAAAAAJQci34AAAAAAAAAAABAyW140e/uu++2l73sZbZ3715LksQ+8YlPuM/zPLe3ve1tdsUVV9jk5KQdOHDAHnzwwVGNF8AWofaBaqL2gWqi9oFqovaBaqL2gWqi9oHtqb7RA5aWluy6666z3/zN37RXvvKVwed/+Id/aO95z3vswx/+sF199dX21re+1W666Sb73ve+ZxMTE0OfJ7PcMjsTxF6Phbjnftvy0rJrn0iPu/bJxSeDLrqdvmsniV8D7fV9EHwSWSOtp4MD5hP5PEnDPrIsc+1O149r1V+apf1a0Mdko+nPI1OdBHc60w1mJmMN2l4eu/RE52wIspN0EcjzcAfdoudNUr9HpAtL5DnrSa8LScf3UYvMYd0fM5H7ie92/TH9fi/oopE2/IaW72O1Kwd0O6aa6VPHJLGLPQ8Xq/YbjYY1GmfmoNMJr03v//T0tGvv2bPHtS+//PKgj2bT14vWYKvVcu1+39fkucY2iJ7DzKxW87V89rrPNY5uV2/+mfuyns61nkOf8xi9Xh17Gvk9Vq/751T7iM2hjiU2R0W0j6J2jJ53586drv2qV73KtfW+xLYtLi66tt5bnS+z8JnSPp///Oe79tGjR4M+7rnnnrU/x+b8fFys2gcwXqh9lJH+dz/2/xswGLUPVBO1D1QTtQ9sTxte9HvpS19qL33pS6Of5Xlu7373u+2//Jf/Yi9/+cvNzOx//I//Ybt377ZPfOIT9prXvCY4pt1uW7vdXmvrX5QCGA/UPlBN1D5QTdQ+UE3UPlBN1D5QTdQ+sD2NNNPvoYcesmPHjtmBAwfWts3Pz9sLX/hCO3z4cPSY22+/3ebn59d+rrrqqlEOCcBFQO0D1UTtA9VE7QPVRO0D1UTtA9VE7QPlNdJFv2PHjpmZ2e7du9323bt3r32mbrvtNltYWFj7ib2uDMB4o/aBaqL2gWqi9oFqovaBaqL2gWqi9oHy2vDrPUet1WpF85HSNF3LjWrVwgy7Ts9nFS2c9rlWWS7ZaVmYnZZrZp1mQRVk2sX2CWIjNK8ussza6/mDVpb8WGs9nwU1M+3zyMzM0qbkEeZ+fnLzfebRSD8/jjQI7dtg+J6ZZX1/ojwLj0lrfuwawTVMFEcwFO1DNqSRnK80uJe+01XJQUwiuYhNmTPN50ul4jq9SGadzFGrLvlzqTz7Qcif2a51D1o2xH3aCueq/W63u5Zdp3l1ZmGGn2b2aVZaLH9Oa133Kcq0M9t4RkwsW05z3jRrcGVlxbVPnTpVeJ5eL/xdV0SvRbMD9XPNCTQL512PGSbTUA2TxxfLORwkNg7tQ5+HWC6k0md1dXXVtfWZGubd96dPn3btXbt2ufarX/3q4Jj15+12u/b973+/8DwX27lqf35+fgtGA+BiOVftA5tpmP8tgc1F7QPVRO0D1UTtA+NhpN/027Nnj5mZHT9+3G0/fvz42mcAth9qH6gmah+oJmofqCZqH6gmah+oJmofKK+RLvpdffXVtmfPHrvzzjvXti0uLto3vvEN279//yhPBWCMUPtANVH7QDVR+0A1UftANVH7QDVR+0B5bfj1nqdPn7Yf/vCHa+2HHnrI7rvvPtu5c6ft27fP3vKWt9gf/MEf2DOf+Uy7+uqr7a1vfavt3bvXXvGKV4xy3AAuMmofqCZqH6gmah+oJmofqCZqH6gmah/Ynja86Petb33Lfu3Xfm2tfeutt5qZ2ete9zr70Ic+ZP/xP/5HW1past/6rd+ykydP2r/8l//SPve5zw2VX7ReK61b82cBaLEMpl4mmXWSg9ZelS8xJmEfaTo442GYBIjc/Hlz6bOv42r7cZuZdVd9Blcr8bdlYtbnfCXNMEusK5l9ieRpJZnm8QVdhMF40g5i8yKRZnJbrNP28x67l82m5qvJDjKntdh9k7Fo3Jpm+MUy/TK5V71Mr7/gJGbW7cn11v0+zbp/r/XUZPie60zuVV8z2uRZ7rbCL+yurjttZ3Bs2tAuVu0vLi6u5Z9p5p1ZmHunWS367vBYpl9R7p3m0cXyYIIMUGlrxl3sneaaabe4uOjamgsXmw/ttyifLzYfOlY9j/ap+XRm4ZzqtcXy+7QfHZvOaey+Fd0rPSbWh543Ns/rxX6P6X3QcbTbbdc+efJk0Ifeh6J8yquuuiro4yUvecnan1dWVuxjH/tYsM9GXazaBzBeqH2gmqh9oJqofaCaqH1ge0py/RvTLba4uGjz8/P26n93ozWbP1v0y8O/YF3p+b/I1sW1VkP+gj2y6NfpdWRLMqA1nFz+olcXkoZZ9Gvqot+E/GVyMxxZTxakdNHPdAErdtsT/ctz//Fwi356vf7a4ot++hfbsoMu+tWGWPQLurjwRb9M5zi2kCz71Or+YnTRL40syOmi30TLL3Lps9xu63NstiN/atGi0+nZh/6/O21hYcHm5ubCE46Js7X/hS98waanp80svviyY8cO19aFkdOnT7t2bJFrcnJy4FjO59fiuC766SLXMIt+2scwi356/bFFPlW06Kft2H3ZjEU/nVNdaI79HtNtnY6vS13008VYs40/y7H/kf2Nb3xj7c8rKyt28ODB0tQ+gNEqS+1vxThj/5gH2C7KUvsARovaB6qJ2geqqaj2R5rpBwAAAAAAAAAAAODiY9EPAAAAAAAAAAAAKLkNZ/pdLL1+35L+mVfvtPuRHCd5jWJdXgHZlVd3xt7ik8qaZ5DZFr7QMhyHdNyV19Utn5LXW4ZvYrQJeb3lxKR/hV9Sk4yuLJyPpGj5NtdMv8hr8uQ8Oh9n78fa55E3IOq2ROasloSv/NO3t3bltZqp5OKlkXdias6fnjeM4wsH39dXGspBOsVJZM080RxE6bPT86/4q+fhtbSa/tWC+npbfS1gFrmWU9lT+8Sel3HWarXWXls4OzsbfK6vONRXYA7zXnF99WJRdlrsedF9tA/9inXsVWKa66bXUvTayXP1O6iP83m9Z+xVlKroFaCx8xbNoV5b7LWiOrbYPkXj0Nd36j76StDY6z31+vX1pvpK2djrT5eWlly76BWxsWu59tpr1/6srwcFgKridZ4AAAAAgKrgm34AAAAAAAAAAABAybHoBwAAAAAAAAAAAJQci34AAAAAAAAAAABAybHoBwAAAAAAAAAAAJRcfasHcC6r/b71+4mZmSVJHnzeqNUGHt/v9vyGPAn2SZJkYDvXduQ8nW7ftRdPtl07802bnW4GfbQm/G3oy/XmlvkDIvORZbJNrldXd/M07COXK0wzmR/pM7FwTlM5Ua3lN2R55LyyLc/99QZHRG5ELRm8ft3NtM/i66+l/r5MTLRcu5/LzTWzrO+fhzT1c9Tt+eey15d7a2Ytmdd63T/rq+32wLaZ2cq6Z0TPOe5mZ2dtdnbWzMJnw8ysHbne9YI6jvShejJHjUbDtVN9sM2s2fS1vGPHjoF9PPbYY0Ef3W7XtaenpwvPW0SvX/uo18Nf+7pPp9MZOM4sC5/bvjz7Oo5hzqtzqp/rOMyKn4eJiYnCcehY9fpOnz7t2npvY9v0mdJr07aZ2dLSkmvr9c7MzLi2Pi9mZnNzc2t/PnXqVPA5AAAAAAAAgO2Lb/oBAAAAAAAAAAAAJceiHwAAAAAAAAAAAFByLPoBAAAAAAAAAAAAJTe2mX71JLX62Zy2NJLHJ1lPmtulh8Ty5zSVKtVcJ8mwW14Js9HaSz5zKe35cU1O+ymuT4XrrP1UM/tkrEEgX9CFaaRfojlm0kc4G2aJZvhl/iCdn1qsF9mU6WBjmX5yUDPxGXZ6nprOj4V5fLHswGKSLSjZifWmH1cjDzO5Vtsrfp+GP6bZ8M9DmkTyxVJ97nyf3Z5/5mKXuj6PMove7fG1urq6lrtWi2R3aq1rHlss903F+h1kamoq2KaZbJqDt7y8XNiv9qHjGmacev2aJaf5dLE8Ph17UaZfbI6131bLZ2DG8gn1+rTf1dXVwvNqH5rZp5/rfMXGpteic6rt2Hk0a1CfB81AjJ33bLblWZpPGLuW9dcfyx4EAAAAAAAAsH3xTT8AAAAAAAAAAACg5Fj0AwAAAAAAAAAAAEqORT8AAAAAAAAAAACg5MY206+R1Kzxs2y3Xh7JPupLLpXkfNUSyfyLnEPzkLTL1WW/od8Oe2nVfGZSQzP7GpI1l4Z91CTDLdEYvODyI5lU2q1syKWdZpGcxFwz/AZn+sVo3prmzeWRLvT6a7IWrYcEOYFm1tecN/lchx6N/Av28flhWd9ndE21fL6WmVma+Gcmz3272/Mn7pvPTjMzy3t+IO2230fHHs19WzeFef988g23zunTp9eeo5mZmeBzzWxTmrcWy5LTPvR3gWbtxfLXFhcXB/ah54jlq2m96Hn08/Oh1x/LoyvK7BsmF3CY7DylY9EMP52P2BzqvSqa09jzUHTv9Nr03g9zHu0z9hzreSYnJwf2GbuX67fpfAJAFQzz3x8AAAAAALYrvukHAAAAAAAAAAAAlByLfgAAAAAAAAAAAEDJsegHAAAAAAAAAAAAlNzYZvqlaWLpz7Le6nm4NtmXoDvNdDPJiYvE4JlJHNLKKd9nPfP5UbMzYZ5UN/XHaP5gELUXyRnRDD/pMugjlvKVmmYYSuZWNjhrzyycoqIMvzwykkw61na9FslX020y9G7Wl49jMyDbivJcIh8X5f5lktnV1xDIyDErHZ8D2G6HGVwqTf1zlmgG2RBRNd3uU2Pr9cqV6be8vDwwj2dqasq1JyZ8tqIeG8vF63R8TqLmwp08edK1221/H83M5ufnXbvVarm2ZrzFrkmz8TSDLZY/VySWe7dRsQzD9WI5knpezazTOY9t0/mYnp52bb1PsWPUKLKd9D7Erl/30edDn9PYHBfNu15LbBzrt8XmCwC2GzL8AAAAAAB4Ct/0AwAAAAAAAAAAAEqORT8AAAAAAAAAAACg5Fj0AwAAAAAAAAAAAEqORT8AAAAAAAAAAACg5OpbPYBzSRKzNDnz51oSWZvMMtfsJ/7jvvkNvdU86KK/4vuo92uuPT3tpydpRfro+m1p6s+byDj6WdhHlvtteeLbiVxbkofzkWu3uYxD2jG6i45LZRZ+rlsSnQ+9GDPr5/4+6HkzmY88cl7dpH0Ep00ifeg+fljW7vRcu9tfDvuwvmv1+l0Zlz9JGnm2c5kPk31yWavvdWR/M+ssPbWt1w0/H2fdbtc6nY6ZmfV6veDzNPXXPzEx4dr1uq/bPPIcr66uuvbKyoprt9vtgX3Gtp0d87nExqH1oNeix3S7/nmK9aHH6LhiNahzWjSHjUajsI9MfkdrO9ZPUVvPEdtWNI6YWs3/7tc5mp6edu1ms1nYh95L/Tym3+8P/LxonKrocwAAAAAAAADbC9/0AwAAAAAAAAAAAEqORT8AAAAAAAAAAACg5Fj0AwAAAAAAAAAAAEpubDP90iSx9Gd5REHGmYUZbZqtd/q0z75K++H65vSEz2VqTPu8pF7i88R6nUi+WDI4s06j42Ixef2CDLs0yOcL+9BQO83wq0lgXSziTzP6NGsvOCSaDTb4vP1+eC/7Ep53PjFUwZTUhsgBLDQ4j7Gfx/LmtAfJhdTHMLLsnsjGTAIru20/X3k3vLaZ9KkstG66vXO9NMNtZmbGtZeWloJjlpd9HqNmx2kfsQw3zRvUPLZhMu00K07HodmDsVxAzd/TcQyT6ddqtQa2deyxceh8aP5gLAdwcnJy4HmKMu7MwuvX8+hYY/ehKBdRs/RiGY96/TrvOqfDZCsG/z2RduzZfuihhwZ+DgBlR14pAAAAAADnxjf9AAAAAAAAAAAAgJJj0Q8AAAAAAAAAAAAouQ0t+t1+++32/Oc/32ZnZ+3yyy+3V7ziFXbkyBG3z+rqqh08eNB27dplMzMzdvPNN9vx48dHOmgAFxe1D1QTtQ9UE7UPVBO1D1QTtQ9UE7UPbF9JHgtnOod//a//tb3mNa+x5z//+dbr9ew//+f/bA888IB973vfW8umeuMb32if+cxn7EMf+pDNz8/bLbfcYmma2le/+tWhzrG4uGjz8/P2b//dAWs2z+QmxbLTllbarr1w0ucn5X2fuTQ/OxH0MTnjs580w67b85lUWRJmQQWZfplvp5qlF8mW0/OqIBcwEmWi50m0rZlVkfNkkq2nY9U+60FAXZhZqDmBsetPCs6jx8TGnssk5am0dWBDPPU6juCcxV2EuTPaZeQU+ji0l/yGtOsP2tEK8+ammk89251uz+742N/ZwsKCzc3NFY455mLW/qc//em1PjXzzSzMwdu9e7dra6bbY489FvShWWea2TY1NeXaw2T6aVvz+PQcZmYTE/73kj6n2tbMN7Mwo06z5LSPWBaSXp+eR8/Rbvvfv7F+Nfcudv06Np1DPSZ2/Xq/Y9mBg85pFo69KI8xlulXdJ6i+Ykdo9f/xBNPuPaXv/zloI8HH3xw7c/tdtve+c53lqb2AYwWtQ9UE7UPVBO1D1QTtQ9UU1Htb2jRT/30pz+1yy+/3A4dOmS/8iu/YgsLC3bZZZfZHXfcYa961avMzOwHP/iB/cIv/IIdPnzYbrjhhsI+WfQLsejHot96W7Hopzaz9ln0O3ebRT8W/da7GIt+ajNrH8BoUftANVH7QDVR+0A1UftANRXV/gVl+i0sLJiZ2c6dO83M7N5777Vut2sHDhxY2+eaa66xffv22eHDh6N9tNttW1xcdD8Axhu1D1QTtQ9UE7UPVBO1D1QTtQ9UE7UPbB/nveiXZZm95S1vsV/+5V+2a6+91szMjh07Zs1m03bs2OH23b17tx07dizaz+23327z8/NrP1ddddX5DgnARUDtA9VE7QPVRO0D1UTtA9VE7QPVRO0D20vxO8rO4eDBg/bAAw/YV77ylQsawG233Wa33nrrWntxcdGuuuoq62U9O/s2zdMrneC4xSf9q/Pynn912twO/4q32mT4SruVvn99Z6qviAza4fj1xZz6Kso0aId0m54nPG/sFZnyOk99zeYQb3ENxi4Dq8nrPGNd9qUPPW8amcNg7MG4vFgfuRyV9Qs6iSl49WYSewD0NHqe4I2Gvo/2ajiwvOu3tXLfydyEf7anm2EZ99Zf/+C3x27YZtf+zMyMzczMmNlT/7poPf0fG/qaxLP/Mums2GsltV99Jaa+RjL2KsaiffS8eo7YNu2j6FWVZuErMft9//BrH7FXZOqrJ7WPYV5V2mq1Bp5HX5FpFo696G3TsT66Xf97fJjXmaqiffS8Om6zcE6KriU2hzrvDz/8sGvffffdrv3Nb35z4Dl0bi7UZtc+gPFE7QPVRO0D1UTtA9VE7QPby3kt+t1yyy326U9/2u6++2678sor17bv2bPHOp2OnTx50v3F/PHjx23Pnj3RvlqtVvCXxQDGE7UPVBO1D1QTtQ9UE7UPVBO1D1QTtQ9sPxt6vWee53bLLbfYxz/+cfviF79oV199tfv8+uuvt0ajYXfeeefatiNHjtjDDz9s+/fvH82IAVx01D5QTdQ+UE3UPlBN1D5QTdQ+UE3UPrB9beibfgcPHrQ77rjD/vqv/9pmZ2fX3t87Pz9vk5OTNj8/b294wxvs1ltvtZ07d9rc3Jy96U1vsv3799sNN9ywKRcAYPNR+0A1UftANVH7QDVR+0A1UftANVH7wPa1oUW/97///WZm9qu/+qtu+wc/+EH79//+35uZ2bve9S5L09Ruvvlma7fbdtNNN9n73ve+kQwWwNag9oFqovaBaqL2gWqi9oFqovaBaqL2ge0ryfM83+pBrLe4uGjz8/N248v2W71xZk2yvdoN9qsliWu3ppuu3Zz0by5NIlfZl225+Q155j9PpB2T+2EF70+NvU810/OmcqJUOo2MI838PokMRA9JZf7MzFIZXGrSh0xiNzYQHYe2LXIjdChyHr2WYH8L713sNO7jWB8FpZDETix0RjLpstuTe90O+5ipNVz7kkn/bDdkGJ1OP+ij03tqJN1uzz766btsYWHB5ubm4gMfA2dr/7777rPZ2VkzM5uZmQn2S+TZ7ff99a+srLh2ux1OcqPh5ziVh1/PEXs2dJ9areba3a7/vdXpdArHoe8913HptZqF16fnrdeL/21Hr9cb2NZrO3t/BtFxDfOfGp1TFetD5+h8zlE0RzofsT70Xmqf2l5dXQ36+N73vufad999t2sfOXLEtYvmtNvt2ic/+cnS1D6A0aL2gWqi9oFqovaBaqL2gWoqqv2N/W0pAAAAAAAAAAAAgLHDoh8AAAAAAAAAAABQciz6AQAAAAAAAAAAACVXHPa0RbrLmeX1M7lkM1ON4PP6lM+YqjVk/XKYqEKJZeprlJ7sEIub0sw2XUWtaRxfdFwFnUg7li2o3ep5EhlIvRau99akj17mT9TLfZ5Y7Eo0O7E4BS+m4KjoiQe3hxpH0SOjUxbptNvxc9ZZ9e2m+ed2rjkR9DEvuW51OY9mtvWz8IFIzvHnMpicnLTJyUkzM3vssceCzzVPTduaJad5bGZhdp62VayPZrM5cB/NbIvlxhVl2KlhsgX1WvQYzTw0C/MG9drO3o9zndMsPkfrZZHnVLMClWYYDpPfdz4xtUWZfXre2Lh1jnSf48ePu/a9994b9PGVr3zFtR9++OGB4yp6pmJzDgAAAAAAAGD74pt+AAAAAAAAAAAAQMmx6AcAAAAAAAAAAACUHIt+AAAAAAAAAAAAQMmNbabfjrkJazTODC+dCDOadEtD1i81yahvoabkI/UlkK6f+KOySOhbnkm+WNF5YxFeuR97okGBetpYpp9ukOXcRuLzpdI8HEhX8rO6mgclh6SRXK9gqKlkC0bOqwdpLmB4SHFmlx6SyzE6xcPQPrq9sJPVJT+HzczP+/yUz0qbimRy5TI4vQ/9YPDhnLrsr6Rca/vHjx+3paUlMwvz+WLO7nuW5q/F8vo0107z2Kamply70QhzRTWzTfPn9LyxHDzNnxtFLp72uby87NqxOdWxTk9PDxyH5hXGxlGUeWgWzpkaJktPr1fb2oeOK3aM0uy8WB+67Sc/+Ylr33XXXa79ne98J+jjkUce2dA4ip6p88k3BAAAAAAAAFBe5VoNAAAAAAAAAAAAABBg0Q8AAAAAAAAAAAAoORb9AAAAAAAAAAAAgJIb20y/+kRq9eaZNck8j+RYxbLx1h8vOU4NC7OgNDuum/rMKc3r00y32Dg0sy7TfKnIOmvQq2S2aXZepgM3s5oMpJFK3ljPz+FqP5IdFuQ/SVaWXmtkHEk0tPDcfZ45rVxf0KmOI3weUtNsxcHjiEULajxWv+/P216RjMdO2MdU4rPfZid8uynZir1umGnWl+vTZ0wj/WL5hLV1FxPLXhxny8vLa1llsRw43aa5cNpeXFwM+tB9LrnkEtfW7DjNhYuNQ/P2ijL/zMJMNm3rOTTTzSzMbdOMQx3H/Pz8hscRO68qyueL5cvpeYbJ31M67zpnRdc2zDg08zH2XD7wwAOufejQIdc+cuSIay8sLAR96Hl1XMNk9JHpBwAAAAAAAFQX3/QDAAAAAAAAAAAASo5FPwAAAAAAAAAAAKDkWPQDAAAAAAAAAAAASo5FPwAAAAAAAAAAAKDk6ls9gHPJ8tyyPDczs1oSrk3mlsuWxLUaqb+0NLK+2cszf0xeG9CjWSezgI4ilw01Oa/2aWaWyMZc9tJj6ml4Lbopz/xA2lnftft5eDF1nSM5cSbH5Hl4NWnsAt0x0a2+FfSRD2yamWWyMdE5lElOddLNrNf117e64tupTNm0NYI+Zuot127W/Zxmfd9JFpuQoudBPtdrM/NzGLlNpdHr9YJttVptYPvxxx937eXl5aCPiYkJ137iiSdcO8v8fdq1a1fQR70++Ndnt9t17Tz+8Duxe7lep9MJtulY1fz8vGs3m81gn5WVlQ2NI/Z5v98f2E4jv7f03hXNaYz2G7u+9WLPlJ5Xn4+TJ0+69v333x/08bnPfc61f/CDH7j27Oysazca4e8PvRa9t0X3WvuIzTkAAAAAAACA7Yu/EQQAAAAAAAAAAABKjkU/AAAAAAAAAAAAoORY9AMAAAAAAAAAAABKbmwz/eppupZdF8/B8+uVQe6fxsBFOmlKnpRlvo96kCUYdrIq+VBh0uDg7MGYmuQwaf5clvusLDOztuTR9bLB+WGaNWhWnE+Y6CRGc7/8Ns1eDLMYzXKNEgwGou3IecOgO2n6dr8bjmPltJ/Dugzs0kmfFZbqwM2s39dsQa9e81va3fBeBtcb5HIV5xP6eS7Okhsn7XZ7LWNNc+Fi29rttmsPk/GmOX+alXfq1CnXjuXx7dmzx7U1n07HGesjeC7lGM0FjGXeTU9Pu7bm0SmdL7Nwzoqy5WK5eEV96vyYFWf46XliGXU6h0XZibHPdRzHjx937b/5m79x7cOHDwd9LCwsuPbU1JRrD5NfqGMbJhdRrT/PMBmAAAAAAAAAALYPvukHAAAAAAAAAAAAlByLfgAAAAAAAAAAAEDJsegHAAAAAAAAAAAAlNzYZvpleWZZfiaPqFVrBJ83Uz90TWnq5T7LKJZ7Vk98xlKWSv6RNCfScBxZ6s/clgymTEaWRuLo0qJ8Qumj2w9zmnqSBRXE78n+WSTXSvOkwvw930stkq0X9Kq7DBHHF45rcDverd/S85Ft1m+HnUzJ/Z1p+GespTlnkXHk8txpuyYPQKtevO6u+ZV63tj8rT8mGyIHbJxMTk7a5OSkmZn99Kc/DT5fWlpybc10a7Varh3LcNNMP6VZaj/5yU+CffQ8l1xyiWtrlmAsB08z+zRbUMd+dl4GjUPnQ8Wy9Yry5nQcOu6YonGYbTxzbpg+i46J3Ycf/vCHrv3Nb37Ttf/u7/7OtWPjnp2dHTgOncNYtmJRHuEw17/+2Y1lYgIAAAAAAADYvsq1GgAAAAAAAAAAAAAgwKIfAAAAAAAAAAAAUHIs+gEAAAAAAAAAAAAlx6IfAAAAAAAAAAAAUHL1rR7AubT7ZlnvzJ+bkVH289y1M/m8niauHVvd7Gb9gWNIE39Uo5YH+0zktYF96jjTNBxJLfFj7Wf+avq57zMxv7+ZWV37yH0fmflxhD2Y1Wv+WpKaH6tciuV9nXUzk/PoMbHzytAt152CdtiL3sp+148t7/rPJ9PwoZqdaLh2TT7vRq938ND6cozeuzSNzYinu6TSRx6Z1fW3Lise9liZnZ21mZkZMzM7depU8Hm3629ms9l07dXVVdfudDpBH2f7P6vf9w9Qu9127dg4Hn30Udeenp4e2NZzmIXXUq/757LR8M9kFrmZer06H9qO9bG8vBxsGyTXwo6IXa/SsSRSQDX9nRSpfaXH6L08cuRIcMzdd9/t2t///vddu+i+xBTNUexadOw6P9pn7Bzrn3d9vgAAAAAAAABsb3zTDwAAAAAAAAAAACg5Fv0AAAAAAAAAAACAktvQot/73/9+e85znmNzc3M2Nzdn+/fvt89+9rNrn6+urtrBgwdt165dNjMzYzfffLMdP3585IMGcHFR+0A1UftANVH7QDVR+0A1UftANVH7wPaV5MOEM/3Mpz71KavVavbMZz7T8jy3D3/4w/aOd7zDvvOd79gv/uIv2hvf+Eb7zGc+Yx/60Idsfn7ebrnlFkvT1L761a8OPaDFxUWbn5+3l77yV63ROJOjlEbikxp1yduTrLxJzYKKnKuX+UuvJf6YpvSR52EWVq/fc+12z7d7QbZeSLPiinLw0limXZBxqAF8cq21SKbdjM8g09yqbtdno62srgR9tNv++msSSJdF5jCTWUnkmFyut9MNH9n2qvTR9/s0M38v5xs+58zMbKrl5yST50Pvk+b1mYX5e3r9wcgjD2aQ4VeQcxbLBVyf+9fpdu2DH/1bW1hYsLm5ufCEQ7iYtX/PPfesZe7Ffj1p/pzm7T355JOurZl3ZuGzrX0uLCy4dix/bWpqyrV37drl2jt37nTtycnJoI+JiYlg23qaixfLydNr0fy5oj7NzB577DHX1hzEVqvl2pqJaBZen+bJ6XMb61fptcTmSzMLV1b876Xvfve7rv2JT3wi6OOHP/zhwLHqvY5ls2r+nl6/zlnseSjKo+zJf19i93L99fd6PTt06FBpah/AaFH7QDVR+0A1UftANVH7QDUV1f6GFv1idu7cae94xzvsVa96lV122WV2xx132Kte9SozM/vBD35gv/ALv2CHDx+2G264IXp8u922dru91l5cXLSrrrqKRb91WPRj0c/1uQWLfjGbVfss+j2FRT8W/dbbikW/mM2qfQCjRe0D1UTtA9VE7QPVRO0D1VRU++ed6dfv9+0jH/mILS0t2f79++3ee++1brdrBw4cWNvnmmuusX379tnhw4fP2c/tt99u8/Pzaz/8IgDGG7UPVBO1D1QTtQ9UE7UPVBO1D1QTtQ9sLxte9Lv//vttZmbGWq2W/fZv/7Z9/OMft2c/+9l27NgxazabtmPHDrf/7t277dixY+fs77bbbrOFhYW1n6NHj274IgBsPmofqCZqH6gmah+oJmofqCZqH6gmah/Ynga/By7iWc96lt133322sLBgH/vYx+x1r3udHTp06LwH0Gq1oq94q+VnfszMVtuRV0LKayLrTX8pHTmkFnk9Xy1Jpa3nyAe2zcwaqX8NXKPp+1zu+9ezner4V76Zha8Z1dc5pqavyAzHoVv0GL38yBshrS6vtNO38XW7/tVyWR6+Wi6XV3XWG/51fLFXpHZ6bdeW6bBVeXXn6mp43iT3FzQjrwWckle31iLv1dTXeYbzLPcpMon1mr//ei+Heab0nZ+6S19eXRp79WS+bqwX+AbfNRer9k+fPr32Z31lpln4Osv1rw0wM5ueHvyaWj2HWfgqxmFe56ivFdVx6KsoL7nkkqAPvX4dh77OUV9lGRtb0StB9TWUwxyjYq8Q1XnW12wO82pSvT6dw9hrRbXfhx56yLXvuOMO1479D87Z2VnX1jnVGorNYWzbenovY6+d1W163litq/VzOsz+w7hYtQ9gvFD7QDVR+0A1UftANVH7wPa04UW/ZrNpz3jGM8zM7Prrr7d77rnH/uiP/she/epXW6fTsZMnT7p/BXD8+HHbs2fPyAYMYGtQ+0A1UftANVH7QDVR+0A1UftANVH7wPZ03pl+Z2VZZu12266//nprNBp25513rn125MgRe/jhh23//v0XehoAY4baB6qJ2geqidoHqonaB6qJ2geqidoHtocNfdPvtttus5e+9KW2b98+O3XqlN1xxx1211132ec//3mbn5+3N7zhDXbrrbfazp07bW5uzt70pjfZ/v377YYbbtis8QO4CKh9oJqofaCaqH2gmqh9oJqofaCaqH1g+9rQot+JEyfsN37jN+zRRx+1+fl5e85znmOf//zn7SUveYmZmb3rXe+yNE3t5ptvtna7bTfddJO9733vO7+BNRKrN87kETXakcyyjmQs1XyeUq5ZapFzaCSb5if1JbMuloOXSy6gHrOS+XYvkmkXyxtcL9PEvmgM3OAMv0S+1JllYb7WwulFf0zqT9Tt+syyXj+SLSjZem3JKEsik6jdrK767KuVFT/WRhI+tnMtnwU2lfp96pEMv2AcksmleXvag+b3mRVnaOkxml9oFmYL5qY5gH6cSSR+LV83z/0RZPpdzNpfWlpa+3MsS09z3nQfzZuLZRrqMTUJsCzKyYuNY+fOna592WWXufbk5GTQh+YAai5cLDtP6TGaHafXH+vz0ksvHXgOvdbY+9l1zubm5lw7Noea4afZeprPePLkyaCPI0eOuPaXvvQl137kkUcG9mkWjl3rWOcw9kzpMTrPmnEYy/QrenZ1nLG8yvXPcqx+Nupi1j6A8UHtA9VE7QPVRO0D1UTtA9tXksf+9nILLS4u2vz8vL3i3/6aNRpn/gK03Q4XyvLED3tqUv4ytC5/iR9ZjKknfp+aDV4ojC361YJFP/8X7guyULba9Z+bmdVy7bhggWqIRT8dayJ95pFl0FTmbBSLfvWa/0v92KJfr+8XBldXZeH0Ii366cQWLfrVIn+hXrTol8r1D7Pop+PSRcB6ZBzrz9Ppdu3P/+rvbGFhIViIGSdna//Tn/702sJMbLy6ALW46Berl5eXXbsrC89mZgsLCwOPGWbRT/vVRb+nP/3prj0/Px/0UbTodz7OZ9Gv6Lzns+in1xabQ+1nMxb9vva1r7m2XotZOCdFi37nQ5+X2O+KjS76xay/l91u1/7mb/6mNLUPYLSofaCaqH2gmqh9oJqofaCaimr/wr8GAAAAAAAAAAAAAGBLsegHAAAAAAAAAAAAlByLfgAAAAAAAAAAAEDJheFO4yI1s59FzLVaYfZRv+fXKztdyVxKfEbVRCTHKgjHk9PUNdcpEtfWlQy/bia5VZoLF8lx0oy2cI8NZv5F6DliEVWdjs+cysxfi2bNZbEJEVkufUZO3Fn19yqTrMDZhr93s/UwT6yVDs7CynJ/Ds04NDOrS96e5u/p4xJ8bmb9TOdZzisZkPXU5yiamXXlmF4s+G/AOX92orU/Fhw+dmq1mtVqZ+ZFs/bMwqy4ZtPnOU5OTrp2rI+iDDfNn4vlwGmGn+bPBc9gJDevKKNtmIy/orw5PUfsd1BRZp/O1zDZco1GY8P7nL3vZ/3oRz9y7cOHDwd93H333a69srLi2pdddplrLy0tBX1o3p6Oo+j5MCt+prTPYeh90XnvdDrBMeufh6KMUQAAAAAAAADbC9/0AwAAAAAAAAAAAEqORT8AAAAAAAAAAACg5Fj0AwAAAAAAAAAAAEpubDP9sjxby2Gr1yIpd7JpeVVyraQ5EYmXqtf8mmdT8tX65vO02pEcJ82K06irluQ4RTPt+po35/dJZW02muAl+Xqa45YnmjUX68X3UU/8pGXSRycP88ZyyVLsy7Vpfp+ZWS3z17dDMtpm65L7FVmr1vsQXJ62I1FXafCcSY6X5Ktp+8w4/IkaMvZG3Y89izxTOorgauXhTyO5Xeu3xT4fZ0mSrGWRadaamVmv53M0Z2ZmXFtzz2LZcqdOnXJtzQmcn58f2D47zvV0rAsLC66tmW9mZrOzs66tWXGx61ea+6fn0Sy52DjU6dOnBx6jc24WZivqfYjlAOocffe733XtO++807Xvu+++wvNqpqM+L7HnQcemxwyTYaiKMg1jeY36TOnvac3wiz0f6/vV6wAAAAAAAACwvfFNPwAAAAAAAAAAAKDkWPQDAAAAAAAAAAAASo5FPwAAAAAAAAAAAKDkxjbTL80TS3+WU9eP5M/1c599JXF8ZpnPU+r2wj7SVDPaJD8p83lIvUj+WioJbBqflkmYXD0N89X6MrSejCPI+Bsio02nLNdQu1gOnF6LpsvVJL8wEozX9ZFT1l71c9ZM9EaZ7Zqacu1JuZm5ZF/lFsvC8m1dzc6TwffJLMxB1FuVyQ69fjiOiQlfUrNzPrNNb8PqylLQR0OuP5HnLpdxpJFnan0WWDy/cXx1Op21PDTNozMzm56edm3NQdPcM818MzO75JJLBrY1sy6Wg6d5aTrPOq7V1dWgj1arNbCtGX+xjDY9r87ZMHl0RdmBev2xZ0rHqsecOHEiOObQoUOu/bGPfcy1V1ZWXPvSSy8N+tB51qw8/VxzFM3C6z958mSwz3qxOdXz6D56b4fJayzK8IvlAsZqBgAAAAAAAEA18E0/AAAAAAAAAAAAoORY9AMAAAAAAAAAAABKjkU/AAAAAAAAAAAAoOTGNtOvkdbWss00F8/Mgmy0RGK7so7POlo6HWYfLbd8J3ldsuNyzZKL5AIGOXiyjpoUZ/o1JIMpyKzTrLmgh/A8mk8XnDUW8yZ99CTzsNuV9mo4p/2uz/WarvlHbL7pc63MzKbk+jVLsFeQ12dmVpP8LL08jSCL5USa3G9L9EyS2RXJBWzW/TGp3EvNAYxmg+l8yHk6kusViRbc0OfjZmFhYS27bHJyMvhcM8uKMt00n8/M7IorrnBtzf0ryuczCzPs9Lw6Ts2nMzNbWvKZjnoe7aPdbgd9FI1Vn7FYLuDZDMWzdN61j9hzq9v+7//9v6791a9+NThGt+m1aIbfMFmCReOKzWEsG28jfcb60HnWexnL3tNrKcprjPWxfmxly/MEAAAAAAAAcGH4ph8AAAAAAAAAAABQciz6AQAAAAAAAAAAACXHoh8AAAAAAAAAAABQciz6AQAAAAAAAAAAACVX3+oBnEuSJJYmiZmZ1dJwbTLr565ds8S105bff2mpG/SxupK59uS076Nek/3lnGZmXfN9pLns47u0PJENZjaV+BM15Xq7mT9HJueMyfS8Mq5YD0ndH9Tt+b2WTvd8H92wl6mWf6R2NCdce0Ku1cys2/f91OX69f4nkdGnOq0F15/m4X3o672TZl1OkqfhtZjcq9WlJflYn49wHEna9235vCbj6EWey/WXotc+7rrdrnW7Z+o1NvZms+nay8vLA/vbuXNnsG16etq1O52Oa7fbbdeem5sL+mi1/C8ZPSbV5zZyr0+fPu3aS/K8zM7ODjynmVkmz1yt5p9LHYd+bhbOqZ5ncnJy4P5mZg8//LBrf/KTn3Ttr33ta8Ex8/Pzrq33pdfzv3Ni9PqLLC4uBtv03sTu1UadfYbP1T6fc+gxem+L9gcAAAAAAACwvfFNPwAAAAAAAAAAAKDkWPQDAAAAAAAAAAAASo5FPwAAAAAAAAAAAKDkxjbTz2xdpJrmoFm4WllLJD+rJpl/rbCPelsy/DKfdVWX2elamC/Vzn3+Wm6+rdlx9SyyzioRW0FmW67tSKZdsGVwRlUjCY/o9fwcdZf8eRp938dEK8z1mq43/DFycb3IvexpJpdm6dWKs9EyyX7TPYJsuEjUVSobdVypnLcWuZU6DsvkmdGxa/iihRl9mmkYZlyGz0O27pmpRc4xzlqt1lqm3DB5hJr7NjU1FfSnNAdQ25oTp32ame3YscO1NfdO+9DcwBjdR/uYmPAZmWbh9RfNmWYPxmhWnGYPPvnkk8ExX/3qV13729/+tmtrfp9ZmA2o19Lv9we2Y4LfdQ3/Oyk2P3pePUbFxlGUnzfM2GN5i+sF2ayRPMP14yhbnicAAAAAAACAC8M3/QAAAAAAAAAAAICSY9EPAAAAAAAAAAAAKDkW/QAAAAAAAAAAAICSG9tMvyzP1/LRYlFJmq/Wy3xeUley9rLIldYlo67X9vlHuZwjjeQtJT3J7ZJ8tUQC6lp5uM4aibnz55XrTyP7Z5L7F2QcyvpuPxIv1m/7OZvs+UmbaPrrn6iH86FZYHqf+mEElaWaL6g3XGPwIoF8OquJ7JNr9mIk6yqtyRxKH5ncqDyWlaeXojcv2CHsIpFMP80J1OzBJJLPmK577oIhjLn1mX6xnDTddskll7j27Oysa2vWnllxdp5mq8Xy2PQZmpmZGXjMwsJC0EdQL9LudruuHcua07HqtWkfeg4zs6WlJdd+4IEHXPvrX/+6a//DP/xD0MfKyopra5ZiLK9umJy79Ypy82L0PsX62Gj2XWzcen1F+XzDXHtRhl/sHOuv73zmCwAAAAAAAEB58U0/AAAAAAAAAAAAoORY9AMAAAAAAAAAAABK7oIW/d7+9rdbkiT2lre8ZW3b6uqqHTx40Hbt2mUzMzN288032/Hjxy90nADGCLUPVBO1D1QTtQ9UE7UPVBO1D1QTtQ9sH+ed6XfPPffYBz7wAXvOc57jtv/O7/yOfeYzn7GPfvSjNj8/b7fccou98pWvtK9+9asb6j9NE6v9LIysk0fytCRfrS+ZflkiOU6R5c2k4ffpdX27u+QPqk+F+UiTkqnUyCQ7zyIhdqKvmVPyeU3WZmPX0pFIqnrib23fx3pZu90L+piQsU/WB+fzxQLpdItmUtUjeWK5hhTKeeqStdfthXMqMXhWkyc7rfnzaj6fmZmcxmp1Pa//PLdYDliYLjhYJJ8w9c+UnkeHHs8jy9d9XjCEDdrs2l9v165dwTbNpKvX6wM/j+Y3yj6aP6d9xvrQjL7V1VXXLsp0i51Xz6N9xnLg5ufnXVsz/ZaXl117eno66EMz/D75yU+69k9/+lPXnpiYCPpoNpuurdev1xLbJ5Y3OGh/s3DOdI7a7bZrx3IRlc6hnjeWlad5e+eTp1eU86fPZewc6zMcNc/xQl3M2gcwPqh9oJqofaCaqH2gmqh9YHs5r2/6nT592l772tfaf/tv/80uueSSte0LCwv2Z3/2Z/bOd77TXvziF9v1119vH/zgB+1rX/uaff3rXx/ZoAFsDWofqCZqH6gmah+oJmofqCZqH6gmah/Yfs5r0e/gwYP267/+63bgwAG3/d5777Vut+u2X3PNNbZv3z47fPhwtK92u22Li4vuB8B4ovaBaqL2gWqi9oFqovaBaqL2gWqi9oHtZ8Ov9/zIRz5i3/72t+2ee+4JPjt27Jg1m03bsWOH27579247duxYtL/bb7/dfv/3f3+jwwBwkVH7QDVR+0A1UftANVH7QDVR+0A1UfvA9rShb/odPXrU3vzmN9v//J//M5rpdD5uu+02W1hYWPs5evToSPoFMDrUPlBN1D5QTdQ+UE3UPlBN1D5QTdQ+sH1t6Jt+9957r504ccKe+9znrm3r9/t299132x//8R/b5z//eet0Onby5En3rwCOHz9ue/bsifbZarWs1WoF2/MktyzJzcys18/CA/N88GDl4zwL90/SxLXTCd/ur/hj8q7/3MysVfdTOFH3x/RzP/YsMu6gV90g7TS2Vtv15+l1/XmSrt992mpBF5MNv02HoWPPI9fS6/ttaeLHmgzxxIXn9e34nU9kHzlvImO38JnqyYkaNd9Ho+7P0Y08lz2Zk3ouz5g8c0WPsZlZItem96GfheNYv09snBt1MWu/1Wqt/Y+N2P/oyCLXu16ShHWq0lTubaPh2nWp625XCsjMHn/8cdfu9XqurddWq4U1p3Ts2u73+8ExOrbV1VXX1v+B9cgjjwR93HXXXa69tLTk2vqvumKK7svU1FThMXp9Omexc+gxeh9U7PeW3ivdR8+hz4tZ8b2K3Tul16fPqX4em4/18xx7bjfqYtY+gPFB7QPVRO0D1UTtA9VE7QPb14YW/W688Ua7//773bbXv/71ds0119h/+k//ya666iprNBp255132s0332xmZkeOHLGHH37Y9u/fP7pRA7ioqH2gmqh9oJqofaCaqH2gmqh9oJqofWD72tCi3+zsrF177bVu2/T0tO3atWtt+xve8Aa79dZbbefOnTY3N2dvetObbP/+/XbDDTeMbtQALipqH6gmah+oJmofqCZqH6gmah+oJmof2L42tOg3jHe9612WpqndfPPN1m637aabbrL3ve99oz4NgDFD7QPVRO0D1UTtA9VE7QPVRO0D1UTtA+WU5LGAoy20uLho8/Pz9orXvMgazTNrkrEcvKJ8ueCIJHKZEv2VSH5SLnFISS/M5Gq2JIOr5nObdJyxuLFU8+hkn54MvdMJs6H6q5JHJ2OdTP36brMeXouOLZjTYAoj+YQFmWRhgGHYjWbY5VY0jnDsaaLZecU5eBK3Z62mn6O6ZPzFsvK6Pb9NjwnHFXRROM992aGThc/D+mzBbrdn//uv77KFhQWbm5sLTzgmztb+F7/4RZuZmTGzeA5es9l0bc1X0xy0WMbfMLl/650+fTrYptl5Og49Ryx/TfPnNEtQ34M+OTkZ9NFut137+9//vmt/6Utfcu0f//jHQR86ZzrHoxDLZ9ScO70WncPYf646nY5ra47dMNemY9NxaZ+xTD/dptei93qYZ1DHoc/D7t27g2OuuOKKtT+vrq7a29/+9tLUPoDRovaBaqL2gWqi9oFqovaBaiqq/fScnwAAAAAAAAAAAAAoBRb9AAAAAAAAAAAAgJJj0Q8AAAAAAAAAAAAouXrxLlsjz/O1/KZ48pFm+A3OzosFFwaZdZq5JXFimr1nZiZRT0Ef9bpk3MXGIXmDmgO4fNr32fVRUWZmNp1qhp/k0WlgXYTuoXNWSwvy+iLH6IZoHl+wQe9L4RHBnAWZj8ER4Xp3ptl5cl69l/VI3lym1ytjzfLijLIsG5w/mKX+814a9tHvP7WtH336x1etVotm+Z2lGW3a1uy8WF9FuX/6+TDjmJqacm3NcNOMt9jYtD09PT1wnGZmDz74oGt/+tOfdu3jx4+7dizTruh69TmN5RMWzalmIMYUZfjFrl+z9AY9O2ZhbuIw9No0a28Ywzxj2q8+U09/+tNd+2lPe1rQx/p8wpWVlQ2PEwAAAAAAAEB58U0/AAAAAAAAAAAAoORY9AMAAAAAAAAAAABKjkU/AAAAAAAAAAAAoOTGN9MvyZ/KuhsiB64WyXpaTzPeor3oLpotl4Q5Tj3N9Ov4dn3ar6vmkbipbk8z+3w7l1im2Vp426Yk1yoJIrfkWqLheprZp5/r7pFMv4IsvdhdCPL3ZKfEhshF1GNkbMHzEVnuToI5knPInKaRnEQda0/y+fQckWg068uJ+nIzeybPhwYJmr/+gtIYO41GI8hpW09zz2L5chdK89bW56SdNWiMZuE4Y1lzmq+n1/LEE0+49ne/+92gj7vuusu1jx075tqTk5MDxzmMWK0rHXtRxl9MUd5eV0NUrTgXcZjnoyijT8eueY1m4fUWXUss43B+ft61r732Wtfes2ePa8eeqdgcAQAAAAAAAKgGvukHAAAAAAAAAAAAlByLfgAAAAAAAAAAAEDJsegHAAAAAAAAAAAAlByLfgAAAAAAAAAAAEDJ1bd6AMPIk3yInQY2LUnCQ7TbTLsMOon0Ufcbs7Zvd9qyfyO8lp7sU+/WXHum4dutenjb0tSft6dXI6dNY8u9iTZlg85XMEFmWcF9iNFu+tJOpJd6GvaaBjc46MQ3Iw+EXm8ufej1JnnYh94H6/v70On5dhZ7tv3ttr7s05cJSmMP5vpxxB7+MZYkSfT+DCuVhzvLtLLNcrmXdakp/bzRaAR96DG9Xs+1JyYmXLtWkxtrZqurq6595MgR177nnnsGfm5m1m77XyBzc3Ou3e12g2MulM6xWXyeN0rnWc/T7/eHGst6ei+HUfQMRX9/yDY9Rq9t9+7dQR9Pe9rTXHvv3r0D+4jd2/VjL5obAAAAAAAAANsLfyMIAAAAAAAAAAAAlByLfgAAAAAAAAAAAEDJsegHAAAAAAAAAAAAlNwYZ/rlNigRLvhE4+ckxynWk6YyxVLeivaotfy6aXCezE9xEkZSWa3nN04lkuHXKF6b1Yipeqr5Urp/LJNK2sEOvtmPRHhppp9m3IXZe2FWXqahfpJPGOsjyDSUPoaJ9dJnJpUINr22JNJpmCwo15b6a8lrkYHp9ck86/Xnkedy/dB03OMuz/O1exF7TmPZeOtp1t4w+XNFuW/DZLg1m03X1qy906dPB308/PDDrv2Xf/mXrv3II4+49vz8fNBHq9UaeF69/ti16rWMIgdvmD51m2bU6b2O9aFZinr/h8mHHEUuYKfTcW3NVty3b59r79mzJ+hDcyC1T800jGVNrp8znRsAAAAAAAAA2xvf9AMAAAAAAAAAAABKjkU/AAAAAAAAAAAAoORY9AMAAAAAAAAAAABKbowz/daJxZ4V7FKc4hRmPRX12R8ik6pe9+uojdxnUvWDvDqzLPM5TbnmE+r+sXwpyX2rScadaTtKc/A0xM73UYvlYCWSizfEMT3JV6vraa0gN9HM+hJcF+yjGY9DROlJfFaQA1ePXL5m+HUlwy9LZX6GeFKDKcv9hiwW2rfuPiRJuUL9kiQZmMOmz6Xuq7lnsb70XhYdo1lrZmHenOavHT9+3LVj+WrLy8uufeLECdfWDL/Jycmgj6JcPL22WH5d0Zwqnb/zPUa3aR/nk0kXO8+FHqP3WufUzGx2dta1r7vuOtfesWOHa+vzEhtH0ZwWZU0Ok2cIAAAAAAAAYPvgm34AAAAAAAAAAABAybHoBwAAAAAAAAAAAJQci34AAAAAAAAAAABAyY1tpl+Wnfk5F40q0uSiJCnOgQsy/GSnft8PoFYP85Em6w3Xznp+n07P52u1e5Fcq9xv68pAan1/m4K8Pgsi/TRaL5iv2Hzo9Wt2oK4QNyJPTyp5c0HWXh5ef02zFWt6jP88mmko9HrDZymSrSibNOdM271a2Ecuc5LV5MQ6x5E8vnSDa/Gx52F9r5qrOO5qtVqQobZe0X3RvLVhcuE0567Varl2u90OjnniiScGnnd6etq1NfPNzGxmZsa1n/WsZ7n2j370o4F9moW5beeTaadz2Gj432t6jth8BBmgQ9B5L8oWLMqwG2Ycw+Tc6RzqOPfu3Rscc/XVV7v2FVdcMbCP2H3SPMZmsznwmFgu4PraOZ9MRAAAAAAAAADlxTf9AAAAAAAAAAAAgJJj0Q8AAAAAAAAAAAAoORb9AAAAAAAAAAAAgJJj0Q8AAAAAAAAAAAAoufpWD+Cckp/9bOiA8/30jMxy115t9117zhrBMZPNmmsvZl3X7tU6rl1rhuusSeZH1+1l/pieH0dSD29bIt1m8rmeNZdrNTPLc78tTfy4GvUhZjHXfn07Cz43S2XwSTL4PLXIx5Fu5SS+2e2HB/T7Mmtynprc/iwykDzxfaRymlw61fs0FLnY+KWvO0++oUIqnSwbPIv6XJuFz1ij4W/uxMSEa584cSLo4/jx46591VVXufbOnTsHnjN2nv3797v24uKiay8vLwd9tFot107Twf+Wo2i+zMz6ff87R4+JXUth3dZqwTY9z8UQex66Xf97e25uzrX37Nnj2ldccUXQx44dO1x7aWnJtZvNpmvXI7/HV1ZWwgGvo89pbP7W3yu9LgAAAAAAAADbG9/0AwAAAAAAAAAAAEqORT8AAAAAAAAAAACg5Mbu9Z5nX73W7fYG7hd5uVzB58X68tq3noyhm4a9djr+9Wk67q7JdWThOmvW9f2mPT+OWhK8IzKQyNh0qNqOvRJSX3unb+vLc53jcD70zYE6pzH6GtHgBaFBF7FXkw4+Ryaf9yJvFSx6vWfwUsTIWxKD13sm+ipOeb1npI/UBs9HphcT9VQfZ5/J2GsNx8nZ8Z0+fXqo/c4axes99TWI2qe+qtEsfNWmjltfxRh7/aUeo6931HHFXteor/MsemVmbL6K5nSYV4KeDx2rzlFRO+Z8nvOieW632669uroa9KH3rtfzv/uLXpka61dfAap9xqyfo7P9laX2AYzWuNfWuI8PKKtxr61xHx9QVuNeW+M+PqCsxr22xn18QFkV1dbYLfqdOnXKzMw+/7+/vsUjAbaXU6dO2fz8/FYP45zO1v6LX/ziLR4JsL2UpfYBjBa1D1QTtQ9UE7UPVBO1D1RTUe0n+ZgtuWdZZo888ojleW779u2zo0eP2tzc3FYPa6DFxUW76qqrGOsIlWWcZuM/1jzP7dSpU7Z3797gW2HjhNrfXGUZa1nGaTb+Y6X2N8+43/v1yjLWsozTbPzHSu1vnnG/9+uVZaxlGafZ+I+V2t88437v1yvLWMsyTrPxHyu1v3nG/d6vV5axlmWcZuM/Vmp/84z7vV+vLGMtyzjNxn+sw9b+2H3TL01Tu/LKK21xcdHMzObm5sZygmMY6+iVZZxm4z3Wcf5XP2dR+xdHWcZalnGajfdYqf3NxVhHryzjNBvvsVL7m4uxjl5Zxmk23mOl9jcXYx29sozTbLzHSu1vLsY6emUZp9l4j5Xa31yMdfTKMk6z8R7rMLU/vv8UAAAAAAAAAAAAAMBQWPQDAAAAAAAAAAAASm5sF/1arZb93u/9nrVara0eSiHGOnplGadZucZaBmWaT8Y6emUZp1m5xloGZZpPxjp6ZRmnWbnGWgZlmk/GOnplGadZucZaBmWaT8Y6emUZp1m5xloGZZpPxjp6ZRmnWbnGWgZlmk/GOnplGadZucY6SJLneb7VgwAAAAAAAAAAAABw/sb2m34AAAAAAAAAAAAAhsOiHwAAAAAAAAAAAFByLPoBAAAAAAAAAAAAJceiHwAAAAAAAAAAAFByLPoBAAAAAAAAAAAAJTe2i37vfe977ed//udtYmLCXvjCF9o3v/nNrR6S3X333fayl73M9u7da0mS2Cc+8Qn3eZ7n9ra3vc2uuOIKm5yctAMHDtiDDz540cd5++232/Of/3ybnZ21yy+/3F7xilfYkSNH3D6rq6t28OBB27Vrl83MzNjNN99sx48fv6jjfP/732/Pec5zbG5uzubm5mz//v322c9+dqzGeC5vf/vbLUkSe8tb3rK2bZzHWybU/vmj9jcftb95qP3zR+1vPmp/81D754/a33zU/uah9s8ftb/5qP3NQ+2fP2p/81H7m4faP3/U/ubbjrU/lot+f/EXf2G33nqr/d7v/Z59+9vftuuuu85uuukmO3HixJaOa2lpya677jp773vfG/38D//wD+0973mP/cmf/Il94xvfsOnpabvppptsdXX1oo7z0KFDdvDgQfv6179uX/jCF6zb7dq/+lf/ypaWltb2+Z3f+R371Kc+ZR/96Eft0KFD9sgjj9grX/nKizrOK6+80t7+9rfbvffea9/61rfsxS9+sb385S+37373u2Mzxph77rnHPvCBD9hznvMct31cx1sm1P6FofY3F7W/eaj9C0Ptby5qf/NQ+xeG2t9c1P7mofYvDLW/uaj9zUPtXxhqf3NR+5uH2r8w1P7m2ra1n4+hF7zgBfnBgwfX2v1+P9+7d29+++23b+GoPDPLP/7xj6+1syzL9+zZk7/jHe9Y23by5Mm81Wrl/+t//a8tGOFTTpw4kZtZfujQobVxNRqN/KMf/ejaPt///vdzM8sPHz68VcPM8zzPL7nkkvy///f/PrZjPHXqVP7MZz4z/8IXvpC/6EUvyt/85jfneT7ec1om1P5oUfujQ+1vLmp/tKj90aH2Nxe1P1rU/uhQ+5uL2h8tan90qP3NRe2PFrU/OtT+5qL2R4vaH53tXPtj902/Tqdj9957rx04cGBtW5qmduDAATt8+PAWjmywhx56yI4dO+bGPT8/by984Qu3fNwLCwtmZrZz504zM7v33nut2+26sV5zzTW2b9++LRtrv9+3j3zkI7a0tGT79+8fyzGamR08eNB+/dd/3Y3LbDzntGyo/dGj9keH2t881P7oUfujQ+1vHmp/9Kj90aH2Nw+1P3rU/uhQ+5uH2h89an90qP3NQ+2PHrU/Otu59utbPQD12GOPWb/ft927d7vtu3fvth/84AdbNKpix44dMzOLjvvsZ1shyzJ7y1veYr/8y79s1157rZmdGWuz2bQdO3a4fbdirPfff7/t37/fVldXbWZmxj7+8Y/bs5/9bLvvvvvGZoxnfeQjH7Fvf/vbds899wSfjdOclhW1P1rU/uhQ+5uL2h8tan90qP3NRe2PFrU/OtT+5qL2R4vaHx1qf3NR+6NF7Y8Otb+5qP3RovZHZ7vX/tgt+mG0Dh48aA888IB95Stf2eqhRD3rWc+y++67zxYWFuxjH/uYve51r7NDhw5t9bACR48etTe/+c32hS98wSYmJrZ6OEAhan80qH2UDbU/GtQ+yobaHw1qH2VD7Y8GtY+yofZHg9pH2VD7o1GF2h+713teeumlVqvV7Pjx42778ePHbc+ePVs0qmJnxzZO477lllvs05/+tH3pS1+yK6+8cm37nj17rNPp2MmTJ93+WzHWZrNpz3jGM+z666+322+/3a677jr7oz/6o7Eao9mZr/WeOHHCnvvc51q9Xrd6vW6HDh2y97znPVav12337t1jNd4yovZHh9ofHWp/81H7o0Ptjw61v/mo/dGh9keH2t981P7oUPujQ+1vPmp/dKj90aH2Nx+1PzrU/uhUofbHbtGv2Wza9ddfb3feeefatizL7M4777T9+/dv4cgGu/rqq23Pnj1u3IuLi/aNb3zjoo87z3O75ZZb7OMf/7h98YtftKuvvtp9fv3111uj0XBjPXLkiD388MNbPsdZllm73R67Md544412//3323333bf287znPc9e+9rXrv15nMZbRtT+haP2R4/a33zU/oWj9keP2t981P6Fo/ZHj9rffNT+haP2R4/a33zU/oWj9keP2t981P6Fo/ZHrxK1n4+hj3zkI3mr1co/9KEP5d/73vfy3/qt38p37NiRHzt2bEvHderUqfw73/lO/p3vfCc3s/yd73xn/p3vfCf/x3/8xzzP8/ztb397vmPHjvyv//qv87//+7/PX/7yl+dXX311vrKyclHH+cY3vjGfn5/P77rrrvzRRx9d+1leXl7b57d/+7fzffv25V/84hfzb33rW/n+/fvz/fv3X9Rx/u7v/m5+6NCh/KGHHsr//u//Pv/d3/3dPEmS/G//9m/HZoyDvOhFL8rf/OY3r7XHfbxlQO1fGGr/4qD2R4/avzDU/sVB7Y8etX9hqP2Lg9ofPWr/wlD7Fwe1P3rU/oWh9i8Oan/0qP0LQ+1fHNut9sdy0S/P8/y//tf/mu/bty9vNpv5C17wgvzrX//6Vg8p/9KXvpSbWfDzute9Ls/zPM+yLH/rW9+a7969O2+1WvmNN96YHzly5KKPMzZGM8s/+MEPru2zsrKS/4f/8B/ySy65JJ+amsr/zb/5N/mjjz56Ucf5m7/5m/nP/dzP5c1mM7/sssvyG2+8ce0XwbiMcRD9ZTDu4y0Lav/8UfsXB7W/Oaj980ftXxzU/uag9s8ftX9xUPubg9o/f9T+xUHtbw5q//xR+xcHtb85qP3zR+1fHNut9pM8z/ONfTcQAAAAAAAAAAAAwDgZu0w/AAAAAAAAAAAAABvDoh8AAAAAAAAAAABQciz6AQAAAAAAAAAAACXHoh8AAAAAAAAAAABQciz6AQAAAAAAAAAAACXHoh8AAAAAAAAAAABQciz6AQAAAAAAAAAAACXHoh8AAAAAAAAAAABQciz6AQAAAAAAAAAAACXHoh8AAAAAAAAAAABQciz6AQAAAAAAAAAAACX3/wPfA0tQ/rXGNAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1800x2200 with 7 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[211]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABv0AAAEDCAYAAAAWb8hiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABnT0lEQVR4nO3debBdZ3nn+2fPZz7S0SxL8oB9bQjYCcbYasjQWMFNU7QJ7spw6RtDqEqlW6YA/9EddzWk0kPZnVQFQjcQqpsyITeOaVMxXEIYHAM2GNnYwsY2NgKDbUnWbEln3vO6f8g6nOf3vjr7SNpH2uus76frVPTsvda73jU8W7Ren/3LJUmSGAAAAAAAAAAAAIDUyp/vCQAAAAAAAAAAAAA4Oyz6AQAAAAAAAAAAACnHoh8AAAAAAAAAAACQciz6AQAAAAAAAAAAACnHoh8AAAAAAAAAAACQciz6AQAAAAAAAAAAACnHoh8AAAAAAAAAAACQciz6AQAAAAAAAAAAACnHoh8AAAAAAAAAAACQciz6AQAAAAAAAAAAACm3ZIt+n/jEJ+yiiy6yvr4+u/baa+373//+Uh0KQA+h94FsoveBbKL3gWyi94FsoveBbKL3gXTJJUmSdHvQz3/+8/b7v//79ld/9Vd27bXX2sc+9jG75557bNeuXbZ27doF922327Zv3z4bHh62XC7X7akBmZMkiU1OTtrGjRstn1/aX+6l94HeQe8D2UTvA9lE7wPZRO8D2UTvA9m06N5PlsAb3/jGZPv27XN1q9VKNm7cmNx+++0d992zZ09iZvzww0+Xf/bs2bMU7e7Q+/zw03s/9D4//GTzh97nh59s/tD7/PCTzR96nx9+svlD7/PDTzZ/OvV+0bqsXq/bzp077bbbbpt7LZ/P27Zt22zHjh3B9rVazWq12lydvPKLh7/2W9dZsXRieivLlWC/QuLraqvl6ra1XZ20ZQcza7X8a/pfHJQKslq6iP8gQcdIzB+j2fbzOjGs3ycvY+j7SeSXM9tynKTDZJMknEcnetTYPAJ5Pw+dp5lZ0vBzadZasoHfZ2UlfB76CyVXV9t+jJlm09X1VuQ+FPxcC7mCP0ap7OpGKzyX6Zmaq/NyviXpuIFC2IJDFX+cftlJV/Hj9+EX51dvNO2z/+d+Gx4ejmzXPd3q/eeee25urj/72c+C/SYmJlw9Ojrq6v7+/mBeSvtUr6nuE7vGnf4LpXLZ38dK5LnV47Tkc2wx/7VWsVhcsFaL+S+r2vI5pfMoFHxvLGabM/kvuvS6P/TQQ8E2X/3qV1195ZVXuvqqq65y9ZYtW4IxdG7j4+Oufumll1w9ODgYjLFp0yZXT01NufrgwYOufvbZZ4MxHn74YVfv3bvX1aVSacFaNZtN27FjR2p6H0B3paX39+zZYyMjI0s6127Q/70B9Krl0vv0HHB60tL7ALqL3geyqVPvd33R78iRI9ZqtWzdunXu9XXr1tmPf/zjYPvbb7/d/vRP/zScWKk4t+hXKofT1EW/VksXl2TRL7JAk893WPQrdn/RL5fmRb9E60V8cBc6L/rpvbK2zF2OU9KVMzMry+JZS8YoyZDtfOdFv6Is+gXHzYfnUizJok2HRb9SZNGvLBuVy/4f9k930e+kpf41+m71/vDw8Nw/AAwNDQXv68KYbjMwMODq+f9j46TzsejX19cXbKPHacri9GIW/XThJ82LfrqNzkPvrVnn66wLdLG/FPW4+ozpGLFFv05/2eoiYOx50Hup1/B0F3hPSkvvA+iutPT+yMhIKhb9gLSg94FsSkvvA+gueh/Ipk693/VFv9N122232a233jpXT0xM2ObNm21V34CVXlnsyCWtYL+WvKb/ONxsdf5NP11/ypcWXqAqRC6mLsgFSy2yTzkf/mO50t8GbC5igS6f8//grksFwW/pRc9l4TpYWIytNek/2stia6MeOZemXGf9DUt5SquRxbZ+Oe6Kkv8H9aGyzCPym356nbV5dGGxkYuMUfT7zNQarq7W/XM7lQt/C60pw+bluH3y25O6SGxm7uboM9orTtX7Tz/99NxCXmyxTRf5dNFHPwtiCyO6uKaLPPpbedVqNRhD99HfMFTT09Md56HHjS1yKV041LkuZqFIr1mnRb/FLEbqGLGFQr2Guo1ej9e97nXBGBoefeedd7r6hz/8oasvuuiiYIyVK1e6utHwfXvkyBFXj42NBWPo+V5wwQWufs1rXuPq9evXB2Po+T766KOu/slPfuLqTgva+nz1ilP1PoDljd4HsulUvc9v8gHLG3/vA9lE7wO9oeuLfqtXr7ZCoRB8ldnBgwdP+Y+csa+9A5Au9D6QTfQ+kE30PpBN9D6QTfQ+kE30PpBOnX9d4zSVy2W7+uqr7f777597rd1u2/33329bt27t9uEA9Ah6H8gmeh/IJnofyCZ6H8gmeh/IJnofSKcl+XrPW2+91W6++WZ7wxveYG984xvtYx/7mE1PT9t73/vepTgcgB5B7wPZRO8D2UTvA9lE7wPZRO8D2UTvA+mzJIt+v/M7v2OHDx+2j3zkI3bgwAH75V/+Zfva174WhH4CWF7ofSCb6H0gm+h9IJvofSCb6H0gm+h9IH1ySZIk53sS801MTNjo6Kj93+/5l1Yul8zMbLI+E2zXbrVdnbT9abQT/34zcpr5fM7V5UJBxuh8aXSMYB8pS3l/DDMzvQX1VtNvkMtJ6evYcYJtpG63/fWJDZKXffTUWhaOUa+3/DY1v5NeYzOzQsl/y2yr6PdpJX7MJDL1FYWyq9eWB1xdkeveitzb6XpDXvHbDJT8MZrtcIyJWs3VDbmX1Yavj0zOBmNY4uc6NuzPZfVQn6sHy5FrOu/W1eoN+6v/96s2Pj5uIyMj4fF6xMne/8d//EcbHBw0M7NNmzZ13K9er7u6IM9Yf39/sI/2XLVaXXCMWM81m/5edvrO8pmZ8HNM53HyvBc6bifa21oXi+F/66HHaTR8L+j16Ovzz6DZia98WOi4k5OTwT6lUsnV+nx2GtPM7LHHHnP1f/7P/9nVTz75pKvXrFkTjHH55Ze7Wq/Hc8895+qhoaFgjGuuucbV+uxecMEFrr7qqquCMfbu3evqnTt3uvqpp55y9U9/+tNgjHz+F5+nzWbTHnvssdT0PoDuSkvv9/o8TzqTv5OB86HXe4q/94GlQe8D2UTvA9nUqfe7nukHAAAAAAAAAAAA4Nxi0Q8AAAAAAAAAAABIORb9AAAAAAAAAAAAgJQLw516RLPdsnz7xJpkwcIMDU1TS3T5UnI38pF4vnxkXPe+5uDFwuRk3VTHrLd9Hl1b8unCEUI6y2jUoG6kkX5yxWJnrmfXNs1JlOzBumQPmlmj6s+vIGdXHAjPNleUTL+2HzeXaKZhMITNmj/uZEty3nIVqcNByjIPvc55eYhKkXmMVkryim8xfR5akYyyQxM+F/DQ+JTfp+Xz1taN+Mw/M7OhefPosdjOjiqVylxmXCwHT/PkNLNvfqaZWZgbZ2bWavn7oDk9i8nr05w7zRbUfL5YDlyneei9W0wen85dxZ6HTpl9ek1j89DX9HrEdMpH0uujtZnZJZdc4up3v/vdrp6YmHC15jeahc+Znoveu6kp35NmZg8++KCr9Rq+6lWvcrU+H2Zm1113nasHBgYWrPW+mJnt2rVr7s9p630AAAAAAAAAZ4ff9AMAAAAAAAAAAABSjkU/AAAAAAAAAAAAIOVY9AMAAAAAAAAAAABSrmcz/So5s/IrcU/5fCF4X1OZGpLppoFs0VxAiTtqSr5aMe/3KRfCeeRz/rWk7QdNcn7MZpBGGGbp6VSDPSIxWBqNFWwiJ5tE5qGv1Rv+mjZqkrUXiQ4rFf31KFT8unI7F8mY0lwzeTvINAxHsKac33jb594VW34eI4Uw561SWHiummkYWzHXXECdfKHtX1gz7PPozMwKMsbLk/5pPzzh88dykdyu0tjw3J/rzTAHrZcdOXJkLmNtZGQkeH9sbMzVmtmn+XSNhn8WYjSzb3Z21tUvv/xysE+nvD3NW9OMt9gYmnGndTuSAak000/nEcvR07lrTqK+r9fHzKxWqwWvLTRmjI4Ry1JUmo33q7/6q64+cOCAq//mb/4mGGP//v2uXr16tatjeYxKnzO9t3v27HH19773vWAMfXY3b97s6m3btrk6ds2PHz9+yjkBAAAAAAAAWN74TT8AAAAAAAAAAAAg5Vj0AwAAAAAAAAAAAFKORT8AAAAAAAAAAAAg5Xo206+YO/FjZpbkwwwqzehrSVZa0jEYz6ydaD6W3yef82uixVyY6deUDL+WjJmTuefasUy/WErd/HnovCIbLTyEJbJPLBmsUfevzk7VXa1nX+kvB2PkK7KVzjUSLxfkEWqumWwfv15+q7rch/GWP5dSJNdsoCDt0OGaLiZbUbfRcxsqhi1YGfLbFCRbcP9RyZubDHO95mewNRqR8MUeNjExEeTSzaf5ameSW6bZaVq3JGcydgzN6NPMOs3f0zHNzMrlsIcWOm5sDH2mNMNPzy2WLai5iLqNZsctdH9ONY/Y3DX3TrfRutP1MjNbsWKFq3/zN3/T1ZqtZ2Z23333uVrPr1Neo1l4nQcGBlxdrfpszm984xvBGD//+c9d/fa3v93Vb3rTm1y9cePGYIx169bN/blerwfvAwDi+bYAAAAAACwH/KYfAAAAAAAAAAAAkHIs+gEAAAAAAAAAAAApx6IfAAAAAAAAAAAAkHIs+gEAAAAAAAAAAAApVzzfEziV6VbL6q2cmZk1k3bwfpIkri4kOdnA1y3z25uZFXJ+zTOfy8n7vo7No94OX5tPhgiOYWaW6NTCTTqLjLvQMZq1VrBNbbbp6oKsCfcPlFydr3ReM9bj6m2K0U1yef9KPryVFtxeqas5f5/G2/5czcLnoSy1ziN2yfW5tJav6w1/3KlWIxijlPfHXVnpc3V+zL9/eKIajHF4cmbuz81meK697MILL7TBwUEzs7n/O1+hUHB1terPvy09WSr559bMrNXyz79eo3q97uqBgYFgjP7+/gXnpcdoNMJ7XSz6j+B8/vT/Owx95jqNkYs8uJVKxdW1Ws3VMzMzdroWcx90m073IegvC89Hr/sFF1zg6ptuuikYY+/eva5+7rnnXL127VpXL+Y+HThwwNUbNmxw9b/+1/862OfFF1909YMPPuhqvV46ppnZjTfeOPfnmZkZ+9znPtdxrgBwPo2Ojp7vKQAAAAAAsGzwm34AAAAAAAAAAABAyrHoBwAAAAAAAAAAAKQci34AAAAAAAAAAABAyvVspt9Uo2Gl3In8pnYkj68v5/OzdPUyJ8lwxQ6Zd2ZhRpvGR8XmUch3ytLz+8TytFQ7llnnBom8JBeg2fDZT42q5LqFkX7WV/KPQ6EsmYdFOUgsX0smp9csiVzDJCevyTXSMWMr1YvJCpyvbmEW46xkNpbz+ozJuUXuU7vlx5it+xy38ZbPKJvMhXl7Q+azz1YVfd7aGrlPfeWwjY9Mzs79uRlGyfW0Cy64wIaHh80szLwzM3v55Zddrblvmq2n78fEsuLmi81DM/q01l6P5cBpHqHm3p3J50enbaanp4PXOuU+ak6e1madM/zK5XKwj94rvUZ672K5iJ3y9XRemvFnZvYv/sW/cPXf/M3fuHp8fNzVsXxC3eaKK65w9Xve8x5Xv/nNbw7G0CzB//Jf/ourv/CFL7j6V3/1V4MxLrnkkrk/6/MFAAAAAAAAYHnjN/0AAAAAAAAAAACAlGPRDwAAAAAAAAAAAEg5Fv0AAAAAAAAAAACAlOvZTL9KLm+lV4Lqau0wf62V86/lJNSuKHU7EnPVlHFzkp+lOYAFDc4zs2YSzm0+3aPVMbDPLC/H1cy72BGbNZ+xVZ/12VcFyaPrq4T5WvmiHFcj/GKT1TGk1ri+mKRTTlmiZbi9XqO87KN1LMNtVoIO+xKfN1aRC9Johrlmky1/3SfbPpNsNuf3iT2XVdlG5zWS83liK/t85p+ZWWVe/mK9vnBeW685duzYXHbbihUrgvf7+vpcrXl0MzMzrq5UwuujY2hWnObexTLvTuYOnqQ5dzpmbB76HOoYmlcXy5LTbTR/cHZ21tWxTL9O2YJ6jFi2XqfzjWUNdsr00310+9hrnXIAY/mMv/Irv+LqF154wdWf+9znXL1x48ZgjPe+972u3rZtm6svuugiVw8MDARj6Da//du/7eo///M/d/WxY8eCMV73utfN/XkxeZYAAAAAAAAAlg9+0w8AAAAAAAAAAABIORb9AAAAAAAAAAAAgJRj0Q8AAAAAAAAAAABIuZ7N9CsXC1YunshqajbC/LW2ZGHlJS6qIC80Itl7LUnH09y7toTJxfLpOkXWaSZVEknk04y6vMxdz7VeDbPkatM+c6wo+Xx9gz6jq1DovN6r5x9cgNj16LRJJMMunyycYaijxK55sIe8oNcwdh9mzV/DnIw61PbZYbORnLfjic8Pa0qYoM4rH7kgTdloIudzucoy9T4Lc876C7+435EYtJ527NixuSyyWO6ZZrJpbpnWo6OjwRg6rubcxXLfVKf8Oc3ni+XxaR6dZvwtJtOuv7/f1bVabcF5xLL1dJtY/uB8eu6LmWssR1PnqvvomOVymEWq90rPpS3ZrbF5rF+/3tVvf/vbFxzzsssuC8Z429ve5mrNo9Rz0XM3C7Mm/9k/+2euvvHGG1195513BmPMz5+MZVECAAAAAAAAWL74TT8AAAAAAAAAAAAg5Vj0AwAAAAAAAAAAAFKORT8AAAAAAAAAAAAg5U570e/BBx+0d7zjHbZx40bL5XL2xS9+0b2fJIl95CMfsQ0bNlh/f79t27bNfvrTn3ZrvgDOE3ofyCZ6H8gmeh/IJnofyCZ6H8gmeh9Ynoqnu8P09LRdddVV9gd/8Af2rne9K3j/z/7sz+zjH/+4/fVf/7VdfPHF9uEPf9huuOEGe+aZZ6yvr2/Rx0nMrH1ykvlc8H677etWO/Hvm2yQ+PfNzPLmx9UtmrJPIZyGFTqMkegrkXPRqdUbTT+Puj+XvH/bzMwGK/5WlvoKMlE5bi5yPXKyTRI54XnakTFakevsjmGR85c6p9voLpFjJPJaKzKqm0dkmnl5qGbluI3EX/harhWM0ZRrktNruPDlObGJnEs18fM6bn4eq/S+mVllXmvHrvmZOFe9XyqVrFQqzR1TFQr+2e7v73d1pVJxtV5PM7NGo+HqYtH3z9DQkKur1Wowhr6m89Ix8/nwv7HQ13QMfT92PY4fP+7qnDwPOmZMsynPdq3m6rb0RmzMwcFBV+t112sem6seR8eIXcNOz8PJZ+mker0ejKE2bdrk6ne/+92uHhsbC/ZZsWKFq/V8Y3NXej3WrFnj6ne84x2ufu6554Ixvvvd7879Wa/nmTpXvQ+gt9D7QDbR+0A20ftANtH7wPJ02ot+b3vb2+xtb3tb9L0kSexjH/uY/af/9J/sxhtvNDOzz33uc7Zu3Tr74he/aL/7u78b7FOr1dw/ME9MTJzulACcA/Q+kE30PpBN9D6QTfQ+kE30PpBN9D6wPHU10+/555+3AwcO2LZt2+ZeGx0dtWuvvdZ27NgR3ef222+30dHRuZ/Nmzd3c0oAzgF6H8gmeh/IJnofyCZ6H8gmeh/IJnofSK+uLvodOHDAzMzWrVvnXl+3bt3ce+q2226z8fHxuZ89e/Z0c0oAzgF6H8gmeh/IJnofyCZ6H8gmeh/IJnofSK/T/nrPbqtUKkEGl5lZLveLjLlSJD+qJvlqmr8Xy2xTsayvhbQjmwdReZ3y6CL5as2Gz4Zr1XxdMn/+lb7wthVKki0o2XJtPddYXp9sole9LXPPRQLqwlxAX0bT5XQXnWqHfD6z8H6HY3Seh77Wbvo8rJmc5I3FchHluuozphl/kTi+YO7tln9hOuef/XIhXLsvzmvt7qR6dd+per/RaMzloU1NTQXvr1q1ytWa2aZZarE+1+w0zd9T5XI5eE1z7zQXr9OYsXFbLd/7+jUIsa9F0H10zMXMQ83MzLhar9ep7tt8ej1i+XKd5tbp3sbG1Yw/vf+xeeg11Pw9zfiLzVufB6XziD2Xelw9/0svvdTV/+bf/JtgjKNHj879udls2v79+xec1/lwqt4HsLzR+0A20ftANtH7QDbR+0Bv6Opv+q1fv97MzA4ePOheP3jw4Nx7AJYfeh/IJnofyCZ6H8gmeh/IJnofyCZ6H0ivri76XXzxxbZ+/Xq7//77516bmJiwRx55xLZu3drNQwHoIfQ+kE30PpBN9D6QTfQ+kE30PpBN9D6QXqf9vW9TU1P23HPPzdXPP/+8PfHEEzY2NmZbtmyxD37wg/Zf/+t/tcsuu8wuvvhi+/CHP2wbN260d77znd2cN4BzjN4HsoneB7KJ3geyid4HsoneB7KJ3geWp9Ne9Hvsscfsn//zfz5X33rrrWZmdvPNN9tnP/tZ+/f//t/b9PS0/eEf/qEdP37c3vzmN9vXvvY16+vrO63jlPN5K7+SbzTbbAXvaxpSMed/abEgGVStSP5cIiluwRYdcuHMzJryqma0aQ5gtRaO0pj1r41WfCZXX5/PqKomYSZVXfLmNCqumNeJBUNYI1k4s07zCvORZLyiXlMJ24tdQx1HM/yCvMbIGDm5/20ZQ7MGY1l6mnvY0jw+zTSM5iIunJ0Y7BINOZRNgiH9C1Pms9PMzMrJL65HPQnfPxPnqvcnJyfnMtbWrFnTcfvZ2VlXa7Za7LvENZOtUw6cZq2ZmQ0ODrpas+I0j62/vz8YQ4+7b98+V2u23sqVK4Mx9Dg6j1guolqxYoWr9froNdV5xV7TbEE9VzOz6enpBbdZTKZftVpdcAzNFtT8vtg++szqcWPz0Gckdr6ddMof1DGvuuqqYIzf/d3fnfvz7Oysfetb3zrteahz1fsAegu9D2QTvQ9kE70PZBO9DyxPuUT/lfE8m5iYsNHRUft/3vNWK5dP/INvbNGv1vL/kKsLR4tZ9GvpIpdusJgrI4s2OTluuOgXrrY1Zv35jVb8P7gvZtGvHSzQecVgNTIYoiuLfroQpmMsatEv0UW/hRc0Y3PTBbwzWvSTmxdb4wvIGB3WAKPz0EVPHUPWN60cWVwYy/1iwaVeb9rf/t39Nj4+biMjI/F594CTvX/XXXfZwMCAmcUX/XThSxd1FrPopwt2upiiC0O6+GIWLvJ0Y9Fvz549rk7Top9es8Us+tXr9QW3GR4ednXsPuhxl2LRT69HTKdFP/27IfZXr26jx9V9JicngzHuu+++uT/Pzs7aLbfckpreB9Bd9D6QTfQ+kE30PpBN9D6QTZ16v6uZfgAAAAAAAAAAAADOPRb9AAAAAAAAAAAAgJQ77Uy/c6WZtC3/ytc66tdwmoVfV6lf36hfApmLfJVaQXPg9Osd5Tswo18JKa815atIGz5uyqwVfsVdf8l/DV6pIl9PJ3l9+nWXZpG8OXlfvxZOv0LSzKxmfu66T5/5eeUja8b69XTBRYt+n6V8nafMLfiqzsgXfOrXuZY0o022b0W+JlCnpjGIOojmBp54TQdduI59xV/wSodL2I58V+v0vJy/RiTzr5cNDAzMff1m7Ks59asl9esbg6/YjdxrHUOPo19NGaNfq6n76Ps6TzOzY8eOuVq/RlPHjF0Ppc+Ufs1k7Gs29es9de4HDx50dexcYl+budC8Yk5+retJ+jWben3MwlxAnYd+7eZirqFm9nXK1osdp5Pgs/IUr83X6StUzcxe//rXz/15MV/tCgAAAAAAAGD54Df9AAAAAAAAAAAAgJRj0Q8AAAAAAAAAAABIORb9AAAAAAAAAAAAgJRj0Q8AAAAAAAAAAABIueL5nsCpNBIzSxIzM8vlcsH7bXkpseCFjnTUfIcxk3Aa1qg1XT0z1XB1IfGXeKC/HIxR6Su4um4tV7fa/hjBxM3mrtWpJqtzb0QukL5STPyacDHn61IhXDPOyTaJzCt2W4J7qeciJ5yPXICC3Dx9ZlptP2Y7OEYokdl2nmf8GZGd5BihYIgOYybt8LVq/hfPUCNphRv0sOHhYRsaGjrl+8Xiwh9bsfuiWi1/TWq1mqsLhcKCdWweIyMjC445MTERjDE1NeXq0dFRVw8ODro6dm6dziWf9z2pxzALz29ycnLBec7MzARjNJv+c0qPq7WZWX9//4Lz0HOr1+sdj6v7DAwMuLrT82NmViqVXF0u+8/txTwP7XakMeeJXQ/dR89FP9dix1i7du3cn/X6AkAaLebvdfxC7P/fBAAAAADIDn7TDwAAAAAAAAAAAEg5Fv0AAAAAAAAAAACAlGPRDwAAAAAAAAAAAEi5ns30K+byVsqdyE1q5sJMspYtnI1WDHLgwvXNlmkekuwjkRjTM5KtZ2bVKf9av+Q6FcqS/VQOx2jl/fk1W5ol5+tcJNokkcy6kpxvuyCZd5GguP625JhJPl85r5l+Ya6VXsNGuyV1mEHVlrunmX2D0eN4+jy0JehOM/xi+TC6TTuvz5iOEc5j4ScqXGVfTOxKcK80vjGyT2ve5Fopy8KZnp6e+7Nm2pmZVSoVV+u91Dy6RsPnbJp1zjrTnLi+vr5gG815O3TokKs1s03nHTuO5gJ2Olez8Py01lw4PaaZ2cGDB12tGX5ax/IJdW56LsPDw8E+moOneYSHDx8O9lH6jOiYnerYa3pv9V7GMv10n055hPr+Yug1juUCzp+bzgkAsPzp3xVk/AEAAABAtvCbfgAAAAAAAAAAAEDKsegHAAAAAAAAAAAApByLfgAAAAAAAAAAAEDK9WymX1++aOX8ienNRnKs9CXNW9PguyQSZ5EkmnMn79eTBWszs4Gyz9waGPCXtFXw+Vn5cjhGTpLgNPauECbBBWN0Ol/NLywlYSZVJe9fK0qoYZAJEskI0RyRjvcpoihZggU5TrMdjqGZfvlch3sbmYdmC8by0zq+r+erB+4wrxNDLJzhF6zURwaZfy6Luea9ZN++fXOZe5s2bQrej+WpzafPaWx7fU2z5DR/LZYDpzl3MzMzro7lAHaieXw6r1gOnD6HmgOo56qZh2ZhHqGefywHUOlxF3Mf9LpqVmC1WnX10NBQMIbm1nXKzovl4HWa+2J0yujT48auqW7Tlr8M9PmIncv818hxAgDE/vcqfz8AAAAAwPLFb/oBAAAAAAAAAAAAKceiHwAAAAAAAAAAAJByLPoBAAAAAAAAAAAAKdezmX7lQsHKC2R31ROfh1Rv+zylpmTYaS6cmVmh4V+rz/oxNVtutN9nR5mZtWWKLZlXuVhy9WC/r83M6g2fBWZVP0ZO5lEshddF8zpqmi8l4XKx1V69RHk5rr7fimSEtCVvT3PyCvnwPuQklE7iCa0muVbNREIPLYy107kFWYOxjEfN9As26H423qISVWSj9iJ2as3Ln2w30pXpd/Dgwbk8vFjmjGa2jY2NuXp4eNjVmotnZnbs2DFXazaaZslpXp9ZmC+nmXWaT6e1WZj7p7VmusXORa/R2rVrXV0q+c+c2dnZYAwVO858mqNnFubz6XH1vsXmorl4em9jmX7a23ov9b7EsgU75Q92yveM0euh56b3NkbndTLrcrH7dMq/BABk05n8vbYUyBYEAAAAgO7jN/0AAAAAAAAAAACAlGPRDwAAAAAAAAAAAEg5Fv0AAAAAAAAAAACAlGPRDwAAAAAAAAAAAEi54vmewKnkcwUr5ApmZtZXjKxNtnxZNx9In7Tbrm7Myg5m1q7610oFHyY/MOQvT6EvDJuvNhq+rjZdXS6WXN1XDC95verHrSd+zP4+GaPkazOzaq3u6py/HNaX89dQ3jYzs2bir1nOl5bL+XkmkUHa8mJeLll4F8yacq8SmV1L721k9q1EtzGp5ZXwVlqir7V1AxkiMkZOTlg3yS9mjMhrbhqyQaOmEzXLzX8cGsHbPW12dtaSV+7n/v37g/f7+/tdPTY2tuB49Xo9eK1arbo6n88v+P7s7GzHcUdGRlw9NTXl6pdffjkYY8OGDa5es2aNqw8fPuzq8fHxYAw9f53XkSNHgn1UuVx29eDgoKubTf+5Vox8julrrZbvdv38MDMbGBhYcIxKpdLxuIVCwdV6LrHjKt1H6TXV58UsPN9OdRL5ANXj6PnqucTmMTExMffnycnJ4H0A6DXj4+PB36HIBv27cDF/ZwMAAAAAFsZv+gEAAAAAAAAAAAApx6IfAAAAAAAAAAAAkHIs+gEAAAAAAAAAAAAp17uZfvm85QuvrElGso/ysl7ZbvhtZiZ9kFljxmdSmZkND/jTHxr2WXkFydJbuTrMG6lIzt+E5HjNTvlssEIuErCWk7lJ8Ft/WbIFY4F8EuJXLPp5lRLJ9ItkZjRl3IZc9+BhWUTuRl5S7TS/z8ys0fZZV7pPXrMEI8dpSQBfMwjgk8yQyBg6bpCfJXV4JuG4RX1B5hG7D0EOouZXzsj1aoZjjM7LvWvkw2e/l7Xb7bn8s1qtFrw/MzPjas1K0xw4zQA0C3PuDh06FMxhvn379gVjTE9Pu1rz+DSfKHYumsmmz9yxY8c6jqH7aB7h/Iw3szADzyzM8NOsPR0zlrmj4+o+sfugx9V72ZDMVH3fLLzOfX19C84rNoZuoxmGi8kc0nH1Xum9juUT6nMXy+ybTzMfzcweeeSRuT/HsijhxbIVzwdyrAAAAAAAANAN/KYfAAAAAAAAAAAAkHIs+gEAAAAAAAAAAAApd1qLfrfffrtdc801Njw8bGvXrrV3vvOdtmvXLrdNtVq17du326pVq2xoaMhuuukmO3jwYFcnDeDcoveBbKL3gWyi94FsoveBbKL3gWyi94Hl67Qy/R544AHbvn27XXPNNdZsNu0//sf/aG9961vtmWeemctm+tCHPmRf+cpX7J577rHR0VG75ZZb7F3vepc99NBDpzWxliXWeiVrRzPfzMwmZ3zW0/i4z09qNXw2Ul9feKrFfp/jVJNsn1LLr4n2lVYHY7z68gv9PhWf6ffCz1909bGjk8EYzaQqL/i5l2X7fDnMIFozPOTqnCTU1Wr+GlZr4TVtzGp+lh8jL7lXxUgGUVum1kzaC75vZlbK+XF1JVp3iWXpFUzz9iQ7T3aKpSfl5FU9Pc1cysWyoDRKUAL6cnJySWQmLYnga1T9vSq2/D4r+n2GmZnZyLz8tHohkiN5ms5l74+MjMzlsmleW+y1VatWuXpoyPfClORsmoUZbp3y92JZek899ZSrNQfukksuWXCeZmH+nObgHT161NWx3K/nnntuwXnoMYaHh4MxNFtP8+Y65fWZhdlomuEXy7DTe1Ov112t51su66dh+JrWmrUXy3DTa6b7aB3LRdT8PT3OYsbQuev5a/bkfffdF4yxY8eOuT9rJuKZOJe9n2WLyY0EzqWs9f656rleyREFTiVrvQ/gBHofyCZ6H1i+TmvR72tf+5qrP/vZz9ratWtt586d9mu/9ms2Pj5un/nMZ+yuu+6yt7zlLWZmduedd9qrX/1qe/jhh+26667r3swBnDP0PpBN9D6QTfQ+kE30PpBN9D6QTfQ+sHydVabf+Pi4mZmNjY2ZmdnOnTut0WjYtm3b5ra54oorbMuWLe63D+ar1Wo2MTHhfgD0NnofyCZ6H8gmeh/IJnofyCZ6H8gmeh9YPs540a/dbtsHP/hBe9Ob3mSvfe1rzczswIEDVi6XbcWKFW7bdevW2YEDB6Lj3H777TY6Ojr3s3nz5jOdEoBzgN4HsoneB7KJ3geyid4HsoneB7KJ3geWl9P6es/5tm/fbk8//bR997vfPasJ3HbbbXbrrbfO1RMTE7Z582abbTat9Uoe2vh0mKc1Nelf02y0gWGfY1UqhVkddfMZS00JnJudmXZ1rRHm4G1ef6mrt1w44OpVK0ZdvfvFl4IxDhzyt2HvXp/b1Gz4eQ2N+KwsM7PBfn+cYsGv5xaKvj5yzGeFmZnNynETyY5LJLCu0QrXjIOkEnmhEMlMCXJUJO9E8/nykRy8oqxf5yTDry1jxrL0Es3wk/clni86D30pyAWUDWpVCfAzs1bNz3VQstBGB/2z3V+uBGO40+1yfMxS9/769ettYOBEH23cuDHYb926da4+ue1Jmjc3OzsbjKEZdjpGu+0foJ/97GfBGJqv9vLLL7t6etp/fqxfvz4YQ/e54oorXK15fMePHw/GOHbsmKs1F0/PJXZNT/5XXCdpxp3S67cYMzMzHbfRnDvNAdRcPLPwOuvcdYxYbpNuo5lLOman63Oquc6nGYBm4b168sknXa3/JZ2+b+afh8XM83Qsde/jF8j4Qy+h97tHe5mMP/Qyeh/IJnofyCZ6H1hezmjR75ZbbrF/+Id/sAcffNA2bdo09/r69eutXq/b8ePH3X8FcPDgweg/eJuZVSoVq1TCRQsAvYfeB7KJ3geyid4HsoneB7KJ3geyid4Hlp/T+nrPJEnslltusXvvvde++c1v2sUXX+zev/rqq61UKtn9998/99quXbts9+7dtnXr1u7MGMA5R+8D2UTvA9lE7wPZRO8D2UTvA9lE7wPL12n9pt/27dvtrrvusi996Us2PDw89/29o6Oj1t/fb6Ojo/a+973Pbr31VhsbG7ORkRF7//vfb1u3brXrrrtuSU4AwNKj94FsoveBbKL3gWyi94FsoveBbKL3geXrtBb9PvWpT5mZ2W/8xm+41++88057z3veY2ZmH/3oRy2fz9tNN91ktVrNbrjhBvvkJz/ZlckCOD/ofSCb6H0gm+h9IJvofSCb6H0gm+h9YPnKJT2WID8xMWGjo6P2zt/+TSuVS2ZmNjXTCrYrF/03k5aHCq7OF3L+/cixmm0/brXVcHVOLs3Vr7kyGOOd//JGV196qQ8nfengc67evefnwRjTM4dd/exPfuLql1+edvXaNWuCMfpKI64uFYf9+319rj788ovBGM/v/pmrpyZqrq63/fazibxgZvmmvy+ltr8vlgu/UVbvbtvkkdQnNPLIBjPRbfzjYO3IU9/u0Ar53IJvnzisTFbPpV7zM01q4bM9VCq5emW/v3flon8/ei7zDlOvN+yzn/+ajY+P28jISLhxjzjZ+1/4whdscHDQzMx9l/ipFIv+v12o1fxzu3v37mAfvQ6rVq1ydbPZdPWXvvSlYIxvfOMbrj569Kirx8bGFjyGmdnAwICrr7rqKlevW7fO1S+88EIwxtTUlKur1aqr9Vxi37v+6le/2tVDQ0ML1hs2bAjG0OOe/C/ETsrnw94fHvafU52+9z02RqFQiGz5C7mcb9zY9iXpOaXXMDYPfQ51zHLZ/y2k18vM7PHHH3f1V7/6VVc///zzC87LzKzVarn3v/e976Wm98+HHvufQD1P+wm9LS293wvz7JVnO+ufSb1yH9KuF3pqIefz731gOaP3gWyi94Fs6tT7p5XpBwAAAAAAAAAAAKD3sOgHAAAAAAAAAAAApByLfgAAAAAAAAAAAEDKFTtvcn4064nlXsmMWzEQJvL1DcjU8z4DQzMxCtHgM18WWv6FfM5nP1Vnfeafmdn09KwfUsboL/e7enTI53yZmVUkC+qC9eOuHuifcfXqlWEmV7Hoj9tsvezrhj//4cHwmm5a7/PDjvX7rLCpqs+PKtfC61Gd9q+1JQhwMUkd4Tann2+SSCaIjhmLDNGkr+Cosk9sjFbL71Wr+sy+XMPvtKLi8/rMzEb7fa5ZKe9nllvEVZw/i8Vs30sGBwfnMv327dsXvD8xMeFqzYFrNPwzGBtD8/U6Zbpppl3sNc30q9frro5luOnn1J49e1w9OTnpas3JMwtz3TRbTmsd08zsJ5IjumLFClevXbvW1fNz407SfML+fv/Z126HGaB6/rGMuvkWk+mneUB6jNjc9TW9ZrHjKs3s0/rgwYOufuCBB4Ixvv/977t67969rtZnKnYu83W6nstd1rOxlkLsmpLBBXRPr/QTn58AAAAAkF78ph8AAAAAAAAAAACQciz6AQAAAAAAAAAAACnHoh8AAAAAAAAAAACQcj2b6TcyWLFy+UTOVrmsaWtmpaJfrzyZ/3dSveGzjxpJmCc1OOzH7U8kg+mIz8U7dOi5YIwD+x519YoVR1xdLo/6Yw6E2WGl4gpXb1y7xb9vPsNsZHg4GMOKL/i5Hvixq1et8vljq1aH2YKF/EpXrxi7wNWNls8k27vnUDDGz8d95pim/pUiUSW5RF7UDC65d61YzIjm7cnbGukYPg1medlLY1VakvLXrIejtOS1Uts/Y0OV0oL1iXno8+4noucSuxz5eZPP90g+zGIdOHBgLh9Oc9DMwuy8Wq3m6tFR33MrV/rn2szs0CH/7Gre3jXXXOPqyy+/PBjjRz/6kas1S1DnpbVZmLmmmX06r1gen2baaR6fXq+pKZ/VaRbO/fDhw65+/vnnXb1li/+MMjN705ve5OqRkRFXx+auGXV6PTQ3MZatqFmBei6az9fXF+Zo6nE1y0j3iWX86T4vvPCCq7/1rW+5+rHHHgvGOHLE//2h10fF5hHLTswKMqgAnEqvZOWlRad8XAAAAABA7+I3/QAAAAAAAAAAAICUY9EPAAAAAAAAAAAASDkW/QAAAAAAAAAAAICU69lMv3K5aOXyiekV82EOR05iixpNn+OkGX8b1oa5Xpdc4XOp8iWfjfXMcztdXZt+Ohhj98983l5tYpOrt7z6SlcPVMJssLpEfbXrPluw3fZrs5VKmMk12O+zv9r9m119+UWv9e9XfHaUmdmhA+OuHhm40NVJwV/j3S8eD8ZoNlquLhR9Zl0uss6c06w8Ca2ryr1sRhL5ipILWJTjaBJJO5YtaJpf4t+v1f25tWthvslg3p/voGT29ZV8yxUimVwaSJgEmX6dc1Xm90wh0j+9bPfu3XMZappHZ2bWavn7oJl9mp334x/7fEszs3379rlas2o0927dunXBGJdeeqmrNW9u9+7drp6eng7G0Ly5WEbbfJo9ZxZm2B0/ftzVeq6aAWgW5gDqGKWSf4713GPj6n3QecZeG5a80jVr1rh6cHAwGGNmZsbVs7OzrtZrrHWMPg+VSsXVmrVoZvbII4+4+jvf+Y6rX3zxRVcfO3YsGEPvb6fnQXvBzM+dDCYAWUR+HwAAAAAgy/hNPwAAAAAAAAAAACDlWPQDAAAAAAAAAAAAUo5FPwAAAAAAAAAAACDlWPQDAAAAAAAAAAAAUq54vidwKrlXfszMcrlc8H6z3VqwHiyVXL1qZEMwxqa1r3X1lkv8Nm9+81Wufu75rwZj/PjR77n68BE/j8Luta6eGG8EY0zKa8PDBVevWr/S1SPD/tzMzPLtqqs3bVjj6gs3/bI/ZuvnwRgrV8tr7YorXz466erj4742M8ubv1fFyL1T7SRxdStpyxb+/Xxigba81sj5MfI5v75diMwrkUEaNZlH3ZfDxXIwxmDZ35tywd/LQt7PI3IqwYuJXB+deaw/bP5ri7gHvWR6etqazeYp3x8ZGXH14OCgq/fv3+/ql19+ORjj2LFjrt63b5+rn3zySVdffvnlwRhbt2519Zo1vudmZ2ddvXnz5mCM4eFhV09O+p46fPiwq2dmZoIxymX/HOo+Wvf19QVj6Datlv8cW7Fihas3bAg/T6vV6oK1PsdmZpWK/4zRe6nPduy5KMlnvdb1um/cRiP8DG63fa/rGHp9vvvd7wZjfP3rX3f13r17Xa33qVgM//rV13Reel9i8vM+Y3R/AAAAAAAAAMsbv+kHAAAAAAAAAAAApByLfgAAAAAAAAAAAEDKsegHAAAAAAAAAAAApFzPZvqVCjkrFU7kOcUyy/KSlVbK+ZyqVsvnR9XqYZ7U7LSEtNX8GJddts3Xm3yGl5nZiqFPunrnI0+5+umnfXbYi3ufDcZoNv1tuPz/usTVF1x4kavLxbFgjHrLZ1Bt2nyhq3MDF7jaJ4m9ss96f/579065emLS51qZzZrKa2ad5vVZmDHVkhC7RG53Memcg6f7JJoDKEl47TDWy1p1Pzc97mDFX+OKPIMx4aMr56phhGaR0D4/j3y+c0bf/Osey1LrZVNTU3O5a5qtZhZm5Wmt2WkDAwPBGJ3y1TQX8MCBA8EYmq/3hje8wdWXXXaZq2O5gJpp99hjj7n6pZdecnUsj04dOXLE1ePj467WjDszs0OHDrl67VqfRapZe7FsPc2bK0h/xLIEh4aGFtxHMw5jOXi6j26jc43NXa/J888/7+rvfOc7rn7ggQeCMSYmJlytOYgq9veaZvB1yuTTc9dx09b7AAAAAAAAAM4Ov+kHAAAAAAAAAAAApByLfgAAAAAAAAAAAEDKsegHAAAAAAAAAAAApFzPZvo1223Lv5JnNFQJc71KeZ9l1Gz5nKbpVs3VjXo1GKMqmVzHj/v8qIlxn2k3Mupz8czMtv7KrX6MY59x9f/3Y58FdXTaH9PMrL/c7+pa3ed2HTvqs6JiOU5r1/m5DQ5KfljDZ3Lt3++PaWb285/6LLCnn/2xq6erfu5JM5xHXvLn2pIppVl7J191Y+i7kn3VOdEu3KcpeX3tSMZjf9E/Z0Mln/tWyndeIw9G1UwtqYuRfD69hrHsr07vz39pEdPuKRs2bJjLf/vJT34SvF+r+d7WzL6VK1e6OpbhptdMM+t0zL179wZj7NixY8F9fu/3fs/Vl1ziszrNzI4ePepqzb3TXLhYRpuOMTXlP7c0F3FkZCQY48ILfQbolVde6Wq9PrFnTjP9NFsvls+omXWarRf7rOt0XB1Tx4hlGv7oRz9y9UMPPeTqxx9/3NWxZ0qvq14jzWOM5TN26vXFXI8053kCAAAAAAAAODspWw4AAAAAAAAAAAAAoFj0AwAAAAAAAAAAAFKORT8AAAAAAAAAAAAg5Vj0AwAAAAAAAAAAAFKueL4ncCpTtYaVkhN/rpTCaepqZStJXD3QX3F1s14NxnhpzyFXX7DhQlePDAwuYqZjrrrmDb/i6u8+9JSrjx2rByP0Vfz5TU/6bV58cb+rG41wFnkb9sc5/BNXT05OuXp86kAwxhNPPeTqn7/4gqtHR/25ttvhPHJSF+SFJNEtwn10Ez1MO5eYarekbvi9mnVfDxRKwRgr+vpcXcz7p6zdDo+rwqn5F/JyboVC53X34Irl/Cv5XHhNC/MO1FrEMXrJq1/9ahscPNF7k5OTwft79uxx9cltT5qdnXV1LnJ9Vq9e7erx8XFXN5tNVxcKhWCMqSnfU7t27XL1/v2+bzdv3hyMMTEx4Wo9l02bNgX7KJ3r8LD/LOjv71/wfTOza665ZsF69+7dHefRavkmbMsHRD4fPoe6T7HoPwv1usfug+6j9Po89dRTwTZf/vKXXa33LpG/X/rksyJ2HD23TudqFp6f7qPz0Gus2+j+AAAAAAAAAJa3dK0GAAAAAAAAAAAAAAiw6AcAAAAAAAAAAACk3Gkt+n3qU5+yK6+80kZGRmxkZMS2bt1qX/3qV+fer1artn37dlu1apUNDQ3ZTTfdZAcPHuz6pAGcW/Q+kE30PpBN9D6QTfQ+kE30PpBN9D6wfJ1Wpt+mTZvsjjvusMsuu8ySJLG//uu/thtvvNEef/xx+6Vf+iX70Ic+ZF/5ylfsnnvusdHRUbvlllvsXe96lz300EOdBxfVRstar6xJHpqcDt4fKPvso4rkIw0VfOZSvelzvszMXj76kqv37lnv6xd95t+mS1csPGkza8/6LMFS2+c85TV8zswabX8uRyZednWt4TP+JidngjH2veQzqIoVf5xC0R9jthZe02Pjh/1cc35NuFzyOXjtJDyXel3y5iTHK5+EuXgNyaXSUZPEv99ohDlWdX2tIRlcOXk+SmGmX1HONydpehoN146ci+brFfKSQSZjNCM5gQW5ZrFMuoXG1Jc67L0o57L3T/6PCTOz66+/Pnj/Zz/7masPHfJ9qv8DJJa/Vqn4PtVsPa1jeXS6jdI8wlqt1nEemuE3MDDgas38i+3TKVsudj3WrFnjas1F1PzCWB6dzlXnEcuf07zBWGbffLG56zXR+/LYY4+5+u///u+DMX7605+6+uTzd6p5xc5FX9PrXpLPnFi2YrXqs2f1Gi7G/OesG5l+57L3AfQOeh/IJnofyCZ6H8gmeh9Yvk5r0e8d73iHq//bf/tv9qlPfcoefvhh27Rpk33mM5+xu+66y97ylreYmdmdd95pr371q+3hhx+26667LjpmrVZz/0jZ6R/SAZx79D6QTfQ+kE30PpBN9D6QTfQ+kE30PrB8nXGmX6vVsrvvvtump6dt69attnPnTms0GrZt27a5ba644grbsmWL7dix45Tj3H777TY6Ojr3s3nz5jOdEoBzgN4HsoneB7KJ3geyid4HsoneB7KJ3geWl9Ne9HvqqadsaGjIKpWK/dEf/ZHde++99prXvMYOHDhg5XLZVqxY4bZft26dHThw4JTj3XbbbTY+Pj73s2fPntM+CQBLj94HsoneB7KJ3geyid4HsoneB7KJ3geWp9P6ek8zs8svv9yeeOIJGx8fty984Qt288032wMPPHDGE6hUKkGulZlZJZ+zUuFEGtnkbDV4vyk5eGuGfK5TQ7KMcu0w2axS8LlVh1/e5+pnf/aUq2dqx4MxyhLJ9tAjX3P13r0/d3WS9xlWZmbtpOznKhl2UzM+G+zIcZ/5Z2bWJxmHG9eNuXps5airJyfCTL/Zmr9GxZLPtcqZz9NqJT5r0Mys3vL3qpz355bPhRl2iWQDNiUba3a24epqLcy5Kknm1lDRH3eo4OtyIcz00+y8JJLZN18xkvNWLPjXCnk/ZrPlzy2WC6hZgprKF+wTyQVszztu5O0zcq56/9ChQ3MZcpdeemnwvubJjY+Pu1pz32J5fJpRNzIy4uqLLrrI1bEsPc29u/zyyxesYzrlNY6O+r7VeZmF2YHPPfecqzXzUM819ppmy2k2nGbemZmNjfnPHP0Kh1g+nd5LvXc6ptZmZtPT/rNs586drv7c5z7nar0eZuH97ZThF8v065RhqOeq19gszH3U665jxJ7t+a91+gxbrHPV+wB6C70PZBO9D2QTvQ9kE70PLE+nvehXLpfn/iH+6quvtkcffdT+8i//0n7nd37H6vW6HT9+3P1XAAcPHrT169d3bcIAzg96H8gmeh/IJnofyCZ6H8gmeh/IJnofWJ7OONPvpHa7bbVaza6++morlUp2//33z723a9cu2717t23duvVsDwOgx9D7QDbR+0A20ftANtH7QDbR+0A20fvA8nBav+l322232dve9jbbsmWLTU5O2l133WXf/va37etf/7qNjo7a+973Prv11lttbGzMRkZG7P3vf79t3brVrrvuuqWaP4BzgN4HsoneB7KJ3geyid4HsoneB7KJ3geWr9Na9Dt06JD9/u//vu3fv99GR0ftyiuvtK9//ev2m7/5m2Zm9tGPftTy+bzddNNNVqvV7IYbbrBPfvKTZzSxwUrRyuUT02s2C8H7zYbPKqo3ffZRIad1+EuNuZIft9nw2VC7n/uZq1/48U+DMQ4d+rGrn9/7hKuPNySTqRxmgxUl901nqplsuXzLVL3h8/UOHz7s6qkJn2E2XQ3zteoNeUEmckxy0DQ30cys2ZJx9bpHIsxqknM3oxl+s/7cyoXweRgr+yywwZLP8CsV/KOuWXtmZhrTpWlYBcnP0vw+MzONaNNILR0jHxwlzOwLYrm0jlzT5BR/PlPnsvdfeOEF6+8/kX0Z+x5wzZ/T3DvN64vlr3XKbxweHnb1ypUrgzH06wyuuuoqV19yySWu1gxAszD3rtHwz75muGnGm1l4jTZs2OBqzd+LncvAwICrNStOsxVjGYc6htKcPLPO91Iz/DS/0czsG9/4hqu/+MUvulozD08+WwvNTZ+ZTnl9MTqm5vVpHdtH6XMay4QslUoLvn+6zmXvA+gd9H62dCsDFulH7wPZRO8D2UTvA8tXLumx/1/exMSEjY6O2ntufruVyyf+8fL4dPiP5U2Z9tiw/4fcfln0iS36DVRKrl61ep2rR4fXurrdDP+h9/QX/fyYZmZ9JT/3cNHP/8Ntoxlej1zijzNY8effX/HHiC36Tdb84prJP/wX8v56RRf9mlVXl4p+HtFFv6Zf6DiTRb9V/X7BoTuLfv4ZO5NFv04rbnoMs3DRL7ho8n4+8iW98+daqzfsU5/7so2PjweLLL3kZO//9//+3+cWZq644opgOz2HZ555xtUvvfSSq2MLNMeOHXP18ePHXa2La7r4ZtZ50e9Vr3qVq2OLfkePHnV1p0W/2P3TueqYuugVW/Rbt85/9uminx5jMYt+uqB5vhb99HmIWYpFP11wiy3YdppHp/dji3rz59psNm3nzp2p6f2z1WP/cyYzurG4jKWRlt7v9jx5Jk9fr3x+cu+6Iy29D6C76H0gm+h9IJs69f5ZZ/oBAAAAAAAAAAAAOL9Y9AMAAAAAAAAAAABSjkU/AAAAAAAAAAAAIOXCoKoeUSwWrFg8kV+0YrAveH9SMummpM5LJsRQpRKMUSj4jLqZaZ99dfjQAX+MmalgjFrjiKvbeT/XQcmaq7XDddaW5kPJ3DXeIsjJM7N2y+fezVR9tt7MrK8tH976ouRFaepfTbIEg3mbWankx83l/TYztTBLcHbWv5Y0ffbViNy74XJ4/oNBdqC/zppUEosu0Wy8nGmm4cL35cS4idT+fR0jH8ma1HDBVtsPopl/+cja/fxMNs1n63XT09Nz+WcvvPBC8P6mTZtcvWHDBldr/tqePXuCMTRfrVTynwWacXfBBRcEY+h3kmsOzZEj/rMh9h3mmoM3PT0dbDOf5uTFjqtj6vc7x/Jy6nX/+TE0NLTgGLGMw5mZmQW3iWUJ6rg6jyeffNLV3//+94Mx/vZv/3bB4+oxNPPQrHPe3mIy/GLXZD79bIiNqfdGx9Re1mc9dhzgbJCvBXQXn9EAAAAAgKWWrtUAAAAAAAAAAAAAAAEW/QAAAAAAAAAAAICUY9EPAAAAAAAAAAAASLmezfRrts1OxsGVIxluwzmfP3ds2mdBzdZ8RtNgKcw+ajf9PvXEb9NIfIZdvhRmMPWVxoLX3DESyXCrh/OYafjXipLzVpKsPc2aMzPL5zXTzt/aZuLnnliY06P5cpW8P25JDltvhdejLePOzPprXJ1tBPuU5LhDFclFlLy1gtx7M7OcjKE5RDmJUMnlw/MvFmQfOZcwhyWSy9Ih/kjnpdmTJ17U++uPk9NMv0hm3/xxo8foYf39/dbXd+IZOHz4cPB+rVZz9S/90i+5eu3ata7ev39/MIbey8HBQVfH8veU5utVJUdT3280wmdf56oZbjpGLMNNFeTzor+/39Wxz1PN0jt+/LirNWtweHg4GOPkPTtVXYnkqu7bt8/VjzzyiKu/973vufrZZ58NxuhkfHzc1ZrfaBbm6+n10B5bTM5Z0OuLyNbUeej91uc29kzN1ymrEL2D7Dwg/cjrAwAAAAD0An7TDwAAAAAAAAAAAEg5Fv0AAAAAAAAAAACAlGPRDwAAAAAAAAAAAEi5ns30S5ITP2ZmtUh2XMv8a7mCZB21fD0bydJr2IyrmxLF0ZZjJEm4RhrmNmkujx+jVAzHKLX9a5qVl2v7MTVrz8wskZy7YK6S6ReLDypI/mBL86XCowavVGd83tqUZC0OFMM8rbE+nznWL7lmOtUkMnl9Re+DZv4lkfPXswmS9RYRuVTQ+98h3iWJbKBz10y+xSTGtNtJ9M9p0Gq15rLINGvPzGxgYGDB/TU7TnPzzMw2btzoas2o09y3WE7PYvL15pudnQ1em5ycdPXIyMiCxzh69GjH42guYCzDTmkeoV53rWP5Y5rht3r1alf//Oc/D/b5+7//e1ffd999rtZMutjzoDl4WusYY2NhDqtuo1mSmse3mHw+fWZ0H51n7DW9/4vJ6Jt//8mJ6w3cB+DcIlsPAAAAAJBl/KYfAAAAAAAAAAAAkHIs+gEAAAAAAAAAAAApx6IfAAAAAAAAAAAAkHI9m+lXKeSsXDiRg9OKpJhpvlp/xb9Qq/lspCOTPmvOzCxXlhdK/jhtyQTRjDszs6LkNGmmm868EsmC6iv5PL4gwy7IJgnnoQdqas6VbhCJO6nJi7W2z49qNGTMWpgvVZfsxP6Sv8hj/T6/zyzM+QtiEXWyi8r0W3gXvbcnXpMxNK9RD7KImCbNctJ8vdg8wuMufKBWK9If8/7cjGRi9rKjR4/O5fKNjo4G72tm36FDh1ytuW+vec1rgjFWrlzpas3B0/tWLuuHhdnMjGSCSv6ajnns2LFgDJ27ZrppDlwsG6xQ8J8fev76fiyPTnMPNY9PcwFjeYa6zU9+8hNXf+1rXwv2+fa3v+1qPX/NCVxMpl0n9Xq94zZ6zdRiMto6zVWfj9g+ej1i+6hOc1/OyM4DAAAAAABA1vGbfgAAAAAAAAAAAEDKsegHAAAAAAAAAAAApByLfgAAAAAAAAAAAEDKsegHAAAAAAAAAAAApFzxfE/gVHKWWN4SMzMr5HPB+0mwvV+/LJT9+8erjWCM+qwfZbDoL0dJjjuTtIMxZlt+3JLMI2cy90RnblYpF3xd8vVMvenqarsVjNGWK9LUK9T2dSu4gmZN8+PWa1LPynHb4RgDxZKrV1YGFnzfzCyXk2uUC8edL7pSHVxmvVe+LuQKFtAx5BqFT2Gordck8swseFCz4PyDISPP0MJOd/vzq9VqWat14lmbnp4O3i9Knzabvj/q9bqrV61aFYwxODjo6snJSVfXajVXr1mzJhhj/fr1rta5njyHk2L37ejRo66emZlxtc5dj2lmVir5nhoaGnK19lelUgnG0H36+/td3dfX5+rYufzoRz9y9V133eXqhx9+ONhH5zIw4D8v9F7G5PML/7cr+ryMj493HDP4TFrE+3pNTr9Pw3107p3mBQAAAAAAACDb+E0/AAAAAAAAAAAAIOVY9AMAAAAAAAAAAABSjkU/AAAAAAAAAAAAIOV6NtOvnbSt9UoeWrsZZiPVWj7HK4h1ksi2ykCY4ZZUfeZWSeLXikU/aL0V5inVJXCtnvh5FXJ+jGIhluEmpW4j5zbbDDP9dFS9HG3JiqpE5pFr+r1mZ31eYSXx17C/L8znG8j71zTDL5a/1ZK56Z0qBvuEz0O77W9ekK/V6RqbmSX+OC0ZMy8Zj6ViJBdQMvz03PKSyVWILLsncjf1XDTWK3ZN5+/SKfOs1/T19c1lvWmWnJnZ6tWrF9xfc+Gq1WqwjWbpaaafXvORkZFgjLGxMVevWLFiwePG8gnDe+tvrma6xfIJ9dnXjMNCwT+nsUw7zR/UZ+bAgQOu3r9/fzDG17/+dVfv2LHD1Zo9GJtbo+E/c/TctI7NVety2Qe8xnLx9Lj63Ok+mr0Y20bPt1P2pFk4d73/SsfUMcgABAD0Ev5eAgAAAICll67VAAAAAAAAAAAAAAABFv0AAAAAAAAAAACAlGPRDwAAAAAAAAAAAEi5ns30a7bbln8lv6neCjPs2pLrJtFY1mj7fXJhnJSVWpLZV/ODtGzhTDczs5yExVUbfp9cztflSphHl0guYE4y3Sp5n3vVjizVav5cUTIz2jm5Xj7C6sRrNV8PF3wW1nDJ16VCJNNO1pE1uiMW5VGQ8z2TCDrNCOkUGdJuh/dB8/VKkumoz1gkWtDykuGYyP3P6TMUm2gw7unnnySn+HMajIyMzGWqxfL7hoaGXK25eKOjo64+mQ84XyxPbT7NdItlp+lrmrc3ODjoas0RNItn1M2n+XuxXDx9TbMENTdvdnY2GENf+9GPfuTqL33pS65+8cUXgzE0O0/Pv1aTDxjrfB/OJI+yU8ZhLCdPPz863ZfY86DXWS3mXE53HrExO+UAAgCWN3LzAAAAACDb+E0/AAAAAAAAAAAAIOVY9AMAAAAAAAAAAABS7qwW/e644w7L5XL2wQ9+cO61arVq27dvt1WrVtnQ0JDddNNNdvDgwbOdJ4AeQu8D2UTvA9lE7wPZRO8D2UTvA9lE7wPLxxmH/zz66KP26U9/2q688kr3+oc+9CH7yle+Yvfcc4+Njo7aLbfcYu9617vsoYceOq3x6+3E7JXctXoSZvoVJK4ikeijRDP/Iscolf0g9Rk/SE3qYn+YkdFX8JewKOuomj2oeX1mZs2W30ai5KwsWVGxbMFq01+jvGQNNuT9Wi3MpCqbP85gn88K03lEs+bkpbzkihQiGVQ5uUaaYtWSfEbNQDQLr4keNzxm+H5ecg+D6yzXNJqVl9N8woXX1WPzlMNE8wc7zWN+nku3s12WuvfXrl1rAwMDZma2fv364P2ZmRlXa6bfYrLTNJNNc/E0ny6W4fbyyy8vOC8doxXJJj15nidpHt+xY8cWPIZZeI0ajUhg5zyx6/PDH/7Q1ffff7+rd+/e7Wo9t9i4mkcXO3+leXSLuYb6WqdMv1hOnj5Dmj+o78fouJ3qGD0XvaaLyeubf/9jz+3ZWOreB9Cb6P3eQmYfzhV6H8gmeh/IJnofWF7O6Df9pqam7N3vfrf9r//1v2zlypVzr4+Pj9tnPvMZ+4u/+At7y1veYldffbXdeeed9r3vfc8efvjhrk0awPlB7wPZRO8D2UTvA9lE7wPZRO8D2UTvA8vPGS36bd++3d7+9rfbtm3b3Os7d+60RqPhXr/iiitsy5YttmPHjuhYtVrNJiYm3A+A3kTvA9lE7wPZRO8D2UTvA9lE7wPZRO8Dy89pf73n3XffbT/4wQ/s0UcfDd47cOCAlctlW7FihXt93bp1duDAgeh4t99+u/3pn/7p6U4DwDlG7wPZRO8D2UTvA9lE7wPZRO8D2UTvA8vTaf2m3549e+wDH/iA/e3f/q319fV1ZQK33XabjY+Pz/3s2bOnK+MC6B56H8gmeh/IJnofyCZ6H8gmeh/IJnofWL5O6zf9du7caYcOHbLXv/71c6+1Wi178MEH7X/+z/9pX//6161er9vx48fdfwVw8OBBW79+fXTMSqVilUoleL2VS6yVS04UJ//vPPpKUCcL12ZmVvBl/4BfA52Zbvo51cJBBgb9JcyXfV1vtxeeaERbtink/Qv5fC7cqSFl1R8370/FhgqlYIi+YtnVpYK/QDk5rJ5abJtiwV/TyMzDSxLcrNyCpZlZO4mNPH8X/34ucg1zsgSu++h1b0bOvyk3r6BTX3iapzjuwtvH7kO93Zr7c6PVCjc4Teey94eHh21gYGDRc9MxSiX/bOcWcdFnZmYWHKNYDD8qX3rpJVc3m77JhoaGOh5X6XHycvOTyAeZHrdWq7n6xRdfdPWzzz4bjPHEE0+4enJy0tX9/f2ujl3Ter2+4DZ6Tc3CuS+FtjSI1mZmBfms6zRG7LlVem6LeQ71/upx9RrHnoeRkZFTzuFMnMveB9A7zmXvj46Odn3+AM4Mf+8D2UTvA9lE7wPL12kt+l1//fX21FNPudfe+9732hVXXGH/4T/8B9u8ebOVSiW7//777aabbjIzs127dtnu3btt69at3Zs1gHOK3geyid4HsoneB7KJ3geyid4HsoneB5av01r0Gx4ette+9rXutcHBQVu1atXc6+973/vs1ltvtbGxMRsZGbH3v//9tnXrVrvuuuu6N2sA5xS9D2QTvQ9kE70PZBO9D2QTvQ9kE70PLF+ntei3GB/96Ectn8/bTTfdZLVazW644Qb75Cc/2e3DAOgx9D6QTfQ+kE30PpBN9D6QTfQ+kE30PpBOuSQWCnQeTUxM2OjoqP3ezW+1cvlEBlQ0xyrxWUct2UZ3icYpSVZaWTLbGjU5RiOcR6UimXUlP4bGR+UjE6lI7l1bNmm2/CC1RpjRVp/125RafpCBos/TqkQyygp5zZJbOEwudl90H83BO5PHrS05eZp5uBjBcSPPQ6Xo514pSZ6abK/3xSxyv+X8Na8vej06RBjqcautMLdrtvmLZ6Reb9jd/+c+Gx8fd3lfveZk73/+85+fy/SLXZ/BwUFXa96cZsfFMtx03Gq1uuCYsXmMj4+7WkOPtRf0GLExNNNPzzUWrKzH2bVrl6v/8R//0dW7d+8OxohlFi4klk+n+XGakxc7hmbUKT232L1cTGbffOVyOXhNz6fR8CGpZ5Lpp9mKei6xa6jPWUvyOHWfdevWBWNccsklc3+u1+v26U9/OjW9D6C76H0gm+h9IJvofSCb6H0gmzr1/sKrOgAAAAAAAAAAAAB6Hot+AAAAAAAAAAAAQMqx6AcAAAAAAAAAAACk3OkFOZ1DySv/z8yi+Wu5IKJN8uh0n8gYmtNUlbC4nI+ksnwSDlKtSeaSxEmVy36QWKZfImlxzaYfZGLa5141q2G+WF/eH2ew7HPNygV/qwuFcL03uGbB+5JPF9lBM6fCmXbeJ6xl+0i+WseowETLcIdWorU/cFHOtyTPh5lZK6f5gzp5qSPzbklmX1OfU8nwq0Uy/ZrzssAakffTIpZ7FjxjcvNnZ2c7jqHZeJ2+X3xqaip47WTu4ElDQ0OunpmZcbVm3pmFuXeaJbh69WpXa8abmdkPf/hDV//TP/2Tq/fs2ePqWKad0muqc19MNqfOdTF5fKf7fkynucWuod4HfWY0j08z/2LOJBNV56bPw+bNm1190UUXBWPMfy5jOZIAAAAAAAAAli9+0w8AAAAAAAAAAABIORb9AAAAAAAAAAAAgJRj0Q8AAAAAAAAAAABIuZ7N9GtbYi07keeUj+TABflysomuZrajOU+5BSozDVzLRzLc6jWfOZVr+VEKZV/HEqqm6z7HqTErOYE+0s+GCuFtGyj5nK5yUbIEJV8qFt/XMVuvw/ZmZu12h6yvyD4tCdPTvL1g7rnYWrXkMeph8ws/L6d6bb7wGYrlzck+ks+nlyd2veqSwacZfg3JOYvlnuXmX49F5K/1koGBARscHDSzeA6evqZ1rVZzteb3mYV5aprppnUsn02z8TSPTeeh+WxmZiMjI67We7l3715XP/PMM8EY3/nOd1x99OhRV+u5LCaPT7eJ9XqnfRbzvo5bLPrPtsXkAnbKztN9Ypl+nc630zFiOl13fT7MzMbGxlx9xRVXuHrt2rWujj1T8/shdq4AAAAAAAAAli9+0w8AAAAAAAAAAABIORb9AAAAAAAAAAAAgJRj0Q8AAAAAAAAAAABIORb9AAAAAAAAAAAAgJQrnu8JnEryyo+ZWXvuT7/QllpXL9uJ1uEYBcu5uiXHackuOb+5mZkVy/7I9Vk/s+qMr3PlcJ21UfN1qVVw9UCp7OpK2b9vZlbIy7gyWZ16LnIyed1HNtFL2NKLHHktL2NELmHkXmntr2GxEF7DghxI55qYziuciV6TRAbRZy52LiE/Rq3R9HXT12Zm7Zzfp9H2R261dSYR884liT24PaxUKlmpVDIzs0IhfNaLRf+x1Wg0Fnw/Nka1WnV1X1+fq8tl33OtVisYQ58X3WdwcHDB983M6vW6q3/wgx+4+p/+6Z9cfeDAgWAMpcfR6xMTO7/58vr5cgZjxD5ztMdi12i+mZmZjmMovf+x7XVunT4LYufSaV56DS+++OJgn4suusjVq1evPu3jzn/+tRcAAAAAAAAALG/8ph8AAAAAAAAAAACQciz6AQAAAAAAAAAAACnHoh8AAAAAAAAAAACQcj0b+JMkybxMpM5ZUK0OdSzHqRTkVPnj5DXzL5YFVfTbFCp+zEbLv1+sh/liJQmxGyhqpp+vo7FOmp0X1HJui8i0C9/3dRKJlguPu3BtZqYRfblE8rRs4bwtM7N8zg8Sy4F0Y0be1txHzSMsBrmBkazJtj6H/iLVWz5frZFEctA6ZCvqvYvlVc4//07Xotfk8/kFM+T0/msen9axsaamplyt91Jz8GJZc53y0nSf2dnZYJtnn33W1ffee6+r9+3b52o9t9hrOnfN2uuUgRfTXkSOZPAZcwY5gJrZt5g8Ph0jluG40DxP9Vqn43YaY2BgwNUbN250teb3mZlVKhVX12o+8FWfOd3ezJ//Yu4bAAAAAAAAgOWD3/QDAAAAAAAAAAAAUo5FPwAAAAAAAAAAACDlWPQDAAAAAAAAAAAAUq5nM/0seeXHYol+kbw9yS3TfRaT41TIaWab377WCvORNOdvsL/kj9Hyl3i6GslYasncZSlWs7EWk+mneXTB5rHrEUxLM+7kekUO0il/LibI0ks0CNCffyxfq9khu+oMYsysnfM76TxzFh6zIfli0w2fydU0/36+EMurDF7xx5V5xU5ufpRg0k5Xpl8ul5t7PmOZZPqaZtotJsNOX5uenna1Zqf19/cHY2hm3/79+109MTHh6tHR0WCMY8eOufqll15y9fDwsKtjeXV6Ls1mc8H3F0M/c7TWaxyzmG10bnpvdYxYTmCnPL6z3X6x+6xcudLVl19+uavHxsZcrdmLZuG90+dQn7nY8zB/n065kwAAAAAAAACWF37TDwAAAAAAAAAAAEg5Fv0AAAAAAAAAAACAlGPRDwAAAAAAAAAAAEi5ng38abcTa7dPHerXKY9P389FBtFIOo2+akiGnx7DzGz1oM/6KkvG0rHpuqubic9sMjPTiLa65FhV2v42VUqR25bTvLlOeXQx/lXdR3cqRpaMc8nCuYixAxeCzD7/ftLhXMzC3Dq9/7pPLOUsOG6QN6ZZcWEmV0Pubz1ZONesoPmFFuYiBpdQ9snrAyQ65Tv2mnw+P5fdFstw0/tSr/sem52ddXUsF1Cz0/R5GRwcXHBMM7Onn37a1UeOHHH1q171KlevWbMmGON1r3udq1/72tcueIwVK1YEY3TKm9McuFjGn57fwMCAqzUbrlqtBmPouN3IEgw+5yMZdpr7p7XuExuj05ilks9qXb9+fbCP3m/dRp/D8fHxYIxOmX76rMf6Y6HxAAAAAAAAACxv/KYfAAAAAAAAAAAAkHIs+gEAAAAAAAAAAAApx6IfAAAAAAAAAAAAkHIs+gEAAAAAAAAAAAApVzzfE1iU3GI28Rvlc75OLAn2aclrjVbb1TOzDVcPlcvBGKMV/9pMw+9TbTdd3d8Xnkyz5uuq38VKTT/PQiEYwgr5hS9SLng73F6vUCHcqSPdQ8fU+2QWzi0cQ0aJLFW3ZZNc5H7PV2+G7zd0EPPPQztpyrv+XpuZteR+5/M6WX92rXbbVEFOMC/3tpXIPkl4TQvzhmh3eDbSJicPTFuuodYx/f39C9bDw8Oufumll4Ix9LWRkRFXb9iwwdXT09PBGH19fa6+/vrrXX3w4EFXT01NBWNUKhVX6/VJEv9ct1qtYIxO17TZ7PRcd77uOo/F7KPHiW1fiH0gztPpepiF10Tv5aZNm1y9fv36YIzR0VFX673Seeq9NzObnJx09czMjKv1Xtdq8peH+XtVrVaD9wEAAAAAAAAsX/ymHwAAAAAAAAAAAJByLPoBAAAAAAAAAAAAKddzX+958qvXGo1ffEWZfr2hWfg1kbqFfmVk/Mse5es9m/6r4+bPwcysEVkjrdX8VzzWmr5u1OVr8SJfxdjUb4ls+m3qcjKlyLc16rftBV9vmUvk/c5f+Rh8DZ7sEv1KUdkl+NrNyFeGBi8lWvoXgm/hjB1Hh5T3u/P1nvI9rJFtLLfw13tGv2pQ95GTCb/OMhjCXdOTz3HsWL3k5Pzmfw1moxF+harS6xH7+kpVKpUW3Eef09hXc+pXJ+qY+vWOsa+m1K9nnJ2ddbV+rWbs3Dpts5iv99TXOn2dZ+xc9LXFPG+n+5Wgse11bp3uZeyrSTudf71ed3XsazX1edBnt9PXkMbG1bnq9SgWw7/C5x/n5JzS0vsAuqvXe6vX5wekVa/3Vq/PD0irXu+tXp8fkFa93lu9Pj8grTr1Vs8t+p3MNPry/3nwPM8EWF4mJyeD3LFecrL3/9W/+lfneSbA8pKW3gfQXfQ+kE30PpBN9D6QTfQ+kE2dej+X9NiSe7vdtn379lmSJLZlyxbbs2ePjYyMnO9pLWhiYsI2b97MXLsoLfM06/25Jklik5OTtnHjxuhvOfUKen9ppWWuaZmnWe/Pld5fOr1+7+dLy1zTMk+z3p8rvb90ev3ez5eWuaZlnma9P1d6f+n0+r2fLy1zTcs8zXp/rvT+0un1ez9fWuaalnma9f5c6f2l0+v3fr60zDUt8zTr/bkutvd77jf98vm8bdq0ySYmJszMbGRkpCcvcAxz7b60zNOst+fay//Vz0n0/rmRlrmmZZ5mvT1Xen9pMdfuS8s8zXp7rvT+0mKu3ZeWeZr19lzp/aXFXLsvLfM06+250vtLi7l2X1rmadbbc6X3lxZz7b60zNOst+e6mN7v3f8UAAAAAAAAAAAAAMCisOgHAAAAAAAAAAAApFzPLvpVKhX7kz/5E6tUKud7Kh0x1+5LyzzN0jXXNEjT9WSu3ZeWeZqla65pkKbryVy7Ly3zNEvXXNMgTdeTuXZfWuZplq65pkGaridz7b60zNMsXXNNgzRdT+bafWmZp1m65poGabqezLX70jJPs3TNdSG5JEmS8z0JAAAAAAAAAAAAAGeuZ3/TDwAAAAAAAAAAAMDisOgHAAAAAAAAAAAApByLfgAAAAAAAAAAAEDKsegHAAAAAAAAAAAApByLfgAAAAAAAAAAAEDK9eyi3yc+8Qm76KKLrK+vz6699lr7/ve/f76nZA8++KC94x3vsI0bN1oul7MvfvGL7v0kSewjH/mIbdiwwfr7+23btm3205/+9JzP8/bbb7drrrnGhoeHbe3atfbOd77Tdu3a5bapVqu2fft2W7VqlQ0NDdlNN91kBw8ePKfz/NSnPmVXXnmljYyM2MjIiG3dutW++tWv9tQcT+WOO+6wXC5nH/zgB+de6+X5pgm9f+bo/aVH7y8dev/M0ftLj95fOvT+maP3lx69v3To/TNH7y89en/p0Ptnjt5fevT+0qH3zxy9v/SWY+/35KLf5z//ebv11lvtT/7kT+wHP/iBXXXVVXbDDTfYoUOHzuu8pqen7aqrrrJPfOIT0ff/7M/+zD7+8Y/bX/3VX9kjjzxig4ODdsMNN1i1Wj2n83zggQds+/bt9vDDD9t9991njUbD3vrWt9r09PTcNh/60Ifsy1/+st1zzz32wAMP2L59++xd73rXOZ3npk2b7I477rCdO3faY489Zm95y1vsxhtvtB/96Ec9M8eYRx991D796U/blVde6V7v1fmmCb1/duj9pUXvLx16/+zQ+0uL3l869P7ZofeXFr2/dOj9s0PvLy16f+nQ+2eH3l9a9P7SoffPDr2/tJZt7yc96I1vfGOyffv2ubrVaiUbN25Mbr/99vM4K8/MknvvvXeubrfbyfr165M///M/n3vt+PHjSaVSSf7u7/7uPMzwFw4dOpSYWfLAAw/MzatUKiX33HPP3DbPPvtsYmbJjh07ztc0kyRJkpUrVyb/+3//756d4+TkZHLZZZcl9913X/Lrv/7ryQc+8IEkSXr7mqYJvd9d9H730PtLi97vLnq/e+j9pUXvdxe93z30/tKi97uL3u8een9p0fvdRe93D72/tOj97qL3u2c5937P/aZfvV63nTt32rZt2+Zey+fztm3bNtuxY8d5nNnCnn/+eTtw4ICb9+joqF177bXnfd7j4+NmZjY2NmZmZjt37rRGo+HmesUVV9iWLVvO21xbrZbdfffdNj09bVu3bu3JOZqZbd++3d7+9re7eZn15jVNG3q/++j97qH3lw693330fvfQ+0uH3u8+er976P2lQ+93H73fPfT+0qH3u4/e7x56f+nQ+91H73fPcu794vmegDpy5Ii1Wi1bt26de33dunX24x//+DzNqrMDBw6YmUXnffK986HdbtsHP/hBe9Ob3mSvfe1rzezEXMvlsq1YscJtez7m+tRTT9nWrVutWq3a0NCQ3Xvvvfaa17zGnnjiiZ6Z40l33323/eAHP7BHH300eK+Xrmla0fvdRe93D72/tOj97qL3u4feX1r0fnfR+91D7y8ter+76P3uofeXFr3fXfR+99D7S4ve7y56v3uWe+/33KIfumv79u329NNP23e/+93zPZWoyy+/3J544gkbHx+3L3zhC3bzzTfbAw88cL6nFdizZ4994AMfsPvuu8/6+vrO93SAjuj97qD3kTb0fnfQ+0gber876H2kDb3fHfQ+0obe7w56H2lD73dHFnq/577ec/Xq1VYoFOzgwYPu9YMHD9r69evP06w6Ozm3Xpr3LbfcYv/wD/9g3/rWt2zTpk1zr69fv97q9bodP37cbX8+5loul+3SSy+1q6++2m6//Xa76qqr7C//8i97ao5mJ36t99ChQ/b617/eisWiFYtFe+CBB+zjH/+4FYtFW7duXU/NN43o/e6h97uH3l969H730PvdQ+8vPXq/e+j97qH3lx693z30fvfQ+0uP3u8eer976P2lR+93D73fPVno/Z5b9CuXy3b11Vfb/fffP/dau922+++/37Zu3XoeZ7awiy++2NavX+/mPTExYY888sg5n3eSJHbLLbfYvffea9/85jft4osvdu9fffXVViqV3Fx37dplu3fvPu/XuN1uW61W67k5Xn/99fbUU0/ZE088Mffzhje8wd797nfP/bmX5ptG9P7Zo/e7j95fevT+2aP3u4/eX3r0/tmj97uP3l969P7Zo/e7j95fevT+2aP3u4/eX3r0/tmj97svE72f9KC77747qVQqyWc/+9nkmWeeSf7wD/8wWbFiRXLgwIHzOq/Jycnk8ccfTx5//PHEzJK/+Iu/SB5//PHkxRdfTJIkSe64445kxYoVyZe+9KXkySefTG688cbk4osvTmZnZ8/pPP/tv/23yejoaPLtb3872b9//9zPzMzM3DZ/9Ed/lGzZsiX55je/mTz22GPJ1q1bk61bt57Tef7xH/9x8sADDyTPP/988uSTTyZ//Md/nORyueQb3/hGz8xxIb/+67+efOADH5ire32+aUDvnx16/9yg97uP3j879P65Qe93H71/duj9c4Pe7z56/+zQ++cGvd999P7ZoffPDXq/++j9s0PvnxvLrfd7ctEvSZLkf/yP/5Fs2bIlKZfLyRvf+Mbk4YcfPt9TSr71rW8lZhb83HzzzUmSJEm73U4+/OEPJ+vWrUsqlUpy/fXXJ7t27Trn84zN0cySO++8c26b2dnZ5N/9u3+XrFy5MhkYGEh+67d+K9m/f/85necf/MEfJBdeeGFSLpeTNWvWJNdff/3cB0GvzHEh+mHQ6/NNC3r/zNH75wa9vzTo/TNH758b9P7SoPfPHL1/btD7S4PeP3P0/rlB7y8Nev/M0fvnBr2/NOj9M0fvnxvLrfdzSZIkp/e7gQAAAAAAAAAAAAB6Sc9l+gEAAAAAAAAAAAA4PSz6AQAAAAAAAAAAACnHoh8AAAAAAAAAAACQciz6AQAAAAAAAAAAACnHoh8AAAAAAAAAAACQciz6AQAAAAAAAAAAACnHoh8AAAAAAAAAAACQciz6AQAAAAAAAAAAACnHoh8AAAAAAAAAAACQciz6AQAAAAAAAAAAACnHoh8AAAAAAAAAAACQcv8/EV3Jg6p7TtsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1800x2200 with 7 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[219]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x2200 with 7 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>B01</th>\n",
       "      <th>B02</th>\n",
       "      <th>B03</th>\n",
       "      <th>B04</th>\n",
       "      <th>B05</th>\n",
       "      <th>B06</th>\n",
       "      <th>B07</th>\n",
       "      <th>B09</th>\n",
       "      <th>B10</th>\n",
       "      <th>...</th>\n",
       "      <th>aero</th>\n",
       "      <th>SAA</th>\n",
       "      <th>SZA</th>\n",
       "      <th>VAA</th>\n",
       "      <th>VZA</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>DOY</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>PID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3570050</td>\n",
       "      <td>-412.0</td>\n",
       "      <td>-199.0</td>\n",
       "      <td>497.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>5493.0</td>\n",
       "      <td>2264.0</td>\n",
       "      <td>1095.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1924.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>14728</td>\n",
       "      <td>3340</td>\n",
       "      <td>23265</td>\n",
       "      <td>99</td>\n",
       "      <td>1550</td>\n",
       "      <td>975</td>\n",
       "      <td>203</td>\n",
       "      <td>0.915940</td>\n",
       "      <td>5050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3570051</td>\n",
       "      <td>-166.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>628.0</td>\n",
       "      <td>543.0</td>\n",
       "      <td>4778.0</td>\n",
       "      <td>2566.0</td>\n",
       "      <td>1533.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>14728</td>\n",
       "      <td>3340</td>\n",
       "      <td>23277</td>\n",
       "      <td>99</td>\n",
       "      <td>1551</td>\n",
       "      <td>975</td>\n",
       "      <td>203</td>\n",
       "      <td>0.795903</td>\n",
       "      <td>5150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3570052</td>\n",
       "      <td>162.0</td>\n",
       "      <td>342.0</td>\n",
       "      <td>865.0</td>\n",
       "      <td>774.0</td>\n",
       "      <td>4477.0</td>\n",
       "      <td>2448.0</td>\n",
       "      <td>1419.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>14728</td>\n",
       "      <td>3340</td>\n",
       "      <td>23289</td>\n",
       "      <td>99</td>\n",
       "      <td>1552</td>\n",
       "      <td>975</td>\n",
       "      <td>203</td>\n",
       "      <td>0.705199</td>\n",
       "      <td>5250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3570053</td>\n",
       "      <td>430.0</td>\n",
       "      <td>589.0</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>944.0</td>\n",
       "      <td>4757.0</td>\n",
       "      <td>2386.0</td>\n",
       "      <td>1252.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1966.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>14728</td>\n",
       "      <td>3340</td>\n",
       "      <td>23301</td>\n",
       "      <td>100</td>\n",
       "      <td>1553</td>\n",
       "      <td>975</td>\n",
       "      <td>203</td>\n",
       "      <td>0.668830</td>\n",
       "      <td>5350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3570054</td>\n",
       "      <td>351.0</td>\n",
       "      <td>511.0</td>\n",
       "      <td>996.0</td>\n",
       "      <td>836.0</td>\n",
       "      <td>4947.0</td>\n",
       "      <td>2394.0</td>\n",
       "      <td>1201.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1964.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>14728</td>\n",
       "      <td>3340</td>\n",
       "      <td>23313</td>\n",
       "      <td>100</td>\n",
       "      <td>1554</td>\n",
       "      <td>975</td>\n",
       "      <td>203</td>\n",
       "      <td>0.710877</td>\n",
       "      <td>5450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7495</th>\n",
       "      <td>3749435</td>\n",
       "      <td>262.0</td>\n",
       "      <td>338.0</td>\n",
       "      <td>591.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>2081.0</td>\n",
       "      <td>1194.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2765.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>14999</td>\n",
       "      <td>3693</td>\n",
       "      <td>24386</td>\n",
       "      <td>119</td>\n",
       "      <td>1595</td>\n",
       "      <td>1024</td>\n",
       "      <td>219</td>\n",
       "      <td>0.543943</td>\n",
       "      <td>9599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7496</th>\n",
       "      <td>3749436</td>\n",
       "      <td>271.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>606.0</td>\n",
       "      <td>577.0</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>2068.0</td>\n",
       "      <td>1179.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2771.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>14999</td>\n",
       "      <td>3693</td>\n",
       "      <td>24395</td>\n",
       "      <td>119</td>\n",
       "      <td>1596</td>\n",
       "      <td>1024</td>\n",
       "      <td>219</td>\n",
       "      <td>0.552540</td>\n",
       "      <td>9699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7497</th>\n",
       "      <td>3749437</td>\n",
       "      <td>266.0</td>\n",
       "      <td>345.0</td>\n",
       "      <td>597.0</td>\n",
       "      <td>566.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2089.0</td>\n",
       "      <td>1193.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2775.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>14999</td>\n",
       "      <td>3693</td>\n",
       "      <td>24403</td>\n",
       "      <td>119</td>\n",
       "      <td>1597</td>\n",
       "      <td>1024</td>\n",
       "      <td>219</td>\n",
       "      <td>0.558846</td>\n",
       "      <td>9799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7498</th>\n",
       "      <td>3749438</td>\n",
       "      <td>268.0</td>\n",
       "      <td>348.0</td>\n",
       "      <td>596.0</td>\n",
       "      <td>573.0</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>2122.0</td>\n",
       "      <td>1215.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2773.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>14999</td>\n",
       "      <td>3693</td>\n",
       "      <td>24411</td>\n",
       "      <td>119</td>\n",
       "      <td>1598</td>\n",
       "      <td>1024</td>\n",
       "      <td>219</td>\n",
       "      <td>0.558891</td>\n",
       "      <td>9899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7499</th>\n",
       "      <td>3749439</td>\n",
       "      <td>261.0</td>\n",
       "      <td>348.0</td>\n",
       "      <td>612.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>2099.0</td>\n",
       "      <td>2118.0</td>\n",
       "      <td>1194.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2763.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>14999</td>\n",
       "      <td>3693</td>\n",
       "      <td>24419</td>\n",
       "      <td>120</td>\n",
       "      <td>1599</td>\n",
       "      <td>1024</td>\n",
       "      <td>219</td>\n",
       "      <td>0.565834</td>\n",
       "      <td>9999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7500 rows  27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0    B01    B02     B03    B04     B05     B06     B07   B09  \\\n",
       "0        3570050 -412.0 -199.0   497.0  241.0  5493.0  2264.0  1095.0   9.0   \n",
       "1        3570051 -166.0   59.0   628.0  543.0  4778.0  2566.0  1533.0   9.0   \n",
       "2        3570052  162.0  342.0   865.0  774.0  4477.0  2448.0  1419.0  10.0   \n",
       "3        3570053  430.0  589.0  1075.0  944.0  4757.0  2386.0  1252.0  11.0   \n",
       "4        3570054  351.0  511.0   996.0  836.0  4947.0  2394.0  1201.0  10.0   \n",
       "...          ...    ...    ...     ...    ...     ...     ...     ...   ...   \n",
       "7495     3749435  262.0  338.0   591.0  576.0  1950.0  2081.0  1194.0   9.0   \n",
       "7496     3749436  271.0  350.0   606.0  577.0  2002.0  2068.0  1179.0   9.0   \n",
       "7497     3749437  266.0  345.0   597.0  566.0  2000.0  2089.0  1193.0  14.0   \n",
       "7498     3749438  268.0  348.0   596.0  573.0  2025.0  2122.0  1215.0  13.0   \n",
       "7499     3749439  261.0  348.0   612.0  582.0  2099.0  2118.0  1194.0  10.0   \n",
       "\n",
       "         B10  ...  aero    SAA   SZA    VAA  VZA     X     Y  DOY      NDVI  \\\n",
       "0     1924.0  ...     3  14728  3340  23265   99  1550   975  203  0.915940   \n",
       "1     1979.0  ...     3  14728  3340  23277   99  1551   975  203  0.795903   \n",
       "2     1982.0  ...     3  14728  3340  23289   99  1552   975  203  0.705199   \n",
       "3     1966.0  ...     3  14728  3340  23301  100  1553   975  203  0.668830   \n",
       "4     1964.0  ...     3  14728  3340  23313  100  1554   975  203  0.710877   \n",
       "...      ...  ...   ...    ...   ...    ...  ...   ...   ...  ...       ...   \n",
       "7495  2765.0  ...     2  14999  3693  24386  119  1595  1024  219  0.543943   \n",
       "7496  2771.0  ...     2  14999  3693  24395  119  1596  1024  219  0.552540   \n",
       "7497  2775.0  ...     2  14999  3693  24403  119  1597  1024  219  0.558846   \n",
       "7498  2773.0  ...     2  14999  3693  24411  119  1598  1024  219  0.558891   \n",
       "7499  2763.0  ...     2  14999  3693  24419  120  1599  1024  219  0.565834   \n",
       "\n",
       "       PID  \n",
       "0     5050  \n",
       "1     5150  \n",
       "2     5250  \n",
       "3     5350  \n",
       "4     5450  \n",
       "...    ...  \n",
       "7495  9599  \n",
       "7496  9699  \n",
       "7497  9799  \n",
       "7498  9899  \n",
       "7499  9999  \n",
       "\n",
       "[7500 rows x 27 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change columns list: ['Unnamed: 0', 'B01', 'B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B09', 'B10', 'B11', 'cirrus', 'cloud', 'adj_cloud', 'cloud_shadow', 'snow_ice', 'water', 'aero', 'SAA', 'SZA', 'VAA', 'VZA', 'X', 'Y', 'DOY', 'NDVI', 'PID']->['B02', 'B03', 'B04', 'B05', 'NDVI', 'X', 'Y', 'DOY', 'PID']\n",
      "clear\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B02</th>\n",
       "      <th>B03</th>\n",
       "      <th>B04</th>\n",
       "      <th>B05</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>DOY</th>\n",
       "      <th>PID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>563.0</td>\n",
       "      <td>958.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>4784.0</td>\n",
       "      <td>0.713467</td>\n",
       "      <td>1558.0</td>\n",
       "      <td>975.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>5850.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>253.0</td>\n",
       "      <td>740.0</td>\n",
       "      <td>537.0</td>\n",
       "      <td>4750.0</td>\n",
       "      <td>0.796860</td>\n",
       "      <td>1559.0</td>\n",
       "      <td>975.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>5950.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>237.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>501.0</td>\n",
       "      <td>4715.0</td>\n",
       "      <td>0.807899</td>\n",
       "      <td>1560.0</td>\n",
       "      <td>975.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>6050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>264.0</td>\n",
       "      <td>729.0</td>\n",
       "      <td>532.0</td>\n",
       "      <td>4745.0</td>\n",
       "      <td>0.798370</td>\n",
       "      <td>1561.0</td>\n",
       "      <td>975.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>6150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>268.0</td>\n",
       "      <td>735.0</td>\n",
       "      <td>528.0</td>\n",
       "      <td>4834.0</td>\n",
       "      <td>0.803059</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>975.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>6250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6300</th>\n",
       "      <td>338.0</td>\n",
       "      <td>591.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>0.543943</td>\n",
       "      <td>1595.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>9599.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6301</th>\n",
       "      <td>350.0</td>\n",
       "      <td>606.0</td>\n",
       "      <td>577.0</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>0.552540</td>\n",
       "      <td>1596.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>9699.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6302</th>\n",
       "      <td>345.0</td>\n",
       "      <td>597.0</td>\n",
       "      <td>566.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.558846</td>\n",
       "      <td>1597.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>9799.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6303</th>\n",
       "      <td>348.0</td>\n",
       "      <td>596.0</td>\n",
       "      <td>573.0</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>0.558891</td>\n",
       "      <td>1598.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>9899.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6304</th>\n",
       "      <td>348.0</td>\n",
       "      <td>612.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>2099.0</td>\n",
       "      <td>0.565834</td>\n",
       "      <td>1599.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>9999.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6305 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        B02    B03    B04     B05      NDVI       X       Y    DOY     PID\n",
       "0     563.0  958.0  800.0  4784.0  0.713467  1558.0   975.0  203.0  5850.0\n",
       "1     253.0  740.0  537.0  4750.0  0.796860  1559.0   975.0  203.0  5950.0\n",
       "2     237.0  706.0  501.0  4715.0  0.807899  1560.0   975.0  203.0  6050.0\n",
       "3     264.0  729.0  532.0  4745.0  0.798370  1561.0   975.0  203.0  6150.0\n",
       "4     268.0  735.0  528.0  4834.0  0.803059  1562.0   975.0  203.0  6250.0\n",
       "...     ...    ...    ...     ...       ...     ...     ...    ...     ...\n",
       "6300  338.0  591.0  576.0  1950.0  0.543943  1595.0  1024.0  219.0  9599.0\n",
       "6301  350.0  606.0  577.0  2002.0  0.552540  1596.0  1024.0  219.0  9699.0\n",
       "6302  345.0  597.0  566.0  2000.0  0.558846  1597.0  1024.0  219.0  9799.0\n",
       "6303  348.0  596.0  573.0  2025.0  0.558891  1598.0  1024.0  219.0  9899.0\n",
       "6304  348.0  612.0  582.0  2099.0  0.565834  1599.0  1024.0  219.0  9999.0\n",
       "\n",
       "[6305 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data [203. 211. 219.]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B02</th>\n",
       "      <th>B03</th>\n",
       "      <th>B04</th>\n",
       "      <th>B05</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>DOY</th>\n",
       "      <th>PID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>563.0</td>\n",
       "      <td>958.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>4784.0</td>\n",
       "      <td>0.713467</td>\n",
       "      <td>1558.0</td>\n",
       "      <td>975.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>5850.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>253.0</td>\n",
       "      <td>740.0</td>\n",
       "      <td>537.0</td>\n",
       "      <td>4750.0</td>\n",
       "      <td>0.796860</td>\n",
       "      <td>1559.0</td>\n",
       "      <td>975.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>5950.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>237.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>501.0</td>\n",
       "      <td>4715.0</td>\n",
       "      <td>0.807899</td>\n",
       "      <td>1560.0</td>\n",
       "      <td>975.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>6050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>264.0</td>\n",
       "      <td>729.0</td>\n",
       "      <td>532.0</td>\n",
       "      <td>4745.0</td>\n",
       "      <td>0.798370</td>\n",
       "      <td>1561.0</td>\n",
       "      <td>975.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>6150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>268.0</td>\n",
       "      <td>735.0</td>\n",
       "      <td>528.0</td>\n",
       "      <td>4834.0</td>\n",
       "      <td>0.803059</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>975.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>6250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6275</th>\n",
       "      <td>338.0</td>\n",
       "      <td>591.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>0.543943</td>\n",
       "      <td>1595.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>9599.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6276</th>\n",
       "      <td>350.0</td>\n",
       "      <td>606.0</td>\n",
       "      <td>577.0</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>0.552540</td>\n",
       "      <td>1596.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>9699.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6277</th>\n",
       "      <td>345.0</td>\n",
       "      <td>597.0</td>\n",
       "      <td>566.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.558846</td>\n",
       "      <td>1597.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>9799.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6278</th>\n",
       "      <td>348.0</td>\n",
       "      <td>596.0</td>\n",
       "      <td>573.0</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>0.558891</td>\n",
       "      <td>1598.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>9899.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6279</th>\n",
       "      <td>348.0</td>\n",
       "      <td>612.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>2099.0</td>\n",
       "      <td>0.565834</td>\n",
       "      <td>1599.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>9999.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6280 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        B02    B03    B04     B05      NDVI       X       Y    DOY     PID\n",
       "0     563.0  958.0  800.0  4784.0  0.713467  1558.0   975.0  203.0  5850.0\n",
       "1     253.0  740.0  537.0  4750.0  0.796860  1559.0   975.0  203.0  5950.0\n",
       "2     237.0  706.0  501.0  4715.0  0.807899  1560.0   975.0  203.0  6050.0\n",
       "3     264.0  729.0  532.0  4745.0  0.798370  1561.0   975.0  203.0  6150.0\n",
       "4     268.0  735.0  528.0  4834.0  0.803059  1562.0   975.0  203.0  6250.0\n",
       "...     ...    ...    ...     ...       ...     ...     ...    ...     ...\n",
       "6275  338.0  591.0  576.0  1950.0  0.543943  1595.0  1024.0  219.0  9599.0\n",
       "6276  350.0  606.0  577.0  2002.0  0.552540  1596.0  1024.0  219.0  9699.0\n",
       "6277  345.0  597.0  566.0  2000.0  0.558846  1597.0  1024.0  219.0  9799.0\n",
       "6278  348.0  596.0  573.0  2025.0  0.558891  1598.0  1024.0  219.0  9899.0\n",
       "6279  348.0  612.0  582.0  2099.0  0.565834  1599.0  1024.0  219.0  9999.0\n",
       "\n",
       "[6280 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B02</th>\n",
       "      <th>B03</th>\n",
       "      <th>B04</th>\n",
       "      <th>B05</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>DOY</th>\n",
       "      <th>PID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>407.0</td>\n",
       "      <td>677.0</td>\n",
       "      <td>709.0</td>\n",
       "      <td>2078.0</td>\n",
       "      <td>0.491209</td>\n",
       "      <td>1595.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>9595.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>378.0</td>\n",
       "      <td>645.0</td>\n",
       "      <td>639.0</td>\n",
       "      <td>2181.0</td>\n",
       "      <td>0.546809</td>\n",
       "      <td>1596.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>9695.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>352.0</td>\n",
       "      <td>614.0</td>\n",
       "      <td>606.0</td>\n",
       "      <td>2098.0</td>\n",
       "      <td>0.551775</td>\n",
       "      <td>1597.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>9795.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>352.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>605.0</td>\n",
       "      <td>2138.0</td>\n",
       "      <td>0.558877</td>\n",
       "      <td>1598.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>9895.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>357.0</td>\n",
       "      <td>636.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>2208.0</td>\n",
       "      <td>0.560424</td>\n",
       "      <td>1599.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>9995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>375.0</td>\n",
       "      <td>678.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>2250.0</td>\n",
       "      <td>0.537936</td>\n",
       "      <td>1595.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>9596.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>373.0</td>\n",
       "      <td>656.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>2144.0</td>\n",
       "      <td>0.528154</td>\n",
       "      <td>1596.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>9696.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>354.0</td>\n",
       "      <td>632.0</td>\n",
       "      <td>629.0</td>\n",
       "      <td>2111.0</td>\n",
       "      <td>0.540876</td>\n",
       "      <td>1597.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>9796.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>343.0</td>\n",
       "      <td>621.0</td>\n",
       "      <td>595.0</td>\n",
       "      <td>2182.0</td>\n",
       "      <td>0.571480</td>\n",
       "      <td>1598.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>9896.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>348.0</td>\n",
       "      <td>624.0</td>\n",
       "      <td>589.0</td>\n",
       "      <td>2208.0</td>\n",
       "      <td>0.578834</td>\n",
       "      <td>1599.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>9996.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>368.0</td>\n",
       "      <td>673.0</td>\n",
       "      <td>691.0</td>\n",
       "      <td>2224.0</td>\n",
       "      <td>0.525901</td>\n",
       "      <td>1595.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>9597.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>363.0</td>\n",
       "      <td>663.0</td>\n",
       "      <td>673.0</td>\n",
       "      <td>2248.0</td>\n",
       "      <td>0.539199</td>\n",
       "      <td>1596.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>9697.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>348.0</td>\n",
       "      <td>639.0</td>\n",
       "      <td>641.0</td>\n",
       "      <td>2235.0</td>\n",
       "      <td>0.554242</td>\n",
       "      <td>1597.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>9797.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>327.0</td>\n",
       "      <td>612.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>2239.0</td>\n",
       "      <td>0.577316</td>\n",
       "      <td>1598.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>9897.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>324.0</td>\n",
       "      <td>603.0</td>\n",
       "      <td>573.0</td>\n",
       "      <td>2227.0</td>\n",
       "      <td>0.590714</td>\n",
       "      <td>1599.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>9997.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>374.0</td>\n",
       "      <td>683.0</td>\n",
       "      <td>704.0</td>\n",
       "      <td>2214.0</td>\n",
       "      <td>0.517478</td>\n",
       "      <td>1595.0</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>9598.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>366.0</td>\n",
       "      <td>677.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>2260.0</td>\n",
       "      <td>0.537938</td>\n",
       "      <td>1596.0</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>9698.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>353.0</td>\n",
       "      <td>647.0</td>\n",
       "      <td>652.0</td>\n",
       "      <td>2189.0</td>\n",
       "      <td>0.541007</td>\n",
       "      <td>1597.0</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>9798.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>335.0</td>\n",
       "      <td>628.0</td>\n",
       "      <td>632.0</td>\n",
       "      <td>2248.0</td>\n",
       "      <td>0.561111</td>\n",
       "      <td>1598.0</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>9898.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>325.0</td>\n",
       "      <td>612.0</td>\n",
       "      <td>606.0</td>\n",
       "      <td>2258.0</td>\n",
       "      <td>0.576816</td>\n",
       "      <td>1599.0</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>9998.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>372.0</td>\n",
       "      <td>677.0</td>\n",
       "      <td>698.0</td>\n",
       "      <td>2116.0</td>\n",
       "      <td>0.503909</td>\n",
       "      <td>1595.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>9599.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>372.0</td>\n",
       "      <td>696.0</td>\n",
       "      <td>702.0</td>\n",
       "      <td>2172.0</td>\n",
       "      <td>0.511482</td>\n",
       "      <td>1596.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>9699.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>348.0</td>\n",
       "      <td>655.0</td>\n",
       "      <td>657.0</td>\n",
       "      <td>2141.0</td>\n",
       "      <td>0.530379</td>\n",
       "      <td>1597.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>9799.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>339.0</td>\n",
       "      <td>631.0</td>\n",
       "      <td>633.0</td>\n",
       "      <td>2149.0</td>\n",
       "      <td>0.544932</td>\n",
       "      <td>1598.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>9899.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>346.0</td>\n",
       "      <td>643.0</td>\n",
       "      <td>644.0</td>\n",
       "      <td>2212.0</td>\n",
       "      <td>0.549020</td>\n",
       "      <td>1599.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>9999.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      B02    B03    B04     B05      NDVI       X       Y    DOY     PID\n",
       "0   407.0  677.0  709.0  2078.0  0.491209  1595.0  1020.0  211.0  9595.0\n",
       "1   378.0  645.0  639.0  2181.0  0.546809  1596.0  1020.0  211.0  9695.0\n",
       "2   352.0  614.0  606.0  2098.0  0.551775  1597.0  1020.0  211.0  9795.0\n",
       "3   352.0  622.0  605.0  2138.0  0.558877  1598.0  1020.0  211.0  9895.0\n",
       "4   357.0  636.0  622.0  2208.0  0.560424  1599.0  1020.0  211.0  9995.0\n",
       "5   375.0  678.0  676.0  2250.0  0.537936  1595.0  1021.0  211.0  9596.0\n",
       "6   373.0  656.0  662.0  2144.0  0.528154  1596.0  1021.0  211.0  9696.0\n",
       "7   354.0  632.0  629.0  2111.0  0.540876  1597.0  1021.0  211.0  9796.0\n",
       "8   343.0  621.0  595.0  2182.0  0.571480  1598.0  1021.0  211.0  9896.0\n",
       "9   348.0  624.0  589.0  2208.0  0.578834  1599.0  1021.0  211.0  9996.0\n",
       "10  368.0  673.0  691.0  2224.0  0.525901  1595.0  1022.0  211.0  9597.0\n",
       "11  363.0  663.0  673.0  2248.0  0.539199  1596.0  1022.0  211.0  9697.0\n",
       "12  348.0  639.0  641.0  2235.0  0.554242  1597.0  1022.0  211.0  9797.0\n",
       "13  327.0  612.0  600.0  2239.0  0.577316  1598.0  1022.0  211.0  9897.0\n",
       "14  324.0  603.0  573.0  2227.0  0.590714  1599.0  1022.0  211.0  9997.0\n",
       "15  374.0  683.0  704.0  2214.0  0.517478  1595.0  1023.0  211.0  9598.0\n",
       "16  366.0  677.0  679.0  2260.0  0.537938  1596.0  1023.0  211.0  9698.0\n",
       "17  353.0  647.0  652.0  2189.0  0.541007  1597.0  1023.0  211.0  9798.0\n",
       "18  335.0  628.0  632.0  2248.0  0.561111  1598.0  1023.0  211.0  9898.0\n",
       "19  325.0  612.0  606.0  2258.0  0.576816  1599.0  1023.0  211.0  9998.0\n",
       "20  372.0  677.0  698.0  2116.0  0.503909  1595.0  1024.0  211.0  9599.0\n",
       "21  372.0  696.0  702.0  2172.0  0.511482  1596.0  1024.0  211.0  9699.0\n",
       "22  348.0  655.0  657.0  2141.0  0.530379  1597.0  1024.0  211.0  9799.0\n",
       "23  339.0  631.0  633.0  2149.0  0.544932  1598.0  1024.0  211.0  9899.0\n",
       "24  346.0  643.0  644.0  2212.0  0.549020  1599.0  1024.0  211.0  9999.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to_impute:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B02</th>\n",
       "      <th>B03</th>\n",
       "      <th>B04</th>\n",
       "      <th>B05</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>DOY</th>\n",
       "      <th>PID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1550.0</td>\n",
       "      <td>975.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>5050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1551.0</td>\n",
       "      <td>975.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>5150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1552.0</td>\n",
       "      <td>975.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>5250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1553.0</td>\n",
       "      <td>975.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>5350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1554.0</td>\n",
       "      <td>975.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>5450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1590.0</td>\n",
       "      <td>976.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>9051.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1591.0</td>\n",
       "      <td>976.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>9151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1592.0</td>\n",
       "      <td>976.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>9251.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1593.0</td>\n",
       "      <td>976.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>9351.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1594.0</td>\n",
       "      <td>976.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>9451.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1195 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    B02  B03  B04  B05  NDVI       X      Y    DOY     PID\n",
       "0   NaN  NaN  NaN  NaN   NaN  1550.0  975.0  203.0  5050.0\n",
       "1   NaN  NaN  NaN  NaN   NaN  1551.0  975.0  203.0  5150.0\n",
       "2   NaN  NaN  NaN  NaN   NaN  1552.0  975.0  203.0  5250.0\n",
       "3   NaN  NaN  NaN  NaN   NaN  1553.0  975.0  203.0  5350.0\n",
       "4   NaN  NaN  NaN  NaN   NaN  1554.0  975.0  203.0  5450.0\n",
       "..  ...  ...  ...  ...   ...     ...    ...    ...     ...\n",
       "5   NaN  NaN  NaN  NaN   NaN  1590.0  976.0  203.0  9051.0\n",
       "6   NaN  NaN  NaN  NaN   NaN  1591.0  976.0  203.0  9151.0\n",
       "7   NaN  NaN  NaN  NaN   NaN  1592.0  976.0  203.0  9251.0\n",
       "8   NaN  NaN  NaN  NaN   NaN  1593.0  976.0  203.0  9351.0\n",
       "9   NaN  NaN  NaN  NaN   NaN  1594.0  976.0  203.0  9451.0\n",
       "\n",
       "[1195 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.environ['TRANSFORMERS_NO_ADVISORY_WARNINGS'] = 'true'\n",
    "\n",
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "print(current_directory)\n",
    "\n",
    "print(f'NumPy version:{np.__version__}')\n",
    "np.float = float # 'float32' # float\n",
    "table_dtype = np.float  #'float32'\n",
    "print(table_dtype)\n",
    "\n",
    "# hls_data = HLSDataSet(table_dtype = table_dtype)\n",
    "hls_data = HLSInference(table_dtype = table_dtype)\n",
    "\n",
    "hls_data.clip_dataset(x1=50.0, y1=50.0, x2=100.0, y2=100.0)\n",
    "\n",
    "doys = [171, 179, 187, 195, 203, 211, 219]\n",
    "doys = [171, 179, 187, 203, 211, 219]\n",
    "doys = [203, 211, 219]\n",
    "df = hls_data._get_data_doys(doys = doys, SHOW=True)\n",
    "display(df)\n",
    "\n",
    "# df = hls_data._set_columns_name()\n",
    "# display(df)\n",
    "\n",
    "df1, df2 = hls_data._nan_9999()\n",
    "# display(df1)\n",
    "# display(df2)\n",
    "\n",
    "df1, df2 = hls_data._set_clear_cloud()\n",
    "# display(df1)\n",
    "# display(df2)\n",
    "\n",
    "data, nan, clear, cloud = hls_data._set_train_columns_name()\n",
    "\n",
    "print('clear')\n",
    "display(clear)\n",
    "\n",
    "# train_data, test_data = hls_data._set_train_test_data(doy=211.0, x1=60.0, y1=40.0, x2=75.0, y2=55.0)\n",
    "\n",
    "train_data, test_data = hls_data._set_train_test_data(doy=211.0, x1=45.0, y1=45.0, x2=50.0, y2=50.0, for_show_nan=False)\n",
    "# train_data, test_data = hls_data._set_timeseries_train_test_data(doy=211.0, x1=50.0, y1=50.0, x2=100.0, y2=100.0)\n",
    "\n",
    "print('train_data', train_data['DOY'].unique())\n",
    "display(train_data)\n",
    "print('test_data')\n",
    "display(test_data)\n",
    "# display(data)\n",
    "# display(nan)\n",
    "# display(clear)\n",
    "# display(cloud)\n",
    "\n",
    "to_impute = hls_data._to_impute()\n",
    "hls_data._inference_train_test_data()\n",
    "hls_data._inference_imshow()\n",
    "\n",
    "# fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1698374090824,
     "user": {
      "displayName": "Koyaua Uvarov",
      "userId": "04551130653342672393"
     },
     "user_tz": -180
    },
    "id": "ZowJTFGIHI-b"
   },
   "outputs": [],
   "source": [
    "def GetModel(train_data, experiment_dir = '', load_model_path = '', tokenizer='',):\n",
    "\n",
    "    data = train_data.copy()\n",
    "    # Get the DataFrame with columns in reverse order\n",
    "    # data = data[data.columns[::-1]].copy()\n",
    "\n",
    "    print(data.dtypes.tolist())\n",
    "    # Reset the index to remove it\n",
    "    data = data.reset_index(drop=True)\n",
    "    display(data)\n",
    "\n",
    "    # Get the current CPU time in seconds since the epoch\n",
    "    current_time = int(time.time())\n",
    "    # Use the current time as a seed for a random number generator\n",
    "    random_seed_state = current_time  # You can use this random_state for various random processes\n",
    "\n",
    "    step_checkpoint = 12000\n",
    "    #### TRAINER HYPERPARAMETERS #############################\n",
    "    save_steps = 1000\n",
    "    logging_steps = 1\n",
    "    \n",
    "    epochs = 1\n",
    "    batch_size = 1\n",
    "    \n",
    "    learning_rate = 1e-12\n",
    "    lr_scheduler_type = 'constant'\n",
    "    # lr_scheduler_type = 'cosine'\n",
    "    num_cycles = 4\n",
    "    \n",
    "    warmup_steps = 5000\n",
    "    \n",
    "    optimizer = 'sophia'\n",
    "    ##########################################################\n",
    "\n",
    "    efficient_finetuning = ''\n",
    "\n",
    "    print('experiment_dir :', experiment_dir)\n",
    "    print('load_model_path:', load_model_path)\n",
    "\n",
    "    # load_model_path = 'load_model/checkpoint-16000'\n",
    "    model = GReaT(llm=load_model_path,\n",
    "                  # tokenizer=load_model_path,\n",
    "                  tokenizer=tokenizer,\n",
    "                  batch_size=batch_size, epochs=epochs, \n",
    "                  logging_steps=logging_steps, save_steps=save_steps,\n",
    "                  # evaluation_strategy='steps',\n",
    "                  # dataloader_num_workers=2, #fp16=True,\n",
    "                  logging_first_step=True,\n",
    "                  save_total_limit=2,\n",
    "                  prediction_loss_only=True,\n",
    "                  experiment_dir=experiment_dir,\n",
    "                  dataloader_num_workers=2,\n",
    "                  efficient_finetuning = efficient_finetuning,\n",
    "                  learning_rate=learning_rate,\n",
    "                  lr_scheduler_type=lr_scheduler_type,\n",
    "                  warmup_steps = warmup_steps,\n",
    "                  num_cycles = num_cycles,\n",
    "                  # warmup_ratio=0.05,\n",
    "                  seed=current_time,\n",
    "                  data_seed=current_time+int(time.time()),\n",
    "                  # optim=TRAINER_DICT['optimizer'],\n",
    "                  fp16 = True,\n",
    "                  # torch_compile=True,   #### uncomment for Ampere\n",
    "                  # bf16=True,            #### uncomment for Ampere\n",
    "                  report_to='none',\n",
    "                  )\n",
    "\n",
    "    # model.load_from_dir(f'{load_model_path}')\n",
    "    # print(f'----------- Model architecture, efficient_finetuning: {efficient_finetuning} -----------------------')\n",
    "    # print(model.model)\n",
    "    # print(f'----------------------------------------------------------------------------------------------------')\n",
    "    \n",
    "    model.fit(data=data[0:2], resume_from_checkpoint=True)\n",
    "    # model.fit(data[0:1])\n",
    "\n",
    "    return model\n",
    "\n",
    "# fn\n",
    "# model.fit(data=train_data, test_data=test_data)\n",
    "\n",
    "# TRAINER_DICT.to_csv(f'{experiment_dir}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 690889,
     "status": "ok",
     "timestamp": 1698374781701,
     "user": {
      "displayName": "Koyaua Uvarov",
      "userId": "04551130653342672393"
     },
     "user_tz": -180
    },
    "id": "3WhEgLr31fmg",
    "outputId": "48086a27-6ad5-4907-ecbb-857d9def648c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home\n",
      "['A0[RGB_TOK[ai]]/run[0]/checkpoint-24000', 'A0[RGB_TOK[ai]]/run[1]/checkpoint-160000']\n",
      "i_run: 1 A0[RGB_TOK[ai]]/run[1]/checkpoint-160000\n",
      "[dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64')]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B02</th>\n",
       "      <th>B03</th>\n",
       "      <th>B04</th>\n",
       "      <th>PID</th>\n",
       "      <th>DOY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>563.0</td>\n",
       "      <td>958.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>5850.0</td>\n",
       "      <td>203.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>253.0</td>\n",
       "      <td>740.0</td>\n",
       "      <td>537.0</td>\n",
       "      <td>5950.0</td>\n",
       "      <td>203.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>237.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>501.0</td>\n",
       "      <td>6050.0</td>\n",
       "      <td>203.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>264.0</td>\n",
       "      <td>729.0</td>\n",
       "      <td>532.0</td>\n",
       "      <td>6150.0</td>\n",
       "      <td>203.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>268.0</td>\n",
       "      <td>735.0</td>\n",
       "      <td>528.0</td>\n",
       "      <td>6250.0</td>\n",
       "      <td>203.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6275</th>\n",
       "      <td>338.0</td>\n",
       "      <td>591.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>9599.0</td>\n",
       "      <td>219.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6276</th>\n",
       "      <td>350.0</td>\n",
       "      <td>606.0</td>\n",
       "      <td>577.0</td>\n",
       "      <td>9699.0</td>\n",
       "      <td>219.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6277</th>\n",
       "      <td>345.0</td>\n",
       "      <td>597.0</td>\n",
       "      <td>566.0</td>\n",
       "      <td>9799.0</td>\n",
       "      <td>219.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6278</th>\n",
       "      <td>348.0</td>\n",
       "      <td>596.0</td>\n",
       "      <td>573.0</td>\n",
       "      <td>9899.0</td>\n",
       "      <td>219.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6279</th>\n",
       "      <td>348.0</td>\n",
       "      <td>612.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>219.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6280 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        B02    B03    B04     PID    DOY\n",
       "0     563.0  958.0  800.0  5850.0  203.0\n",
       "1     253.0  740.0  537.0  5950.0  203.0\n",
       "2     237.0  706.0  501.0  6050.0  203.0\n",
       "3     264.0  729.0  532.0  6150.0  203.0\n",
       "4     268.0  735.0  528.0  6250.0  203.0\n",
       "...     ...    ...    ...     ...    ...\n",
       "6275  338.0  591.0  576.0  9599.0  219.0\n",
       "6276  350.0  606.0  577.0  9699.0  219.0\n",
       "6277  345.0  597.0  566.0  9799.0  219.0\n",
       "6278  348.0  596.0  573.0  9899.0  219.0\n",
       "6279  348.0  612.0  582.0  9999.0  219.0\n",
       "\n",
       "[6280 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment_dir : A0[RGB_TOK[ai]]/run[1]\n",
      "load_model_path: A0[RGB_TOK[ai]]/run[1]/checkpoint-160000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:accelerate.utils.other:Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimiser: Sophia\n",
      "self.train_hyperparameters: {'logging_steps': 1, 'save_steps': 1000, 'logging_first_step': True, 'save_total_limit': 2, 'prediction_loss_only': True, 'dataloader_num_workers': 2, 'learning_rate': 1e-12, 'lr_scheduler_type': 'constant', 'warmup_steps': 5000, 'seed': 1699687880, 'data_seed': 3399375760, 'fp16': True, 'report_to': 'none'}\n",
      "total_train_steps calculated: 3 2 1\n",
      "warmup_steps: 5000\n",
      "lr_scheduler_type: constant\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='160000' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [160000/2 : < :, Epoch 5000/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to impute data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B02</th>\n",
       "      <th>B03</th>\n",
       "      <th>B04</th>\n",
       "      <th>B05</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>DOY</th>\n",
       "      <th>PID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1550.0</td>\n",
       "      <td>975.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>5050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1551.0</td>\n",
       "      <td>975.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>5150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1552.0</td>\n",
       "      <td>975.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>5250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1553.0</td>\n",
       "      <td>975.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>5350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1554.0</td>\n",
       "      <td>975.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>5450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1563.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>6390.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1564.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>6490.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1565.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>6590.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1566.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>6690.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1567.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>6790.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>829 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     B02  B03  B04  B05  NDVI       X       Y    DOY     PID\n",
       "0    NaN  NaN  NaN  NaN   NaN  1550.0   975.0  211.0  5050.0\n",
       "1    NaN  NaN  NaN  NaN   NaN  1551.0   975.0  211.0  5150.0\n",
       "2    NaN  NaN  NaN  NaN   NaN  1552.0   975.0  211.0  5250.0\n",
       "3    NaN  NaN  NaN  NaN   NaN  1553.0   975.0  211.0  5350.0\n",
       "4    NaN  NaN  NaN  NaN   NaN  1554.0   975.0  211.0  5450.0\n",
       "..   ...  ...  ...  ...   ...     ...     ...    ...     ...\n",
       "824  NaN  NaN  NaN  NaN   NaN  1563.0  1015.0  211.0  6390.0\n",
       "825  NaN  NaN  NaN  NaN   NaN  1564.0  1015.0  211.0  6490.0\n",
       "826  NaN  NaN  NaN  NaN   NaN  1565.0  1015.0  211.0  6590.0\n",
       "827  NaN  NaN  NaN  NaN   NaN  1566.0  1015.0  211.0  6690.0\n",
       "828  NaN  NaN  NaN  NaN   NaN  1567.0  1015.0  211.0  6790.0\n",
       "\n",
       "[829 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B02</th>\n",
       "      <th>B03</th>\n",
       "      <th>B04</th>\n",
       "      <th>B05</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>DOY</th>\n",
       "      <th>PID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>333.0</td>\n",
       "      <td>722.0</td>\n",
       "      <td>563.0</td>\n",
       "      <td>4134.0</td>\n",
       "      <td>0.760273</td>\n",
       "      <td>1560.0</td>\n",
       "      <td>975.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>6050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>341.0</td>\n",
       "      <td>731.0</td>\n",
       "      <td>571.0</td>\n",
       "      <td>4168.0</td>\n",
       "      <td>0.759021</td>\n",
       "      <td>1561.0</td>\n",
       "      <td>975.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>6150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>334.0</td>\n",
       "      <td>735.0</td>\n",
       "      <td>554.0</td>\n",
       "      <td>4358.0</td>\n",
       "      <td>0.774430</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>975.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>6250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>308.0</td>\n",
       "      <td>707.0</td>\n",
       "      <td>503.0</td>\n",
       "      <td>4450.0</td>\n",
       "      <td>0.796891</td>\n",
       "      <td>1563.0</td>\n",
       "      <td>975.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>6350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>313.0</td>\n",
       "      <td>699.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>4221.0</td>\n",
       "      <td>0.783647</td>\n",
       "      <td>1564.0</td>\n",
       "      <td>975.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>6450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1666</th>\n",
       "      <td>372.0</td>\n",
       "      <td>677.0</td>\n",
       "      <td>698.0</td>\n",
       "      <td>2116.0</td>\n",
       "      <td>0.503909</td>\n",
       "      <td>1595.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>9599.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1667</th>\n",
       "      <td>372.0</td>\n",
       "      <td>696.0</td>\n",
       "      <td>702.0</td>\n",
       "      <td>2172.0</td>\n",
       "      <td>0.511482</td>\n",
       "      <td>1596.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>9699.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1668</th>\n",
       "      <td>348.0</td>\n",
       "      <td>655.0</td>\n",
       "      <td>657.0</td>\n",
       "      <td>2141.0</td>\n",
       "      <td>0.530379</td>\n",
       "      <td>1597.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>9799.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1669</th>\n",
       "      <td>339.0</td>\n",
       "      <td>631.0</td>\n",
       "      <td>633.0</td>\n",
       "      <td>2149.0</td>\n",
       "      <td>0.544932</td>\n",
       "      <td>1598.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>9899.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>346.0</td>\n",
       "      <td>643.0</td>\n",
       "      <td>644.0</td>\n",
       "      <td>2212.0</td>\n",
       "      <td>0.549020</td>\n",
       "      <td>1599.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>9999.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1671 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        B02    B03    B04     B05      NDVI       X       Y    DOY     PID\n",
       "0     333.0  722.0  563.0  4134.0  0.760273  1560.0   975.0  211.0  6050.0\n",
       "1     341.0  731.0  571.0  4168.0  0.759021  1561.0   975.0  211.0  6150.0\n",
       "2     334.0  735.0  554.0  4358.0  0.774430  1562.0   975.0  211.0  6250.0\n",
       "3     308.0  707.0  503.0  4450.0  0.796891  1563.0   975.0  211.0  6350.0\n",
       "4     313.0  699.0  512.0  4221.0  0.783647  1564.0   975.0  211.0  6450.0\n",
       "...     ...    ...    ...     ...       ...     ...     ...    ...     ...\n",
       "1666  372.0  677.0  698.0  2116.0  0.503909  1595.0  1024.0  211.0  9599.0\n",
       "1667  372.0  696.0  702.0  2172.0  0.511482  1596.0  1024.0  211.0  9699.0\n",
       "1668  348.0  655.0  657.0  2141.0  0.530379  1597.0  1024.0  211.0  9799.0\n",
       "1669  339.0  631.0  633.0  2149.0  0.544932  1598.0  1024.0  211.0  9899.0\n",
       "1670  346.0  643.0  644.0  2212.0  0.549020  1599.0  1024.0  211.0  9999.0\n",
       "\n",
       "[1671 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy version:1.26.1\n",
      "IMPUTE:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B02</th>\n",
       "      <th>B03</th>\n",
       "      <th>B04</th>\n",
       "      <th>PID</th>\n",
       "      <th>DOY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5050.0</td>\n",
       "      <td>211.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5150.0</td>\n",
       "      <td>211.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5250.0</td>\n",
       "      <td>211.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5350.0</td>\n",
       "      <td>211.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5450.0</td>\n",
       "      <td>211.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6390.0</td>\n",
       "      <td>211.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6490.0</td>\n",
       "      <td>211.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6590.0</td>\n",
       "      <td>211.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6690.0</td>\n",
       "      <td>211.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6790.0</td>\n",
       "      <td>211.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>829 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     B02  B03  B04     PID    DOY\n",
       "0    NaN  NaN  NaN  5050.0  211.0\n",
       "1    NaN  NaN  NaN  5150.0  211.0\n",
       "2    NaN  NaN  NaN  5250.0  211.0\n",
       "3    NaN  NaN  NaN  5350.0  211.0\n",
       "4    NaN  NaN  NaN  5450.0  211.0\n",
       "..   ...  ...  ...     ...    ...\n",
       "824  NaN  NaN  NaN  6390.0  211.0\n",
       "825  NaN  NaN  NaN  6490.0  211.0\n",
       "826  NaN  NaN  NaN  6590.0  211.0\n",
       "827  NaN  NaN  NaN  6690.0  211.0\n",
       "828  NaN  NaN  NaN  6790.0  211.0\n",
       "\n",
       "[829 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/829 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop_iter: ['DOY is 211.0, PID is 5050.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 5050.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '0', '.', '0', ',', '', 'B04', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/829 [00:01<16:27,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '0', '.', '0', ',', '', 'B04', 'is', '', '3', '8', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '2', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '6', '8', '0', ',', '', 'B04', 'is', '']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5050.0, B04 is 385.0, B02 is 229.0, B03 is 748.07680, B04 is ']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5150.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 5150.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '0', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '5', '0']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5150.0, B03 is 767.0, B04 is 546.0, B02 is 309.0 PID is B04 is 50']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 546.0, PID is 5150.0, B03 is 767.0, B02 is']\n",
      "prompt: DOY is 211.0, B04 is 546.0, PID is 5150.0, B03 is 767.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '3', '1', '9', '2', '.', '0', ',', '', 'PID']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 546.0, PID is 5150.0, B03 is 767.0, B02 is 309.03192.0, PID']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 767.0, B04 is 546.0, PID is 5150.0, B02 is']\n",
      "prompt: DOY is 211.0, B03 is 767.0, B04 is 546.0, PID is 5150.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '0', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '9', '6', '4', '.']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 767.0, B04 is 546.0, PID is 5150.0, B02 is 309.0 B04 is 5964.']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 767.0, DOY is 211.0, B04 is 546.0, PID is 5150.0, B02 is']\n",
      "prompt: B03 is 767.0, DOY is 211.0, B04 is 546.0, PID is 5150.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '0', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '2', '7']]\n",
      "decoded_data: ['B03 is 767.0, DOY is 211.0, B04 is 546.0, PID is 5150.0, B02 is 309.0 B04 is PID is 27']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5150.0, B03 is 767.0, DOY is 211.0, B04 is 546.0, B02 is']\n",
      "prompt: PID is 5150.0, B03 is 767.0, DOY is 211.0, B04 is 546.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '1', '5', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '1', '5', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '6', '5', '0', '9', '6', '1', '.', '0']]\n",
      "decoded_data: ['PID is 5150.0, B03 is 767.0, DOY is 211.0, B04 is 546.0, B02 is 309.06650961.0']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5150.0, B03 is 767.0, B04 is 546.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 5150.0, B03 is 767.0, B04 is 546.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '1', '5', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '1', '5', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '1', '6', '6', '6', '6', '6', '6', '1', '.']]\n",
      "decoded_data: ['PID is 5150.0, B03 is 767.0, B04 is 546.0, DOY is 211.0, B02 is 309.016666661.']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 767.0, PID is 5150.0, B04 is 546.0, B02 is']\n",
      "prompt: DOY is 211.0, B03 is 767.0, PID is 5150.0, B04 is 546.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '9', '5', '9', '3']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 767.0, PID is 5150.0, B04 is 546.0, B02 is 309.0 B04 is 59593']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 767.0, DOY is 211.0, B04 is 546.0, PID is 5150.0, B02 is']\n",
      "prompt: B03 is 767.0, DOY is 211.0, B04 is 546.0, PID is 5150.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '0', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '3', '1']]\n",
      "decoded_data: ['B03 is 767.0, DOY is 211.0, B04 is 546.0, PID is 5150.0, B02 is 309.0 B04 is PID is 31']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 546.0, PID is 5150.0, DOY is 211.0, B03 is 767.0, B02 is']\n",
      "prompt: B04 is 546.0, PID is 5150.0, DOY is 211.0, B03 is 767.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '4', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '4', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['B04 is 546.0, PID is 5150.0, DOY is 211.0, B03 is 767.0, B02 is 309.0 PID is B04 is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 546.0, PID is 5150.0, DOY is 211.0, B03 is 767.0, B02 is']\n",
      "prompt: B04 is 546.0, PID is 5150.0, DOY is 211.0, B03 is 767.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '4', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '4', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B03', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['B04 is 546.0, PID is 5150.0, DOY is 211.0, B03 is 767.0, B02 is 309.0 PID is B03 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 767.0, PID is 5150.0, B04 is 546.0, DOY is 211.0, B02 is']\n",
      "prompt: B03 is 767.0, PID is 5150.0, B04 is 546.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '6', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '6', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['B03 is 767.0, PID is 5150.0, B04 is 546.0, DOY is 211.0, B02 is 309.0 B04 is PID is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 546.0, B03 is 767.0, PID is 5150.0, B02 is']\n",
      "prompt: DOY is 211.0, B04 is 546.0, B03 is 767.0, PID is 5150.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '0', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '0', '9', '6', '.', '0', ',', '', 'B03']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 546.0, B03 is 767.0, PID is 5150.0, B02 is 309.05096.0, B03']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 767.0, PID is 5150.0, DOY is 211.0, B04 is 546.0, B02 is']\n",
      "prompt: B03 is 767.0, PID is 5150.0, DOY is 211.0, B04 is 546.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '6', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '6', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '0', '9', '6', '6', '.', '0', '9', '1', '.']]\n",
      "decoded_data: ['B03 is 767.0, PID is 5150.0, DOY is 211.0, B04 is 546.0, B02 is 309.00966.091.']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 546.0, DOY is 211.0, B03 is 767.0, PID is 5150.0, B02 is']\n",
      "prompt: B04 is 546.0, DOY is 211.0, B03 is 767.0, PID is 5150.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '4', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '0', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '4', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '0', '0', '.', '0', '9', '5', '9', '6']]\n",
      "decoded_data: ['B04 is 546.0, DOY is 211.0, B03 is 767.0, PID is 5150.0, B02 is 349.0500.09596']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 767.0, B04 is 546.0, DOY is 211.0, PID is 5150.0, B02 is']\n",
      "prompt: B03 is 767.0, B04 is 546.0, DOY is 211.0, PID is 5150.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '0', '.', '0', ',', '', 'B02', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      "  0%|          | 2/829 [00:03<25:15,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B03', 'is', '', '7', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '1', '.', '0', ',', '', 'B04', 'is', '']]\n",
      "decoded_data: ['B03 is 767.0, B04 is 546.0, DOY is 211.0, PID is 5150.0, B02 is 309.061.0, B04 is ']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5250.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 5250.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '0', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '8', '6', '6', '6']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5250.0, B02 is 331.0, B03 is 740.0, B04 is 566.0 PID is 58666']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 331.0, B03 is 740.0, PID is 5250.0, DOY is 211.0, B04 is']\n",
      "prompt: B02 is 331.0, B03 is 740.0, PID is 5250.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B02', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['B02 is 331.0, B03 is 740.0, PID is 5250.0, DOY is 211.0, B04 is 566.0 PID is B02 is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 331.0, B03 is 740.0, PID is 5250.0, B04 is']\n",
      "prompt: DOY is 211.0, B02 is 331.0, B03 is 740.0, PID is 5250.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '8', '6', '6', '.', '0', ',', '']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 331.0, B03 is 740.0, PID is 5250.0, B04 is 566.0 5866.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 331.0, PID is 5250.0, B03 is 740.0, B04 is']\n",
      "prompt: DOY is 211.0, B02 is 331.0, PID is 5250.0, B03 is 740.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '8', '6', '6', '6', '6', '.', '0', '.']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 331.0, PID is 5250.0, B03 is 740.0, B04 is 566.0586666.0.']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5250.0, B03 is 740.0, B02 is 331.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 5250.0, B03 is 740.0, B02 is 331.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '9', '6', '6', '6', '6', '6', '.']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5250.0, B03 is 740.0, B02 is 331.0, B04 is 566.0 5966666.']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 740.0, PID is 5250.0, B02 is 331.0, DOY is 211.0, B04 is']\n",
      "prompt: B03 is 740.0, PID is 5250.0, B02 is 331.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '4', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '4', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '8', '8', '6', '6', '6', '6', '.']]\n",
      "decoded_data: ['B03 is 740.0, PID is 5250.0, B02 is 331.0, DOY is 211.0, B04 is 566.0 5886666.']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 331.0, B03 is 740.0, DOY is 211.0, PID is 5250.0, B04 is']\n",
      "prompt: B02 is 331.0, B03 is 740.0, DOY is 211.0, PID is 5250.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '8', '.', '0', '.', '0', '.', '0']]\n",
      "decoded_data: ['B02 is 331.0, B03 is 740.0, DOY is 211.0, PID is 5250.0, B04 is 566.0 58.0.0.0']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 740.0, B02 is 331.0, PID is 5250.0, B04 is']\n",
      "prompt: DOY is 211.0, B03 is 740.0, B02 is 331.0, PID is 5250.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '1', '1', '.', '0', '.', '0', ',', '']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 740.0, B02 is 331.0, PID is 5250.0, B04 is 566.0511.0.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 331.0, DOY is 211.0, PID is 5250.0, B03 is 740.0, B04 is']\n",
      "prompt: B02 is 331.0, DOY is 211.0, PID is 5250.0, B03 is 740.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '8', '6', '6', '6']]\n",
      "decoded_data: ['B02 is 331.0, DOY is 211.0, PID is 5250.0, B03 is 740.0, B04 is 566.0 PID is 58666']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 331.0, B03 is 740.0, DOY is 211.0, PID is 5250.0, B04 is']\n",
      "prompt: B02 is 331.0, B03 is 740.0, DOY is 211.0, PID is 5250.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '8', '6', '6', '6', '.', '0', '.', '0']]\n",
      "decoded_data: ['B02 is 331.0, B03 is 740.0, DOY is 211.0, PID is 5250.0, B04 is 566.058666.0.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 740.0, DOY is 211.0, PID is 5250.0, B02 is 331.0, B04 is']\n",
      "prompt: B03 is 740.0, DOY is 211.0, PID is 5250.0, B02 is 331.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '4', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '4', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '8', '6', '6', '6', '6', '6', '.', '0']]\n",
      "decoded_data: ['B03 is 740.0, DOY is 211.0, PID is 5250.0, B02 is 331.0, B04 is 566.05866666.0']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5250.0, DOY is 211.0, B02 is 331.0, B03 is 740.0, B04 is']\n",
      "prompt: PID is 5250.0, DOY is 211.0, B02 is 331.0, B03 is 740.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '2', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '2', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '8', '7', '2', '1', '8', '6', '6']]\n",
      "decoded_data: ['PID is 5250.0, DOY is 211.0, B02 is 331.0, B03 is 740.0, B04 is 566.0 58721866']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 740.0, DOY is 211.0, B02 is 331.0, PID is 5250.0, B04 is']\n",
      "prompt: B03 is 740.0, DOY is 211.0, B02 is 331.0, PID is 5250.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '4', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '4', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '1', '8', '6', '6', '6', '.', '0']]\n",
      "decoded_data: ['B03 is 740.0, DOY is 211.0, B02 is 331.0, PID is 5250.0, B04 is 566.0 518666.0']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 740.0, B02 is 331.0, PID is 5250.0, B04 is']\n",
      "prompt: DOY is 211.0, B03 is 740.0, B02 is 331.0, PID is 5250.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '8', '6', '6', '6', '.', '0', '8']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 740.0, B02 is 331.0, PID is 5250.0, B04 is 566.0 58666.08']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 331.0, DOY is 211.0, B03 is 740.0, PID is 5250.0, B04 is']\n",
      "prompt: B02 is 331.0, DOY is 211.0, B03 is 740.0, PID is 5250.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '0', '.', '0', ',', '', 'B04', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      "  0%|          | 3/829 [00:05<27:43,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '1', '.', '0', '.', '0', '3', '3', '3']]\n",
      "decoded_data: ['B02 is 331.0, DOY is 211.0, B03 is 740.0, PID is 5250.0, B04 is 566.051.0.0333']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5350.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 5350.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '0', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '2', '9', '9', '9', '9', '9', '9', '9', '.']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5350.0, B03 is 748.0, B04 is 504.0, B02 is 299.029999999.']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 504.0, PID is 5350.0, DOY is 211.0, B03 is 748.0, B02 is']\n",
      "prompt: B04 is 504.0, PID is 5350.0, DOY is 211.0, B03 is 748.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '0', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '8', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '0', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '8', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '2', '9']]\n",
      "decoded_data: ['B04 is 504.0, PID is 5350.0, DOY is 211.0, B03 is 748.0, B02 is 299.0 PID is B04 is 29']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 504.0, DOY is 211.0, B03 is 748.0, PID is 5350.0, B02 is']\n",
      "prompt: B04 is 504.0, DOY is 211.0, B03 is 748.0, PID is 5350.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '0', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '0', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '0', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '0', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '9', '9', '9', '0', '.', '0', '.', '0', '.']]\n",
      "decoded_data: ['B04 is 504.0, DOY is 211.0, B03 is 748.0, PID is 5350.0, B02 is 299.09990.0.0.']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 504.0, B03 is 748.0, DOY is 211.0, PID is 5350.0, B02 is']\n",
      "prompt: B04 is 504.0, B03 is 748.0, DOY is 211.0, PID is 5350.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '0', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '0', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '0', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '0', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'PID', 'is', '', '5', '0']]\n",
      "decoded_data: ['B04 is 504.0, B03 is 748.0, DOY is 211.0, PID is 5350.0, B02 is 299.0 B03 is PID is 50']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 504.0, PID is 5350.0, DOY is 211.0, B03 is 748.0, B02 is']\n",
      "prompt: B04 is 504.0, PID is 5350.0, DOY is 211.0, B03 is 748.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '0', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '8', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '0', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '8', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', 'B03', 'is']]\n",
      "decoded_data: ['B04 is 504.0, PID is 5350.0, DOY is 211.0, B03 is 748.0, B02 is 299.0 PID is B04 is B03 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5350.0, B03 is 748.0, B04 is 504.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 5350.0, B03 is 748.0, B04 is 504.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '4', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '2', '9', '9', '9', '9', '9', '.', '0', '.']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5350.0, B03 is 748.0, B04 is 504.0, B02 is 299.0299999.0.']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5350.0, B04 is 504.0, B03 is 748.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 5350.0, B04 is 504.0, B03 is 748.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '3', '5', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '3', '5', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '2', '9', '9', '9', '9']]\n",
      "decoded_data: ['PID is 5350.0, B04 is 504.0, B03 is 748.0, DOY is 211.0, B02 is 299.0 PID is 29999']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5350.0, B04 is 504.0, B03 is 748.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 5350.0, B04 is 504.0, B03 is 748.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '3', '5', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '3', '5', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'PID', 'is', '', '2', '9']]\n",
      "decoded_data: ['PID is 5350.0, B04 is 504.0, B03 is 748.0, DOY is 211.0, B02 is 299.0 B03 is PID is 29']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 504.0, B03 is 748.0, PID is 5350.0, B02 is']\n",
      "prompt: DOY is 211.0, B04 is 504.0, B03 is 748.0, PID is 5350.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '0', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '0', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '2', '9', '9', '.', '0', '.', '0', ',']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 504.0, B03 is 748.0, PID is 5350.0, B02 is 299.0 299.0.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 748.0, DOY is 211.0, B04 is 504.0, PID is 5350.0, B02 is']\n",
      "prompt: B03 is 748.0, DOY is 211.0, B04 is 504.0, PID is 5350.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '4', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '0', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '4', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '0', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '2', '9', '9', '9', '9']]\n",
      "decoded_data: ['B03 is 748.0, DOY is 211.0, B04 is 504.0, PID is 5350.0, B02 is 299.0 PID is 29999']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5350.0, DOY is 211.0, B03 is 748.0, B04 is 504.0, B02 is']\n",
      "prompt: PID is 5350.0, DOY is 211.0, B03 is 748.0, B04 is 504.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '3', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '4', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '3', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '2', '9', '9', '9', '9']]\n",
      "decoded_data: ['PID is 5350.0, DOY is 211.0, B03 is 748.0, B04 is 504.0, B02 is 299.0 PID is 29999']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 748.0, B04 is 504.0, PID is 5350.0, B02 is']\n",
      "prompt: DOY is 211.0, B03 is 748.0, B04 is 504.0, PID is 5350.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '0', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '0', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '2', '.', '0', ',', '', 'PID', 'is', '']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 748.0, B04 is 504.0, PID is 5350.0, B02 is 299.0 2.0, PID is ']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 504.0, DOY is 211.0, PID is 5350.0, B03 is 748.0, B02 is']\n",
      "prompt: B04 is 504.0, DOY is 211.0, PID is 5350.0, B03 is 748.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '0', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '8', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '0', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '8', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '2', '9', '9', '9', '9']]\n",
      "decoded_data: ['B04 is 504.0, DOY is 211.0, PID is 5350.0, B03 is 748.0, B02 is 299.0 PID is 29999']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 504.0, PID is 5350.0, DOY is 211.0, B03 is 748.0, B02 is']\n",
      "prompt: B04 is 504.0, PID is 5350.0, DOY is 211.0, B03 is 748.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '0', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '8', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '0', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '8', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '2', '8', '8', '8', '8', '8', '2', '5']]\n",
      "decoded_data: ['B04 is 504.0, PID is 5350.0, DOY is 211.0, B03 is 748.0, B02 is 299.0 28888825']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5350.0, DOY is 211.0, B03 is 748.0, B04 is 504.0, B02 is']\n",
      "prompt: PID is 5350.0, DOY is 211.0, B03 is 748.0, B04 is 504.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '3', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '4', '.', '0', ',', '', 'B02', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      "  0%|          | 4/829 [00:07<28:53,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '5', '3', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '9', '9', '9', '9', '.', '0', '.', '0', '.']]\n",
      "decoded_data: ['PID is 5350.0, DOY is 211.0, B03 is 748.0, B04 is 504.0, B02 is 299.09999.0.0.']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5450.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 5450.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '4', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '4', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '3', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['PID is 5450.0, DOY is 211.0, B04 is 503.0, B02 is 301.0, B03 is 764.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 301.0, B04 is 503.0, DOY is 211.0, PID is 5450.0, B03 is']\n",
      "prompt: B02 is 301.0, B04 is 503.0, DOY is 211.0, PID is 5450.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '0', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '7', '9', '0', '4', '.']]\n",
      "decoded_data: ['B02 is 301.0, B04 is 503.0, DOY is 211.0, PID is 5450.0, B03 is 764.0 B04 is 7904.']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 301.0, B04 is 503.0, PID is 5450.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 301.0, B04 is 503.0, PID is 5450.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '0', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '9', '6', '.', '0', ',', '', 'B04', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 301.0, B04 is 503.0, PID is 5450.0, B03 is 764.0796.0, B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 503.0, B02 is 301.0, PID is 5450.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 503.0, B02 is 301.0, PID is 5450.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '0', '3', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '0', '3', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '9']]\n",
      "decoded_data: ['B04 is 503.0, B02 is 301.0, PID is 5450.0, DOY is 211.0, B03 is 764.0 B04 is PID is 79']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 301.0, PID is 5450.0, B04 is 503.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 301.0, PID is 5450.0, B04 is 503.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '9']]\n",
      "decoded_data: ['B02 is 301.0, PID is 5450.0, B04 is 503.0, DOY is 211.0, B03 is 764.0 B04 is PID is 79']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 301.0, DOY is 211.0, B04 is 503.0, PID is 5450.0, B03 is']\n",
      "prompt: B02 is 301.0, DOY is 211.0, B04 is 503.0, PID is 5450.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '0', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['B02 is 301.0, DOY is 211.0, B04 is 503.0, PID is 5450.0, B03 is 764.0 B04 is PID is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 503.0, PID is 5450.0, B02 is 301.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 503.0, PID is 5450.0, B02 is 301.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '0', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '0', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['B04 is 503.0, PID is 5450.0, B02 is 301.0, DOY is 211.0, B03 is 764.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 503.0, B02 is 301.0, PID is 5450.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 503.0, B02 is 301.0, PID is 5450.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '0', '3', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '0', '3', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '0', '9', '6', '4', '.', '0', '3', '9', '9']]\n",
      "decoded_data: ['B04 is 503.0, B02 is 301.0, PID is 5450.0, DOY is 211.0, B03 is 764.00964.0399']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 301.0, PID is 5450.0, DOY is 211.0, B04 is 503.0, B03 is']\n",
      "prompt: B02 is 301.0, PID is 5450.0, DOY is 211.0, B04 is 503.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '3', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 5/829 [00:09<25:31,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '9', '9', '9', '9', '6', '4', '0', '4']]\n",
      "decoded_data: ['B02 is 301.0, PID is 5450.0, DOY is 211.0, B04 is 503.0, B03 is 764.0799996404']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5550.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 5550.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '1', '3', '8', '.', '0', '1', '.', '0']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5550.0, B04 is 511.0, B02 is 291.0, B03 is 740.07138.01.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 511.0, PID is 5550.0, DOY is 211.0, B02 is 291.0, B03 is']\n",
      "prompt: B04 is 511.0, PID is 5550.0, DOY is 211.0, B02 is 291.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['B04 is 511.0, PID is 5550.0, DOY is 211.0, B02 is 291.0, B03 is 740.0 PID is B04 is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5550.0, B04 is 511.0, DOY is 211.0, B02 is 291.0, B03 is']\n",
      "prompt: PID is 5550.0, B04 is 511.0, DOY is 211.0, B02 is 291.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '5', '5', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '5', '5', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '1']]\n",
      "decoded_data: ['PID is 5550.0, B04 is 511.0, DOY is 211.0, B02 is 291.0, B03 is 740.0 B04 is PID is 71']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 511.0, DOY is 211.0, PID is 5550.0, B02 is 291.0, B03 is']\n",
      "prompt: B04 is 511.0, DOY is 211.0, PID is 5550.0, B02 is 291.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '1', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '0', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '1', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '0', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B02', 'is', '', 'B04', 'is', '', '2', '1']]\n",
      "decoded_data: ['B04 is 511.0, DOY is 211.0, PID is 5550.0, B02 is 291.0, B03 is 740.0 B02 is B04 is 21']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 511.0, B02 is 291.0, DOY is 211.0, PID is 5550.0, B03 is']\n",
      "prompt: B04 is 511.0, B02 is 291.0, DOY is 211.0, PID is 5550.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '0', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/829 [00:10<21:31,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B04', 'is', '', '5', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '4', '0', '1', '.', '0', '1', '.', '0']]\n",
      "decoded_data: ['B04 is 511.0, B02 is 291.0, DOY is 211.0, PID is 5550.0, B03 is 740.07401.01.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 511.0, PID is 5550.0, DOY is 211.0, B02 is 291.0, B03 is']\n",
      "prompt: B04 is 511.0, PID is 5550.0, DOY is 211.0, B02 is 291.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '1', '4', '0', '4', '0', '4', '0', '1']]\n",
      "decoded_data: ['B04 is 511.0, PID is 5550.0, DOY is 211.0, B02 is 291.0, B03 is 740.0714040401']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5650.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 5650.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '6', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '6', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '6', '1', '7', '1', '3', '6', '8', '.']]\n",
      "decoded_data: ['PID is 5650.0, DOY is 211.0, B02 is 333.0, B04 is 547.0, B03 is 717.076171368.']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5650.0, DOY is 211.0, B04 is 547.0, B02 is 333.0, B03 is']\n",
      "prompt: PID is 5650.0, DOY is 211.0, B04 is 547.0, B02 is 333.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '6', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '6', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '1', '7', '1', '7', '4', '.', '0', ',']]\n",
      "decoded_data: ['PID is 5650.0, DOY is 211.0, B04 is 547.0, B02 is 333.0, B03 is 717.0717174.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5650.0, DOY is 211.0, B04 is 547.0, B02 is 333.0, B03 is']\n",
      "prompt: PID is 5650.0, DOY is 211.0, B04 is 547.0, B02 is 333.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '6', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '6', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '1', '7', '1', '7', '1', '3', '.', '0']]\n",
      "decoded_data: ['PID is 5650.0, DOY is 211.0, B04 is 547.0, B02 is 333.0, B03 is 717.07171713.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 333.0, PID is 5650.0, DOY is 211.0, B04 is 547.0, B03 is']\n",
      "prompt: B02 is 333.0, PID is 5650.0, DOY is 211.0, B04 is 547.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '3', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '3', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '1']]\n",
      "decoded_data: ['B02 is 333.0, PID is 5650.0, DOY is 211.0, B04 is 547.0, B03 is 717.0 B04 is PID is 71']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 333.0, B04 is 547.0, PID is 5650.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 333.0, B04 is 547.0, PID is 5650.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '3', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '3', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '1', '8', '1', '8', '1', '8', '1', '.']]\n",
      "decoded_data: ['B02 is 333.0, B04 is 547.0, PID is 5650.0, DOY is 211.0, B03 is 717.071818181.']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 333.0, PID is 5650.0, B04 is 547.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 333.0, PID is 5650.0, B04 is 547.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '1', '7', '1', '7']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 333.0, PID is 5650.0, B04 is 547.0, B03 is 717.0 PID is 71717']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 547.0, DOY is 211.0, PID is 5650.0, B02 is 333.0, B03 is']\n",
      "prompt: B04 is 547.0, DOY is 211.0, PID is 5650.0, B02 is 333.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '2', '2', '.', '0', ',', '', 'PID', 'is']]\n",
      "decoded_data: ['B04 is 547.0, DOY is 211.0, PID is 5650.0, B02 is 333.0, B03 is 717.0722.0, PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 547.0, B02 is 333.0, PID is 5650.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 547.0, B02 is 333.0, PID is 5650.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '0', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B02', 'is', '', 'PID', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 547.0, B02 is 333.0, PID is 5650.0, B03 is 717.0 B02 is PID is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 333.0, B04 is 547.0, PID is 5650.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 333.0, B04 is 547.0, PID is 5650.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '0', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '2', '2', '.', '0', '9', '5', '6', '8', '1']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 333.0, B04 is 547.0, PID is 5650.0, B03 is 717.022.095681']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5650.0, B04 is 547.0, B02 is 333.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5650.0, B04 is 547.0, B02 is 333.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '6', '5', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '6', '5', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '2', '.', '0', '9', '5', '6', '7', '2']]\n",
      "decoded_data: ['PID is 5650.0, B04 is 547.0, B02 is 333.0, DOY is 211.0, B03 is 717.072.095672']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 547.0, DOY is 211.0, PID is 5650.0, B02 is 333.0, B03 is']\n",
      "prompt: B04 is 547.0, DOY is 211.0, PID is 5650.0, B02 is 333.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '1', '7', '1', '7', '1', '3', '.', '0']]\n",
      "decoded_data: ['B04 is 547.0, DOY is 211.0, PID is 5650.0, B02 is 333.0, B03 is 717.07171713.0']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5650.0, B04 is 547.0, B02 is 333.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5650.0, B04 is 547.0, B02 is 333.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '6', '5', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '6', '5', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '7', '1', '7', '1', '7', '1', '7', '1']]\n",
      "decoded_data: ['PID is 5650.0, B04 is 547.0, B02 is 333.0, DOY is 211.0, B03 is 717.0 71717171']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 333.0, PID is 5650.0, B04 is 547.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 333.0, PID is 5650.0, B04 is 547.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '3', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '3', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '7', '1', '7', '1', '.', '0', '9', '5']]\n",
      "decoded_data: ['B02 is 333.0, PID is 5650.0, B04 is 547.0, DOY is 211.0, B03 is 717.0 7171.095']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 333.0, B04 is 547.0, PID is 5650.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 333.0, B04 is 547.0, PID is 5650.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '3', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '3', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '1', '7', '1', '7', '1', '1', '.', '0']]\n",
      "decoded_data: ['B02 is 333.0, B04 is 547.0, PID is 5650.0, DOY is 211.0, B03 is 717.07171711.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 547.0, DOY is 211.0, PID is 5650.0, B02 is 333.0, B03 is']\n",
      "prompt: B04 is 547.0, DOY is 211.0, PID is 5650.0, B02 is 333.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '3', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      "  1%|          | 7/829 [00:12<24:40,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '1', '7', '2', '2']]\n",
      "decoded_data: ['B04 is 547.0, DOY is 211.0, PID is 5650.0, B02 is 333.0, B03 is 717.0 PID is 71722']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5750.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5750.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '7', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '7', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '0', '1', '2', '9', '8', '7', '1']]\n",
      "decoded_data: ['PID is 5750.0, DOY is 211.0, B03 is 704.0, B02 is 264.0, B04 is 457.0 40129871']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 264.0, PID is 5750.0, DOY is 211.0, B03 is 704.0, B04 is']\n",
      "prompt: B02 is 264.0, PID is 5750.0, DOY is 211.0, B03 is 704.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '6', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '4', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '6', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '4', '5', '7', '1', '2']]\n",
      "decoded_data: ['B02 is 264.0, PID is 5750.0, DOY is 211.0, B03 is 704.0, B04 is 457.0 PID is 45712']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 704.0, B02 is 264.0, DOY is 211.0, PID is 5750.0, B04 is']\n",
      "prompt: B03 is 704.0, B02 is 264.0, DOY is 211.0, PID is 5750.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '0', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '0', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '0', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '4', '0', '1', '.', '0', '1', '2', '9', 'B02']]\n",
      "decoded_data: ['B03 is 704.0, B02 is 264.0, DOY is 211.0, PID is 5750.0, B04 is 457.0401.0129B02']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 704.0, PID is 5750.0, B02 is 264.0, DOY is 211.0, B04 is']\n",
      "prompt: B03 is 704.0, PID is 5750.0, B02 is 264.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '0', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '0', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '0', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '0', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B02', 'is', '', '4']]\n",
      "decoded_data: ['B03 is 704.0, PID is 5750.0, B02 is 264.0, DOY is 211.0, B04 is 457.0 PID is B02 is 4']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 264.0, DOY is 211.0, B03 is 704.0, PID is 5750.0, B04 is']\n",
      "prompt: B02 is 264.0, DOY is 211.0, B03 is 704.0, PID is 5750.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '0', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '4', '.', '0', '1', '1', '2', '.', '0', ',']]\n",
      "decoded_data: ['B02 is 264.0, DOY is 211.0, B03 is 704.0, PID is 5750.0, B04 is 457.04.0112.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 704.0, B02 is 264.0, PID is 5750.0, DOY is 211.0, B04 is']\n",
      "prompt: B03 is 704.0, B02 is 264.0, PID is 5750.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '0', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '0', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '5', '7', '5', '7', '5', '7', '8']]\n",
      "decoded_data: ['B03 is 704.0, B02 is 264.0, PID is 5750.0, DOY is 211.0, B04 is 457.0 45757578']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 704.0, PID is 5750.0, DOY is 211.0, B02 is 264.0, B04 is']\n",
      "prompt: B03 is 704.0, PID is 5750.0, DOY is 211.0, B02 is 264.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '0', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '4', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '0', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '4', '.', '0', '1', '2', '9', '7', '1', '.']]\n",
      "decoded_data: ['B03 is 704.0, PID is 5750.0, DOY is 211.0, B02 is 264.0, B04 is 457.04.012971.']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 704.0, PID is 5750.0, DOY is 211.0, B02 is 264.0, B04 is']\n",
      "prompt: B03 is 704.0, PID is 5750.0, DOY is 211.0, B02 is 264.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '0', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '4', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '0', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '4', '5', '7', '1', '2']]\n",
      "decoded_data: ['B03 is 704.0, PID is 5750.0, DOY is 211.0, B02 is 264.0, B04 is 457.0 PID is 45712']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5750.0, B02 is 264.0, DOY is 211.0, B03 is 704.0, B04 is']\n",
      "prompt: PID is 5750.0, B02 is 264.0, DOY is 211.0, B03 is 704.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '7', '5', '0', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '4', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '7', '5', '0', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'PID', 'is', '', '4', '5']]\n",
      "decoded_data: ['PID is 5750.0, B02 is 264.0, DOY is 211.0, B03 is 704.0, B04 is 457.0 B03 is PID is 45']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 264.0, B03 is 704.0, PID is 5750.0, DOY is 211.0, B04 is']\n",
      "prompt: B02 is 264.0, B03 is 704.0, PID is 5750.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '4', '5', '7', '1', '2']]\n",
      "decoded_data: ['B02 is 264.0, B03 is 704.0, PID is 5750.0, DOY is 211.0, B04 is 457.0 PID is 45712']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5750.0, B03 is 704.0, DOY is 211.0, B02 is 264.0, B04 is']\n",
      "prompt: PID is 5750.0, B03 is 704.0, DOY is 211.0, B02 is 264.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '7', '5', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '4', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '7', '5', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '5', '7', '1', '2', '.', '0', '1']]\n",
      "decoded_data: ['PID is 5750.0, B03 is 704.0, DOY is 211.0, B02 is 264.0, B04 is 457.0 45712.01']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5750.0, B02 is 264.0, B03 is 704.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 5750.0, B02 is 264.0, B03 is 704.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '7', '5', '0', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '7', '5', '0', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B02', 'is', '', '4', '5']]\n",
      "decoded_data: ['PID is 5750.0, B02 is 264.0, B03 is 704.0, DOY is 211.0, B04 is 457.0 PID is B02 is 45']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 264.0, DOY is 211.0, B03 is 704.0, PID is 5750.0, B04 is']\n",
      "prompt: B02 is 264.0, DOY is 211.0, B03 is 704.0, PID is 5750.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '0', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '1', '.', '0', '.', '0', '.', '0', ',', '']]\n",
      "decoded_data: ['B02 is 264.0, DOY is 211.0, B03 is 704.0, PID is 5750.0, B04 is 457.01.0.0.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 704.0, DOY is 211.0, PID is 5750.0, B02 is 264.0, B04 is']\n",
      "prompt: B03 is 704.0, DOY is 211.0, PID is 5750.0, B02 is 264.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '0', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '0', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '4', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '0', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '0', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B02', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['B03 is 704.0, DOY is 211.0, PID is 5750.0, B02 is 264.0, B04 is 457.0 PID is B02 is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 264.0, B03 is 704.0, DOY is 211.0, PID is 5750.0, B04 is']\n",
      "prompt: B02 is 264.0, B03 is 704.0, DOY is 211.0, PID is 5750.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '0', '.', '0', ',', '', 'B04', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      "  1%|          | 8/829 [00:14<26:42,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B02', 'is', '', '2', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '0', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '.', '0', '1', '2', '.', '0', ',']]\n",
      "decoded_data: ['B02 is 264.0, B03 is 704.0, DOY is 211.0, PID is 5750.0, B04 is 457.0 4.012.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5850.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 5850.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '8', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '8', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '8', '0', '0', '.', '0', ',', '', 'B03', 'is', '', '9', '5', '8', '.', '0', ',', '', 'B02', 'is', '', '5', '6', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '3', '4', '3', '6', '9', '3', '2', '.', '0']]\n",
      "decoded_data: ['PID is 5850.0, DOY is 211.0, B04 is 800.0, B03 is 958.0, B02 is 563.03436932.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 800.0, PID is 5850.0, B03 is 958.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 800.0, PID is 5850.0, B03 is 958.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '8', '0', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '0', '.', '0', ',', '', 'B03', 'is', '', '9', '5', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '8', '0', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '0', '.', '0', ',', '', 'B03', 'is', '', '9', '5', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '5', '6', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '6', '3', '9', '3', '2', '.', '0', ',']]\n",
      "decoded_data: ['B04 is 800.0, PID is 5850.0, B03 is 958.0, DOY is 211.0, B02 is 563.0563932.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5850.0, B04 is 800.0, B03 is 958.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 5850.0, B04 is 800.0, B03 is 958.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '0', '.', '0', ',', '', 'B04', 'is', '', '8', '0', '0', '.', '0', ',', '', 'B03', 'is', '', '9', '5', '8', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '0', '.', '0', ',', '', 'B04', 'is', '', '8', '0', '0', '.', '0', ',', '', 'B03', 'is', '', '9', '5', '8', '.', '0', ',', '', 'B02', 'is', '', '5', '6', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '3', '4', '5', '6']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5850.0, B04 is 800.0, B03 is 958.0, B02 is 563.0 B04 is 53456']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 800.0, B03 is 958.0, PID is 5850.0, B02 is']\n",
      "prompt: DOY is 211.0, B04 is 800.0, B03 is 958.0, PID is 5850.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '8', '0', '0', '.', '0', ',', '', 'B03', 'is', '', '9', '5', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '0', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '8', '0', '0', '.', '0', ',', '', 'B03', 'is', '', '9', '5', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '0', '.', '0', ',', '', 'B02', 'is', '', '5', '6', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '0', '5', '6', '3']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 800.0, B03 is 958.0, PID is 5850.0, B02 is 563.0 PID is 50563']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 800.0, PID is 5850.0, B03 is 958.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 800.0, PID is 5850.0, B03 is 958.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '8', '0', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '0', '.', '0', ',', '', 'B03', 'is', '', '9', '5', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '8', '0', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '0', '.', '0', ',', '', 'B03', 'is', '', '9', '5', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '5', '6', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B02', 'is', '', '5', '3', '9', '3', '9']]\n",
      "decoded_data: ['B04 is 800.0, PID is 5850.0, B03 is 958.0, DOY is 211.0, B02 is 563.0 B02 is 53939']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 800.0, PID is 5850.0, B03 is 958.0, B02 is']\n",
      "prompt: DOY is 211.0, B04 is 800.0, PID is 5850.0, B03 is 958.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '8', '0', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '0', '.', '0', ',', '', 'B03', 'is', '', '9', '5', '8', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '8', '0', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '0', '.', '0', ',', '', 'B03', 'is', '', '9', '5', '8', '.', '0', ',', '', 'B02', 'is', '', '5', '6', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '6', '3', '.', '0']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 800.0, PID is 5850.0, B03 is 958.0, B02 is 563.0 B04 is 563.0']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 958.0, PID is 5850.0, B04 is 800.0, B02 is']\n",
      "prompt: DOY is 211.0, B03 is 958.0, PID is 5850.0, B04 is 800.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '9', '5', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '0', '.', '0', ',', '', 'B04', 'is', '', '8', '0', '0', '.', '0', ',', '', 'B02', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 9/829 [00:16<23:03,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '9', '5', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '0', '.', '0', ',', '', 'B04', 'is', '', '8', '0', '0', '.', '0', ',', '', 'B02', 'is', '', '5', '6', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '3', '2', '0', '1', '4', '3', '9', '3']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 958.0, PID is 5850.0, B04 is 800.0, B02 is 563.0532014393']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5950.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 5950.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '9', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '9', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '1', '6', '3', 'B02', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['PID is 5950.0, DOY is 211.0, B02 is 277.0, B04 is 458.0, B03 is 721.07163B02 is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 458.0, DOY is 211.0, PID is 5950.0, B02 is 277.0, B03 is']\n",
      "prompt: B04 is 458.0, DOY is 211.0, PID is 5950.0, B02 is 277.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '5', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '0', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '5', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '0', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '4', '5', '3', '5']]\n",
      "decoded_data: ['B04 is 458.0, DOY is 211.0, PID is 5950.0, B02 is 277.0, B03 is 721.0 PID is 74535']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 458.0, DOY is 211.0, B02 is 277.0, PID is 5950.0, B03 is']\n",
      "prompt: B04 is 458.0, DOY is 211.0, B02 is 277.0, PID is 5950.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '5', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '0', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '5', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '1', '5', '3', '.', '0', ',', '', 'PID']]\n",
      "decoded_data: ['B04 is 458.0, DOY is 211.0, B02 is 277.0, PID is 5950.0, B03 is 721.07153.0, PID']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 458.0, PID is 5950.0, DOY is 211.0, B02 is 277.0, B03 is']\n",
      "prompt: B04 is 458.0, PID is 5950.0, DOY is 211.0, B02 is 277.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '5', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '5', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '3', '5', '3', '.']]\n",
      "decoded_data: ['B04 is 458.0, PID is 5950.0, DOY is 211.0, B02 is 277.0, B03 is 721.0 B04 is 5353.']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 458.0, B02 is 277.0, DOY is 211.0, PID is 5950.0, B03 is']\n",
      "prompt: B04 is 458.0, B02 is 277.0, DOY is 211.0, PID is 5950.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '5', '8', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '0', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '5', '8', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '4']]\n",
      "decoded_data: ['B04 is 458.0, B02 is 277.0, DOY is 211.0, PID is 5950.0, B03 is 721.0 B04 is PID is 74']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 458.0, B02 is 277.0, PID is 5950.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 458.0, B02 is 277.0, PID is 5950.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '8', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '0', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '8', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '6']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 458.0, B02 is 277.0, PID is 5950.0, B03 is 721.0 B04 is PID is 76']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 277.0, PID is 5950.0, DOY is 211.0, B04 is 458.0, B03 is']\n",
      "prompt: B02 is 277.0, PID is 5950.0, DOY is 211.0, B04 is 458.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '3', '8', '4', '0']]\n",
      "decoded_data: ['B02 is 277.0, PID is 5950.0, DOY is 211.0, B04 is 458.0, B03 is 721.0 B04 is 53840']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5950.0, B02 is 277.0, DOY is 211.0, B04 is 458.0, B03 is']\n",
      "prompt: PID is 5950.0, B02 is 277.0, DOY is 211.0, B04 is 458.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '9', '5', '0', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '9', '5', '0', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '4', '0', '3', '5', '1', '7', '1', '.']]\n",
      "decoded_data: ['PID is 5950.0, B02 is 277.0, DOY is 211.0, B04 is 458.0, B03 is 721.074035171.']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 277.0, B04 is 458.0, PID is 5950.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 277.0, B04 is 458.0, PID is 5950.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '0', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', '4', '5']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 277.0, B04 is 458.0, PID is 5950.0, B03 is 721.0 B04 is B04 is 45']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 277.0, B04 is 458.0, PID is 5950.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 277.0, B04 is 458.0, PID is 5950.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '0', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '6']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 277.0, B04 is 458.0, PID is 5950.0, B03 is 721.0 B04 is PID is 76']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 458.0, PID is 5950.0, B02 is 277.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 458.0, PID is 5950.0, B02 is 277.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '0', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '0', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '2', '1', '7', 'B03']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 458.0, PID is 5950.0, B02 is 277.0, B03 is 721.0 PID is 7217B03']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 277.0, PID is 5950.0, DOY is 211.0, B04 is 458.0, B03 is']\n",
      "prompt: B02 is 277.0, PID is 5950.0, DOY is 211.0, B04 is 458.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '2', '1', '4', '0', '3', '9', '1', '.']]\n",
      "decoded_data: ['B02 is 277.0, PID is 5950.0, DOY is 211.0, B04 is 458.0, B03 is 721.072140391.']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 458.0, B02 is 277.0, PID is 5950.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 458.0, B02 is 277.0, PID is 5950.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '8', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '0', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '8', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B02', 'is', '', '7', '7']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 458.0, B02 is 277.0, PID is 5950.0, B03 is 721.0 PID is B02 is 77']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5950.0, DOY is 211.0, B04 is 458.0, B02 is 277.0, B03 is']\n",
      "prompt: PID is 5950.0, DOY is 211.0, B04 is 458.0, B02 is 277.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '9', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '8', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '9', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '8', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '1', '6', '0', '3', '5', '3', 'B02', 'is']]\n",
      "decoded_data: ['PID is 5950.0, DOY is 211.0, B04 is 458.0, B02 is 277.0, B03 is 721.07160353B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 277.0, PID is 5950.0, B04 is 458.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 277.0, PID is 5950.0, B04 is 458.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '0', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '8', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      "  1%|          | 10/829 [00:18<25:15,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '0', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '1', '0', '3', '9']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 277.0, PID is 5950.0, B04 is 458.0, B03 is 721.0 B04 is 51039']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5051.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 5051.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '0', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '0', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B02', 'is', '', '5', '5']]\n",
      "decoded_data: ['PID is 5051.0, DOY is 211.0, B02 is 290.0, B03 is 740.0, B04 is 551.0 PID is B02 is 55']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5051.0, B02 is 290.0, B03 is 740.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 5051.0, B02 is 290.0, B03 is 740.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', '5', '1', '7', '1', '0']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5051.0, B02 is 290.0, B03 is 740.0, B04 is 551.0 B03 is 51710']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 290.0, PID is 5051.0, B03 is 740.0, B04 is']\n",
      "prompt: DOY is 211.0, B02 is 290.0, PID is 5051.0, B03 is 740.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '1', '7', '1', '7']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 290.0, PID is 5051.0, B03 is 740.0, B04 is 551.0 PID is 51717']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 740.0, DOY is 211.0, PID is 5051.0, B02 is 290.0, B04 is']\n",
      "prompt: B03 is 740.0, DOY is 211.0, PID is 5051.0, B02 is 290.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '4', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '4', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '1', '1', '.', '0', '1', '7', '1']]\n",
      "decoded_data: ['B03 is 740.0, DOY is 211.0, PID is 5051.0, B02 is 290.0, B04 is 551.0 511.0171']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5051.0, B03 is 740.0, B02 is 290.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 5051.0, B03 is 740.0, B02 is 290.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '0', '5', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '0', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '0', '5', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '0', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '1', '7', '1', '5']]\n",
      "decoded_data: ['PID is 5051.0, B03 is 740.0, B02 is 290.0, DOY is 211.0, B04 is 551.0 PID is 51715']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 290.0, PID is 5051.0, B03 is 740.0, DOY is 211.0, B04 is']\n",
      "prompt: B02 is 290.0, PID is 5051.0, B03 is 740.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '1', '5', '1', '0']]\n",
      "decoded_data: ['B02 is 290.0, PID is 5051.0, B03 is 740.0, DOY is 211.0, B04 is 551.0 PID is 51510']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 740.0, B02 is 290.0, PID is 5051.0, B04 is']\n",
      "prompt: DOY is 211.0, B03 is 740.0, B02 is 290.0, PID is 5051.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '0', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '0', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '1', '.', '0', ',', '', '5', '1', '.']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 740.0, B02 is 290.0, PID is 5051.0, B04 is 551.051.0, 51.']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5051.0, B02 is 290.0, B03 is 740.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 5051.0, B02 is 290.0, B03 is 740.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '0', '5', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '0', '5', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '1', '.', '0', ',', '', 'PID', 'is']]\n",
      "decoded_data: ['PID is 5051.0, B02 is 290.0, B03 is 740.0, DOY is 211.0, B04 is 551.0 51.0, PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 290.0, PID is 5051.0, DOY is 211.0, B03 is 740.0, B04 is']\n",
      "prompt: B02 is 290.0, PID is 5051.0, DOY is 211.0, B03 is 740.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '1', '.', '0', ',', '', 'PID', 'is']]\n",
      "decoded_data: ['B02 is 290.0, PID is 5051.0, DOY is 211.0, B03 is 740.0, B04 is 551.0 51.0, PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 290.0, B03 is 740.0, DOY is 211.0, PID is 5051.0, B04 is']\n",
      "prompt: B02 is 290.0, B03 is 740.0, DOY is 211.0, PID is 5051.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'DOY', 'is', '', '5', '1', '.', '0', '2']]\n",
      "decoded_data: ['B02 is 290.0, B03 is 740.0, DOY is 211.0, PID is 5051.0, B04 is 551.0 DOY is 51.02']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5051.0, B02 is 290.0, B03 is 740.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 5051.0, B02 is 290.0, B03 is 740.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '0', '5', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '0', '5', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '5', '1', '4', '8']]\n",
      "decoded_data: ['PID is 5051.0, B02 is 290.0, B03 is 740.0, DOY is 211.0, B04 is 551.0 PID is 55148']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 290.0, PID is 5051.0, B03 is 740.0, DOY is 211.0, B04 is']\n",
      "prompt: B02 is 290.0, PID is 5051.0, B03 is 740.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '1', '.', '0', '7', '1', '7', '1']]\n",
      "decoded_data: ['B02 is 290.0, PID is 5051.0, B03 is 740.0, DOY is 211.0, B04 is 551.0 51.07171']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 290.0, PID is 5051.0, DOY is 211.0, B03 is 740.0, B04 is']\n",
      "prompt: B02 is 290.0, PID is 5051.0, DOY is 211.0, B03 is 740.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '0', '.', '0', ',', '', 'B04', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 11/829 [00:20<26:13,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '1', '7', '1', '.', '0', ',', '']]\n",
      "decoded_data: ['B02 is 290.0, PID is 5051.0, DOY is 211.0, B03 is 740.0, B04 is 551.0 5171.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5051.0, DOY is 211.0, B03 is 740.0, B02 is 290.0, B04 is']\n",
      "prompt: PID is 5051.0, DOY is 211.0, B03 is 740.0, B02 is 290.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '0', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '0', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '0', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '0', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', ',', '', 'PID', 'is', '', '5', '1', '.', '0']]\n",
      "decoded_data: ['PID is 5051.0, DOY is 211.0, B03 is 740.0, B02 is 290.0, B04 is 551.0, PID is 51.0']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5151.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5151.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '1', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 12/829 [00:20<20:02,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '5', '1', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'B04', 'is', '', '5', '6']]\n",
      "decoded_data: ['PID is 5151.0, DOY is 211.0, B03 is 761.0, B04 is 560.0, B02 is 304.0 B03 is B04 is 56']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 560.0, PID is 5151.0, DOY is 211.0, B03 is 761.0, B02 is']\n",
      "prompt: B04 is 560.0, PID is 5151.0, DOY is 211.0, B03 is 761.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '6', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '6', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '0', '4', '0', '4', '0', '7', '7', '7', '7']]\n",
      "decoded_data: ['B04 is 560.0, PID is 5151.0, DOY is 211.0, B03 is 761.0, B02 is 304.0040407777']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5251.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 5251.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '2', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '2', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '1', '8', '0', '1']]\n",
      "decoded_data: ['PID is 5251.0, DOY is 211.0, B02 is 307.0, B04 is 548.0, B03 is 771.0 PID is 71801']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 307.0, DOY is 211.0, PID is 5251.0, B04 is 548.0, B03 is']\n",
      "prompt: B02 is 307.0, DOY is 211.0, PID is 5251.0, B04 is 548.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '0', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '0', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B02', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['B02 is 307.0, DOY is 211.0, PID is 5251.0, B04 is 548.0, B03 is 771.0 PID is B02 is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 548.0, DOY is 211.0, PID is 5251.0, B02 is 307.0, B03 is']\n",
      "prompt: B04 is 548.0, DOY is 211.0, PID is 5251.0, B02 is 307.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '4', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '4', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '1', '8', '7', '1']]\n",
      "decoded_data: ['B04 is 548.0, DOY is 211.0, PID is 5251.0, B02 is 307.0, B03 is 771.0 PID is 71871']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 307.0, B04 is 548.0, DOY is 211.0, PID is 5251.0, B03 is']\n",
      "prompt: B02 is 307.0, B04 is 548.0, DOY is 211.0, PID is 5251.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '0', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '0', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '6']]\n",
      "decoded_data: ['B02 is 307.0, B04 is 548.0, DOY is 211.0, PID is 5251.0, B03 is 771.0 B04 is PID is 76']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 548.0, B02 is 307.0, PID is 5251.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 548.0, B02 is 307.0, PID is 5251.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '4', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '4', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '7', '1', '.', '0', '1']]\n",
      "decoded_data: ['B04 is 548.0, B02 is 307.0, PID is 5251.0, DOY is 211.0, B03 is 771.0 B04 is 71.01']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5251.0, B04 is 548.0, B02 is 307.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 5251.0, B04 is 548.0, B02 is 307.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '7', '1']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5251.0, B04 is 548.0, B02 is 307.0, B03 is 771.0 PID is B04 is 71']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5251.0, DOY is 211.0, B04 is 548.0, B02 is 307.0, B03 is']\n",
      "prompt: PID is 5251.0, DOY is 211.0, B04 is 548.0, B02 is 307.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '2', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '2', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B02', 'is', '', 'DOY', 'is']]\n",
      "decoded_data: ['PID is 5251.0, DOY is 211.0, B04 is 548.0, B02 is 307.0, B03 is 771.0 B04 is B02 is DOY is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 307.0, B04 is 548.0, PID is 5251.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 307.0, B04 is 548.0, PID is 5251.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '0', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '0', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '1', '8', '4', '0']]\n",
      "decoded_data: ['B02 is 307.0, B04 is 548.0, PID is 5251.0, DOY is 211.0, B03 is 771.0 PID is 71840']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5251.0, DOY is 211.0, B02 is 307.0, B04 is 548.0, B03 is']\n",
      "prompt: PID is 5251.0, DOY is 211.0, B02 is 307.0, B04 is 548.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '2', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '2', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '4', '9', '5', '2']]\n",
      "decoded_data: ['PID is 5251.0, DOY is 211.0, B02 is 307.0, B04 is 548.0, B03 is 771.0 B04 is 54952']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 548.0, B02 is 307.0, DOY is 211.0, PID is 5251.0, B03 is']\n",
      "prompt: B04 is 548.0, B02 is 307.0, DOY is 211.0, PID is 5251.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '4', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '4', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '7', '1', '8', '0', '4', '9', '5', '4']]\n",
      "decoded_data: ['B04 is 548.0, B02 is 307.0, DOY is 211.0, PID is 5251.0, B03 is 771.0 71804954']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5251.0, B02 is 307.0, DOY is 211.0, B04 is 548.0, B03 is']\n",
      "prompt: PID is 5251.0, B02 is 307.0, DOY is 211.0, B04 is 548.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '2', '5', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '2', '5', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '5', '4']]\n",
      "decoded_data: ['PID is 5251.0, B02 is 307.0, DOY is 211.0, B04 is 548.0, B03 is 771.0 PID is B04 is 54']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 548.0, DOY is 211.0, B02 is 307.0, PID is 5251.0, B03 is']\n",
      "prompt: B04 is 548.0, DOY is 211.0, B02 is 307.0, PID is 5251.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '4', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '4', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '1', '.', '0', '4', '0', '9', '5', '3']]\n",
      "decoded_data: ['B04 is 548.0, DOY is 211.0, B02 is 307.0, PID is 5251.0, B03 is 771.071.040953']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5251.0, B04 is 548.0, DOY is 211.0, B02 is 307.0, B03 is']\n",
      "prompt: PID is 5251.0, B04 is 548.0, DOY is 211.0, B02 is 307.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '2', '5', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '2', '5', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '1']]\n",
      "decoded_data: ['PID is 5251.0, B04 is 548.0, DOY is 211.0, B02 is 307.0, B03 is 771.0 B04 is PID is 71']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5251.0, DOY is 211.0, B02 is 307.0, B04 is 548.0, B03 is']\n",
      "prompt: PID is 5251.0, DOY is 211.0, B02 is 307.0, B04 is 548.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '2', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '2', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '1']]\n",
      "decoded_data: ['PID is 5251.0, DOY is 211.0, B02 is 307.0, B04 is 548.0, B03 is 771.0 B04 is PID is 71']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 307.0, PID is 5251.0, DOY is 211.0, B04 is 548.0, B03 is']\n",
      "prompt: B02 is 307.0, PID is 5251.0, DOY is 211.0, B04 is 548.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '0', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '8', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      "  2%|         | 13/829 [00:22<23:04,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B02', 'is', '', '3', '0', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '1', '8', '1', '8']]\n",
      "decoded_data: ['B02 is 307.0, PID is 5251.0, DOY is 211.0, B04 is 548.0, B03 is 771.0 PID is 71818']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5351.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 5351.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '3', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '3', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'DOY', 'is']]\n",
      "decoded_data: ['PID is 5351.0, DOY is 211.0, B02 is 290.0, B04 is 517.0, B03 is 760.0 B04 is PID is DOY is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 290.0, PID is 5351.0, B04 is 517.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 290.0, PID is 5351.0, B04 is 517.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '3', '6', '0', '2']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 290.0, PID is 5351.0, B04 is 517.0, B03 is 760.0 PID is 73602']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 290.0, PID is 5351.0, DOY is 211.0, B04 is 517.0, B03 is']\n",
      "prompt: B02 is 290.0, PID is 5351.0, DOY is 211.0, B04 is 517.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '7', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 14/829 [00:23<18:28,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '3', '6', '0', '3', '6', '7', '7', '3']]\n",
      "decoded_data: ['B02 is 290.0, PID is 5351.0, DOY is 211.0, B04 is 517.0, B03 is 760.0736036773']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5451.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 5451.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '4', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 15/829 [00:23<14:02,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '5', '4', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '2', '7', '8', '1', '8', '4', '7', '5']]\n",
      "decoded_data: ['PID is 5451.0, DOY is 211.0, B02 is 327.0, B04 is 507.0, B03 is 752.0527818475']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5551.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 5551.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '4', '5', '4', '5']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5551.0, B02 is 290.0, B04 is 514.0, B03 is 754.0 B04 is 54545']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5551.0, B04 is 514.0, DOY is 211.0, B02 is 290.0, B03 is']\n",
      "prompt: PID is 5551.0, B04 is 514.0, DOY is 211.0, B02 is 290.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '5', '5', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '5', '5', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['PID is 5551.0, B04 is 514.0, DOY is 211.0, B02 is 290.0, B03 is 754.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 290.0, PID is 5551.0, B04 is 514.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 290.0, PID is 5551.0, B04 is 514.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '4', '7', '1', '0', '5', '4', '.', '0']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 290.0, PID is 5551.0, B04 is 514.0, B03 is 754.05471054.0']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5551.0, B04 is 514.0, DOY is 211.0, B02 is 290.0, B03 is']\n",
      "prompt: PID is 5551.0, B04 is 514.0, DOY is 211.0, B02 is 290.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '5', '5', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '5', '5', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['PID is 5551.0, B04 is 514.0, DOY is 211.0, B02 is 290.0, B03 is 754.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 290.0, B04 is 514.0, PID is 5551.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 290.0, B04 is 514.0, PID is 5551.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '1', '5', '4', '.', '0', '2', '6', '.']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 290.0, B04 is 514.0, PID is 5551.0, B03 is 754.07154.026.']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 514.0, DOY is 211.0, B02 is 290.0, PID is 5551.0, B03 is']\n",
      "prompt: B04 is 514.0, DOY is 211.0, B02 is 290.0, PID is 5551.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '1', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '1', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '4', '7', '1', '.', '0', ',', '', 'B04']]\n",
      "decoded_data: ['B04 is 514.0, DOY is 211.0, B02 is 290.0, PID is 5551.0, B03 is 754.05471.0, B04']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 290.0, B04 is 514.0, DOY is 211.0, PID is 5551.0, B03 is']\n",
      "prompt: B02 is 290.0, B04 is 514.0, DOY is 211.0, PID is 5551.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '7', '.', '0', ',', '', 'B04', 'is', '']]\n",
      "decoded_data: ['B02 is 290.0, B04 is 514.0, DOY is 211.0, PID is 5551.0, B03 is 754.077.0, B04 is ']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5551.0, B02 is 290.0, B04 is 514.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5551.0, B02 is 290.0, B04 is 514.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '5', '5', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '5', '5', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '4', '.', '0', '5', '4', '5', '4', '.']]\n",
      "decoded_data: ['PID is 5551.0, B02 is 290.0, B04 is 514.0, DOY is 211.0, B03 is 754.054.05454.']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5551.0, B02 is 290.0, B04 is 514.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5551.0, B02 is 290.0, B04 is 514.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '5', '5', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '5', '5', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', '5', '4']]\n",
      "decoded_data: ['PID is 5551.0, B02 is 290.0, B04 is 514.0, DOY is 211.0, B03 is 754.0 B04 is B04 is 54']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 290.0, PID is 5551.0, DOY is 211.0, B04 is 514.0, B03 is']\n",
      "prompt: B02 is 290.0, PID is 5551.0, DOY is 211.0, B04 is 514.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '5', '4', '7', '9', '5', '4', '.', '0']]\n",
      "decoded_data: ['B02 is 290.0, PID is 5551.0, DOY is 211.0, B04 is 514.0, B03 is 754.07547954.0']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 514.0, PID is 5551.0, B02 is 290.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 514.0, PID is 5551.0, B02 is 290.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '5', '4', '0', '5']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 514.0, PID is 5551.0, B02 is 290.0, B03 is 754.0 PID is 75405']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 514.0, B02 is 290.0, PID is 5551.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 514.0, B02 is 290.0, PID is 5551.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 514.0, B02 is 290.0, PID is 5551.0, B03 is 754.0 PID is B04 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 290.0, DOY is 211.0, PID is 5551.0, B04 is 514.0, B03 is']\n",
      "prompt: B02 is 290.0, DOY is 211.0, PID is 5551.0, B04 is 514.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '7', '1', '.', '0', '5', '4', '0', '5']]\n",
      "decoded_data: ['B02 is 290.0, DOY is 211.0, PID is 5551.0, B04 is 514.0, B03 is 754.0 71.05405']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5551.0, B02 is 290.0, DOY is 211.0, B04 is 514.0, B03 is']\n",
      "prompt: PID is 5551.0, B02 is 290.0, DOY is 211.0, B04 is 514.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '5', '5', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '5', '5', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '4', '5', '4', '5', '4', '5', '4', '.']]\n",
      "decoded_data: ['PID is 5551.0, B02 is 290.0, DOY is 211.0, B04 is 514.0, B03 is 754.054545454.']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 290.0, PID is 5551.0, B04 is 514.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 290.0, PID is 5551.0, B04 is 514.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '4', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      "  2%|         | 16/829 [00:26<19:08,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 290.0, PID is 5551.0, B04 is 514.0, B03 is 754.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5651.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 5651.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '6', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '6', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['PID is 5651.0, DOY is 211.0, B04 is 524.0, B02 is 288.0, B03 is 752.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 524.0, B02 is 288.0, DOY is 211.0, PID is 5651.0, B03 is']\n",
      "prompt: B04 is 524.0, B02 is 288.0, DOY is 211.0, PID is 5651.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '2', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '2', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'DOY', 'is', '', 'B02', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['B04 is 524.0, B02 is 288.0, DOY is 211.0, PID is 5651.0, B03 is 752.0 DOY is B02 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 288.0, PID is 5651.0, DOY is 211.0, B04 is 524.0, B03 is']\n",
      "prompt: B02 is 288.0, PID is 5651.0, DOY is 211.0, B04 is 524.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '3', '9', '5', '2']]\n",
      "decoded_data: ['B02 is 288.0, PID is 5651.0, DOY is 211.0, B04 is 524.0, B03 is 752.0 B04 is 53952']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 524.0, B02 is 288.0, DOY is 211.0, PID is 5651.0, B03 is']\n",
      "prompt: B04 is 524.0, B02 is 288.0, DOY is 211.0, PID is 5651.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '2', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '2', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '5']]\n",
      "decoded_data: ['B04 is 524.0, B02 is 288.0, DOY is 211.0, PID is 5651.0, B03 is 752.0 B04 is PID is 75']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5651.0, B04 is 524.0, B02 is 288.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 5651.0, B04 is 524.0, B02 is 288.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', '5', '2']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5651.0, B04 is 524.0, B02 is 288.0, B03 is 752.0 B04 is B04 is 52']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5651.0, B04 is 524.0, B02 is 288.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5651.0, B04 is 524.0, B02 is 288.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '6', '5', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '6', '5', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '5']]\n",
      "decoded_data: ['PID is 5651.0, B04 is 524.0, B02 is 288.0, DOY is 211.0, B03 is 752.0 B04 is PID is 75']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5651.0, B04 is 524.0, B02 is 288.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 5651.0, B04 is 524.0, B02 is 288.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5651.0, B04 is 524.0, B02 is 288.0, B03 is 752.0 B04 is B04 is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5651.0, B04 is 524.0, DOY is 211.0, B02 is 288.0, B03 is']\n",
      "prompt: PID is 5651.0, B04 is 524.0, DOY is 211.0, B02 is 288.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '6', '5', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '6', '5', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '5']]\n",
      "decoded_data: ['PID is 5651.0, B04 is 524.0, DOY is 211.0, B02 is 288.0, B03 is 752.0 B04 is PID is 75']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 524.0, PID is 5651.0, DOY is 211.0, B02 is 288.0, B03 is']\n",
      "prompt: B04 is 524.0, PID is 5651.0, DOY is 211.0, B02 is 288.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '2', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '2', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '5', '2', '7', '5']]\n",
      "decoded_data: ['B04 is 524.0, PID is 5651.0, DOY is 211.0, B02 is 288.0, B03 is 752.0 PID is 75275']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5651.0, B04 is 524.0, B02 is 288.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5651.0, B04 is 524.0, B02 is 288.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '6', '5', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '6', '5', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '7', '5', '2', '4', '0']]\n",
      "decoded_data: ['PID is 5651.0, B04 is 524.0, B02 is 288.0, DOY is 211.0, B03 is 752.0 B04 is 75240']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 288.0, PID is 5651.0, B04 is 524.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 288.0, PID is 5651.0, B04 is 524.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '2', '.', '0', '8']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 288.0, PID is 5651.0, B04 is 524.0, B03 is 752.0 B04 is 52.08']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 524.0, B02 is 288.0, PID is 5651.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 524.0, B02 is 288.0, PID is 5651.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '8', '1', '.', '0', ',', '', 'PID', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 524.0, B02 is 288.0, PID is 5651.0, B03 is 752.0781.0, PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5651.0, B02 is 288.0, DOY is 211.0, B04 is 524.0, B03 is']\n",
      "prompt: PID is 5651.0, B02 is 288.0, DOY is 211.0, B04 is 524.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '6', '5', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '6', '5', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '7', '5', '2', '4', '0']]\n",
      "decoded_data: ['PID is 5651.0, B02 is 288.0, DOY is 211.0, B04 is 524.0, B03 is 752.0 B04 is 75240']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 524.0, PID is 5651.0, B02 is 288.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 524.0, PID is 5651.0, B02 is 288.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '2', '.', '0', ',', '', 'PID', 'is', '']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 524.0, PID is 5651.0, B02 is 288.0, B03 is 752.052.0, PID is ']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5651.0, B04 is 524.0, B02 is 288.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5651.0, B04 is 524.0, B02 is 288.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '6', '5', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      "  2%|         | 17/829 [00:28<22:23,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '5', '6', '5', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '2', '5', '2', '.', '0', ',', '', 'B04']]\n",
      "decoded_data: ['PID is 5651.0, B04 is 524.0, B02 is 288.0, DOY is 211.0, B03 is 752.05252.0, B04']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5751.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 5751.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '0', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B03', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5751.0, B04 is 511.0, B03 is 750.0, B02 is 284.0 B04 is B03 is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5751.0, B03 is 750.0, DOY is 211.0, B04 is 511.0, B02 is']\n",
      "prompt: PID is 5751.0, B03 is 750.0, DOY is 211.0, B04 is 511.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '7', '5', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '7', '5', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '5', '1']]\n",
      "decoded_data: ['PID is 5751.0, B03 is 750.0, DOY is 211.0, B04 is 511.0, B02 is 284.0 PID is B04 is 51']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 750.0, PID is 5751.0, B04 is 511.0, DOY is 211.0, B02 is']\n",
      "prompt: B03 is 750.0, PID is 5751.0, B04 is 511.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '5', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '5', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '5', '4']]\n",
      "decoded_data: ['B03 is 750.0, PID is 5751.0, B04 is 511.0, DOY is 211.0, B02 is 284.0 PID is B04 is 54']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 750.0, B04 is 511.0, DOY is 211.0, PID is 5751.0, B02 is']\n",
      "prompt: B03 is 750.0, B04 is 511.0, DOY is 211.0, PID is 5751.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '5', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '5', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'B04', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['B03 is 750.0, B04 is 511.0, DOY is 211.0, PID is 5751.0, B02 is 284.0 B03 is B04 is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5751.0, B03 is 750.0, B04 is 511.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 5751.0, B03 is 750.0, B04 is 511.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '7', '5', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 18/829 [00:29<19:38,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '5', '7', '5', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '7', '5', 'B04', 'is']]\n",
      "decoded_data: ['PID is 5751.0, B03 is 750.0, B04 is 511.0, DOY is 211.0, B02 is 284.0 B04 is 575B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5751.0, B03 is 750.0, B04 is 511.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 5751.0, B03 is 750.0, B04 is 511.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '7', '5', '4', '0', '9', '8', '4', '0']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5751.0, B03 is 750.0, B04 is 511.0, B02 is 284.0575409840']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5851.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 5851.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B03', 'is', '', '8', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5851.0, B04 is 604.0, B02 is 314.0, B03 is 801.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 604.0, B02 is 314.0, PID is 5851.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 604.0, B02 is 314.0, PID is 5851.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '1', '.', '0', ',', '', 'B03', 'is', '', '8', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '8', '0', '1', '1', '.', '0', '1', '.', '0']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 604.0, B02 is 314.0, PID is 5851.0, B03 is 801.08011.01.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 314.0, PID is 5851.0, DOY is 211.0, B04 is 604.0, B03 is']\n",
      "prompt: B02 is 314.0, PID is 5851.0, DOY is 211.0, B04 is 604.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '4', '.', '0', ',', '', 'B03', 'is', '', '8', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '8', '0', '1', '1', '1']]\n",
      "decoded_data: ['B02 is 314.0, PID is 5851.0, DOY is 211.0, B04 is 604.0, B03 is 801.0 PID is 80111']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 604.0, PID is 5851.0, B02 is 314.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 604.0, PID is 5851.0, B02 is 314.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B03', 'is', '', '8', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B02', 'is', '', '8', '0']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 604.0, PID is 5851.0, B02 is 314.0, B03 is 801.0 PID is B02 is 80']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 314.0, PID is 5851.0, B04 is 604.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 314.0, PID is 5851.0, B04 is 604.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '4', '.', '0', ',', '', 'B03', 'is', '', '8', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '6', '7', '1', '.', '0']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 314.0, PID is 5851.0, B04 is 604.0, B03 is 801.0 B04 is 671.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 604.0, DOY is 211.0, PID is 5851.0, B02 is 314.0, B03 is']\n",
      "prompt: B04 is 604.0, DOY is 211.0, PID is 5851.0, B02 is 314.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '6', '0', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '6', '0', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B03', 'is', '', '8', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '8', '0', '1', '1', '8', '0', '1', '8']]\n",
      "decoded_data: ['B04 is 604.0, DOY is 211.0, PID is 5851.0, B02 is 314.0, B03 is 801.0 80118018']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5851.0, DOY is 211.0, B04 is 604.0, B02 is 314.0, B03 is']\n",
      "prompt: PID is 5851.0, DOY is 211.0, B04 is 604.0, B02 is 314.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '8', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '8', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B03', 'is', '', '8', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '8', '0', '1', '1', '.', '0', '1', '8', '0']]\n",
      "decoded_data: ['PID is 5851.0, DOY is 211.0, B04 is 604.0, B02 is 314.0, B03 is 801.08011.0180']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 604.0, PID is 5851.0, DOY is 211.0, B02 is 314.0, B03 is']\n",
      "prompt: B04 is 604.0, PID is 5851.0, DOY is 211.0, B02 is 314.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '6', '0', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '6', '0', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B03', 'is', '', '8', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '8', '0', '1', '1', '1', '1', '.', '0', '1']]\n",
      "decoded_data: ['B04 is 604.0, PID is 5851.0, DOY is 211.0, B02 is 314.0, B03 is 801.0801111.01']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 604.0, B02 is 314.0, DOY is 211.0, PID is 5851.0, B03 is']\n",
      "prompt: B04 is 604.0, B02 is 314.0, DOY is 211.0, PID is 5851.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '6', '0', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '6', '0', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '1', '.', '0', ',', '', 'B03', 'is', '', '8', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', '6', '0']]\n",
      "decoded_data: ['B04 is 604.0, B02 is 314.0, DOY is 211.0, PID is 5851.0, B03 is 801.0 B04 is B04 is 60']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 604.0, B02 is 314.0, PID is 5851.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 604.0, B02 is 314.0, PID is 5851.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '1', '.', '0', ',', '', 'B03', 'is', '', '8', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '8', '0', '1', '8', '0']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 604.0, B02 is 314.0, PID is 5851.0, B03 is 801.0 B04 is 80180']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5851.0, B02 is 314.0, B04 is 604.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 5851.0, B02 is 314.0, B04 is 604.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '4', '.', '0', ',', '', 'B03', 'is', '', '8', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '8', '0', '1', '1', '1']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5851.0, B02 is 314.0, B04 is 604.0, B03 is 801.0 B04 is 80111']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 604.0, DOY is 211.0, B02 is 314.0, PID is 5851.0, B03 is']\n",
      "prompt: B04 is 604.0, DOY is 211.0, B02 is 314.0, PID is 5851.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '6', '0', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '6', '0', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '1', '.', '0', ',', '', 'B03', 'is', '', '8', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '8', '0', '1', '1', '1']]\n",
      "decoded_data: ['B04 is 604.0, DOY is 211.0, B02 is 314.0, PID is 5851.0, B03 is 801.0 PID is 80111']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5851.0, DOY is 211.0, B02 is 314.0, B04 is 604.0, B03 is']\n",
      "prompt: PID is 5851.0, DOY is 211.0, B02 is 314.0, B04 is 604.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '8', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '8', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '4', '.', '0', ',', '', 'B03', 'is', '', '8', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '6', '0']]\n",
      "decoded_data: ['PID is 5851.0, DOY is 211.0, B02 is 314.0, B04 is 604.0, B03 is 801.0 B04 is PID is 60']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 314.0, B04 is 604.0, PID is 5851.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 314.0, B04 is 604.0, PID is 5851.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '8', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '8', '0', '1', '8', '0', '1', '8', '0']]\n",
      "decoded_data: ['B02 is 314.0, B04 is 604.0, PID is 5851.0, DOY is 211.0, B03 is 801.0 80180180']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 604.0, DOY is 211.0, B02 is 314.0, PID is 5851.0, B03 is']\n",
      "prompt: B04 is 604.0, DOY is 211.0, B02 is 314.0, PID is 5851.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '6', '0', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '1', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      "  2%|         | 19/829 [00:31<22:40,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B04', 'is', '', '6', '0', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '1', '.', '0', ',', '', 'B03', 'is', '', '8', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '2', '.', '0', '1', '1', '.', '0', ',']]\n",
      "decoded_data: ['B04 is 604.0, DOY is 211.0, B02 is 314.0, PID is 5851.0, B03 is 801.062.011.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5951.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5951.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '9', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '9', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '0', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '2', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'DOY', 'is', '', 'PID', 'is', '', 'B03', 'is']]\n",
      "decoded_data: ['PID is 5951.0, DOY is 211.0, B03 is 710.0, B02 is 272.0, B04 is 456.0 DOY is PID is B03 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 272.0, PID is 5951.0, B03 is 710.0, B04 is']\n",
      "prompt: DOY is 211.0, B02 is 272.0, PID is 5951.0, B03 is 710.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '0', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B03', 'is', '', '4', '6']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 272.0, PID is 5951.0, B03 is 710.0, B04 is 456.0 PID is B03 is 46']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 272.0, PID is 5951.0, DOY is 211.0, B03 is 710.0, B04 is']\n",
      "prompt: B02 is 272.0, PID is 5951.0, DOY is 211.0, B03 is 710.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '7', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '7', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '0', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'DOY', 'is', '', 'PID', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['B02 is 272.0, PID is 5951.0, DOY is 211.0, B03 is 710.0, B04 is 456.0 DOY is PID is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 272.0, PID is 5951.0, B03 is 710.0, DOY is 211.0, B04 is']\n",
      "prompt: B02 is 272.0, PID is 5951.0, B03 is 710.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '7', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '7', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '4', '5', '6', '5', '6']]\n",
      "decoded_data: ['B02 is 272.0, PID is 5951.0, B03 is 710.0, DOY is 211.0, B04 is 456.0 PID is 45656']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 710.0, DOY is 211.0, PID is 5951.0, B02 is 272.0, B04 is']\n",
      "prompt: B03 is 710.0, DOY is 211.0, PID is 5951.0, B02 is 272.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '1', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '2', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '1', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '2', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'DOY', 'is', '', 'PID', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['B03 is 710.0, DOY is 211.0, PID is 5951.0, B02 is 272.0, B04 is 456.0 DOY is PID is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 272.0, DOY is 211.0, PID is 5951.0, B03 is 710.0, B04 is']\n",
      "prompt: B02 is 272.0, DOY is 211.0, PID is 5951.0, B03 is 710.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '7', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '7', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '0', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '3', '6', '3', '6', '.', '0', '3']]\n",
      "decoded_data: ['B02 is 272.0, DOY is 211.0, PID is 5951.0, B03 is 710.0, B04 is 456.0 43636.03']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5951.0, B02 is 272.0, B03 is 710.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 5951.0, B02 is 272.0, B03 is 710.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '0', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'DOY', 'is', '', 'PID', 'is', '', '4', '6']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5951.0, B02 is 272.0, B03 is 710.0, B04 is 456.0 DOY is PID is 46']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5951.0, B03 is 710.0, B02 is 272.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 5951.0, B03 is 710.0, B02 is 272.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '0', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '2', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '0', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '2', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '4', '5', '6', '3', '6', '.', '0', '3', '6']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5951.0, B03 is 710.0, B02 is 272.0, B04 is 456.045636.036']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 272.0, B03 is 710.0, PID is 5951.0, DOY is 211.0, B04 is']\n",
      "prompt: B02 is 272.0, B03 is 710.0, PID is 5951.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '7', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '7', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '5', '6', '.', '0', '3', '6', '6']]\n",
      "decoded_data: ['B02 is 272.0, B03 is 710.0, PID is 5951.0, DOY is 211.0, B04 is 456.0 456.0366']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 272.0, PID is 5951.0, B03 is 710.0, DOY is 211.0, B04 is']\n",
      "prompt: B02 is 272.0, PID is 5951.0, B03 is 710.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '7', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '7', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B02', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['B02 is 272.0, PID is 5951.0, B03 is 710.0, DOY is 211.0, B04 is 456.0 PID is B02 is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 272.0, PID is 5951.0, B03 is 710.0, DOY is 211.0, B04 is']\n",
      "prompt: B02 is 272.0, PID is 5951.0, B03 is 710.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '7', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '7', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '4', '6', '5', '6', '2']]\n",
      "decoded_data: ['B02 is 272.0, PID is 5951.0, B03 is 710.0, DOY is 211.0, B04 is 456.0 PID is 46562']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5951.0, B03 is 710.0, B02 is 272.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 5951.0, B03 is 710.0, B02 is 272.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '9', '5', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '0', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '9', '5', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '0', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'DOY', 'is', '', '2', '0']]\n",
      "decoded_data: ['PID is 5951.0, B03 is 710.0, B02 is 272.0, DOY is 211.0, B04 is 456.0 PID is DOY is 20']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5951.0, DOY is 211.0, B03 is 710.0, B02 is 272.0, B04 is']\n",
      "prompt: PID is 5951.0, DOY is 211.0, B03 is 710.0, B02 is 272.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '9', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '0', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '2', '.', '0', ',', '', 'B04', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 20/829 [00:33<23:45,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '5', '9', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '0', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '2', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '4', '6', '0', '4', '9', '9', '6', '8', '3']]\n",
      "decoded_data: ['PID is 5951.0, DOY is 211.0, B03 is 710.0, B02 is 272.0, B04 is 456.0460499683']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5052.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 5052.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '9', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B02', 'is', '', '3', '1']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5052.0, B03 is 756.0, B04 is 594.0, B02 is 331.0 PID is B02 is 31']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 594.0, B03 is 756.0, PID is 5052.0, B02 is']\n",
      "prompt: DOY is 211.0, B04 is 594.0, B03 is 756.0, PID is 5052.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '9', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '2', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '9', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'PID', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 594.0, B03 is 756.0, PID is 5052.0, B02 is 331.0 B03 is PID is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5052.0, B04 is 594.0, B03 is 756.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 5052.0, B04 is 594.0, B03 is 756.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '0', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '5', '9', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 21/829 [00:34<18:53,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '5', '0', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '5', '9', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '3', '1', '7', '4', '9', '5', '4', '9', '9']]\n",
      "decoded_data: ['PID is 5052.0, B04 is 594.0, B03 is 756.0, DOY is 211.0, B02 is 331.0317495499']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5152.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 5152.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '1', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '1', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', '4', '4']]\n",
      "decoded_data: ['PID is 5152.0, DOY is 211.0, B04 is 487.0, B02 is 281.0, B03 is 744.0 B04 is B04 is 44']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 281.0, PID is 5152.0, DOY is 211.0, B04 is 487.0, B03 is']\n",
      "prompt: B02 is 281.0, PID is 5152.0, DOY is 211.0, B04 is 487.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '8', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '8', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '7', '4', '4', '4', '4', '4', '4', '4']]\n",
      "decoded_data: ['B02 is 281.0, PID is 5152.0, DOY is 211.0, B04 is 487.0, B03 is 744.0 74444444']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 487.0, DOY is 211.0, PID is 5152.0, B02 is 281.0, B03 is']\n",
      "prompt: B04 is 487.0, DOY is 211.0, PID is 5152.0, B02 is 281.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '8', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '8', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B02', 'is', '', '2', '6']]\n",
      "decoded_data: ['B04 is 487.0, DOY is 211.0, PID is 5152.0, B02 is 281.0, B03 is 744.0 PID is B02 is 26']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 281.0, PID is 5152.0, DOY is 211.0, B04 is 487.0, B03 is']\n",
      "prompt: B02 is 281.0, PID is 5152.0, DOY is 211.0, B04 is 487.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '8', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '8', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '7']]\n",
      "decoded_data: ['B02 is 281.0, PID is 5152.0, DOY is 211.0, B04 is 487.0, B03 is 744.0 B04 is PID is 77']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 281.0, DOY is 211.0, PID is 5152.0, B04 is 487.0, B03 is']\n",
      "prompt: B02 is 281.0, DOY is 211.0, PID is 5152.0, B04 is 487.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '8', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '8', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '4', '4', '4', '4', '4']]\n",
      "decoded_data: ['B02 is 281.0, DOY is 211.0, PID is 5152.0, B04 is 487.0, B03 is 744.0 B04 is 44444']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 487.0, B02 is 281.0, PID is 5152.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 487.0, B02 is 281.0, PID is 5152.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '8', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '8', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', '4', '4']]\n",
      "decoded_data: ['B04 is 487.0, B02 is 281.0, PID is 5152.0, DOY is 211.0, B03 is 744.0 B04 is B04 is 44']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 281.0, PID is 5152.0, B04 is 487.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 281.0, PID is 5152.0, B04 is 487.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '8', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '8', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B02', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['B02 is 281.0, PID is 5152.0, B04 is 487.0, DOY is 211.0, B03 is 744.0 B04 is B02 is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 281.0, PID is 5152.0, DOY is 211.0, B04 is 487.0, B03 is']\n",
      "prompt: B02 is 281.0, PID is 5152.0, DOY is 211.0, B04 is 487.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '8', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '8', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '7', '7', '4', '4', '4', '4', '4', '4']]\n",
      "decoded_data: ['B02 is 281.0, PID is 5152.0, DOY is 211.0, B04 is 487.0, B03 is 744.0 77444444']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 487.0, B02 is 281.0, DOY is 211.0, PID is 5152.0, B03 is']\n",
      "prompt: B04 is 487.0, B02 is 281.0, DOY is 211.0, PID is 5152.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '8', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '8', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '5', '4']]\n",
      "decoded_data: ['B04 is 487.0, B02 is 281.0, DOY is 211.0, PID is 5152.0, B03 is 744.0 B04 is PID is 54']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 281.0, B04 is 487.0, PID is 5152.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 281.0, B04 is 487.0, PID is 5152.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '8', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '8', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '7', '4', '4', '4', '4']]\n",
      "decoded_data: ['B02 is 281.0, B04 is 487.0, PID is 5152.0, DOY is 211.0, B03 is 744.0 B04 is 74444']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 487.0, B02 is 281.0, DOY is 211.0, PID is 5152.0, B03 is']\n",
      "prompt: B04 is 487.0, B02 is 281.0, DOY is 211.0, PID is 5152.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '8', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '8', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['B04 is 487.0, B02 is 281.0, DOY is 211.0, PID is 5152.0, B03 is 744.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 281.0, B04 is 487.0, PID is 5152.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 281.0, B04 is 487.0, PID is 5152.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '8', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '8', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B02', 'is', '', 'B04', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['B02 is 281.0, B04 is 487.0, PID is 5152.0, DOY is 211.0, B03 is 744.0 B02 is B04 is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 487.0, DOY is 211.0, B02 is 281.0, PID is 5152.0, B03 is']\n",
      "prompt: B04 is 487.0, DOY is 211.0, B02 is 281.0, PID is 5152.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '8', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '8', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B02', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['B04 is 487.0, DOY is 211.0, B02 is 281.0, PID is 5152.0, B03 is 744.0 B04 is B02 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 281.0, PID is 5152.0, B04 is 487.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 281.0, PID is 5152.0, B04 is 487.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '4', '4', '4', '4', '6']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 281.0, PID is 5152.0, B04 is 487.0, B03 is 744.0 B04 is 44446']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 281.0, DOY is 211.0, PID is 5152.0, B04 is 487.0, B03 is']\n",
      "prompt: B02 is 281.0, DOY is 211.0, PID is 5152.0, B04 is 487.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '8', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '7', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      "  3%|         | 22/829 [00:36<22:05,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B02', 'is', '', '2', '8', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '6', '8', '7', 'B02', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['B02 is 281.0, DOY is 211.0, PID is 5152.0, B04 is 487.0, B03 is 744.0 687B02 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5252.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 5252.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '2', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '2', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '0', '1', '3', '6', 'PID', 'is', '', 'B04']]\n",
      "decoded_data: ['PID is 5252.0, DOY is 211.0, B02 is 288.0, B04 is 514.0, B03 is 755.070136PID is B04']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5252.0, DOY is 211.0, B04 is 514.0, B02 is 288.0, B03 is']\n",
      "prompt: PID is 5252.0, DOY is 211.0, B04 is 514.0, B02 is 288.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '2', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '2', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['PID is 5252.0, DOY is 211.0, B04 is 514.0, B02 is 288.0, B03 is 755.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 514.0, DOY is 211.0, PID is 5252.0, B02 is 288.0, B03 is']\n",
      "prompt: B04 is 514.0, DOY is 211.0, PID is 5252.0, B02 is 288.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '1', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '1', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '5', '5', '1', '.', '0', '.', '0', ',']]\n",
      "decoded_data: ['B04 is 514.0, DOY is 211.0, PID is 5252.0, B02 is 288.0, B03 is 755.05551.0.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5252.0, B04 is 514.0, DOY is 211.0, B02 is 288.0, B03 is']\n",
      "prompt: PID is 5252.0, B04 is 514.0, DOY is 211.0, B02 is 288.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '2', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '2', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '5', '5', '5', '5', '4', '.', '0', '.']]\n",
      "decoded_data: ['PID is 5252.0, B04 is 514.0, DOY is 211.0, B02 is 288.0, B03 is 755.0555554.0.']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5252.0, B02 is 288.0, B04 is 514.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 5252.0, B02 is 288.0, B04 is 514.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '4', '5', '2', '6']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5252.0, B02 is 288.0, B04 is 514.0, B03 is 755.0 B04 is 54526']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5252.0, B04 is 514.0, DOY is 211.0, B02 is 288.0, B03 is']\n",
      "prompt: PID is 5252.0, B04 is 514.0, DOY is 211.0, B02 is 288.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '2', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '2', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '5', '5', '2', '8', '.', '0', '.', '0']]\n",
      "decoded_data: ['PID is 5252.0, B04 is 514.0, DOY is 211.0, B02 is 288.0, B03 is 755.055528.0.0']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5252.0, B02 is 288.0, DOY is 211.0, B04 is 514.0, B03 is']\n",
      "prompt: PID is 5252.0, B02 is 288.0, DOY is 211.0, B04 is 514.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '2', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '2', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '5', '4', '5', '5']]\n",
      "decoded_data: ['PID is 5252.0, B02 is 288.0, DOY is 211.0, B04 is 514.0, B03 is 755.0 B04 is 55455']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5252.0, B04 is 514.0, B02 is 288.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5252.0, B04 is 514.0, B02 is 288.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '2', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '2', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['PID is 5252.0, B04 is 514.0, B02 is 288.0, DOY is 211.0, B03 is 755.0 PID is B04 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5252.0, B02 is 288.0, B04 is 514.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5252.0, B02 is 288.0, B04 is 514.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '2', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '2', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', '5', '4']]\n",
      "decoded_data: ['PID is 5252.0, B02 is 288.0, B04 is 514.0, DOY is 211.0, B03 is 755.0 B04 is B04 is 54']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5252.0, DOY is 211.0, B02 is 288.0, B04 is 514.0, B03 is']\n",
      "prompt: PID is 5252.0, DOY is 211.0, B02 is 288.0, B04 is 514.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '2', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '2', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '5']]\n",
      "decoded_data: ['PID is 5252.0, DOY is 211.0, B02 is 288.0, B04 is 514.0, B03 is 755.0 B04 is PID is 75']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 514.0, PID is 5252.0, B02 is 288.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 514.0, PID is 5252.0, B02 is 288.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 514.0, PID is 5252.0, B02 is 288.0, B03 is 755.0 PID is B04 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 288.0, B04 is 514.0, PID is 5252.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 288.0, B04 is 514.0, PID is 5252.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['B02 is 288.0, B04 is 514.0, PID is 5252.0, DOY is 211.0, B03 is 755.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5252.0, B02 is 288.0, DOY is 211.0, B04 is 514.0, B03 is']\n",
      "prompt: PID is 5252.0, B02 is 288.0, DOY is 211.0, B04 is 514.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '2', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '2', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '5']]\n",
      "decoded_data: ['PID is 5252.0, B02 is 288.0, DOY is 211.0, B04 is 514.0, B03 is 755.0 B04 is PID is 75']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 514.0, B02 is 288.0, PID is 5252.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 514.0, B02 is 288.0, PID is 5252.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '1', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '1', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['B04 is 514.0, B02 is 288.0, PID is 5252.0, DOY is 211.0, B03 is 755.0 PID is B04 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5252.0, B04 is 514.0, B02 is 288.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 5252.0, B04 is 514.0, B02 is 288.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      "  3%|         | 23/829 [00:38<24:33,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '5', '5', '.', '0', '.', '0', ',', '']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5252.0, B04 is 514.0, B02 is 288.0, B03 is 755.0555.0.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5352.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 5352.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '3', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '3', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '3', '9', '9', '9']]\n",
      "decoded_data: ['PID is 5352.0, DOY is 211.0, B02 is 288.0, B04 is 524.0, B03 is 739.0 PID is 73999']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5352.0, B04 is 524.0, B02 is 288.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 5352.0, B04 is 524.0, B02 is 288.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '0']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5352.0, B04 is 524.0, B02 is 288.0, B03 is 739.0 B04 is PID is 70']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 288.0, B04 is 524.0, PID is 5352.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 288.0, B04 is 524.0, PID is 5352.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'DOY', 'is', '', '2', '7']]\n",
      "decoded_data: ['B02 is 288.0, B04 is 524.0, PID is 5352.0, DOY is 211.0, B03 is 739.0 PID is DOY is 27']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5352.0, B02 is 288.0, B04 is 524.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 5352.0, B02 is 288.0, B04 is 524.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'DOY', 'is', '', '7', '0']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5352.0, B02 is 288.0, B04 is 524.0, B03 is 739.0 B04 is DOY is 70']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5352.0, B02 is 288.0, DOY is 211.0, B04 is 524.0, B03 is']\n",
      "prompt: PID is 5352.0, B02 is 288.0, DOY is 211.0, B04 is 524.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '3', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '3', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', 'DOY', 'is', '', 'B04']]\n",
      "decoded_data: ['PID is 5352.0, B02 is 288.0, DOY is 211.0, B04 is 524.0, B03 is 739.0 PID is 7DOY is B04']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5352.0, B02 is 288.0, B04 is 524.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 5352.0, B02 is 288.0, B04 is 524.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5352.0, B02 is 288.0, B04 is 524.0, B03 is 739.0 B04 is PID is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 288.0, B04 is 524.0, PID is 5352.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 288.0, B04 is 524.0, PID is 5352.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '9', '9', '9', '9']]\n",
      "decoded_data: ['B02 is 288.0, B04 is 524.0, PID is 5352.0, DOY is 211.0, B03 is 739.0 PID is 79999']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 524.0, B02 is 288.0, PID is 5352.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 524.0, B02 is 288.0, PID is 5352.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', '7', '3', '9', '.', '0']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 524.0, B02 is 288.0, PID is 5352.0, B03 is 739.0 B03 is 739.0']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5352.0, B02 is 288.0, B04 is 524.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5352.0, B02 is 288.0, B04 is 524.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '3', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '3', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '7', '2']]\n",
      "decoded_data: ['PID is 5352.0, B02 is 288.0, B04 is 524.0, DOY is 211.0, B03 is 739.0 PID is B04 is 72']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5352.0, DOY is 211.0, B02 is 288.0, B04 is 524.0, B03 is']\n",
      "prompt: PID is 5352.0, DOY is 211.0, B02 is 288.0, B04 is 524.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '3', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '3', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '0', '4', '0', '4']]\n",
      "decoded_data: ['PID is 5352.0, DOY is 211.0, B02 is 288.0, B04 is 524.0, B03 is 739.0 B04 is 50404']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 524.0, B02 is 288.0, PID is 5352.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 524.0, B02 is 288.0, PID is 5352.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '2', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '2', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '2', '4', '.', '0']]\n",
      "decoded_data: ['B04 is 524.0, B02 is 288.0, PID is 5352.0, DOY is 211.0, B03 is 739.0 B04 is 524.0']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5352.0, B02 is 288.0, B04 is 524.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5352.0, B02 is 288.0, B04 is 524.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '3', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '3', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '7', '9']]\n",
      "decoded_data: ['PID is 5352.0, B02 is 288.0, B04 is 524.0, DOY is 211.0, B03 is 739.0 PID is B04 is 79']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 524.0, PID is 5352.0, B02 is 288.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 524.0, PID is 5352.0, B02 is 288.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '2', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '2', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B02', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['B04 is 524.0, PID is 5352.0, B02 is 288.0, DOY is 211.0, B03 is 739.0 B02 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5352.0, DOY is 211.0, B02 is 288.0, B04 is 524.0, B03 is']\n",
      "prompt: PID is 5352.0, DOY is 211.0, B02 is 288.0, B04 is 524.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '3', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '3', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '2', '4', 'DOY', 'is', '', 'B04', 'is', '', '5']]\n",
      "decoded_data: ['PID is 5352.0, DOY is 211.0, B02 is 288.0, B04 is 524.0, B03 is 739.024DOY is B04 is 5']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5352.0, DOY is 211.0, B04 is 524.0, B02 is 288.0, B03 is']\n",
      "prompt: PID is 5352.0, DOY is 211.0, B04 is 524.0, B02 is 288.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '3', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      "  3%|         | 24/829 [00:40<26:24,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '5', '3', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '9', '9', '9', 'B02', 'is', '', 'PID', 'is', '']]\n",
      "decoded_data: ['PID is 5352.0, DOY is 211.0, B04 is 524.0, B02 is 288.0, B03 is 739.0999B02 is PID is ']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5452.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 5452.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '2', '8', '4', '7', '4', '7', '4', '6', '.']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5452.0, B03 is 754.0, B04 is 516.0, B02 is 284.028474746.']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 516.0, B03 is 754.0, PID is 5452.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 516.0, B03 is 754.0, PID is 5452.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '1', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '1', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '8', '4', '9', '5', '7', '8', '4', '.', '0']]\n",
      "decoded_data: ['B04 is 516.0, B03 is 754.0, PID is 5452.0, DOY is 211.0, B02 is 284.08495784.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 754.0, PID is 5452.0, B04 is 516.0, DOY is 211.0, B02 is']\n",
      "prompt: B03 is 754.0, PID is 5452.0, B04 is 516.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '5', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '5', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '2', '8', '4', '3', '6', '.', '0', ',', '']]\n",
      "decoded_data: ['B03 is 754.0, PID is 5452.0, B04 is 516.0, DOY is 211.0, B02 is 284.028436.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 754.0, PID is 5452.0, B04 is 516.0, DOY is 211.0, B02 is']\n",
      "prompt: B03 is 754.0, PID is 5452.0, B04 is 516.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '5', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '5', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'DOY', 'is', '', '2', '1']]\n",
      "decoded_data: ['B03 is 754.0, PID is 5452.0, B04 is 516.0, DOY is 211.0, B02 is 284.0 B04 is DOY is 21']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5452.0, B04 is 516.0, B03 is 754.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 5452.0, B04 is 516.0, B03 is 754.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '4', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '4', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['PID is 5452.0, B04 is 516.0, B03 is 754.0, DOY is 211.0, B02 is 284.0 PID is B04 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 754.0, B04 is 516.0, PID is 5452.0, DOY is 211.0, B02 is']\n",
      "prompt: B03 is 754.0, B04 is 516.0, PID is 5452.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '2', '8']]\n",
      "decoded_data: ['B03 is 754.0, B04 is 516.0, PID is 5452.0, DOY is 211.0, B02 is 284.0 PID is B04 is 28']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5452.0, B03 is 754.0, B04 is 516.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 5452.0, B03 is 754.0, B04 is 516.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '4', '5', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '4', '5', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['PID is 5452.0, B03 is 754.0, B04 is 516.0, DOY is 211.0, B02 is 284.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 754.0, B04 is 516.0, PID is 5452.0, DOY is 211.0, B02 is']\n",
      "prompt: B03 is 754.0, B04 is 516.0, PID is 5452.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '1', '8', '4', '0', '8', '4', '0', '.', '0']]\n",
      "decoded_data: ['B03 is 754.0, B04 is 516.0, PID is 5452.0, DOY is 211.0, B02 is 284.01840840.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 516.0, PID is 5452.0, B03 is 754.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 516.0, PID is 5452.0, B03 is 754.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '1', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '1', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '8', '4', '7', '4', '.', '0', ',', '', 'PID']]\n",
      "decoded_data: ['B04 is 516.0, PID is 5452.0, B03 is 754.0, DOY is 211.0, B02 is 284.08474.0, PID']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 516.0, B03 is 754.0, PID is 5452.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 516.0, B03 is 754.0, PID is 5452.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '1', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '1', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '2', '.', '0', ',', '', 'PID', 'is', '']]\n",
      "decoded_data: ['B04 is 516.0, B03 is 754.0, PID is 5452.0, DOY is 211.0, B02 is 284.0 2.0, PID is ']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 754.0, DOY is 211.0, PID is 5452.0, B04 is 516.0, B02 is']\n",
      "prompt: B03 is 754.0, DOY is 211.0, PID is 5452.0, B04 is 516.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '6', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '0', '9', '4', '.']]\n",
      "decoded_data: ['B03 is 754.0, DOY is 211.0, PID is 5452.0, B04 is 516.0, B02 is 284.0 B04 is 5094.']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 516.0, DOY is 211.0, PID is 5452.0, B03 is 754.0, B02 is']\n",
      "prompt: B04 is 516.0, DOY is 211.0, PID is 5452.0, B03 is 754.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '1', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '4', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '1', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'DOY', 'is', '', '2', '8']]\n",
      "decoded_data: ['B04 is 516.0, DOY is 211.0, PID is 5452.0, B03 is 754.0, B02 is 284.0 B04 is DOY is 28']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 754.0, B04 is 516.0, DOY is 211.0, PID is 5452.0, B02 is']\n",
      "prompt: B03 is 754.0, B04 is 516.0, DOY is 211.0, PID is 5452.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '2', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'DOY', 'is', '', '2', '.']]\n",
      "decoded_data: ['B03 is 754.0, B04 is 516.0, DOY is 211.0, PID is 5452.0, B02 is 284.0 B04 is DOY is 2.']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 516.0, DOY is 211.0, PID is 5452.0, B03 is 754.0, B02 is']\n",
      "prompt: B04 is 516.0, DOY is 211.0, PID is 5452.0, B03 is 754.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '1', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '4', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '1', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '2', '8', '4', '3', '1']]\n",
      "decoded_data: ['B04 is 516.0, DOY is 211.0, PID is 5452.0, B03 is 754.0, B02 is 284.0 PID is 28431']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5452.0, DOY is 211.0, B04 is 516.0, B03 is 754.0, B02 is']\n",
      "prompt: PID is 5452.0, DOY is 211.0, B04 is 516.0, B03 is 754.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '4', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '4', '.', '0', ',', '', 'B02', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      "  3%|         | 25/829 [00:43<27:24,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '5', '4', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', '5', '0']]\n",
      "decoded_data: ['PID is 5452.0, DOY is 211.0, B04 is 516.0, B03 is 754.0, B02 is 284.0 B04 is B04 is 50']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5552.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 5552.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '2', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '4', '0', '1', '9', '.']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5552.0, B02 is 277.0, B04 is 486.0, B03 is 777.0 B04 is 4019.']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 277.0, PID is 5552.0, DOY is 211.0, B04 is 486.0, B03 is']\n",
      "prompt: B02 is 277.0, PID is 5552.0, DOY is 211.0, B04 is 486.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '7']]\n",
      "decoded_data: ['B02 is 277.0, PID is 5552.0, DOY is 211.0, B04 is 486.0, B03 is 777.0 B04 is PID is 77']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5552.0, DOY is 211.0, B04 is 486.0, B02 is 277.0, B03 is']\n",
      "prompt: PID is 5552.0, DOY is 211.0, B04 is 486.0, B02 is 277.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '5', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '5', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '7']]\n",
      "decoded_data: ['PID is 5552.0, DOY is 211.0, B04 is 486.0, B02 is 277.0, B03 is 777.0 B04 is PID is 77']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 486.0, PID is 5552.0, B02 is 277.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 486.0, PID is 5552.0, B02 is 277.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '8', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '8', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '7', '7', '7', '7', '7', '7', '7', '7']]\n",
      "decoded_data: ['B04 is 486.0, PID is 5552.0, B02 is 277.0, DOY is 211.0, B03 is 777.0 77777777']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 277.0, B04 is 486.0, PID is 5552.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 277.0, B04 is 486.0, PID is 5552.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['B02 is 277.0, B04 is 486.0, PID is 5552.0, DOY is 211.0, B03 is 777.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 277.0, PID is 5552.0, B04 is 486.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 277.0, PID is 5552.0, B04 is 486.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B02', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['B02 is 277.0, PID is 5552.0, B04 is 486.0, DOY is 211.0, B03 is 777.0 B04 is B02 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5552.0, B02 is 277.0, DOY is 211.0, B04 is 486.0, B03 is']\n",
      "prompt: PID is 5552.0, B02 is 277.0, DOY is 211.0, B04 is 486.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '5', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '6', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 26/829 [00:44<24:09,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '5', '5', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '4', '0', '9', '4', '0']]\n",
      "decoded_data: ['PID is 5552.0, B02 is 277.0, DOY is 211.0, B04 is 486.0, B03 is 777.0 B04 is 40940']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5552.0, B02 is 277.0, B04 is 486.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5552.0, B02 is 277.0, B04 is 486.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '5', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '5', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '7', '7', '7', '7', '7', '7', '7', '7']]\n",
      "decoded_data: ['PID is 5552.0, B02 is 277.0, B04 is 486.0, DOY is 211.0, B03 is 777.0777777777']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5652.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 5652.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '2', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '1', '.', '0', ',', '', 'B04', 'is', '']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5652.0, B02 is 276.0, B04 is 483.0, B03 is 761.061.0, B04 is ']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5652.0, DOY is 211.0, B02 is 276.0, B04 is 483.0, B03 is']\n",
      "prompt: PID is 5652.0, DOY is 211.0, B02 is 276.0, B04 is 483.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '6', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '6', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '7', '7', '6', '1', '.', '0', '7', '1']]\n",
      "decoded_data: ['PID is 5652.0, DOY is 211.0, B02 is 276.0, B04 is 483.0, B03 is 761.0 7761.071']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5652.0, B04 is 483.0, B02 is 276.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5652.0, B04 is 483.0, B02 is 276.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '6', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '6', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '7', '6', '1', '6', '1', '.', '0', '0']]\n",
      "decoded_data: ['PID is 5652.0, B04 is 483.0, B02 is 276.0, DOY is 211.0, B03 is 761.0 76161.00']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5652.0, DOY is 211.0, B04 is 483.0, B02 is 276.0, B03 is']\n",
      "prompt: PID is 5652.0, DOY is 211.0, B04 is 483.0, B02 is 276.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '6', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '6', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', '4', '5']]\n",
      "decoded_data: ['PID is 5652.0, DOY is 211.0, B04 is 483.0, B02 is 276.0, B03 is 761.0 B04 is B04 is 45']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5652.0, DOY is 211.0, B02 is 276.0, B04 is 483.0, B03 is']\n",
      "prompt: PID is 5652.0, DOY is 211.0, B02 is 276.0, B04 is 483.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '6', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '6', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', '4', '0']]\n",
      "decoded_data: ['PID is 5652.0, DOY is 211.0, B02 is 276.0, B04 is 483.0, B03 is 761.0 B04 is B04 is 40']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5652.0, B02 is 276.0, B04 is 483.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 5652.0, B02 is 276.0, B04 is 483.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '7', '6', '.', '0', ',', '', 'B04', 'is']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5652.0, B02 is 276.0, B04 is 483.0, B03 is 761.0776.0, B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 483.0, PID is 5652.0, DOY is 211.0, B02 is 276.0, B03 is']\n",
      "prompt: B04 is 483.0, PID is 5652.0, DOY is 211.0, B02 is 276.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '8', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '8', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '7', '6', '1', '.', '0', '5', '.', '0']]\n",
      "decoded_data: ['B04 is 483.0, PID is 5652.0, DOY is 211.0, B02 is 276.0, B03 is 761.0 761.05.0']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 483.0, B02 is 276.0, PID is 5652.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 483.0, B02 is 276.0, PID is 5652.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '7', '5', '6', '1', '.', '0', ',', '']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 483.0, B02 is 276.0, PID is 5652.0, B03 is 761.0 7561.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 483.0, B02 is 276.0, DOY is 211.0, PID is 5652.0, B03 is']\n",
      "prompt: B04 is 483.0, B02 is 276.0, DOY is 211.0, PID is 5652.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '8', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '8', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '7', '6', '1', '.', '0', ',', '', 'B04']]\n",
      "decoded_data: ['B04 is 483.0, B02 is 276.0, DOY is 211.0, PID is 5652.0, B03 is 761.0 761.0, B04']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 276.0, PID is 5652.0, DOY is 211.0, B04 is 483.0, B03 is']\n",
      "prompt: B02 is 276.0, PID is 5652.0, DOY is 211.0, B04 is 483.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '7', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '7', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '4', '0', '1', '3', '.']]\n",
      "decoded_data: ['B02 is 276.0, PID is 5652.0, DOY is 211.0, B04 is 483.0, B03 is 761.0 B04 is 4013.']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5652.0, B04 is 483.0, B02 is 276.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5652.0, B04 is 483.0, B02 is 276.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '6', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '6', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '4', '0', '0', '1', '6']]\n",
      "decoded_data: ['PID is 5652.0, B04 is 483.0, B02 is 276.0, DOY is 211.0, B03 is 761.0 B04 is 40016']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 276.0, B04 is 483.0, DOY is 211.0, PID is 5652.0, B03 is']\n",
      "prompt: B02 is 276.0, B04 is 483.0, DOY is 211.0, PID is 5652.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '7', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '7', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '7', '5', '6', '1', '6', '.', '0', '.']]\n",
      "decoded_data: ['B02 is 276.0, B04 is 483.0, DOY is 211.0, PID is 5652.0, B03 is 761.0 75616.0.']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5652.0, B02 is 276.0, B04 is 483.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5652.0, B02 is 276.0, B04 is 483.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '6', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '6', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '7', '6', '1', '.', '0']]\n",
      "decoded_data: ['PID is 5652.0, B02 is 276.0, B04 is 483.0, DOY is 211.0, B03 is 761.0 B04 is 761.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 276.0, PID is 5652.0, DOY is 211.0, B04 is 483.0, B03 is']\n",
      "prompt: B02 is 276.0, PID is 5652.0, DOY is 211.0, B04 is 483.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '7', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '7', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '7', '6', '1', '9', '6', '1', '.', '0']]\n",
      "decoded_data: ['B02 is 276.0, PID is 5652.0, DOY is 211.0, B04 is 483.0, B03 is 761.0 761961.0']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5652.0, B04 is 483.0, B02 is 276.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 5652.0, B04 is 483.0, B02 is 276.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '6', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      "  3%|         | 27/829 [00:46<25:40,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '1', '6', '1', '.', '0', ',', '', 'B04']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5652.0, B04 is 483.0, B02 is 276.0, B03 is 761.06161.0, B04']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5752.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 5752.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '7', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '7', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '8', '7', '8', '7', '8', '.', '0', ',']]\n",
      "decoded_data: ['PID is 5752.0, DOY is 211.0, B04 is 499.0, B02 is 283.0, B03 is 756.0787878.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5752.0, DOY is 211.0, B04 is 499.0, B02 is 283.0, B03 is']\n",
      "prompt: PID is 5752.0, DOY is 211.0, B04 is 499.0, B02 is 283.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '7', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '7', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', '4', '5']]\n",
      "decoded_data: ['PID is 5752.0, DOY is 211.0, B04 is 499.0, B02 is 283.0, B03 is 756.0 B04 is B04 is 45']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5752.0, B04 is 499.0, B02 is 283.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 5752.0, B04 is 499.0, B02 is 283.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5752.0, B04 is 499.0, B02 is 283.0, B03 is 756.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 499.0, B02 is 283.0, PID is 5752.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 499.0, B02 is 283.0, PID is 5752.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '1', '.', '0', ',', '', 'B04', 'is', '', 'PID']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 499.0, B02 is 283.0, PID is 5752.0, B03 is 756.01.0, B04 is PID']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5752.0, B02 is 283.0, B04 is 499.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5752.0, B02 is 283.0, B04 is 499.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '7', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '7', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '6', '0']]\n",
      "decoded_data: ['PID is 5752.0, B02 is 283.0, B04 is 499.0, DOY is 211.0, B03 is 756.0 B04 is PID is 60']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 499.0, B02 is 283.0, PID is 5752.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 499.0, B02 is 283.0, PID is 5752.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '9', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '9', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', 'B04', 'is', '', 'B02', 'is', '', 'B03', 'is']]\n",
      "decoded_data: ['B04 is 499.0, B02 is 283.0, PID is 5752.0, DOY is 211.0, B03 is 756.06B04 is B02 is B03 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 283.0, PID is 5752.0, B04 is 499.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 283.0, PID is 5752.0, B04 is 499.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '8', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '8', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', 'B04', 'is', '', 'PID', 'is', '', '6', '8']]\n",
      "decoded_data: ['B02 is 283.0, PID is 5752.0, B04 is 499.0, DOY is 211.0, B03 is 756.06B04 is PID is 68']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5752.0, B02 is 283.0, B04 is 499.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 5752.0, B02 is 283.0, B04 is 499.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '9', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', 'DOY', 'is', '', 'B04', 'is', '', '4', '5']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5752.0, B02 is 283.0, B04 is 499.0, B03 is 756.06DOY is B04 is 45']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5752.0, B04 is 499.0, B02 is 283.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5752.0, B04 is 499.0, B02 is 283.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '7', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 28/829 [00:48<24:05,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '5', '7', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['PID is 5752.0, B04 is 499.0, B02 is 283.0, DOY is 211.0, B03 is 756.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 283.0, B04 is 499.0, DOY is 211.0, PID is 5752.0, B03 is']\n",
      "prompt: B02 is 283.0, B04 is 499.0, DOY is 211.0, PID is 5752.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '8', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '8', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '6', 'is', '', 'B04', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['B02 is 283.0, B04 is 499.0, DOY is 211.0, PID is 5752.0, B03 is 756.076 is B04 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5852.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 5852.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '8', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 29/829 [00:48<18:38,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '5', '8', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '7', '3', '.', '0', ',', '', 'B02', 'is', '', '1', '9', '0', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['PID is 5852.0, DOY is 211.0, B04 is 473.0, B02 is 190.0, B03 is 687.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 473.0, B02 is 190.0, PID is 5852.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 473.0, B02 is 190.0, PID is 5852.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '7', '3', '.', '0', ',', '', 'B02', 'is', '', '1', '9', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '7', '3', '.', '0', ',', '', 'B02', 'is', '', '1', '9', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '4', '3', '9', '7', '3', '6', '9', '7', '3']]\n",
      "decoded_data: ['B04 is 473.0, B02 is 190.0, PID is 5852.0, DOY is 211.0, B03 is 687.0439736973']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5952.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 5952.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '9', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '9', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '7', '0', '0', '3', '5', '2', '5', '6']]\n",
      "decoded_data: ['PID is 5952.0, DOY is 211.0, B04 is 492.0, B02 is 263.0, B03 is 713.0 70035256']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 263.0, PID is 5952.0, DOY is 211.0, B04 is 492.0, B03 is']\n",
      "prompt: B02 is 263.0, PID is 5952.0, DOY is 211.0, B04 is 492.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '6', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '6', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '4', '3', '.', '0', '3']]\n",
      "decoded_data: ['B02 is 263.0, PID is 5952.0, DOY is 211.0, B04 is 492.0, B03 is 713.0 B04 is 43.03']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 492.0, DOY is 211.0, PID is 5952.0, B02 is 263.0, B03 is']\n",
      "prompt: B04 is 492.0, DOY is 211.0, PID is 5952.0, B02 is 263.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '0', '7', '0', '3', '.', '0', '3', '.']]\n",
      "decoded_data: ['B04 is 492.0, DOY is 211.0, PID is 5952.0, B02 is 263.0, B03 is 713.070703.03.']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 263.0, DOY is 211.0, B04 is 492.0, PID is 5952.0, B03 is']\n",
      "prompt: B02 is 263.0, DOY is 211.0, B04 is 492.0, PID is 5952.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '6', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '6', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '0']]\n",
      "decoded_data: ['B02 is 263.0, DOY is 211.0, B04 is 492.0, PID is 5952.0, B03 is 713.0 B04 is PID is 70']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 492.0, PID is 5952.0, B02 is 263.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 492.0, PID is 5952.0, B02 is 263.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '0']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 492.0, PID is 5952.0, B02 is 263.0, B03 is 713.0 B04 is PID is 70']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 263.0, B04 is 492.0, DOY is 211.0, PID is 5952.0, B03 is']\n",
      "prompt: B02 is 263.0, B04 is 492.0, DOY is 211.0, PID is 5952.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '6', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '6', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', '7', '4', '1', '3', '.']]\n",
      "decoded_data: ['B02 is 263.0, B04 is 492.0, DOY is 211.0, PID is 5952.0, B03 is 713.0 B03 is 7413.']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 263.0, B04 is 492.0, PID is 5952.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 263.0, B04 is 492.0, PID is 5952.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '7', '.', '0', '3', '.']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 263.0, B04 is 492.0, PID is 5952.0, B03 is 713.0 B04 is 7.03.']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 492.0, DOY is 211.0, B02 is 263.0, PID is 5952.0, B03 is']\n",
      "prompt: B04 is 492.0, DOY is 211.0, B02 is 263.0, PID is 5952.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '7', '1', '3', '.', '0', '.', '0', ',']]\n",
      "decoded_data: ['B04 is 492.0, DOY is 211.0, B02 is 263.0, PID is 5952.0, B03 is 713.0 713.0.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 263.0, PID is 5952.0, B04 is 492.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 263.0, PID is 5952.0, B04 is 492.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '4', '3', '0', '7', '0']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 263.0, PID is 5952.0, B04 is 492.0, B03 is 713.0 B04 is 43070']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 263.0, DOY is 211.0, PID is 5952.0, B04 is 492.0, B03 is']\n",
      "prompt: B02 is 263.0, DOY is 211.0, PID is 5952.0, B04 is 492.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '6', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '6', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '7', '4', '3', '0', '7']]\n",
      "decoded_data: ['B02 is 263.0, DOY is 211.0, PID is 5952.0, B04 is 492.0, B03 is 713.0 B04 is 74307']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5952.0, DOY is 211.0, B04 is 492.0, B02 is 263.0, B03 is']\n",
      "prompt: PID is 5952.0, DOY is 211.0, B04 is 492.0, B02 is 263.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '9', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '9', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '7', '3', '.', '0', ',', '', 'B04', 'is']]\n",
      "decoded_data: ['PID is 5952.0, DOY is 211.0, B04 is 492.0, B02 is 263.0, B03 is 713.0 73.0, B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5952.0, B02 is 263.0, B04 is 492.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5952.0, B02 is 263.0, B04 is 492.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '9', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '9', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '7', '1', '3', '0', '3']]\n",
      "decoded_data: ['PID is 5952.0, B02 is 263.0, B04 is 492.0, DOY is 211.0, B03 is 713.0 B04 is 71303']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 263.0, DOY is 211.0, B04 is 492.0, PID is 5952.0, B03 is']\n",
      "prompt: B02 is 263.0, DOY is 211.0, B04 is 492.0, PID is 5952.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '6', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '6', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '7', '4', '3', '.', '0']]\n",
      "decoded_data: ['B02 is 263.0, DOY is 211.0, B04 is 492.0, PID is 5952.0, B03 is 713.0 B04 is 743.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 492.0, B02 is 263.0, DOY is 211.0, PID is 5952.0, B03 is']\n",
      "prompt: B04 is 492.0, B02 is 263.0, DOY is 211.0, PID is 5952.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '7', '4', '.', '0', '3', '5', '8', '4']]\n",
      "decoded_data: ['B04 is 492.0, B02 is 263.0, DOY is 211.0, PID is 5952.0, B03 is 713.0 74.03584']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 263.0, DOY is 211.0, PID is 5952.0, B04 is 492.0, B03 is']\n",
      "prompt: B02 is 263.0, DOY is 211.0, PID is 5952.0, B04 is 492.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '6', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      "  4%|         | 30/829 [00:50<22:24,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B02', 'is', '', '2', '6', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '7', '0', '3', '0', '3', '1', '3', '.']]\n",
      "decoded_data: ['B02 is 263.0, DOY is 211.0, PID is 5952.0, B04 is 492.0, B03 is 713.0 7030313.']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5053.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 5053.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '0', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '0', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '3', '2', '2', '2', '2']]\n",
      "decoded_data: ['PID is 5053.0, DOY is 211.0, B04 is 605.0, B03 is 758.0, B02 is 363.0 B04 is 32222']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 758.0, DOY is 211.0, B04 is 605.0, PID is 5053.0, B02 is']\n",
      "prompt: B03 is 758.0, DOY is 211.0, B04 is 605.0, PID is 5053.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '5', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '3', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '5', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '3', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '3', '6', '3', '6', '3']]\n",
      "decoded_data: ['B03 is 758.0, DOY is 211.0, B04 is 605.0, PID is 5053.0, B02 is 363.0 PID is 36363']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5053.0, B04 is 605.0, B03 is 758.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 5053.0, B04 is 605.0, B03 is 758.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '0', '5', '3', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '0', '5', '3', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '3', '6', '3', '6', '3']]\n",
      "decoded_data: ['PID is 5053.0, B04 is 605.0, B03 is 758.0, DOY is 211.0, B02 is 363.0 PID is 36363']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5053.0, B03 is 758.0, DOY is 211.0, B04 is 605.0, B02 is']\n",
      "prompt: PID is 5053.0, B03 is 758.0, DOY is 211.0, B04 is 605.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '0', '5', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '5', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '0', '5', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '3', '6', '3', '1', '7']]\n",
      "decoded_data: ['PID is 5053.0, B03 is 758.0, DOY is 211.0, B04 is 605.0, B02 is 363.0 PID is 36317']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 605.0, B03 is 758.0, PID is 5053.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 605.0, B03 is 758.0, PID is 5053.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '6', '0', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '6', '0', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '3', '1', '7', '0', '7', '0', '.', '0']]\n",
      "decoded_data: ['B04 is 605.0, B03 is 758.0, PID is 5053.0, DOY is 211.0, B02 is 363.06317070.0']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5053.0, B03 is 758.0, B04 is 605.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 5053.0, B03 is 758.0, B04 is 605.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '0', '5', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '8', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '0', '5', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '8', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '3', '6', '3', '6', '3']]\n",
      "decoded_data: ['PID is 5053.0, B03 is 758.0, B04 is 605.0, DOY is 211.0, B02 is 363.0 PID is 36363']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 758.0, PID is 5053.0, DOY is 211.0, B04 is 605.0, B02 is']\n",
      "prompt: B03 is 758.0, PID is 5053.0, DOY is 211.0, B04 is 605.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '5', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '5', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '5', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B02', 'is', '', '3', '6']]\n",
      "decoded_data: ['B03 is 758.0, PID is 5053.0, DOY is 211.0, B04 is 605.0, B02 is 363.0 PID is B02 is 36']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 758.0, DOY is 211.0, PID is 5053.0, B04 is 605.0, B02 is']\n",
      "prompt: B03 is 758.0, DOY is 211.0, PID is 5053.0, B04 is 605.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '5', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '3', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '5', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '5', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '3', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '3', '1', '7', '0', '7']]\n",
      "decoded_data: ['B03 is 758.0, DOY is 211.0, PID is 5053.0, B04 is 605.0, B02 is 363.0 PID is 31707']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 605.0, PID is 5053.0, B03 is 758.0, B02 is']\n",
      "prompt: DOY is 211.0, B04 is 605.0, PID is 5053.0, B03 is 758.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '8', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '3', '6', '3', '.', '0', ',', '', 'PID']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 605.0, PID is 5053.0, B03 is 758.0, B02 is 363.0 363.0, PID']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 605.0, PID is 5053.0, DOY is 211.0, B03 is 758.0, B02 is']\n",
      "prompt: B04 is 605.0, PID is 5053.0, DOY is 211.0, B03 is 758.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '6', '0', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '8', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '6', '0', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '3', '6', '3', '6', '3']]\n",
      "decoded_data: ['B04 is 605.0, PID is 5053.0, DOY is 211.0, B03 is 758.0, B02 is 363.0 PID is 36363']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5053.0, B04 is 605.0, B03 is 758.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 5053.0, B04 is 605.0, B03 is 758.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '3', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '8', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '3', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B02', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5053.0, B04 is 605.0, B03 is 758.0, B02 is 363.0 B04 is B02 is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 605.0, B03 is 758.0, PID is 5053.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 605.0, B03 is 758.0, PID is 5053.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '6', '0', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '6', '0', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '0', '5', '3', '9', '0', '7', '0', '.', '0']]\n",
      "decoded_data: ['B04 is 605.0, B03 is 758.0, PID is 5053.0, DOY is 211.0, B02 is 363.00539070.0']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 605.0, B03 is 758.0, PID is 5053.0, B02 is']\n",
      "prompt: DOY is 211.0, B04 is 605.0, B03 is 758.0, PID is 5053.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '3', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '3', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '3', '6', '3', '6', '3']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 605.0, B03 is 758.0, PID is 5053.0, B02 is 363.0 PID is 36363']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5053.0, B03 is 758.0, B04 is 605.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 5053.0, B03 is 758.0, B04 is 605.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '0', '5', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '8', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '0', '5', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '8', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '3', '6', '3', '1', '7', '0', '0', '.', '0']]\n",
      "decoded_data: ['PID is 5053.0, B03 is 758.0, B04 is 605.0, DOY is 211.0, B02 is 363.03631700.0']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5053.0, DOY is 211.0, B03 is 758.0, B04 is 605.0, B02 is']\n",
      "prompt: PID is 5053.0, DOY is 211.0, B03 is 758.0, B04 is 605.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '0', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '8', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '5', '.', '0', ',', '', 'B02', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      "  4%|         | 31/829 [00:53<24:41,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '5', '0', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '8', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '3', '6', '3', '2', '2', '2', '2', '2']]\n",
      "decoded_data: ['PID is 5053.0, DOY is 211.0, B03 is 758.0, B04 is 605.0, B02 is 363.0 36322222']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5153.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 5153.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '3', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '3', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '7', '3', '8', 'B04', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5153.0, B02 is 327.0, B04 is 546.0, B03 is 738.0 738B04 is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 327.0, PID is 5153.0, DOY is 211.0, B04 is 546.0, B03 is']\n",
      "prompt: B02 is 327.0, PID is 5153.0, DOY is 211.0, B04 is 546.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '2', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '2', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '3']]\n",
      "decoded_data: ['B02 is 327.0, PID is 5153.0, DOY is 211.0, B04 is 546.0, B03 is 738.0 B04 is PID is 73']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 327.0, PID is 5153.0, B04 is 546.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 327.0, PID is 5153.0, B04 is 546.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '7', '3', '8', '4', '7', '3', '.', '0']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 327.0, PID is 5153.0, B04 is 546.0, B03 is 738.0 738473.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 327.0, PID is 5153.0, DOY is 211.0, B04 is 546.0, B03 is']\n",
      "prompt: B02 is 327.0, PID is 5153.0, DOY is 211.0, B04 is 546.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '2', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '2', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '.', '0', '3', '8', '4', '7', '4', '7', '3']]\n",
      "decoded_data: ['B02 is 327.0, PID is 5153.0, DOY is 211.0, B04 is 546.0, B03 is 738.0.03847473']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5153.0, B02 is 327.0, DOY is 211.0, B04 is 546.0, B03 is']\n",
      "prompt: PID is 5153.0, B02 is 327.0, DOY is 211.0, B04 is 546.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '1', '5', '3', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '1', '5', '3', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '3', '8', '4', '7']]\n",
      "decoded_data: ['PID is 5153.0, B02 is 327.0, DOY is 211.0, B04 is 546.0, B03 is 738.0 PID is 73847']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 327.0, PID is 5153.0, DOY is 211.0, B04 is 546.0, B03 is']\n",
      "prompt: B02 is 327.0, PID is 5153.0, DOY is 211.0, B04 is 546.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '2', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '2', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '7', '3']]\n",
      "decoded_data: ['B02 is 327.0, PID is 5153.0, DOY is 211.0, B04 is 546.0, B03 is 738.0 PID is B04 is 73']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 546.0, DOY is 211.0, PID is 5153.0, B02 is 327.0, B03 is']\n",
      "prompt: B04 is 546.0, DOY is 211.0, PID is 5153.0, B02 is 327.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '4', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '3', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '4', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '3', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '3', '8', '4', '7']]\n",
      "decoded_data: ['B04 is 546.0, DOY is 211.0, PID is 5153.0, B02 is 327.0, B03 is 738.0 PID is 73847']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 327.0, B04 is 546.0, PID is 5153.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 327.0, B04 is 546.0, PID is 5153.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '2', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '2', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '3']]\n",
      "decoded_data: ['B02 is 327.0, B04 is 546.0, PID is 5153.0, DOY is 211.0, B03 is 738.0 B04 is PID is 73']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5153.0, B04 is 546.0, B02 is 327.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5153.0, B04 is 546.0, B02 is 327.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '1', '5', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '1', '5', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['PID is 5153.0, B04 is 546.0, B02 is 327.0, DOY is 211.0, B03 is 738.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 327.0, DOY is 211.0, B04 is 546.0, PID is 5153.0, B03 is']\n",
      "prompt: B02 is 327.0, DOY is 211.0, B04 is 546.0, PID is 5153.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '2', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '2', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '3']]\n",
      "decoded_data: ['B02 is 327.0, DOY is 211.0, B04 is 546.0, PID is 5153.0, B03 is 738.0 B04 is PID is 73']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 327.0, PID is 5153.0, B04 is 546.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 327.0, PID is 5153.0, B04 is 546.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B02', 'is', '', 'PID', 'is', '', '7', '3']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 327.0, PID is 5153.0, B04 is 546.0, B03 is 738.0 B02 is PID is 73']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5153.0, B04 is 546.0, B02 is 327.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 5153.0, B04 is 546.0, B02 is 327.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '2', '5', '1', '7', '9', '3', '8', '.']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5153.0, B04 is 546.0, B02 is 327.0, B03 is 738.072517938.']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5153.0, B02 is 327.0, B04 is 546.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 5153.0, B02 is 327.0, B04 is 546.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '3', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '3', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '3', '8', '6', '7']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5153.0, B02 is 327.0, B04 is 546.0, B03 is 738.0 PID is 73867']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 546.0, B02 is 327.0, PID is 5153.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 546.0, B02 is 327.0, PID is 5153.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B02', 'is', '', '7', '3']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 546.0, B02 is 327.0, PID is 5153.0, B03 is 738.0 PID is B02 is 73']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5153.0, B02 is 327.0, B04 is 546.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5153.0, B02 is 327.0, B04 is 546.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '1', '5', '3', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      "  4%|         | 32/829 [00:55<26:20,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '5', '1', '5', '3', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B02', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['PID is 5153.0, B02 is 327.0, B04 is 546.0, DOY is 211.0, B03 is 738.0 B04 is B02 is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5253.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5253.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '2', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '2', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '9', '3', '9', '3', '.', '0', '8', '3', '.']]\n",
      "decoded_data: ['PID is 5253.0, DOY is 211.0, B03 is 731.0, B04 is 501.0, B02 is 293.09393.083.']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 731.0, B04 is 501.0, PID is 5253.0, DOY is 211.0, B02 is']\n",
      "prompt: B03 is 731.0, B04 is 501.0, PID is 5253.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '3', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '3', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '2', '8', '6', '8', '3', '7', '0', '8']]\n",
      "decoded_data: ['B03 is 731.0, B04 is 501.0, PID is 5253.0, DOY is 211.0, B02 is 293.0 28683708']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 501.0, B03 is 731.0, PID is 5253.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 501.0, B03 is 731.0, PID is 5253.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '0', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '0', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '2', '.', '0', '8', '8', '3', '.', '0']]\n",
      "decoded_data: ['B04 is 501.0, B03 is 731.0, PID is 5253.0, DOY is 211.0, B02 is 293.0 2.0883.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 731.0, PID is 5253.0, DOY is 211.0, B04 is 501.0, B02 is']\n",
      "prompt: B03 is 731.0, PID is 5253.0, DOY is 211.0, B04 is 501.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '3', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '3', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '5', '0']]\n",
      "decoded_data: ['B03 is 731.0, PID is 5253.0, DOY is 211.0, B04 is 501.0, B02 is 293.0 PID is B04 is 50']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5253.0, B04 is 501.0, B03 is 731.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 5253.0, B04 is 501.0, B03 is 731.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '2', '1', '.', '0', '0', '.', '0', '8', '3']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5253.0, B04 is 501.0, B03 is 731.0, B02 is 293.021.00.083']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5253.0, B03 is 731.0, DOY is 211.0, B04 is 501.0, B02 is']\n",
      "prompt: PID is 5253.0, B03 is 731.0, DOY is 211.0, B04 is 501.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '2', '5', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '2', '5', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '0', '8', '8', '3', '9', '3', '.', '0', ',']]\n",
      "decoded_data: ['PID is 5253.0, B03 is 731.0, DOY is 211.0, B04 is 501.0, B02 is 293.0088393.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 501.0, PID is 5253.0, B03 is 731.0, B02 is']\n",
      "prompt: DOY is 211.0, B04 is 501.0, PID is 5253.0, B03 is 731.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '9', '3', '7', '0', '2']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 501.0, PID is 5253.0, B03 is 731.0, B02 is 293.0 PID is 93702']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 501.0, PID is 5253.0, B03 is 731.0, B02 is']\n",
      "prompt: DOY is 211.0, B04 is 501.0, PID is 5253.0, B03 is 731.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '2', '8', '8', '4', '3']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 501.0, PID is 5253.0, B03 is 731.0, B02 is 293.0 PID is 28843']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 731.0, PID is 5253.0, B04 is 501.0, B02 is']\n",
      "prompt: DOY is 211.0, B03 is 731.0, PID is 5253.0, B04 is 501.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '0', '8', '6', '2', '.', '0', ',', '', 'PID']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 731.0, PID is 5253.0, B04 is 501.0, B02 is 293.00862.0, PID']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 501.0, PID is 5253.0, B03 is 731.0, B02 is']\n",
      "prompt: DOY is 211.0, B04 is 501.0, PID is 5253.0, B03 is 731.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '2', '4', '7', '0', '8', '3', '.', '0']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 501.0, PID is 5253.0, B03 is 731.0, B02 is 293.0 247083.0']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5253.0, B04 is 501.0, B03 is 731.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 5253.0, B04 is 501.0, B03 is 731.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '2', '5', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '2', '5', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '0', '7', '0', '8', '8', '3', '.', '0', '7']]\n",
      "decoded_data: ['PID is 5253.0, B04 is 501.0, B03 is 731.0, DOY is 211.0, B02 is 293.0070883.07']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5253.0, B03 is 731.0, DOY is 211.0, B04 is 501.0, B02 is']\n",
      "prompt: PID is 5253.0, B03 is 731.0, DOY is 211.0, B04 is 501.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '2', '5', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '2', '5', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '1', '.', '0', '0', ',', '', 'PID', 'is', '']]\n",
      "decoded_data: ['PID is 5253.0, B03 is 731.0, DOY is 211.0, B04 is 501.0, B02 is 293.01.00, PID is ']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 731.0, PID is 5253.0, B04 is 501.0, B02 is']\n",
      "prompt: DOY is 211.0, B03 is 731.0, PID is 5253.0, B04 is 501.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B02', 'is', '', '2', '1', '0', '.', '0']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 731.0, PID is 5253.0, B04 is 501.0, B02 is 293.0 B02 is 210.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 731.0, DOY is 211.0, B04 is 501.0, PID is 5253.0, B02 is']\n",
      "prompt: B03 is 731.0, DOY is 211.0, B04 is 501.0, PID is 5253.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '3', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '3', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '3', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '0', '.', '0', ',']]\n",
      "decoded_data: ['B03 is 731.0, DOY is 211.0, B04 is 501.0, PID is 5253.0, B02 is 293.0 B04 is 50.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 731.0, B04 is 501.0, DOY is 211.0, PID is 5253.0, B02 is']\n",
      "prompt: B03 is 731.0, B04 is 501.0, DOY is 211.0, PID is 5253.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '3', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '3', '.', '0', ',', '', 'B02', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      "  4%|         | 33/829 [00:57<27:42,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B03', 'is', '', '7', '3', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '9', '3', '.', '0', '.']]\n",
      "decoded_data: ['B03 is 731.0, B04 is 501.0, DOY is 211.0, PID is 5253.0, B02 is 293.0 B04 is 93.0.']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5353.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 5353.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '3', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '0', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5353.0, B04 is 490.0, B02 is 274.0, B03 is 751.0 B04 is PID is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 490.0, PID is 5353.0, B02 is 274.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 490.0, PID is 5353.0, B02 is 274.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B02', 'is', '', '7', '5']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 490.0, PID is 5353.0, B02 is 274.0, B03 is 751.0 PID is B02 is 75']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5353.0, DOY is 211.0, B04 is 490.0, B02 is 274.0, B03 is']\n",
      "prompt: PID is 5353.0, DOY is 211.0, B04 is 490.0, B02 is 274.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '3', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '0', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '3', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '0', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '4', '2', '.', '0', ',', '', 'PID', 'is']]\n",
      "decoded_data: ['PID is 5353.0, DOY is 211.0, B04 is 490.0, B02 is 274.0, B03 is 751.0742.0, PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 490.0, DOY is 211.0, B02 is 274.0, PID is 5353.0, B03 is']\n",
      "prompt: B04 is 490.0, DOY is 211.0, B02 is 274.0, PID is 5353.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '9', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '9', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '5', '1', '2', '7']]\n",
      "decoded_data: ['B04 is 490.0, DOY is 211.0, B02 is 274.0, PID is 5353.0, B03 is 751.0 PID is 75127']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5353.0, B04 is 490.0, B02 is 274.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5353.0, B04 is 490.0, B02 is 274.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '3', '5', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '0', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '3', '5', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '0', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['PID is 5353.0, B04 is 490.0, B02 is 274.0, DOY is 211.0, B03 is 751.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 490.0, B02 is 274.0, PID is 5353.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 490.0, B02 is 274.0, PID is 5353.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '0', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '0', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '4', '.', '0', ',', '', 'B03', 'is', '']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 490.0, B02 is 274.0, PID is 5353.0, B03 is 751.074.0, B03 is ']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 490.0, PID is 5353.0, DOY is 211.0, B02 is 274.0, B03 is']\n",
      "prompt: B04 is 490.0, PID is 5353.0, DOY is 211.0, B02 is 274.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '9', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '9', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '7', '4']]\n",
      "decoded_data: ['B04 is 490.0, PID is 5353.0, DOY is 211.0, B02 is 274.0, B03 is 751.0 PID is B04 is 74']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5353.0, B02 is 274.0, DOY is 211.0, B04 is 490.0, B03 is']\n",
      "prompt: PID is 5353.0, B02 is 274.0, DOY is 211.0, B04 is 490.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '3', '5', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '0', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '3', '5', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '4', '0', '4', '8', '4']]\n",
      "decoded_data: ['PID is 5353.0, B02 is 274.0, DOY is 211.0, B04 is 490.0, B03 is 751.0 B04 is 40484']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5353.0, B04 is 490.0, B02 is 274.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 5353.0, B04 is 490.0, B02 is 274.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '0', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '0', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '4', '2', '.', '0', '4', '0', '4', '0']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5353.0, B04 is 490.0, B02 is 274.0, B03 is 751.0742.04040']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5353.0, DOY is 211.0, B02 is 274.0, B04 is 490.0, B03 is']\n",
      "prompt: PID is 5353.0, DOY is 211.0, B02 is 274.0, B04 is 490.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '3', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '0', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '3', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '7', '5']]\n",
      "decoded_data: ['PID is 5353.0, DOY is 211.0, B02 is 274.0, B04 is 490.0, B03 is 751.0 PID is B04 is 75']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5353.0, B04 is 490.0, DOY is 211.0, B02 is 274.0, B03 is']\n",
      "prompt: PID is 5353.0, B04 is 490.0, DOY is 211.0, B02 is 274.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '3', '5', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '3', '5', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B02', 'is', '', '7', '5']]\n",
      "decoded_data: ['PID is 5353.0, B04 is 490.0, DOY is 211.0, B02 is 274.0, B03 is 751.0 B04 is B02 is 75']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5353.0, B02 is 274.0, B04 is 490.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5353.0, B02 is 274.0, B04 is 490.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '3', '5', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '3', '5', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '4', '8', '4', '8', '7', 'PID', 'is', '']]\n",
      "decoded_data: ['PID is 5353.0, B02 is 274.0, B04 is 490.0, DOY is 211.0, B03 is 751.0748487PID is ']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 274.0, B04 is 490.0, DOY is 211.0, PID is 5353.0, B03 is']\n",
      "prompt: B02 is 274.0, B04 is 490.0, DOY is 211.0, PID is 5353.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '7', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '7', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '6', '.', '0', ',', '', 'B04', 'is', '']]\n",
      "decoded_data: ['B02 is 274.0, B04 is 490.0, DOY is 211.0, PID is 5353.0, B03 is 751.076.0, B04 is ']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 490.0, PID is 5353.0, B02 is 274.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 490.0, PID is 5353.0, B02 is 274.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '9', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '9', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '5', '1', '3', '6']]\n",
      "decoded_data: ['B04 is 490.0, PID is 5353.0, B02 is 274.0, DOY is 211.0, B03 is 751.0 PID is 75136']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 490.0, DOY is 211.0, B02 is 274.0, PID is 5353.0, B03 is']\n",
      "prompt: B04 is 490.0, DOY is 211.0, B02 is 274.0, PID is 5353.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '9', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '3', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 34/829 [00:59<28:22,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B04', 'is', '', '4', '9', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '9', '0', ',', '', 'B03', 'is', '', 'B02']]\n",
      "decoded_data: ['B04 is 490.0, DOY is 211.0, B02 is 274.0, PID is 5353.0, B03 is 751.0790, B03 is B02']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5453.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 5453.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '3', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B02', 'is', '', '4', '8']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5453.0, B02 is 283.0, B04 is 487.0, B03 is 771.0 B04 is B02 is 48']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 283.0, PID is 5453.0, DOY is 211.0, B04 is 487.0, B03 is']\n",
      "prompt: B02 is 283.0, PID is 5453.0, DOY is 211.0, B04 is 487.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '8', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '8', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '5', '6', '5', '6']]\n",
      "decoded_data: ['B02 is 283.0, PID is 5453.0, DOY is 211.0, B04 is 487.0, B03 is 724.0 PID is 75656']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5453.0, B02 is 283.0, B04 is 487.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 5453.0, B02 is 283.0, B04 is 487.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '4', '8', '1', '3', '.']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5453.0, B02 is 283.0, B04 is 487.0, B03 is 771.0 B04 is 4813.']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5453.0, B02 is 283.0, B04 is 487.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 5453.0, B02 is 283.0, B04 is 487.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '7', '5', '1', '.', '0', ',', '', 'PID']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5453.0, B02 is 283.0, B04 is 487.0, B03 is 771.06751.0, PID']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 487.0, PID is 5453.0, B02 is 283.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 487.0, PID is 5453.0, B02 is 283.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B02', 'is', '', '7', '1']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 487.0, PID is 5453.0, B02 is 283.0, B03 is 771.0 PID is B02 is 71']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 487.0, DOY is 211.0, B02 is 283.0, PID is 5453.0, B03 is']\n",
      "prompt: B04 is 487.0, DOY is 211.0, B02 is 283.0, PID is 5453.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '8', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '8', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B02', 'is', '', '7', '5', '1', '8', '7']]\n",
      "decoded_data: ['B04 is 487.0, DOY is 211.0, B02 is 283.0, PID is 5453.0, B03 is 771.0 B02 is 75187']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5453.0, DOY is 211.0, B02 is 283.0, B04 is 487.0, B03 is']\n",
      "prompt: PID is 5453.0, DOY is 211.0, B02 is 283.0, B04 is 487.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '4', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '4', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '6', '2', '7', '1', '7']]\n",
      "decoded_data: ['PID is 5453.0, DOY is 211.0, B02 is 283.0, B04 is 487.0, B03 is 772.0 B04 is 62717']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 487.0, PID is 5453.0, B02 is 283.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 487.0, PID is 5453.0, B02 is 283.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B02', 'is', '', 'B04', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 487.0, PID is 5453.0, B02 is 283.0, B03 is 772.0 B02 is B04 is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5453.0, B04 is 487.0, DOY is 211.0, B02 is 283.0, B03 is']\n",
      "prompt: PID is 5453.0, B04 is 487.0, DOY is 211.0, B02 is 283.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '4', '5', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '4', '5', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['PID is 5453.0, B04 is 487.0, DOY is 211.0, B02 is 283.0, B03 is 772.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 487.0, DOY is 211.0, B02 is 283.0, PID is 5453.0, B03 is']\n",
      "prompt: B04 is 487.0, DOY is 211.0, B02 is 283.0, PID is 5453.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '8', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '8', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B02', 'is', '', '4', '7']]\n",
      "decoded_data: ['B04 is 487.0, DOY is 211.0, B02 is 283.0, PID is 5453.0, B03 is 771.0 B04 is B02 is 47']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 487.0, PID is 5453.0, B02 is 283.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 487.0, PID is 5453.0, B02 is 283.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '2', '.', '0', ',', '', 'B02', 'is', '']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 487.0, PID is 5453.0, B02 is 283.0, B03 is 772.062.0, B02 is ']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 487.0, B02 is 283.0, DOY is 211.0, PID is 5453.0, B03 is']\n",
      "prompt: B04 is 487.0, B02 is 283.0, DOY is 211.0, PID is 5453.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '8', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '8', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B02', 'is', '', 'B02', 'is', '', '2', '.']]\n",
      "decoded_data: ['B04 is 487.0, B02 is 283.0, DOY is 211.0, PID is 5453.0, B03 is 771.0 B02 is B02 is 2.']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 283.0, B04 is 487.0, DOY is 211.0, PID is 5453.0, B03 is']\n",
      "prompt: B02 is 283.0, B04 is 487.0, DOY is 211.0, PID is 5453.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '8', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '8', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '0', '.', '0', '.', '0', ',', '', 'B04']]\n",
      "decoded_data: ['B02 is 283.0, B04 is 487.0, DOY is 211.0, PID is 5453.0, B03 is 772.070.0.0, B04']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 487.0, B02 is 283.0, PID is 5453.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 487.0, B02 is 283.0, PID is 5453.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '8', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '8', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '7', '5', '5', '6', '7', '5', '2', '.']]\n",
      "decoded_data: ['B04 is 487.0, B02 is 283.0, PID is 5453.0, DOY is 211.0, B03 is 772.0 7556752.']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5453.0, B02 is 283.0, B04 is 487.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5453.0, B02 is 283.0, B04 is 487.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '4', '5', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      "  4%|         | 35/829 [01:02<28:41,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '5', '4', '5', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '0']]\n",
      "decoded_data: ['PID is 5453.0, B02 is 283.0, B04 is 487.0, DOY is 211.0, B03 is 772.0 B04 is PID is 70']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5553.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 5553.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'DOY', 'is', '', 'B02', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5553.0, B03 is 762.0, B02 is 257.0, B04 is 452.0 DOY is B02 is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5553.0, B03 is 762.0, B02 is 257.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 5553.0, B03 is 762.0, B02 is 257.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '5', '5', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '5', '5', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B02', 'is', '', 'B03', 'is', '', '4', '5']]\n",
      "decoded_data: ['PID is 5553.0, B03 is 762.0, B02 is 257.0, DOY is 211.0, B04 is 452.0 B02 is B03 is 45']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 762.0, B02 is 257.0, DOY is 211.0, PID is 5553.0, B04 is']\n",
      "prompt: B03 is 762.0, B02 is 257.0, DOY is 211.0, PID is 5553.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '6', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '3', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '6', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', '4', '5', '2', '.', '0']]\n",
      "decoded_data: ['B03 is 762.0, B02 is 257.0, DOY is 211.0, PID is 5553.0, B04 is 452.0 B03 is 452.0']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5553.0, DOY is 211.0, B03 is 762.0, B02 is 257.0, B04 is']\n",
      "prompt: PID is 5553.0, DOY is 211.0, B03 is 762.0, B02 is 257.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '5', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '5', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', '4', '5', '2', '.', '0']]\n",
      "decoded_data: ['PID is 5553.0, DOY is 211.0, B03 is 762.0, B02 is 257.0, B04 is 452.0 B03 is 452.0']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 257.0, PID is 5553.0, B03 is 762.0, B04 is']\n",
      "prompt: DOY is 211.0, B02 is 257.0, PID is 5553.0, B03 is 762.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '2', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '2', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '4', '5', '2', '7', '7']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 257.0, PID is 5553.0, B03 is 762.0, B04 is 452.0 PID is 45277']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 762.0, B02 is 257.0, PID is 5553.0, DOY is 211.0, B04 is']\n",
      "prompt: B03 is 762.0, B02 is 257.0, PID is 5553.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '6', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '6', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '5', '2', '3', '2', '3', '6', '5']]\n",
      "decoded_data: ['B03 is 762.0, B02 is 257.0, PID is 5553.0, DOY is 211.0, B04 is 452.0 45232365']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 762.0, B02 is 257.0, PID is 5553.0, DOY is 211.0, B04 is']\n",
      "prompt: B03 is 762.0, B02 is 257.0, PID is 5553.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '6', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '6', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '4', '0', '4', '5', '2']]\n",
      "decoded_data: ['B03 is 762.0, B02 is 257.0, PID is 5553.0, DOY is 211.0, B04 is 452.0 PID is 40452']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 762.0, PID is 5553.0, B02 is 257.0, B04 is']\n",
      "prompt: DOY is 211.0, B03 is 762.0, PID is 5553.0, B02 is 257.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '5', '2', '3', '.', '0', ',', '']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 762.0, PID is 5553.0, B02 is 257.0, B04 is 452.0 4523.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 257.0, B03 is 762.0, DOY is 211.0, PID is 5553.0, B04 is']\n",
      "prompt: B02 is 257.0, B03 is 762.0, DOY is 211.0, PID is 5553.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '5', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '3', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '5', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'DOY', 'is', '', 'B02', 'is', '', '2', '3']]\n",
      "decoded_data: ['B02 is 257.0, B03 is 762.0, DOY is 211.0, PID is 5553.0, B04 is 452.0 DOY is B02 is 23']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5553.0, B03 is 762.0, B02 is 257.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 5553.0, B03 is 762.0, B02 is 257.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '5', '5', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '5', '5', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '0', '4', '5', '2', '7', '0', '4']]\n",
      "decoded_data: ['PID is 5553.0, B03 is 762.0, B02 is 257.0, DOY is 211.0, B04 is 452.0 40452704']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5553.0, B02 is 257.0, DOY is 211.0, B03 is 762.0, B04 is']\n",
      "prompt: PID is 5553.0, B02 is 257.0, DOY is 211.0, B03 is 762.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '5', '5', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '2', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '5', '5', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '2', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '5', '2', '.', '0', ',', '', 'PID']]\n",
      "decoded_data: ['PID is 5553.0, B02 is 257.0, DOY is 211.0, B03 is 762.0, B04 is 452.0 452.0, PID']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 257.0, PID is 5553.0, B03 is 762.0, B04 is']\n",
      "prompt: DOY is 211.0, B02 is 257.0, PID is 5553.0, B03 is 762.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '2', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '2', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'DOY', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 257.0, PID is 5553.0, B03 is 762.0, B04 is 452.0 PID is DOY is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5553.0, B02 is 257.0, DOY is 211.0, B03 is 762.0, B04 is']\n",
      "prompt: PID is 5553.0, B02 is 257.0, DOY is 211.0, B03 is 762.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '5', '5', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '2', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '5', '5', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '2', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '4', '5', '2', '7', '5']]\n",
      "decoded_data: ['PID is 5553.0, B02 is 257.0, DOY is 211.0, B03 is 762.0, B04 is 452.0 PID is 45275']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5553.0, B03 is 762.0, B02 is 257.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 5553.0, B03 is 762.0, B02 is 257.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '5', '5', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '5', '5', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '5', '2', '7', '5', '2', '.', '0']]\n",
      "decoded_data: ['PID is 5553.0, B03 is 762.0, B02 is 257.0, DOY is 211.0, B04 is 452.0 452752.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 257.0, PID is 5553.0, DOY is 211.0, B03 is 762.0, B04 is']\n",
      "prompt: B02 is 257.0, PID is 5553.0, DOY is 211.0, B03 is 762.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '5', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '2', '.', '0', ',', '', 'B04', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      "  4%|         | 36/829 [01:04<28:49,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B02', 'is', '', '2', '5', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '2', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '4', '5', '2', '7', '5']]\n",
      "decoded_data: ['B02 is 257.0, PID is 5553.0, DOY is 211.0, B03 is 762.0, B04 is 452.0 PID is 45275']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5653.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 5653.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '3', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '8', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '4', '9', '1', '.', '0', ',', '', 'B04', 'is']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5653.0, B04 is 438.0, B02 is 258.0, B03 is 734.0491.0, B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5653.0, DOY is 211.0, B04 is 438.0, B02 is 258.0, B03 is']\n",
      "prompt: PID is 5653.0, DOY is 211.0, B04 is 438.0, B02 is 258.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '6', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '8', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '6', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '8', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', '5', '8']]\n",
      "decoded_data: ['PID is 5653.0, DOY is 211.0, B04 is 438.0, B02 is 258.0, B03 is 734.0 B04 is B04 is 58']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 438.0, PID is 5653.0, B02 is 258.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 438.0, PID is 5653.0, B02 is 258.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '3', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '3', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', '5', '2']]\n",
      "decoded_data: ['B04 is 438.0, PID is 5653.0, B02 is 258.0, DOY is 211.0, B03 is 734.0 B04 is B04 is 52']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 258.0, B04 is 438.0, DOY is 211.0, PID is 5653.0, B03 is']\n",
      "prompt: B02 is 258.0, B04 is 438.0, DOY is 211.0, PID is 5653.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '5', '8', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '5', '8', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '4', '0', '8', '3', '4', '0', '8', '2', '.']]\n",
      "decoded_data: ['B02 is 258.0, B04 is 438.0, DOY is 211.0, PID is 5653.0, B03 is 734.040834082.']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 438.0, PID is 5653.0, DOY is 211.0, B02 is 258.0, B03 is']\n",
      "prompt: B04 is 438.0, PID is 5653.0, DOY is 211.0, B02 is 258.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '3', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '8', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 37/829 [01:05<23:39,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B04', 'is', '', '4', '3', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '1', '7', '0', '1', '3', '4', '9', '2']]\n",
      "decoded_data: ['B04 is 438.0, PID is 5653.0, DOY is 211.0, B02 is 258.0, B03 is 734.0717013492']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5753.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 5753.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '3', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', '4', '6']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5753.0, B02 is 271.0, B04 is 466.0, B03 is 730.0 B04 is B04 is 46']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 466.0, PID is 5753.0, DOY is 211.0, B02 is 271.0, B03 is']\n",
      "prompt: B04 is 466.0, PID is 5753.0, DOY is 211.0, B02 is 271.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['B04 is 466.0, PID is 5753.0, DOY is 211.0, B02 is 271.0, B03 is 730.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5753.0, B04 is 466.0, B02 is 271.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 5753.0, B04 is 466.0, B02 is 271.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', '4', '0']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5753.0, B04 is 466.0, B02 is 271.0, B03 is 730.0 B04 is B04 is 40']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5753.0, DOY is 211.0, B04 is 466.0, B02 is 271.0, B03 is']\n",
      "prompt: PID is 5753.0, DOY is 211.0, B04 is 466.0, B02 is 271.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '7', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '7', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '3']]\n",
      "decoded_data: ['PID is 5753.0, DOY is 211.0, B04 is 466.0, B02 is 271.0, B03 is 730.0 B04 is PID is 73']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5753.0, B02 is 271.0, B04 is 466.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5753.0, B02 is 271.0, B04 is 466.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '7', '5', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '7', '5', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '2']]\n",
      "decoded_data: ['PID is 5753.0, B02 is 271.0, B04 is 466.0, DOY is 211.0, B03 is 730.0 B04 is PID is 72']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 271.0, B04 is 466.0, PID is 5753.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 271.0, B04 is 466.0, PID is 5753.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', 'B03', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 271.0, B04 is 466.0, PID is 5753.0, B03 is 730.0 PID is B04 is B03 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 271.0, PID is 5753.0, B04 is 466.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 271.0, PID is 5753.0, B04 is 466.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', 'B03', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 271.0, PID is 5753.0, B04 is 466.0, B03 is 730.0 B04 is B04 is B03 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5753.0, DOY is 211.0, B04 is 466.0, B02 is 271.0, B03 is']\n",
      "prompt: PID is 5753.0, DOY is 211.0, B04 is 466.0, B02 is 271.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '7', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '7', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['PID is 5753.0, DOY is 211.0, B04 is 466.0, B02 is 271.0, B03 is 730.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 466.0, DOY is 211.0, B02 is 271.0, PID is 5753.0, B03 is']\n",
      "prompt: B04 is 466.0, DOY is 211.0, B02 is 271.0, PID is 5753.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '4', '0', '4', '0']]\n",
      "decoded_data: ['B04 is 466.0, DOY is 211.0, B02 is 271.0, PID is 5753.0, B03 is 730.0 PID is 74040']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5753.0, B04 is 466.0, DOY is 211.0, B02 is 271.0, B03 is']\n",
      "prompt: PID is 5753.0, B04 is 466.0, DOY is 211.0, B02 is 271.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '7', '5', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '7', '5', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'DOY', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['PID is 5753.0, B04 is 466.0, DOY is 211.0, B02 is 271.0, B03 is 730.0 B04 is DOY is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 271.0, DOY is 211.0, PID is 5753.0, B04 is 466.0, B03 is']\n",
      "prompt: B02 is 271.0, DOY is 211.0, PID is 5753.0, B04 is 466.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '7', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '7', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '4', '3', '0', '6', '3']]\n",
      "decoded_data: ['B02 is 271.0, DOY is 211.0, PID is 5753.0, B04 is 466.0, B03 is 730.0 B04 is 43063']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5753.0, DOY is 211.0, B04 is 466.0, B02 is 271.0, B03 is']\n",
      "prompt: PID is 5753.0, DOY is 211.0, B04 is 466.0, B02 is 271.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '7', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '7', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '7', '3', '2', '2', '2', '2', '2', '2']]\n",
      "decoded_data: ['PID is 5753.0, DOY is 211.0, B04 is 466.0, B02 is 271.0, B03 is 730.0 73222222']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 271.0, DOY is 211.0, PID is 5753.0, B04 is 466.0, B03 is']\n",
      "prompt: B02 is 271.0, DOY is 211.0, PID is 5753.0, B04 is 466.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '7', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '7', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '4', '0']]\n",
      "decoded_data: ['B02 is 271.0, DOY is 211.0, PID is 5753.0, B04 is 466.0, B03 is 730.0 PID is B04 is 40']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 466.0, B02 is 271.0, DOY is 211.0, PID is 5753.0, B03 is']\n",
      "prompt: B04 is 466.0, B02 is 271.0, DOY is 211.0, PID is 5753.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B03', 'is', '', '7', '6']]\n",
      "decoded_data: ['B04 is 466.0, B02 is 271.0, DOY is 211.0, PID is 5753.0, B03 is 730.0 B04 is B03 is 76']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 466.0, PID is 5753.0, B02 is 271.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 466.0, PID is 5753.0, B02 is 271.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '1', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      "  5%|         | 38/829 [01:07<25:23,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '3', '0', '1', '9', '.', '0', '7', '3']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 466.0, PID is 5753.0, B02 is 271.0, B03 is 730.073019.073']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5853.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 5853.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '4', '9', '5', '2', '2']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5853.0, B03 is 726.0, B02 is 276.0, B04 is 465.0 PID is 49522']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 726.0, DOY is 211.0, B02 is 276.0, PID is 5853.0, B04 is']\n",
      "prompt: B03 is 726.0, DOY is 211.0, B02 is 276.0, PID is 5853.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '2', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '3', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '2', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '.', '0', ',', '', 'DOY', 'is', '']]\n",
      "decoded_data: ['B03 is 726.0, DOY is 211.0, B02 is 276.0, PID is 5853.0, B04 is 465.0 4.0, DOY is ']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5853.0, B03 is 726.0, B02 is 276.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 5853.0, B03 is 726.0, B02 is 276.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '6', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '4', '9', '5', '2', '2']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5853.0, B03 is 726.0, B02 is 276.0, B04 is 465.0 PID is 49522']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 726.0, PID is 5853.0, DOY is 211.0, B02 is 276.0, B04 is']\n",
      "prompt: B03 is 726.0, PID is 5853.0, DOY is 211.0, B02 is 276.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '2', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '6', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '2', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '9', '1', '2', '8', '1', '2', '2']]\n",
      "decoded_data: ['B03 is 726.0, PID is 5853.0, DOY is 211.0, B02 is 276.0, B04 is 465.0 49128122']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5853.0, B03 is 726.0, B02 is 276.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 5853.0, B03 is 726.0, B02 is 276.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '6', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '2', '.', '0', '2', '2', '8', '7']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5853.0, B03 is 726.0, B02 is 276.0, B04 is 465.0 52.02287']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 276.0, B03 is 726.0, DOY is 211.0, PID is 5853.0, B04 is']\n",
      "prompt: B02 is 276.0, B03 is 726.0, DOY is 211.0, PID is 5853.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '7', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '3', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '7', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '4', '.', '0', '0', '0']]\n",
      "decoded_data: ['B02 is 276.0, B03 is 726.0, DOY is 211.0, PID is 5853.0, B04 is 465.0 B04 is 4.000']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5853.0, B02 is 276.0, B03 is 726.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 5853.0, B02 is 276.0, B03 is 726.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '6', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '4', '9', '5', '2', '8']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5853.0, B02 is 276.0, B03 is 726.0, B04 is 465.0 B04 is 49528']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5853.0, B02 is 276.0, B03 is 726.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 5853.0, B02 is 276.0, B03 is 726.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '8', '5', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '8', '5', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B02', 'is', '', 'PID', 'is', '', '4', '9']]\n",
      "decoded_data: ['PID is 5853.0, B02 is 276.0, B03 is 726.0, DOY is 211.0, B04 is 465.0 B02 is PID is 49']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 276.0, DOY is 211.0, PID is 5853.0, B03 is 726.0, B04 is']\n",
      "prompt: B02 is 276.0, DOY is 211.0, PID is 5853.0, B03 is 726.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '7', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '6', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '7', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '4', '9', '5', '2', '.']]\n",
      "decoded_data: ['B02 is 276.0, DOY is 211.0, PID is 5853.0, B03 is 726.0, B04 is 465.0 B04 is 4952.']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5853.0, B02 is 276.0, B03 is 726.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 5853.0, B02 is 276.0, B03 is 726.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '6', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '4', '2']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5853.0, B02 is 276.0, B03 is 726.0, B04 is 465.0 PID is B04 is 42']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 276.0, PID is 5853.0, DOY is 211.0, B03 is 726.0, B04 is']\n",
      "prompt: B02 is 276.0, PID is 5853.0, DOY is 211.0, B03 is 726.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '7', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '6', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '7', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '4', '6']]\n",
      "decoded_data: ['B02 is 276.0, PID is 5853.0, DOY is 211.0, B03 is 726.0, B04 is 465.0 PID is B04 is 46']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 726.0, B02 is 276.0, DOY is 211.0, PID is 5853.0, B04 is']\n",
      "prompt: B03 is 726.0, B02 is 276.0, DOY is 211.0, PID is 5853.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '2', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '3', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '2', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '4', '9', '5', '2', '.']]\n",
      "decoded_data: ['B03 is 726.0, B02 is 276.0, DOY is 211.0, PID is 5853.0, B04 is 465.0 PID is 4952.']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 276.0, PID is 5853.0, B03 is 726.0, B04 is']\n",
      "prompt: DOY is 211.0, B02 is 276.0, PID is 5853.0, B03 is 726.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '6', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '4', '2', '2', '2', '2']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 276.0, PID is 5853.0, B03 is 726.0, B04 is 465.0 PID is 42222']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5853.0, B03 is 726.0, DOY is 211.0, B02 is 276.0, B04 is']\n",
      "prompt: PID is 5853.0, B03 is 726.0, DOY is 211.0, B02 is 276.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '8', '5', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '6', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '8', '5', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '9', '5', '2', '8', '1', '.', '0']]\n",
      "decoded_data: ['PID is 5853.0, B03 is 726.0, DOY is 211.0, B02 is 276.0, B04 is 465.0 495281.0']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5853.0, B02 is 276.0, B03 is 726.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 5853.0, B02 is 276.0, B03 is 726.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '6', '.', '0', ',', '', 'B04', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      "  5%|         | 39/829 [01:09<26:46,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '5', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '4', '9', '0', '0', '0']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5853.0, B02 is 276.0, B03 is 726.0, B04 is 465.0 B04 is 49000']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5953.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 5953.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '3', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B02', 'is', '', '2', '6']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5953.0, B04 is 494.0, B03 is 716.0, B02 is 260.0 B04 is B02 is 26']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5953.0, B03 is 716.0, B04 is 494.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 5953.0, B03 is 716.0, B04 is 494.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '4', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B02', 'is', '', '2', '0', '0', '3', '0']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5953.0, B03 is 716.0, B04 is 494.0, B02 is 260.0 B02 is 20030']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 494.0, PID is 5953.0, DOY is 211.0, B03 is 716.0, B02 is']\n",
      "prompt: B04 is 494.0, PID is 5953.0, DOY is 211.0, B03 is 716.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '9', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'B02', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|         | 40/829 [01:10<21:26,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B04', 'is', '', '4', '9', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '2', '7', '1', '0', '3', '6', '3', '6']]\n",
      "decoded_data: ['B04 is 494.0, PID is 5953.0, DOY is 211.0, B03 is 716.0, B02 is 260.0 27103636']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5953.0, B04 is 494.0, B03 is 716.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 5953.0, B04 is 494.0, B03 is 716.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '9', '5', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '9', '5', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '9', '3', '6', '0', '3', '0', '3', '0', '3']]\n",
      "decoded_data: ['PID is 5953.0, B04 is 494.0, B03 is 716.0, DOY is 211.0, B02 is 260.0936030303']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5054.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5054.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '0', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '0', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '8', '7', '.', '0', ',', '', 'B02', 'is', '', '4', '1', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '4', '6', '1', '1', '.', '0', ',', '', 'B03']]\n",
      "decoded_data: ['PID is 5054.0, DOY is 211.0, B03 is 781.0, B04 is 687.0, B02 is 411.04611.0, B03']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5054.0, DOY is 211.0, B04 is 687.0, B03 is 781.0, B02 is']\n",
      "prompt: PID is 5054.0, DOY is 211.0, B04 is 687.0, B03 is 781.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '0', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '8', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '0', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '8', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '1', '.', '0', ',', '', 'B02', 'is', '', '4', '1', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '9', '1', '1', '1', '1', '1', '1']]\n",
      "decoded_data: ['PID is 5054.0, DOY is 211.0, B04 is 687.0, B03 is 781.0, B02 is 411.0 49111111']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5054.0, B03 is 781.0, B04 is 687.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 5054.0, B03 is 781.0, B04 is 687.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '0', '5', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '8', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '0', '5', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '8', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '4', '1', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '9', '1', '1', '1', '1', '1', '.']]\n",
      "decoded_data: ['PID is 5054.0, B03 is 781.0, B04 is 687.0, DOY is 211.0, B02 is 411.0 4911111.']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5054.0, B03 is 781.0, B04 is 687.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 5054.0, B03 is 781.0, B04 is 687.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '0', '5', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '8', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '0', '5', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '8', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '4', '1', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '1', '1', '1', '1', '.', '0', ',', '', 'PID']]\n",
      "decoded_data: ['PID is 5054.0, B03 is 781.0, B04 is 687.0, DOY is 211.0, B02 is 411.01111.0, PID']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5054.0, DOY is 211.0, B04 is 687.0, B03 is 781.0, B02 is']\n",
      "prompt: PID is 5054.0, DOY is 211.0, B04 is 687.0, B03 is 781.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '0', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '8', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '0', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '8', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '1', '.', '0', ',', '', 'B02', 'is', '', '4', '1', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '9', '1', '1', '1', '1', '1', '7']]\n",
      "decoded_data: ['PID is 5054.0, DOY is 211.0, B04 is 687.0, B03 is 781.0, B02 is 411.0 49111117']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5054.0, B03 is 781.0, DOY is 211.0, B04 is 687.0, B02 is']\n",
      "prompt: PID is 5054.0, B03 is 781.0, DOY is 211.0, B04 is 687.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '0', '5', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '8', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '0', '5', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '8', '7', '.', '0', ',', '', 'B02', 'is', '', '4', '1', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '4', '9', '1', '1', '1', '1', '1', '.', '0']]\n",
      "decoded_data: ['PID is 5054.0, B03 is 781.0, DOY is 211.0, B04 is 687.0, B02 is 411.04911111.0']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5054.0, DOY is 211.0, B04 is 687.0, B03 is 781.0, B02 is']\n",
      "prompt: PID is 5054.0, DOY is 211.0, B04 is 687.0, B03 is 781.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '0', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '8', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '0', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '8', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '1', '.', '0', ',', '', 'B02', 'is', '', '4', '1', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '4', '1', '1', '1', '1']]\n",
      "decoded_data: ['PID is 5054.0, DOY is 211.0, B04 is 687.0, B03 is 781.0, B02 is 411.0 PID is 41111']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5054.0, DOY is 211.0, B03 is 781.0, B04 is 687.0, B02 is']\n",
      "prompt: PID is 5054.0, DOY is 211.0, B03 is 781.0, B04 is 687.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '0', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '8', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '0', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '8', '7', '.', '0', ',', '', 'B02', 'is', '', '4', '1', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '9', '7', '9', '1', '1', '1', '1']]\n",
      "decoded_data: ['PID is 5054.0, DOY is 211.0, B03 is 781.0, B04 is 687.0, B02 is 411.0 49791111']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5054.0, B04 is 687.0, B03 is 781.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 5054.0, B04 is 687.0, B03 is 781.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '6', '8', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '6', '8', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '1', '.', '0', ',', '', 'B02', 'is', '', '4', '1', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '9', '1', '1', '1', '1', '1', '.']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5054.0, B04 is 687.0, B03 is 781.0, B02 is 411.0 4911111.']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 781.0, B04 is 687.0, PID is 5054.0, DOY is 211.0, B02 is']\n",
      "prompt: B03 is 781.0, B04 is 687.0, PID is 5054.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '8', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '8', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '8', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '8', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '4', '1', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B02', 'is', '', '4', '9', '1', '1', '1']]\n",
      "decoded_data: ['B03 is 781.0, B04 is 687.0, PID is 5054.0, DOY is 211.0, B02 is 411.0 B02 is 49111']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5054.0, B04 is 687.0, DOY is 211.0, B03 is 781.0, B02 is']\n",
      "prompt: PID is 5054.0, B04 is 687.0, DOY is 211.0, B03 is 781.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '0', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '6', '8', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '1', '.', '0', ',', '', 'B02', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|         | 41/829 [01:12<21:49,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '5', '0', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '6', '8', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '1', '.', '0', ',', '', 'B02', 'is', '', '4', '1', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '4', '6', '7', '9', '7', '3', '8', '1', '1']]\n",
      "decoded_data: ['PID is 5054.0, B04 is 687.0, DOY is 211.0, B03 is 781.0, B02 is 411.0467973811']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5154.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 5154.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '4', '.', '0', ',', '', 'B04', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|         | 42/829 [01:12<17:02,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '6', '3', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '8', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B02', 'is', '', '3', '9', '6', '1', '.']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5154.0, B04 is 631.0, B03 is 755.0, B02 is 381.0 B02 is 3961.']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5154.0, B03 is 755.0, B04 is 631.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 5154.0, B03 is 755.0, B04 is 631.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '5', '.', '0', ',', '', 'B04', 'is', '', '6', '3', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '5', '.', '0', ',', '', 'B04', 'is', '', '6', '3', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '8', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '3', '1', '7', '1', '8', '1', '8', '1', '8']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5154.0, B03 is 755.0, B04 is 631.0, B02 is 381.0317181818']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5254.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 5254.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '4', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '2', '2', '2', '2']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5254.0, B04 is 525.0, B03 is 724.0, B02 is 313.0 B04 is 52222']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 525.0, PID is 5254.0, B03 is 724.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 525.0, PID is 5254.0, B03 is 724.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '2', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '2', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '3', '1', '3', '1', '3', '5', '9', '5']]\n",
      "decoded_data: ['B04 is 525.0, PID is 5254.0, B03 is 724.0, DOY is 211.0, B02 is 313.0 31313595']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 724.0, B04 is 525.0, DOY is 211.0, PID is 5254.0, B02 is']\n",
      "prompt: B03 is 724.0, B04 is 525.0, DOY is 211.0, PID is 5254.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '4', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '3', '1', '3', '1', '3', '1', '3', '1']]\n",
      "decoded_data: ['B03 is 724.0, B04 is 525.0, DOY is 211.0, PID is 5254.0, B02 is 313.0 31313131']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 724.0, DOY is 211.0, PID is 5254.0, B04 is 525.0, B02 is']\n",
      "prompt: B03 is 724.0, DOY is 211.0, PID is 5254.0, B04 is 525.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '5', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '2', '2', '2', '2']]\n",
      "decoded_data: ['B03 is 724.0, DOY is 211.0, PID is 5254.0, B04 is 525.0, B02 is 313.0 B04 is 52222']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5254.0, DOY is 211.0, B03 is 724.0, B04 is 525.0, B02 is']\n",
      "prompt: PID is 5254.0, DOY is 211.0, B03 is 724.0, B04 is 525.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '2', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '5', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '2', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '1', '2', '2', '.']]\n",
      "decoded_data: ['PID is 5254.0, DOY is 211.0, B03 is 724.0, B04 is 525.0, B02 is 313.0 B04 is 5122.']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 525.0, B03 is 724.0, PID is 5254.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 525.0, B03 is 724.0, PID is 5254.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '2', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '2', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '3', '1', '3', '9', '5']]\n",
      "decoded_data: ['B04 is 525.0, B03 is 724.0, PID is 5254.0, DOY is 211.0, B02 is 313.0 PID is 31395']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5254.0, DOY is 211.0, B03 is 724.0, B04 is 525.0, B02 is']\n",
      "prompt: PID is 5254.0, DOY is 211.0, B03 is 724.0, B04 is 525.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '2', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '5', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '2', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '1', '3', '1', '3', '1', '3', '1', '3', '.']]\n",
      "decoded_data: ['PID is 5254.0, DOY is 211.0, B03 is 724.0, B04 is 525.0, B02 is 313.013131313.']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 724.0, PID is 5254.0, DOY is 211.0, B04 is 525.0, B02 is']\n",
      "prompt: B03 is 724.0, PID is 5254.0, DOY is 211.0, B04 is 525.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '5', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '1', '3', '1', '3', '.', '0', '.', '0', '9']]\n",
      "decoded_data: ['B03 is 724.0, PID is 5254.0, DOY is 211.0, B04 is 525.0, B02 is 313.01313.0.09']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5254.0, DOY is 211.0, B03 is 724.0, B04 is 525.0, B02 is']\n",
      "prompt: PID is 5254.0, DOY is 211.0, B03 is 724.0, B04 is 525.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '2', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '5', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '2', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '3', '1', '3', '1', '3', '1', '3', '1']]\n",
      "decoded_data: ['PID is 5254.0, DOY is 211.0, B03 is 724.0, B04 is 525.0, B02 is 313.0 31313131']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 724.0, B04 is 525.0, PID is 5254.0, B02 is']\n",
      "prompt: DOY is 211.0, B03 is 724.0, B04 is 525.0, PID is 5254.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '4', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '1', '3', '1', '3', '1', '3', '.', '0', '.']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 724.0, B04 is 525.0, PID is 5254.0, B02 is 313.0131313.0.']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 525.0, B03 is 724.0, PID is 5254.0, B02 is']\n",
      "prompt: DOY is 211.0, B04 is 525.0, B03 is 724.0, PID is 5254.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '4', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '3', '1', '3', '1', '3']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 525.0, B03 is 724.0, PID is 5254.0, B02 is 313.0 PID is 31313']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 525.0, PID is 5254.0, B03 is 724.0, B02 is']\n",
      "prompt: DOY is 211.0, B04 is 525.0, PID is 5254.0, B03 is 724.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B02', 'is', '', '2', '2']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 525.0, PID is 5254.0, B03 is 724.0, B02 is 313.0 PID is B02 is 22']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 525.0, PID is 5254.0, B03 is 724.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 525.0, PID is 5254.0, B03 is 724.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '2', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '2', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '3', '1', '3', '1', '.', '0', '9', '5']]\n",
      "decoded_data: ['B04 is 525.0, PID is 5254.0, B03 is 724.0, DOY is 211.0, B02 is 313.0 3131.095']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 525.0, B03 is 724.0, PID is 5254.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 525.0, B03 is 724.0, PID is 5254.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '2', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '2', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '1', '3', '1', '3', '4', '.', '0', '.', '0']]\n",
      "decoded_data: ['B04 is 525.0, B03 is 724.0, PID is 5254.0, DOY is 211.0, B02 is 313.013134.0.0']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 525.0, PID is 5254.0, B03 is 724.0, B02 is']\n",
      "prompt: DOY is 211.0, B04 is 525.0, PID is 5254.0, B03 is 724.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'B02', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      "  5%|         | 43/829 [01:15<21:26,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 525.0, PID is 5254.0, B03 is 724.0, B02 is 313.0 PID is B04 is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5354.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 5354.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '3', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '3', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '2', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '4', '2', '4', '2', '7']]\n",
      "decoded_data: ['PID is 5354.0, DOY is 211.0, B02 is 262.0, B04 is 482.0, B03 is 763.0 B04 is 42427']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 482.0, B02 is 262.0, PID is 5354.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 482.0, B02 is 262.0, PID is 5354.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', '4', '5']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 482.0, B02 is 262.0, PID is 5354.0, B03 is 763.0 B04 is B04 is 45']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5354.0, B04 is 482.0, B02 is 262.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 5354.0, B04 is 482.0, B02 is 262.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '7']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5354.0, B04 is 482.0, B02 is 262.0, B03 is 763.0 B04 is PID is 77']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5354.0, B04 is 482.0, DOY is 211.0, B02 is 262.0, B03 is']\n",
      "prompt: PID is 5354.0, B04 is 482.0, DOY is 211.0, B02 is 262.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '3', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '3', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '3', '4', '2', '6', '3', '.', '0', ',']]\n",
      "decoded_data: ['PID is 5354.0, B04 is 482.0, DOY is 211.0, B02 is 262.0, B03 is 763.0734263.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5354.0, B04 is 482.0, B02 is 262.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5354.0, B04 is 482.0, B02 is 262.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '3', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '3', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '2']]\n",
      "decoded_data: ['PID is 5354.0, B04 is 482.0, B02 is 262.0, DOY is 211.0, B03 is 763.0 B04 is PID is 72']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5354.0, B04 is 482.0, B02 is 262.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5354.0, B04 is 482.0, B02 is 262.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '3', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '3', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['PID is 5354.0, B04 is 482.0, B02 is 262.0, DOY is 211.0, B03 is 763.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5354.0, B02 is 262.0, DOY is 211.0, B04 is 482.0, B03 is']\n",
      "prompt: PID is 5354.0, B02 is 262.0, DOY is 211.0, B04 is 482.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '3', '5', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '3', '5', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '4', '2', '6', '3', '2']]\n",
      "decoded_data: ['PID is 5354.0, B02 is 262.0, DOY is 211.0, B04 is 482.0, B03 is 763.0 B04 is 42632']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5354.0, DOY is 211.0, B04 is 482.0, B02 is 262.0, B03 is']\n",
      "prompt: PID is 5354.0, DOY is 211.0, B04 is 482.0, B02 is 262.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '3', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '3', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '2', '3', '2', '6', '3', '2', '.', '0', ',']]\n",
      "decoded_data: ['PID is 5354.0, DOY is 211.0, B04 is 482.0, B02 is 262.0, B03 is 763.0232632.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 482.0, DOY is 211.0, B02 is 262.0, PID is 5354.0, B03 is']\n",
      "prompt: B04 is 482.0, DOY is 211.0, B02 is 262.0, PID is 5354.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '8', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '8', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '2', '.', '0', ',', '', 'B04', 'is', '', 'B02']]\n",
      "decoded_data: ['B04 is 482.0, DOY is 211.0, B02 is 262.0, PID is 5354.0, B03 is 763.02.0, B04 is B02']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 482.0, PID is 5354.0, DOY is 211.0, B02 is 262.0, B03 is']\n",
      "prompt: B04 is 482.0, PID is 5354.0, DOY is 211.0, B02 is 262.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '8', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '8', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '7', '1', '5', '3', '.']]\n",
      "decoded_data: ['B04 is 482.0, PID is 5354.0, DOY is 211.0, B02 is 262.0, B03 is 763.0 B04 is 7153.']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 482.0, B02 is 262.0, PID is 5354.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 482.0, B02 is 262.0, PID is 5354.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', '7', '2', '.', '0', ',']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 482.0, B02 is 262.0, PID is 5354.0, B03 is 763.0 B03 is 72.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 482.0, B02 is 262.0, PID is 5354.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 482.0, B02 is 262.0, PID is 5354.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '4']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 482.0, B02 is 262.0, PID is 5354.0, B03 is 763.0 B04 is PID is 74']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 262.0, PID is 5354.0, B04 is 482.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 262.0, PID is 5354.0, B04 is 482.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '2', '7', '4', '.', '0', '2', '.', '0', ',']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 262.0, PID is 5354.0, B04 is 482.0, B03 is 763.0274.02.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 482.0, PID is 5354.0, DOY is 211.0, B02 is 262.0, B03 is']\n",
      "prompt: B04 is 482.0, PID is 5354.0, DOY is 211.0, B02 is 262.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '8', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '8', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '4', '2']]\n",
      "decoded_data: ['B04 is 482.0, PID is 5354.0, DOY is 211.0, B02 is 262.0, B03 is 763.0 B04 is PID is 42']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 482.0, PID is 5354.0, B02 is 262.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 482.0, PID is 5354.0, B02 is 262.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '8', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      "  5%|         | 44/829 [01:17<24:08,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B04', 'is', '', '4', '8', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '6', '3', '4', '2', '.', '0', '4', '2']]\n",
      "decoded_data: ['B04 is 482.0, PID is 5354.0, B02 is 262.0, DOY is 211.0, B03 is 763.076342.042']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5454.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 5454.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '4', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '4', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['PID is 5454.0, DOY is 211.0, B04 is 462.0, B02 is 243.0, B03 is 774.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 462.0, B02 is 243.0, PID is 5454.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 462.0, B02 is 243.0, PID is 5454.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'DOY', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 462.0, B02 is 243.0, PID is 5454.0, B03 is 774.0 B04 is DOY is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5454.0, B04 is 462.0, B02 is 243.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5454.0, B04 is 462.0, B02 is 243.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '4', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '4', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '7', '4', '6', '4', '8', '.', '0', '.']]\n",
      "decoded_data: ['PID is 5454.0, B04 is 462.0, B02 is 243.0, DOY is 211.0, B03 is 774.0 74648.0.']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 243.0, B04 is 462.0, PID is 5454.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 243.0, B04 is 462.0, PID is 5454.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '8', '4', '8', '4', '8', '.', '0']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 243.0, B04 is 462.0, PID is 5454.0, B03 is 774.0 484848.0']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 243.0, PID is 5454.0, B04 is 462.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 243.0, PID is 5454.0, B04 is 462.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '4', '6', '4', '6', '.']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 243.0, PID is 5454.0, B04 is 462.0, B03 is 774.0 B04 is 4646.']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 462.0, B02 is 243.0, DOY is 211.0, PID is 5454.0, B03 is']\n",
      "prompt: B04 is 462.0, B02 is 243.0, DOY is 211.0, PID is 5454.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '6', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '6', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '7', '4', '8', '3', '.']]\n",
      "decoded_data: ['B04 is 462.0, B02 is 243.0, DOY is 211.0, PID is 5454.0, B03 is 774.0 B04 is 7483.']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 243.0, B04 is 462.0, DOY is 211.0, PID is 5454.0, B03 is']\n",
      "prompt: B02 is 243.0, B04 is 462.0, DOY is 211.0, PID is 5454.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '4', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '4', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '4', '6', '.', '0', '.']]\n",
      "decoded_data: ['B02 is 243.0, B04 is 462.0, DOY is 211.0, PID is 5454.0, B03 is 774.0 B04 is 46.0.']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 462.0, B02 is 243.0, DOY is 211.0, PID is 5454.0, B03 is']\n",
      "prompt: B04 is 462.0, B02 is 243.0, DOY is 211.0, PID is 5454.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '6', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '6', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B02', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['B04 is 462.0, B02 is 243.0, DOY is 211.0, PID is 5454.0, B03 is 774.0 B04 is B02 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 243.0, PID is 5454.0, B04 is 462.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 243.0, PID is 5454.0, B04 is 462.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '4', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '4', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B02', 'is', '', 'B04', 'is', '', '4', '8']]\n",
      "decoded_data: ['B02 is 243.0, PID is 5454.0, B04 is 462.0, DOY is 211.0, B03 is 774.0 B02 is B04 is 48']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5454.0, B02 is 243.0, B04 is 462.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5454.0, B02 is 243.0, B04 is 462.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '4', '5', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '4', '5', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B02', 'is', '', 'B04', 'is', '', 'DOY', 'is']]\n",
      "decoded_data: ['PID is 5454.0, B02 is 243.0, B04 is 462.0, DOY is 211.0, B03 is 774.0 B02 is B04 is DOY is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5454.0, B02 is 243.0, B04 is 462.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5454.0, B02 is 243.0, B04 is 462.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '4', '5', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '4', '5', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'DOY', 'is', '', '2', '6']]\n",
      "decoded_data: ['PID is 5454.0, B02 is 243.0, B04 is 462.0, DOY is 211.0, B03 is 774.0 B04 is DOY is 26']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 243.0, PID is 5454.0, DOY is 211.0, B04 is 462.0, B03 is']\n",
      "prompt: B02 is 243.0, PID is 5454.0, DOY is 211.0, B04 is 462.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '4', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '4', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '4', '6', '4', '6', '4']]\n",
      "decoded_data: ['B02 is 243.0, PID is 5454.0, DOY is 211.0, B04 is 462.0, B03 is 774.0 B04 is 46464']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 462.0, PID is 5454.0, B02 is 243.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 462.0, PID is 5454.0, B02 is 243.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '6', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '6', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'DOY', 'is', '', '2', '4']]\n",
      "decoded_data: ['B04 is 462.0, PID is 5454.0, B02 is 243.0, DOY is 211.0, B03 is 774.0 B04 is DOY is 24']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 462.0, PID is 5454.0, B02 is 243.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 462.0, PID is 5454.0, B02 is 243.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '6', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '6', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '7', '4', '6', '4', '6']]\n",
      "decoded_data: ['B04 is 462.0, PID is 5454.0, B02 is 243.0, DOY is 211.0, B03 is 774.0 B04 is 74646']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5454.0, B02 is 243.0, DOY is 211.0, B04 is 462.0, B03 is']\n",
      "prompt: PID is 5454.0, B02 is 243.0, DOY is 211.0, B04 is 462.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '4', '5', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '2', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      "  5%|         | 45/829 [01:19<26:08,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '5', '4', '5', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'DOY', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['PID is 5454.0, B02 is 243.0, DOY is 211.0, B04 is 462.0, B03 is 774.0 B04 is DOY is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5554.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 5554.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '8', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '0', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '3', '7', '1', '3', '7', '1', '.', '0']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5554.0, B03 is 738.0, B02 is 250.0, B04 is 453.05371371.0']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 738.0, PID is 5554.0, B02 is 250.0, B04 is']\n",
      "prompt: DOY is 211.0, B03 is 738.0, PID is 5554.0, B02 is 250.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '0', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '5', '3', '.', '0', '7', '1', '.']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 738.0, PID is 5554.0, B02 is 250.0, B04 is 453.0 453.071.']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 738.0, DOY is 211.0, PID is 5554.0, B02 is 250.0, B04 is']\n",
      "prompt: B03 is 738.0, DOY is 211.0, PID is 5554.0, B02 is 250.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '3', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '3', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '0', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '3', '7', '1', '2', '.', '0', ',', '']]\n",
      "decoded_data: ['B03 is 738.0, DOY is 211.0, PID is 5554.0, B02 is 250.0, B04 is 453.053712.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 738.0, B02 is 250.0, PID is 5554.0, B04 is']\n",
      "prompt: DOY is 211.0, B03 is 738.0, B02 is 250.0, PID is 5554.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '8', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '4', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '8', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '4', '5', '3', '7', '7']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 738.0, B02 is 250.0, PID is 5554.0, B04 is 453.0 PID is 45377']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 250.0, PID is 5554.0, DOY is 211.0, B03 is 738.0, B04 is']\n",
      "prompt: B02 is 250.0, PID is 5554.0, DOY is 211.0, B03 is 738.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '5', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '8', '.', '0', ',', '', 'B04', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|         | 46/829 [01:20<22:26,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B02', 'is', '', '2', '5', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '8', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B02', 'is', '', '5', '3']]\n",
      "decoded_data: ['B02 is 250.0, PID is 5554.0, DOY is 211.0, B03 is 738.0, B04 is 453.0 PID is B02 is 53']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5554.0, B03 is 738.0, B02 is 250.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 5554.0, B03 is 738.0, B02 is 250.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '5', '5', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '8', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '5', '5', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '8', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '3', '7', '1', '2', '1', '9', '2', '1']]\n",
      "decoded_data: ['PID is 5554.0, B03 is 738.0, B02 is 250.0, DOY is 211.0, B04 is 453.0537121921']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5654.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 5654.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '6', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '6', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '0', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '0']]\n",
      "decoded_data: ['PID is 5654.0, DOY is 211.0, B04 is 407.0, B02 is 247.0, B03 is 701.0 B04 is PID is 70']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 247.0, PID is 5654.0, B04 is 407.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 247.0, PID is 5654.0, B04 is 407.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '4', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '0', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '4', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '0', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '0']]\n",
      "decoded_data: ['B02 is 247.0, PID is 5654.0, B04 is 407.0, DOY is 211.0, B03 is 701.0 B04 is PID is 70']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 247.0, PID is 5654.0, DOY is 211.0, B04 is 407.0, B03 is']\n",
      "prompt: B02 is 247.0, PID is 5654.0, DOY is 211.0, B04 is 407.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '4', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '0', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '4', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '0', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '0', '1', '6', '8']]\n",
      "decoded_data: ['B02 is 247.0, PID is 5654.0, DOY is 211.0, B04 is 407.0, B03 is 701.0 PID is 70168']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 247.0, DOY is 211.0, B04 is 407.0, PID is 5654.0, B03 is']\n",
      "prompt: B02 is 247.0, DOY is 211.0, B04 is 407.0, PID is 5654.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '0', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '0', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '7', '0', '1', '.', '0']]\n",
      "decoded_data: ['B02 is 247.0, DOY is 211.0, B04 is 407.0, PID is 5654.0, B03 is 701.0 B04 is 701.0']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 407.0, PID is 5654.0, B02 is 247.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 407.0, PID is 5654.0, B02 is 247.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '0', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '0', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '0', '1', '.', '0', ',', '', 'PID', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 407.0, PID is 5654.0, B02 is 247.0, B03 is 701.0701.0, PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5654.0, B04 is 407.0, DOY is 211.0, B02 is 247.0, B03 is']\n",
      "prompt: PID is 5654.0, B04 is 407.0, DOY is 211.0, B02 is 247.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '6', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '0', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '6', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '0', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '0']]\n",
      "decoded_data: ['PID is 5654.0, B04 is 407.0, DOY is 211.0, B02 is 247.0, B03 is 701.0 B04 is PID is 70']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 247.0, PID is 5654.0, B04 is 407.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 247.0, PID is 5654.0, B04 is 407.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '4', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '0', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '4', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '0', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'DOY', 'is', '', '2', '7']]\n",
      "decoded_data: ['B02 is 247.0, PID is 5654.0, B04 is 407.0, DOY is 211.0, B03 is 701.0 B04 is DOY is 27']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5654.0, DOY is 211.0, B02 is 247.0, B04 is 407.0, B03 is']\n",
      "prompt: PID is 5654.0, DOY is 211.0, B02 is 247.0, B04 is 407.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '6', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '0', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '6', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '0', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '0', '1', '6', '.', '0', '.', '0', ',']]\n",
      "decoded_data: ['PID is 5654.0, DOY is 211.0, B02 is 247.0, B04 is 407.0, B03 is 701.07016.0.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5654.0, B02 is 247.0, DOY is 211.0, B04 is 407.0, B03 is']\n",
      "prompt: PID is 5654.0, B02 is 247.0, DOY is 211.0, B04 is 407.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '6', '5', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '0', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '6', '5', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '0', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '4', '7', '0', '1', '6']]\n",
      "decoded_data: ['PID is 5654.0, B02 is 247.0, DOY is 211.0, B04 is 407.0, B03 is 701.0 B04 is 47016']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5654.0, B04 is 407.0, DOY is 211.0, B02 is 247.0, B03 is']\n",
      "prompt: PID is 5654.0, B04 is 407.0, DOY is 211.0, B02 is 247.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '6', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '0', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '6', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '0', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '0', '1', '8', '1']]\n",
      "decoded_data: ['PID is 5654.0, B04 is 407.0, DOY is 211.0, B02 is 247.0, B03 is 701.0 PID is 70181']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 407.0, PID is 5654.0, DOY is 211.0, B02 is 247.0, B03 is']\n",
      "prompt: B04 is 407.0, PID is 5654.0, DOY is 211.0, B02 is 247.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '0', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '0', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '7', '0', '1', '6', '6']]\n",
      "decoded_data: ['B04 is 407.0, PID is 5654.0, DOY is 211.0, B02 is 247.0, B03 is 701.0 B04 is 70166']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5654.0, B04 is 407.0, DOY is 211.0, B02 is 247.0, B03 is']\n",
      "prompt: PID is 5654.0, B04 is 407.0, DOY is 211.0, B02 is 247.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '6', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '0', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '6', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '0', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '7', '0', '1', '7', '0']]\n",
      "decoded_data: ['PID is 5654.0, B04 is 407.0, DOY is 211.0, B02 is 247.0, B03 is 701.0 B04 is 70170']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5654.0, B04 is 407.0, DOY is 211.0, B02 is 247.0, B03 is']\n",
      "prompt: PID is 5654.0, B04 is 407.0, DOY is 211.0, B02 is 247.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '6', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '0', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '6', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '0', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '7', '0', '1', '6', '1']]\n",
      "decoded_data: ['PID is 5654.0, B04 is 407.0, DOY is 211.0, B02 is 247.0, B03 is 701.0 B04 is 70161']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 407.0, PID is 5654.0, B02 is 247.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 407.0, PID is 5654.0, B02 is 247.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '0', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '0', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'DOY', 'is', '', '2', '1', '9', '9', '4']]\n",
      "decoded_data: ['B04 is 407.0, PID is 5654.0, B02 is 247.0, DOY is 211.0, B03 is 701.0 DOY is 21994']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 407.0, B02 is 247.0, DOY is 211.0, PID is 5654.0, B03 is']\n",
      "prompt: B04 is 407.0, B02 is 247.0, DOY is 211.0, PID is 5654.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '0', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '4', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      "  6%|         | 47/829 [01:23<25:12,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B04', 'is', '', '4', '0', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', '4', '7']]\n",
      "decoded_data: ['B04 is 407.0, B02 is 247.0, DOY is 211.0, PID is 5654.0, B03 is 701.0 B04 is B04 is 47']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5754.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 5754.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '4', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '0', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'B04', 'is', '', '6', '5']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5754.0, B04 is 401.0, B03 is 689.0, B02 is 253.0 B03 is B04 is 65']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 401.0, B03 is 689.0, PID is 5754.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 401.0, B03 is 689.0, PID is 5754.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '0', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '9', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '0', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '9', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '2', '7', '1', '0', '2', '.', '0', ',']]\n",
      "decoded_data: ['B04 is 401.0, B03 is 689.0, PID is 5754.0, DOY is 211.0, B02 is 253.0 27102.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5754.0, B04 is 401.0, B03 is 689.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 5754.0, B04 is 401.0, B03 is 689.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '0', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '9', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '0', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '2', '7', '1', '.', '0']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5754.0, B04 is 401.0, B03 is 689.0, B02 is 253.0 B04 is 271.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 689.0, PID is 5754.0, DOY is 211.0, B04 is 401.0, B02 is']\n",
      "prompt: B03 is 689.0, PID is 5754.0, DOY is 211.0, B04 is 401.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '8', '9', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '0', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '6', '8', '9', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '0', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '2', '3', '4', '6', '4', '2', '.', '0', '.']]\n",
      "decoded_data: ['B03 is 689.0, PID is 5754.0, DOY is 211.0, B04 is 401.0, B02 is 253.0234642.0.']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 401.0, PID is 5754.0, B03 is 689.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 401.0, PID is 5754.0, B03 is 689.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '4', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '4', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '5', '3', '9', '8', '9', '4', '.', '0']]\n",
      "decoded_data: ['B04 is 401.0, PID is 5754.0, B03 is 689.0, DOY is 211.0, B02 is 253.06539894.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 689.0, PID is 5754.0, B04 is 401.0, DOY is 211.0, B02 is']\n",
      "prompt: B03 is 689.0, PID is 5754.0, B04 is 401.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '8', '9', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '0', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '6', '8', '9', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '0', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['B03 is 689.0, PID is 5754.0, B04 is 401.0, DOY is 211.0, B02 is 253.0 PID is B04 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5754.0, DOY is 211.0, B04 is 401.0, B03 is 689.0, B02 is']\n",
      "prompt: PID is 5754.0, DOY is 211.0, B04 is 401.0, B03 is 689.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '7', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '0', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '9', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '7', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '0', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '2', '9']]\n",
      "decoded_data: ['PID is 5754.0, DOY is 211.0, B04 is 401.0, B03 is 689.0, B02 is 253.0 B04 is PID is 29']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5754.0, B04 is 401.0, B03 is 689.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 5754.0, B04 is 401.0, B03 is 689.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '0', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '9', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '0', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '2', '9']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5754.0, B04 is 401.0, B03 is 689.0, B02 is 253.0 B04 is PID is 29']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5754.0, DOY is 211.0, B04 is 401.0, B03 is 689.0, B02 is']\n",
      "prompt: PID is 5754.0, DOY is 211.0, B04 is 401.0, B03 is 689.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '7', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '0', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '9', '.', '0', ',', '', 'B02', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|         | 48/829 [01:24<23:32,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '5', '7', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '0', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '2', '9', '3', '4', '4', '4', '4', '4']]\n",
      "decoded_data: ['PID is 5754.0, DOY is 211.0, B04 is 401.0, B03 is 689.0, B02 is 253.0 29344444']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 689.0, DOY is 211.0, PID is 5754.0, B04 is 401.0, B02 is']\n",
      "prompt: B03 is 689.0, DOY is 211.0, PID is 5754.0, B04 is 401.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '8', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '0', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '6', '8', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '0', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '2', '7', '1', '0', ',', '', 'PID', 'is', '']]\n",
      "decoded_data: ['B03 is 689.0, DOY is 211.0, PID is 5754.0, B04 is 401.0, B02 is 253.02710, PID is ']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5854.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 5854.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '8', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '8', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '0', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'B04', 'is', '', '4', '6']]\n",
      "decoded_data: ['PID is 5854.0, DOY is 211.0, B02 is 279.0, B03 is 720.0, B04 is 458.0 B03 is B04 is 46']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5854.0, DOY is 211.0, B03 is 720.0, B02 is 279.0, B04 is']\n",
      "prompt: PID is 5854.0, DOY is 211.0, B03 is 720.0, B02 is 279.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '8', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '0', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '8', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '0', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '9', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', '5', '8', '0', '3', '4']]\n",
      "decoded_data: ['PID is 5854.0, DOY is 211.0, B03 is 720.0, B02 is 279.0, B04 is 458.0 B03 is 58034']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5854.0, B03 is 720.0, DOY is 211.0, B02 is 279.0, B04 is']\n",
      "prompt: PID is 5854.0, B03 is 720.0, DOY is 211.0, B02 is 279.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '8', '5', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '9', '.', '0', ',', '', 'B04', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|         | 49/829 [01:25<19:12,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '5', '8', '5', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '9', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '8', '7', '3', '5', '3', '4', '.']]\n",
      "decoded_data: ['PID is 5854.0, B03 is 720.0, DOY is 211.0, B02 is 279.0, B04 is 458.0 5873534.']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5854.0, B03 is 720.0, B02 is 279.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 5854.0, B03 is 720.0, B02 is 279.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '8', '5', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '0', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '8', '5', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '0', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '3', '8', '7', '0', '3', '5', '3', '5']]\n",
      "decoded_data: ['PID is 5854.0, B03 is 720.0, B02 is 279.0, DOY is 211.0, B04 is 458.0738703535']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5954.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 5954.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', '2', '7', '1', '9', '5']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5954.0, B03 is 735.0, B04 is 551.0, B02 is 356.0 B03 is 27195']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 735.0, B04 is 551.0, DOY is 211.0, PID is 5954.0, B02 is']\n",
      "prompt: B03 is 735.0, B04 is 551.0, DOY is 211.0, PID is 5954.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '3', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '4', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '3', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '2', '.', '0', ',', '']]\n",
      "decoded_data: ['B03 is 735.0, B04 is 551.0, DOY is 211.0, PID is 5954.0, B02 is 297.0 B04 is 2.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5954.0, B04 is 551.0, DOY is 211.0, B03 is 735.0, B02 is']\n",
      "prompt: PID is 5954.0, B04 is 551.0, DOY is 211.0, B03 is 735.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '9', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '5', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '9', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '5', '5', '3', '5']]\n",
      "decoded_data: ['PID is 5954.0, B04 is 551.0, DOY is 211.0, B03 is 735.0, B02 is 297.0 B04 is 55535']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 735.0, PID is 5954.0, DOY is 211.0, B04 is 551.0, B02 is']\n",
      "prompt: B03 is 735.0, PID is 5954.0, DOY is 211.0, B04 is 551.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '3', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '3', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'DOY', 'is', '', '2', '9', '7', '2', '9']]\n",
      "decoded_data: ['B03 is 735.0, PID is 5954.0, DOY is 211.0, B04 is 551.0, B02 is 297.0 DOY is 29729']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5954.0, B04 is 551.0, B03 is 735.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 5954.0, B04 is 551.0, B03 is 735.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '9', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|         | 50/829 [01:26<17:10,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '5', '9', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '2', '9', '7', '1', '0', '8', '4', '9']]\n",
      "decoded_data: ['PID is 5954.0, B04 is 551.0, B03 is 735.0, DOY is 211.0, B02 is 297.0 29710849']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 551.0, PID is 5954.0, B03 is 735.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 551.0, PID is 5954.0, B03 is 735.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '5', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '5', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '5', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '5', '0', '5', '3', '5', '3', '5', '3']]\n",
      "decoded_data: ['B04 is 551.0, PID is 5954.0, B03 is 735.0, DOY is 211.0, B02 is 353.0550535353']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5055.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 5055.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '0', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '0', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '7', '3', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '9', '5', '.', '0', ',', '', 'B02', 'is', '', '4', '2', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', 'B03', 'is']]\n",
      "decoded_data: ['PID is 5055.0, DOY is 211.0, B04 is 737.0, B03 is 795.0, B02 is 429.0 PID is B04 is B03 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 795.0, B04 is 737.0, DOY is 211.0, PID is 5055.0, B02 is']\n",
      "prompt: B03 is 795.0, B04 is 737.0, DOY is 211.0, PID is 5055.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '9', '5', '.', '0', ',', '', 'B04', 'is', '', '7', '3', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '5', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '9', '5', '.', '0', ',', '', 'B04', 'is', '', '7', '3', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '5', '.', '0', ',', '', 'B02', 'is', '', '4', '2', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '7', '7', '3', '.', '0', ',', '', 'PID']]\n",
      "decoded_data: ['B03 is 795.0, B04 is 737.0, DOY is 211.0, PID is 5055.0, B02 is 429.07773.0, PID']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 795.0, DOY is 211.0, B04 is 737.0, PID is 5055.0, B02 is']\n",
      "prompt: B03 is 795.0, DOY is 211.0, B04 is 737.0, PID is 5055.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '9', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '7', '3', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '5', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '9', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '7', '3', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '5', '.', '0', ',', '', 'B02', 'is', '', '4', '2', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'DOY', 'is', '', 'PID', 'is', '', 'B03', 'is']]\n",
      "decoded_data: ['B03 is 795.0, DOY is 211.0, B04 is 737.0, PID is 5055.0, B02 is 429.0 DOY is PID is B03 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5055.0, B03 is 795.0, DOY is 211.0, B04 is 737.0, B02 is']\n",
      "prompt: PID is 5055.0, B03 is 795.0, DOY is 211.0, B04 is 737.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '0', '5', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '9', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '7', '3', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '0', '5', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '9', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '7', '3', '7', '.', '0', ',', '', 'B02', 'is', '', '4', '2', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', 'DOY', 'is']]\n",
      "decoded_data: ['PID is 5055.0, B03 is 795.0, DOY is 211.0, B04 is 737.0, B02 is 429.0 PID is B04 is DOY is']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 795.0, DOY is 211.0, B04 is 737.0, PID is 5055.0, B02 is']\n",
      "prompt: B03 is 795.0, DOY is 211.0, B04 is 737.0, PID is 5055.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '9', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '7', '3', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '5', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '9', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '7', '3', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '5', '.', '0', ',', '', 'B02', 'is', '', '4', '2', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '6', '8', '1', '5', '6']]\n",
      "decoded_data: ['B03 is 795.0, DOY is 211.0, B04 is 737.0, PID is 5055.0, B02 is 429.0 PID is 68156']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5055.0, B03 is 795.0, B04 is 737.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 5055.0, B03 is 795.0, B04 is 737.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '0', '5', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '9', '5', '.', '0', ',', '', 'B04', 'is', '', '7', '3', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '0', '5', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '9', '5', '.', '0', ',', '', 'B04', 'is', '', '7', '3', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '4', '2', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '4', '6', '9', '8', '3']]\n",
      "decoded_data: ['PID is 5055.0, B03 is 795.0, B04 is 737.0, DOY is 211.0, B02 is 429.0 PID is 46983']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 737.0, B03 is 795.0, PID is 5055.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 737.0, B03 is 795.0, PID is 5055.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '7', '3', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '9', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '7', '3', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '9', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '4', '2', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '4', '6', '8', '6', '1']]\n",
      "decoded_data: ['B04 is 737.0, B03 is 795.0, PID is 5055.0, DOY is 211.0, B02 is 429.0 PID is 46861']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5055.0, B03 is 795.0, B04 is 737.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 5055.0, B03 is 795.0, B04 is 737.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '0', '5', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '9', '5', '.', '0', ',', '', 'B04', 'is', '', '7', '3', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '0', '5', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '9', '5', '.', '0', ',', '', 'B04', 'is', '', '7', '3', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '4', '2', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '4', '6', '1', '5', '7']]\n",
      "decoded_data: ['PID is 5055.0, B03 is 795.0, B04 is 737.0, DOY is 211.0, B02 is 429.0 PID is 46157']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 795.0, PID is 5055.0, DOY is 211.0, B04 is 737.0, B02 is']\n",
      "prompt: B03 is 795.0, PID is 5055.0, DOY is 211.0, B04 is 737.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '9', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '7', '3', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '9', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '7', '3', '7', '.', '0', ',', '', 'B02', 'is', '', '4', '2', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['B03 is 795.0, PID is 5055.0, DOY is 211.0, B04 is 737.0, B02 is 429.0 PID is B04 is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 737.0, DOY is 211.0, B03 is 795.0, PID is 5055.0, B02 is']\n",
      "prompt: B04 is 737.0, DOY is 211.0, B03 is 795.0, PID is 5055.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '7', '3', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '9', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '5', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '7', '3', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '9', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '5', '.', '0', ',', '', 'B02', 'is', '', '4', '2', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B02', 'is', '', '4', '6']]\n",
      "decoded_data: ['B04 is 737.0, DOY is 211.0, B03 is 795.0, PID is 5055.0, B02 is 429.0 PID is B02 is 46']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 795.0, B04 is 737.0, PID is 5055.0, DOY is 211.0, B02 is']\n",
      "prompt: B03 is 795.0, B04 is 737.0, PID is 5055.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '9', '5', '.', '0', ',', '', 'B04', 'is', '', '7', '3', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '9', '5', '.', '0', ',', '', 'B04', 'is', '', '7', '3', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '4', '2', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '0', ',', '', 'B04', 'is']]\n",
      "decoded_data: ['B03 is 795.0, B04 is 737.0, PID is 5055.0, DOY is 211.0, B02 is 429.0 PID is 0, B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 795.0, PID is 5055.0, DOY is 211.0, B04 is 737.0, B02 is']\n",
      "prompt: B03 is 795.0, PID is 5055.0, DOY is 211.0, B04 is 737.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '9', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '7', '3', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '9', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '7', '3', '7', '.', '0', ',', '', 'B02', 'is', '', '4', '2', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B02', 'is', '', '4', '2']]\n",
      "decoded_data: ['B03 is 795.0, PID is 5055.0, DOY is 211.0, B04 is 737.0, B02 is 429.0 PID is B02 is 42']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 737.0, PID is 5055.0, B03 is 795.0, B02 is']\n",
      "prompt: DOY is 211.0, B04 is 737.0, PID is 5055.0, B03 is 795.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '7', '3', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '9', '5', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '7', '3', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '9', '5', '.', '0', ',', '', 'B02', 'is', '', '4', '2', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B02', 'is', '', '4', '6']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 737.0, PID is 5055.0, B03 is 795.0, B02 is 429.0 PID is B02 is 46']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 795.0, DOY is 211.0, PID is 5055.0, B04 is 737.0, B02 is']\n",
      "prompt: B03 is 795.0, DOY is 211.0, PID is 5055.0, B04 is 737.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '9', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '5', '.', '0', ',', '', 'B04', 'is', '', '7', '3', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '9', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '5', '.', '0', ',', '', 'B04', 'is', '', '7', '3', '7', '.', '0', ',', '', 'B02', 'is', '', '4', '2', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B03', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['B03 is 795.0, DOY is 211.0, PID is 5055.0, B04 is 737.0, B02 is 429.0 PID is B03 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 737.0, B03 is 795.0, PID is 5055.0, B02 is']\n",
      "prompt: DOY is 211.0, B04 is 737.0, B03 is 795.0, PID is 5055.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '7', '3', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '9', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '5', '.', '0', ',', '', 'B02', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      "  6%|         | 51/829 [01:28<20:54,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '7', '3', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '9', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '5', '5', '.', '0', ',', '', 'B02', 'is', '', '4', '2', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'PID', 'is', '', '5', '6']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 737.0, B03 is 795.0, PID is 5055.0, B02 is 429.0 PID is PID is 56']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5155.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5155.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '1', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '1', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '6', '7', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '9', '6', '7', '1', '.', '0', ',', '']]\n",
      "decoded_data: ['PID is 5155.0, DOY is 211.0, B03 is 768.0, B04 is 671.0, B02 is 396.069671.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 768.0, DOY is 211.0, B04 is 671.0, PID is 5155.0, B02 is']\n",
      "prompt: B03 is 768.0, DOY is 211.0, B04 is 671.0, PID is 5155.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '7', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '5', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '7', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B02', 'is', '', '3', '9']]\n",
      "decoded_data: ['B03 is 768.0, DOY is 211.0, B04 is 671.0, PID is 5155.0, B02 is 396.0 PID is B02 is 39']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 768.0, PID is 5155.0, B04 is 671.0, DOY is 211.0, B02 is']\n",
      "prompt: B03 is 768.0, PID is 5155.0, B04 is 671.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '6', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '5', '.', '0', ',', '', 'B04', 'is', '', '6', '7', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '6', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '5', '.', '0', ',', '', 'B04', 'is', '', '6', '7', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'DOY', 'is', '', '2', '1', '9', '6', '9']]\n",
      "decoded_data: ['B03 is 768.0, PID is 5155.0, B04 is 671.0, DOY is 211.0, B02 is 396.0 DOY is 21969']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5155.0, DOY is 211.0, B03 is 768.0, B04 is 671.0, B02 is']\n",
      "prompt: PID is 5155.0, DOY is 211.0, B03 is 768.0, B04 is 671.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '1', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '6', '7', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '1', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '6', '7', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '3', '9', '6', '1', '1', '1', '1', '.']]\n",
      "decoded_data: ['PID is 5155.0, DOY is 211.0, B03 is 768.0, B04 is 671.0, B02 is 396.0 3961111.']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 768.0, B04 is 671.0, DOY is 211.0, PID is 5155.0, B02 is']\n",
      "prompt: B03 is 768.0, B04 is 671.0, DOY is 211.0, PID is 5155.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '6', '7', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '5', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '6', '7', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B02', 'is', '', 'PID', 'is', '', '3', '1']]\n",
      "decoded_data: ['B03 is 768.0, B04 is 671.0, DOY is 211.0, PID is 5155.0, B02 is 396.0 B02 is PID is 31']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 768.0, PID is 5155.0, DOY is 211.0, B04 is 671.0, B02 is']\n",
      "prompt: B03 is 768.0, PID is 5155.0, DOY is 211.0, B04 is 671.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '6', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '7', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '6', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '7', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '9', '6', '1', '.', '0', ',', '', 'PID', 'is']]\n",
      "decoded_data: ['B03 is 768.0, PID is 5155.0, DOY is 211.0, B04 is 671.0, B02 is 396.0961.0, PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 768.0, B04 is 671.0, PID is 5155.0, B02 is']\n",
      "prompt: DOY is 211.0, B03 is 768.0, B04 is 671.0, PID is 5155.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '6', '7', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '5', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '6', '7', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '3', '.', '0', ',', '']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 768.0, B04 is 671.0, PID is 5155.0, B02 is 396.0 PID is 3.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5155.0, B04 is 671.0, B03 is 768.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 5155.0, B04 is 671.0, B03 is 768.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '5', '.', '0', ',', '', 'B04', 'is', '', '6', '7', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '8', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '5', '.', '0', ',', '', 'B04', 'is', '', '6', '7', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'PID', 'is', '', '3', '9']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5155.0, B04 is 671.0, B03 is 768.0, B02 is 396.0 B03 is PID is 39']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5155.0, DOY is 211.0, B03 is 768.0, B04 is 671.0, B02 is']\n",
      "prompt: PID is 5155.0, DOY is 211.0, B03 is 768.0, B04 is 671.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '1', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '6', '7', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '1', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '6', '7', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '1', '.', '0', ',', '', 'B03', 'is', '']]\n",
      "decoded_data: ['PID is 5155.0, DOY is 211.0, B03 is 768.0, B04 is 671.0, B02 is 396.061.0, B03 is ']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 671.0, B03 is 768.0, PID is 5155.0, B02 is']\n",
      "prompt: DOY is 211.0, B04 is 671.0, B03 is 768.0, PID is 5155.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '7', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '5', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '7', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '.', '0', ',', '', 'B03', 'is', '', 'PID']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 671.0, B03 is 768.0, PID is 5155.0, B02 is 396.06.0, B03 is PID']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 671.0, B03 is 768.0, PID is 5155.0, B02 is']\n",
      "prompt: DOY is 211.0, B04 is 671.0, B03 is 768.0, PID is 5155.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '7', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '5', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '7', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'PID', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 671.0, B03 is 768.0, PID is 5155.0, B02 is 396.0 B03 is PID is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5155.0, B03 is 768.0, DOY is 211.0, B04 is 671.0, B02 is']\n",
      "prompt: PID is 5155.0, B03 is 768.0, DOY is 211.0, B04 is 671.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '1', '5', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '7', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '1', '5', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '7', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['PID is 5155.0, B03 is 768.0, DOY is 211.0, B04 is 671.0, B02 is 396.0 B04 is PID is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 768.0, DOY is 211.0, B04 is 671.0, PID is 5155.0, B02 is']\n",
      "prompt: B03 is 768.0, DOY is 211.0, B04 is 671.0, PID is 5155.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '7', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '5', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '7', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '3', '1', '9', '6', '9']]\n",
      "decoded_data: ['B03 is 768.0, DOY is 211.0, B04 is 671.0, PID is 5155.0, B02 is 396.0 PID is 31969']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 768.0, PID is 5155.0, B04 is 671.0, B02 is']\n",
      "prompt: DOY is 211.0, B03 is 768.0, PID is 5155.0, B04 is 671.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '5', '.', '0', ',', '', 'B04', 'is', '', '6', '7', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '5', '.', '0', ',', '', 'B04', 'is', '', '6', '7', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B03', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 768.0, PID is 5155.0, B04 is 671.0, B02 is 396.0 PID is B03 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 671.0, PID is 5155.0, DOY is 211.0, B03 is 768.0, B02 is']\n",
      "prompt: B04 is 671.0, PID is 5155.0, DOY is 211.0, B03 is 768.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '6', '7', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '8', '.', '0', ',', '', 'B02', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      "  6%|         | 52/829 [01:31<23:33,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B04', 'is', '', '6', '7', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'PID', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['B04 is 671.0, PID is 5155.0, DOY is 211.0, B03 is 768.0, B02 is 396.0 B03 is PID is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5255.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 5255.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '2', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '2', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '3', '4', '7', '2']]\n",
      "decoded_data: ['PID is 5255.0, DOY is 211.0, B02 is 322.0, B03 is 735.0, B04 is 547.0 PID is 53472']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5255.0, DOY is 211.0, B02 is 322.0, B03 is 735.0, B04 is']\n",
      "prompt: PID is 5255.0, DOY is 211.0, B02 is 322.0, B03 is 735.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '2', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '5', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '2', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '2', '0', '2', '0']]\n",
      "decoded_data: ['PID is 5255.0, DOY is 211.0, B02 is 322.0, B03 is 735.0, B04 is 547.0 PID is 52020']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 735.0, PID is 5255.0, DOY is 211.0, B02 is 322.0, B04 is']\n",
      "prompt: B03 is 735.0, PID is 5255.0, DOY is 211.0, B02 is 322.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '3', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '3', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '8', '6', '5', '8', '.', '0', '7', '0']]\n",
      "decoded_data: ['B03 is 735.0, PID is 5255.0, DOY is 211.0, B02 is 322.0, B04 is 547.058658.070']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 735.0, B02 is 322.0, PID is 5255.0, DOY is 211.0, B04 is']\n",
      "prompt: B03 is 735.0, B02 is 322.0, PID is 5255.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '3', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '3', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '0', '4', '7', '5']]\n",
      "decoded_data: ['B03 is 735.0, B02 is 322.0, PID is 5255.0, DOY is 211.0, B04 is 547.0 PID is 50475']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5255.0, B03 is 735.0, B02 is 322.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 5255.0, B03 is 735.0, B02 is 322.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '2', '5', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '2', '5', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'DOY', 'is', '', 'B02', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['PID is 5255.0, B03 is 735.0, B02 is 322.0, DOY is 211.0, B04 is 547.0 DOY is B02 is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 322.0, PID is 5255.0, B03 is 735.0, DOY is 211.0, B04 is']\n",
      "prompt: B02 is 322.0, PID is 5255.0, B03 is 735.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '4', '7', '2', '1']]\n",
      "decoded_data: ['B02 is 322.0, PID is 5255.0, B03 is 735.0, DOY is 211.0, B04 is 547.0 PID is 54721']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5255.0, B02 is 322.0, B03 is 735.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 5255.0, B02 is 322.0, B03 is 735.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '2', '5', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '2', '5', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', '5', '8', '2', '9', '5']]\n",
      "decoded_data: ['PID is 5255.0, B02 is 322.0, B03 is 735.0, DOY is 211.0, B04 is 547.0 B03 is 58295']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5255.0, DOY is 211.0, B02 is 322.0, B03 is 735.0, B04 is']\n",
      "prompt: PID is 5255.0, DOY is 211.0, B02 is 322.0, B03 is 735.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '2', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '5', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '2', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '2', '9', '4', '7', '9', '4', '6']]\n",
      "decoded_data: ['PID is 5255.0, DOY is 211.0, B02 is 322.0, B03 is 735.0, B04 is 547.0 52947946']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 322.0, DOY is 211.0, B03 is 735.0, PID is 5255.0, B04 is']\n",
      "prompt: B02 is 322.0, DOY is 211.0, B03 is 735.0, PID is 5255.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '5', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '2', '0', '2', '0']]\n",
      "decoded_data: ['B02 is 322.0, DOY is 211.0, B03 is 735.0, PID is 5255.0, B04 is 547.0 PID is 52020']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 322.0, DOY is 211.0, B03 is 735.0, PID is 5255.0, B04 is']\n",
      "prompt: B02 is 322.0, DOY is 211.0, B03 is 735.0, PID is 5255.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '5', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '1', '5', '4', '7']]\n",
      "decoded_data: ['B02 is 322.0, DOY is 211.0, B03 is 735.0, PID is 5255.0, B04 is 547.0 PID is 51547']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 322.0, DOY is 211.0, PID is 5255.0, B03 is 735.0, B04 is']\n",
      "prompt: B02 is 322.0, DOY is 211.0, PID is 5255.0, B03 is 735.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '5', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '4', '7', '5', '5']]\n",
      "decoded_data: ['B02 is 322.0, DOY is 211.0, PID is 5255.0, B03 is 735.0, B04 is 547.0 PID is 54755']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 735.0, PID is 5255.0, B02 is 322.0, B04 is']\n",
      "prompt: DOY is 211.0, B03 is 735.0, PID is 5255.0, B02 is 322.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '2', '.', '0', '2', '7', '9', '5']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 735.0, PID is 5255.0, B02 is 322.0, B04 is 547.0 52.02795']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 735.0, PID is 5255.0, B02 is 322.0, DOY is 211.0, B04 is']\n",
      "prompt: B03 is 735.0, PID is 5255.0, B02 is 322.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '3', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '3', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '8', '6', '5', '8']]\n",
      "decoded_data: ['B03 is 735.0, PID is 5255.0, B02 is 322.0, DOY is 211.0, B04 is 547.0 PID is 58658']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 735.0, B02 is 322.0, PID is 5255.0, B04 is']\n",
      "prompt: DOY is 211.0, B03 is 735.0, B02 is 322.0, PID is 5255.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '5', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '4', '7', '5', '4']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 735.0, B02 is 322.0, PID is 5255.0, B04 is 547.0 PID is 54754']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 322.0, PID is 5255.0, DOY is 211.0, B03 is 735.0, B04 is']\n",
      "prompt: B02 is 322.0, PID is 5255.0, DOY is 211.0, B03 is 735.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '5', '.', '0', ',', '', 'B04', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      "  6%|         | 53/829 [01:33<25:17,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '8', '5', '4', '7']]\n",
      "decoded_data: ['B02 is 322.0, PID is 5255.0, DOY is 211.0, B03 is 735.0, B04 is 547.0 PID is 58547']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5355.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 5355.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '3', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '3', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '4', '1', '.', '0', ',', '', 'B04', 'is']]\n",
      "decoded_data: ['PID is 5355.0, DOY is 211.0, B04 is 492.0, B02 is 271.0, B03 is 741.0741.0, B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 492.0, PID is 5355.0, DOY is 211.0, B02 is 271.0, B03 is']\n",
      "prompt: B04 is 492.0, PID is 5355.0, DOY is 211.0, B02 is 271.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '4', '1', '4', '1']]\n",
      "decoded_data: ['B04 is 492.0, PID is 5355.0, DOY is 211.0, B02 is 271.0, B03 is 741.0 PID is 74141']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5355.0, B02 is 271.0, B04 is 492.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5355.0, B02 is 271.0, B04 is 492.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '3', '5', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '3', '5', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B02', 'is', '', 'DOY', 'is', '', '2', '7']]\n",
      "decoded_data: ['PID is 5355.0, B02 is 271.0, B04 is 492.0, DOY is 211.0, B03 is 741.0 B02 is DOY is 27']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 271.0, PID is 5355.0, DOY is 211.0, B04 is 492.0, B03 is']\n",
      "prompt: B02 is 271.0, PID is 5355.0, DOY is 211.0, B04 is 492.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '7', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '7', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '4', '1', '3', '5']]\n",
      "decoded_data: ['B02 is 271.0, PID is 5355.0, DOY is 211.0, B04 is 492.0, B03 is 741.0 PID is 74135']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 271.0, B04 is 492.0, PID is 5355.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 271.0, B04 is 492.0, PID is 5355.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '7', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '7', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '7', '4', '8', '4', '1', '.', '0', '.']]\n",
      "decoded_data: ['B02 is 271.0, B04 is 492.0, PID is 5355.0, DOY is 211.0, B03 is 741.0 74841.0.']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5355.0, B02 is 271.0, B04 is 492.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5355.0, B02 is 271.0, B04 is 492.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '3', '5', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '3', '5', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '7', '4', '1', '.', '0']]\n",
      "decoded_data: ['PID is 5355.0, B02 is 271.0, B04 is 492.0, DOY is 211.0, B03 is 741.0 B04 is 741.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 492.0, PID is 5355.0, DOY is 211.0, B02 is 271.0, B03 is']\n",
      "prompt: B04 is 492.0, PID is 5355.0, DOY is 211.0, B02 is 271.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'DOY', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['B04 is 492.0, PID is 5355.0, DOY is 211.0, B02 is 271.0, B03 is 741.0 B04 is DOY is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5355.0, B04 is 492.0, B02 is 271.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 5355.0, B04 is 492.0, B02 is 271.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '5', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '5', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'DOY', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5355.0, B04 is 492.0, B02 is 271.0, B03 is 741.0 B04 is DOY is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 492.0, DOY is 211.0, B02 is 271.0, PID is 5355.0, B03 is']\n",
      "prompt: B04 is 492.0, DOY is 211.0, B02 is 271.0, PID is 5355.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '5', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', '7', '4', '1', '3', '0']]\n",
      "decoded_data: ['B04 is 492.0, DOY is 211.0, B02 is 271.0, PID is 5355.0, B03 is 741.0 B03 is 74130']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5355.0, B02 is 271.0, B04 is 492.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 5355.0, B02 is 271.0, B04 is 492.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '2', '7', '4', '1', '.', '0', ',', '', 'B04']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5355.0, B02 is 271.0, B04 is 492.0, B03 is 741.02741.0, B04']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 492.0, PID is 5355.0, B02 is 271.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 492.0, PID is 5355.0, B02 is 271.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '1', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|         | 54/829 [01:35<24:31,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '5', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '4', '1', '3', '0', ',', '', 'PID', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 492.0, PID is 5355.0, B02 is 271.0, B03 is 741.074130, PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5455.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 5455.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '5', '.', '0', ',', '', 'B04', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|         | 55/829 [01:35<18:46,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '5', '.', '0', ',', '', 'B04', 'is', '', '4', '7', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5455.0, B04 is 477.0, B02 is 288.0, B03 is 709.0 B04 is PID is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5455.0, B04 is 477.0, B02 is 288.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 5455.0, B04 is 477.0, B02 is 288.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '5', '.', '0', ',', '', 'B04', 'is', '', '4', '7', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '5', '5', '.', '0', ',', '', 'B04', 'is', '', '4', '7', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '0', ',', '', 'B04', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5455.0, B04 is 477.0, B02 is 288.0, B03 is 736.070, B04 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5555.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 5555.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '5', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B02', 'is', '', '2', '5']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5555.0, B03 is 724.0, B02 is 251.0, B04 is 448.0 PID is B02 is 25']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 251.0, B03 is 724.0, PID is 5555.0, B04 is']\n",
      "prompt: DOY is 211.0, B02 is 251.0, B03 is 724.0, PID is 5555.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '5', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '5', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B02', 'is', '', '4', '5']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 251.0, B03 is 724.0, PID is 5555.0, B04 is 448.0 PID is B02 is 45']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 251.0, DOY is 211.0, B03 is 724.0, PID is 5555.0, B04 is']\n",
      "prompt: B02 is 251.0, DOY is 211.0, B03 is 724.0, PID is 5555.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '5', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '5', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B02', 'is', '', 'PID', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['B02 is 251.0, DOY is 211.0, B03 is 724.0, PID is 5555.0, B04 is 448.0 B02 is PID is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5555.0, B03 is 724.0, DOY is 211.0, B02 is 251.0, B04 is']\n",
      "prompt: PID is 5555.0, B03 is 724.0, DOY is 211.0, B02 is 251.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '5', '5', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '5', '5', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '8', '7', '7', '7', '7', '7', '1']]\n",
      "decoded_data: ['PID is 5555.0, B03 is 724.0, DOY is 211.0, B02 is 251.0, B04 is 448.0 48777771']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 251.0, PID is 5555.0, B03 is 724.0, DOY is 211.0, B04 is']\n",
      "prompt: B02 is 251.0, PID is 5555.0, B03 is 724.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '5', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '5', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B03', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['B02 is 251.0, PID is 5555.0, B03 is 724.0, DOY is 211.0, B04 is 448.0 PID is B03 is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 724.0, B02 is 251.0, PID is 5555.0, B04 is']\n",
      "prompt: DOY is 211.0, B03 is 724.0, B02 is 251.0, PID is 5555.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '5', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '5', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'DOY', 'is', '', 'B02', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 724.0, B02 is 251.0, PID is 5555.0, B04 is 448.0 DOY is B02 is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5555.0, B03 is 724.0, B02 is 251.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 5555.0, B03 is 724.0, B02 is 251.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '5', '5', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '5', '5', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B03', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['PID is 5555.0, B03 is 724.0, B02 is 251.0, DOY is 211.0, B04 is 448.0 PID is B03 is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5555.0, DOY is 211.0, B02 is 251.0, B03 is 724.0, B04 is']\n",
      "prompt: PID is 5555.0, DOY is 211.0, B02 is 251.0, B03 is 724.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '5', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '5', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B02', 'is', '', '4', '8', '8', '8', '7']]\n",
      "decoded_data: ['PID is 5555.0, DOY is 211.0, B02 is 251.0, B03 is 724.0, B04 is 448.0 B02 is 48887']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 251.0, PID is 5555.0, DOY is 211.0, B03 is 724.0, B04 is']\n",
      "prompt: B02 is 251.0, PID is 5555.0, DOY is 211.0, B03 is 724.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '5', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '5', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '4', '8', '8', '8', '8', '7', '1', '.', '0']]\n",
      "decoded_data: ['B02 is 251.0, PID is 5555.0, DOY is 211.0, B03 is 724.0, B04 is 448.04888871.0']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5555.0, B03 is 724.0, B02 is 251.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 5555.0, B03 is 724.0, B02 is 251.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B03', 'is', '', '4', '8']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5555.0, B03 is 724.0, B02 is 251.0, B04 is 448.0 PID is B03 is 48']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 724.0, B02 is 251.0, DOY is 211.0, PID is 5555.0, B04 is']\n",
      "prompt: B03 is 724.0, B02 is 251.0, DOY is 211.0, PID is 5555.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '5', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '5', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B02', 'is', '', '5', '8']]\n",
      "decoded_data: ['B03 is 724.0, B02 is 251.0, DOY is 211.0, PID is 5555.0, B04 is 448.0 PID is B02 is 58']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 251.0, DOY is 211.0, PID is 5555.0, B03 is 724.0, B04 is']\n",
      "prompt: B02 is 251.0, DOY is 211.0, PID is 5555.0, B03 is 724.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B02', 'is', '', 'B03', 'is']]\n",
      "decoded_data: ['B02 is 251.0, DOY is 211.0, PID is 5555.0, B03 is 724.0, B04 is 448.0 PID is B02 is B03 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 251.0, B03 is 724.0, PID is 5555.0, B04 is']\n",
      "prompt: DOY is 211.0, B02 is 251.0, B03 is 724.0, PID is 5555.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '5', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '5', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '4', '4', '.', '0', ',', '', 'PID', 'is', '']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 251.0, B03 is 724.0, PID is 5555.0, B04 is 448.044.0, PID is ']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5555.0, B03 is 724.0, DOY is 211.0, B02 is 251.0, B04 is']\n",
      "prompt: PID is 5555.0, B03 is 724.0, DOY is 211.0, B02 is 251.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '5', '5', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '5', '5', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'DOY', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['PID is 5555.0, B03 is 724.0, DOY is 211.0, B02 is 251.0, B04 is 448.0 PID is DOY is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 724.0, B02 is 251.0, PID is 5555.0, DOY is 211.0, B04 is']\n",
      "prompt: B03 is 724.0, B02 is 251.0, PID is 5555.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      "  7%|         | 56/829 [01:37<21:48,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B02', 'is', '', 'B03', 'is']]\n",
      "decoded_data: ['B03 is 724.0, B02 is 251.0, PID is 5555.0, DOY is 211.0, B04 is 448.0 PID is B02 is B03 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5655.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 5655.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '5', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '5', '.', '0', ',', '', 'B04', 'is', '', '3', '7', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '3', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '6', '6', '.', '0', '6', '2', '.', '0']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5655.0, B04 is 376.0, B02 is 237.0, B03 is 682.0666.062.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 376.0, B02 is 237.0, PID is 5655.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 376.0, B02 is 237.0, PID is 5655.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '3', '7', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '3', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '3', '7', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '3', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['B04 is 376.0, B02 is 237.0, PID is 5655.0, DOY is 211.0, B03 is 682.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 376.0, PID is 5655.0, DOY is 211.0, B02 is 237.0, B03 is']\n",
      "prompt: B04 is 376.0, PID is 5655.0, DOY is 211.0, B02 is 237.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '3', '7', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '3', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '3', '7', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '3', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['B04 is 376.0, PID is 5655.0, DOY is 211.0, B02 is 237.0, B03 is 682.0 PID is B04 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 376.0, B02 is 237.0, DOY is 211.0, PID is 5655.0, B03 is']\n",
      "prompt: B04 is 376.0, B02 is 237.0, DOY is 211.0, PID is 5655.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '3', '7', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '3', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '5', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '3', '7', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '3', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '5', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['B04 is 376.0, B02 is 237.0, DOY is 211.0, PID is 5655.0, B03 is 682.0 B04 is B04 is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 237.0, DOY is 211.0, PID is 5655.0, B04 is 376.0, B03 is']\n",
      "prompt: B02 is 237.0, DOY is 211.0, PID is 5655.0, B04 is 376.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '3', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '5', '.', '0', ',', '', 'B04', 'is', '', '3', '7', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '3', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '5', '.', '0', ',', '', 'B04', 'is', '', '3', '7', '6', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['B02 is 237.0, DOY is 211.0, PID is 5655.0, B04 is 376.0, B03 is 682.0 B04 is PID is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5655.0, DOY is 211.0, B02 is 237.0, B04 is 376.0, B03 is']\n",
      "prompt: PID is 5655.0, DOY is 211.0, B02 is 237.0, B04 is 376.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '6', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '3', '7', '.', '0', ',', '', 'B04', 'is', '', '3', '7', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '6', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '3', '7', '.', '0', ',', '', 'B04', 'is', '', '3', '7', '6', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['PID is 5655.0, DOY is 211.0, B02 is 237.0, B04 is 376.0, B03 is 682.0 PID is B04 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5655.0, DOY is 211.0, B04 is 376.0, B02 is 237.0, B03 is']\n",
      "prompt: PID is 5655.0, DOY is 211.0, B04 is 376.0, B02 is 237.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '6', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '3', '7', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '3', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '6', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '3', '7', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '3', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['PID is 5655.0, DOY is 211.0, B04 is 376.0, B02 is 237.0, B03 is 682.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5655.0, DOY is 211.0, B02 is 237.0, B04 is 376.0, B03 is']\n",
      "prompt: PID is 5655.0, DOY is 211.0, B02 is 237.0, B04 is 376.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '6', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '3', '7', '.', '0', ',', '', 'B04', 'is', '', '3', '7', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '6', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '3', '7', '.', '0', ',', '', 'B04', 'is', '', '3', '7', '6', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '3', '7']]\n",
      "decoded_data: ['PID is 5655.0, DOY is 211.0, B02 is 237.0, B04 is 376.0, B03 is 682.0 B04 is PID is 37']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 237.0, PID is 5655.0, B04 is 376.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 237.0, PID is 5655.0, B04 is 376.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '3', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '5', '.', '0', ',', '', 'B04', 'is', '', '3', '7', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '3', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '5', '.', '0', ',', '', 'B04', 'is', '', '3', '7', '6', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', '3', '7']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 237.0, PID is 5655.0, B04 is 376.0, B03 is 682.0 B04 is B04 is 37']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 376.0, PID is 5655.0, B02 is 237.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 376.0, PID is 5655.0, B02 is 237.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '3', '7', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '3', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '3', '7', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '3', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '6', '2']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 376.0, PID is 5655.0, B02 is 237.0, B03 is 682.0 B04 is PID is 62']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 376.0, B02 is 237.0, PID is 5655.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 376.0, B02 is 237.0, PID is 5655.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '3', '7', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '3', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '3', '7', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '3', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '3', '7']]\n",
      "decoded_data: ['B04 is 376.0, B02 is 237.0, PID is 5655.0, DOY is 211.0, B03 is 682.0 PID is B04 is 37']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5655.0, DOY is 211.0, B02 is 237.0, B04 is 376.0, B03 is']\n",
      "prompt: PID is 5655.0, DOY is 211.0, B02 is 237.0, B04 is 376.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '6', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '3', '7', '.', '0', ',', '', 'B04', 'is', '', '3', '7', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '6', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '3', '7', '.', '0', ',', '', 'B04', 'is', '', '3', '7', '6', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '3', '7']]\n",
      "decoded_data: ['PID is 5655.0, DOY is 211.0, B02 is 237.0, B04 is 376.0, B03 is 682.0 B04 is PID is 37']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 237.0, B04 is 376.0, PID is 5655.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 237.0, B04 is 376.0, PID is 5655.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '3', '7', '.', '0', ',', '', 'B04', 'is', '', '3', '7', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|         | 57/829 [01:39<23:04,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B02', 'is', '', '2', '3', '7', '.', '0', ',', '', 'B04', 'is', '', '3', '7', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '6', '8', '2', '7', '6', '6', '8', '2']]\n",
      "decoded_data: ['B02 is 237.0, B04 is 376.0, PID is 5655.0, DOY is 211.0, B03 is 682.0668276682']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5264.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5264.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '2', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '2', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '9', '5', '9', '5', '9', '5', '9', '.']]\n",
      "decoded_data: ['PID is 5264.0, DOY is 211.0, B03 is 766.0, B02 is 313.0, B04 is 559.059595959.']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 313.0, PID is 5264.0, DOY is 211.0, B03 is 766.0, B04 is']\n",
      "prompt: B02 is 313.0, PID is 5264.0, DOY is 211.0, B03 is 766.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '1', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '6', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '1', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '.', '0', '3', '4', '2', '5', '9', '5', '9']]\n",
      "decoded_data: ['B02 is 313.0, PID is 5264.0, DOY is 211.0, B03 is 766.0, B04 is 559.0.03425959']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 313.0, PID is 5264.0, B03 is 766.0, B04 is']\n",
      "prompt: DOY is 211.0, B02 is 313.0, PID is 5264.0, B03 is 766.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '6', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '3', '7', '6', '.', '0', ',', '', 'PID', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 313.0, PID is 5264.0, B03 is 766.0, B04 is 559.0376.0, PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 766.0, B02 is 313.0, PID is 5264.0, DOY is 211.0, B04 is']\n",
      "prompt: B03 is 766.0, B02 is 313.0, PID is 5264.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '9', '5', '9', '5', '9', '.', '0']]\n",
      "decoded_data: ['B03 is 766.0, B02 is 313.0, PID is 5264.0, DOY is 211.0, B04 is 559.0 595959.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 766.0, PID is 5264.0, B02 is 313.0, DOY is 211.0, B04 is']\n",
      "prompt: B03 is 766.0, PID is 5264.0, B02 is 313.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '9', '5', '9', '5']]\n",
      "decoded_data: ['B03 is 766.0, PID is 5264.0, B02 is 313.0, DOY is 211.0, B04 is 559.0 PID is 59595']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 313.0, PID is 5264.0, B03 is 766.0, DOY is 211.0, B04 is']\n",
      "prompt: B02 is 313.0, PID is 5264.0, B03 is 766.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '1', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '1', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '.', '0', '7', '6', '4', '2', '.', '0', ',']]\n",
      "decoded_data: ['B02 is 313.0, PID is 5264.0, B03 is 766.0, DOY is 211.0, B04 is 559.0.07642.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5264.0, B02 is 313.0, B03 is 766.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 5264.0, B02 is 313.0, B03 is 766.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '6', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'DOY', 'is', '', '5', '9']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5264.0, B02 is 313.0, B03 is 766.0, B04 is 559.0 PID is DOY is 59']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 313.0, DOY is 211.0, B03 is 766.0, PID is 5264.0, B04 is']\n",
      "prompt: B02 is 313.0, DOY is 211.0, B03 is 766.0, PID is 5264.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '1', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '4', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '1', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '9', '5', '9', '5']]\n",
      "decoded_data: ['B02 is 313.0, DOY is 211.0, B03 is 766.0, PID is 5264.0, B04 is 559.0 PID is 59595']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 766.0, B02 is 313.0, PID is 5264.0, DOY is 211.0, B04 is']\n",
      "prompt: B03 is 766.0, B02 is 313.0, PID is 5264.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '9', '5', '9', '5']]\n",
      "decoded_data: ['B03 is 766.0, B02 is 313.0, PID is 5264.0, DOY is 211.0, B04 is 559.0 PID is 59595']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 766.0, PID is 5264.0, B02 is 313.0, B04 is']\n",
      "prompt: DOY is 211.0, B03 is 766.0, PID is 5264.0, B02 is 313.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '3', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '9', '5', '9', '5']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 766.0, PID is 5264.0, B02 is 313.0, B04 is 559.0 PID is 59595']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5264.0, B03 is 766.0, B02 is 313.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 5264.0, B03 is 766.0, B02 is 313.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '2', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '2', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'DOY', 'is', '', '2', '1', '8', '8', '8']]\n",
      "decoded_data: ['PID is 5264.0, B03 is 766.0, B02 is 313.0, DOY is 211.0, B04 is 559.0 DOY is 21888']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5264.0, B02 is 313.0, DOY is 211.0, B03 is 766.0, B04 is']\n",
      "prompt: PID is 5264.0, B02 is 313.0, DOY is 211.0, B03 is 766.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '2', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '6', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '2', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '9', '5', '9', '5']]\n",
      "decoded_data: ['PID is 5264.0, B02 is 313.0, DOY is 211.0, B03 is 766.0, B04 is 559.0 PID is 59595']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 313.0, B03 is 766.0, PID is 5264.0, B04 is']\n",
      "prompt: DOY is 211.0, B02 is 313.0, B03 is 766.0, PID is 5264.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '4', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '9', '5', '9', '5']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 313.0, B03 is 766.0, PID is 5264.0, B04 is 559.0 PID is 59595']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5264.0, DOY is 211.0, B03 is 766.0, B02 is 313.0, B04 is']\n",
      "prompt: PID is 5264.0, DOY is 211.0, B03 is 766.0, B02 is 313.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '2', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '3', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '2', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '9', '5', '9', '5']]\n",
      "decoded_data: ['PID is 5264.0, DOY is 211.0, B03 is 766.0, B02 is 313.0, B04 is 559.0 PID is 59595']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 766.0, B02 is 313.0, PID is 5264.0, DOY is 211.0, B04 is']\n",
      "prompt: B03 is 766.0, B02 is 313.0, PID is 5264.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      "  7%|         | 58/829 [01:42<25:04,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B03', 'is', '', '7', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '9', '9', '5', '9', '5', '9', '5', '.', '0']]\n",
      "decoded_data: ['B03 is 766.0, B02 is 313.0, PID is 5264.0, DOY is 211.0, B04 is 559.09959595.0']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5364.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 5364.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '4', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|         | 59/829 [01:42<19:13,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', '3', '9', '1', '6', '4']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5364.0, B03 is 777.0, B04 is 575.0, B02 is 316.0 B03 is 39164']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 575.0, PID is 5364.0, B03 is 777.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 575.0, PID is 5364.0, B03 is 777.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '7', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '7', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '3', '1', '6', '6', '0', '9', '1', '6', '6']]\n",
      "decoded_data: ['B04 is 575.0, PID is 5364.0, B03 is 777.0, DOY is 211.0, B02 is 316.0316609166']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5464.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5464.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '4', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '4', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '5', '.', '0', ',', '', 'B04', 'is', '', '6', '4', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['PID is 5464.0, DOY is 211.0, B03 is 755.0, B04 is 640.0, B02 is 307.0 B03 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 640.0, DOY is 211.0, PID is 5464.0, B03 is 755.0, B02 is']\n",
      "prompt: B04 is 640.0, DOY is 211.0, PID is 5464.0, B03 is 755.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '6', '4', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '5', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '6', '4', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '7', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', 'B03', 'is']]\n",
      "decoded_data: ['B04 is 640.0, DOY is 211.0, PID is 5464.0, B03 is 755.0, B02 is 378.0 PID is B04 is B03 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5464.0, B03 is 755.0, B04 is 640.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 5464.0, B03 is 755.0, B04 is 640.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '5', '.', '0', ',', '', 'B04', 'is', '', '6', '4', '0', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '5', '.', '0', ',', '', 'B04', 'is', '', '6', '4', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'B04', 'is', '', '5', '9']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5464.0, B03 is 755.0, B04 is 640.0, B02 is 307.0 B03 is B04 is 59']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5464.0, B03 is 755.0, DOY is 211.0, B04 is 640.0, B02 is']\n",
      "prompt: PID is 5464.0, B03 is 755.0, DOY is 211.0, B04 is 640.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '4', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '4', '0', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '4', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '4', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'B04', 'is', '', 'DOY', 'is']]\n",
      "decoded_data: ['PID is 5464.0, B03 is 755.0, DOY is 211.0, B04 is 640.0, B02 is 307.0 B03 is B04 is DOY is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 640.0, B03 is 755.0, PID is 5464.0, B02 is']\n",
      "prompt: DOY is 211.0, B04 is 640.0, B03 is 755.0, PID is 5464.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '4', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '4', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '4', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 640.0, B03 is 755.0, PID is 5464.0, B02 is 307.0 B03 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5464.0, DOY is 211.0, B03 is 755.0, B04 is 640.0, B02 is']\n",
      "prompt: PID is 5464.0, DOY is 211.0, B03 is 755.0, B04 is 640.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '4', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '5', '.', '0', ',', '', 'B04', 'is', '', '6', '4', '0', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '4', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '5', '.', '0', ',', '', 'B04', 'is', '', '6', '4', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B02', 'is', '', '3', '0']]\n",
      "decoded_data: ['PID is 5464.0, DOY is 211.0, B03 is 755.0, B04 is 640.0, B02 is 307.0 B04 is B02 is 30']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5464.0, B03 is 755.0, DOY is 211.0, B04 is 640.0, B02 is']\n",
      "prompt: PID is 5464.0, B03 is 755.0, DOY is 211.0, B04 is 640.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '4', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '4', '0', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '4', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '4', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '7', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'B04', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['PID is 5464.0, B03 is 755.0, DOY is 211.0, B04 is 640.0, B02 is 378.0 B03 is B04 is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 640.0, DOY is 211.0, PID is 5464.0, B03 is 755.0, B02 is']\n",
      "prompt: B04 is 640.0, DOY is 211.0, PID is 5464.0, B03 is 755.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '6', '4', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '5', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '6', '4', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '8', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '8', '3', '6', '2', '2', '2', 'B03', 'is']]\n",
      "decoded_data: ['B04 is 640.0, DOY is 211.0, PID is 5464.0, B03 is 755.0, B02 is 383.07836222B03 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 640.0, DOY is 211.0, B03 is 755.0, PID is 5464.0, B02 is']\n",
      "prompt: B04 is 640.0, DOY is 211.0, B03 is 755.0, PID is 5464.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '6', '4', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '4', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '6', '4', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '8', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '0', '7', '8', '.', '0', ',', '', 'PID', 'is']]\n",
      "decoded_data: ['B04 is 640.0, DOY is 211.0, B03 is 755.0, PID is 5464.0, B02 is 380.0078.0, PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5464.0, DOY is 211.0, B03 is 755.0, B04 is 640.0, B02 is']\n",
      "prompt: PID is 5464.0, DOY is 211.0, B03 is 755.0, B04 is 640.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '4', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '5', '.', '0', ',', '', 'B04', 'is', '', '6', '4', '0', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '4', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '5', '.', '0', ',', '', 'B04', 'is', '', '6', '4', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '7', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B03', 'is', '', 'B03', 'is']]\n",
      "decoded_data: ['PID is 5464.0, DOY is 211.0, B03 is 755.0, B04 is 640.0, B02 is 378.0 B04 is B03 is B03 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 640.0, PID is 5464.0, B03 is 755.0, B02 is']\n",
      "prompt: DOY is 211.0, B04 is 640.0, PID is 5464.0, B03 is 755.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '4', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '5', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '4', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 640.0, PID is 5464.0, B03 is 755.0, B02 is 307.0 PID is B04 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5464.0, DOY is 211.0, B03 is 755.0, B04 is 640.0, B02 is']\n",
      "prompt: PID is 5464.0, DOY is 211.0, B03 is 755.0, B04 is 640.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '4', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '5', '.', '0', ',', '', 'B04', 'is', '', '6', '4', '0', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '4', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '5', '.', '0', ',', '', 'B04', 'is', '', '6', '4', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '0', '7', '7', '8', '.', '0', '7', '8', '0']]\n",
      "decoded_data: ['PID is 5464.0, DOY is 211.0, B03 is 755.0, B04 is 640.0, B02 is 307.00778.0780']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 755.0, B04 is 640.0, PID is 5464.0, DOY is 211.0, B02 is']\n",
      "prompt: B03 is 755.0, B04 is 640.0, PID is 5464.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '5', '5', '.', '0', ',', '', 'B04', 'is', '', '6', '4', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '5', '5', '.', '0', ',', '', 'B04', 'is', '', '6', '4', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B02', 'is', '', '3', '0']]\n",
      "decoded_data: ['B03 is 755.0, B04 is 640.0, PID is 5464.0, DOY is 211.0, B02 is 307.0 B04 is B02 is 30']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5464.0, B04 is 640.0, B03 is 755.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 5464.0, B04 is 640.0, B03 is 755.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '6', '4', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '5', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '6', '4', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '7', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'B04', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5464.0, B04 is 640.0, B03 is 755.0, B02 is 378.0 B03 is B04 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5464.0, B04 is 640.0, B03 is 755.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 5464.0, B04 is 640.0, B03 is 755.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '6', '4', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '5', '.', '0', ',', '', 'B02', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      "  7%|         | 60/829 [01:44<22:08,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '6', '4', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B03', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5464.0, B04 is 640.0, B03 is 755.0, B02 is 307.0 B04 is B03 is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5564.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 5564.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '3', '5', '3', '4']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5564.0, B03 is 730.0, B04 is 534.0, B02 is 289.0 B04 is 53534']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 534.0, B03 is 730.0, PID is 5564.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 534.0, B03 is 730.0, PID is 5564.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '3', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '3', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '3', '0', '9', '.', '0', '4', '6', '9']]\n",
      "decoded_data: ['B04 is 534.0, B03 is 730.0, PID is 5564.0, DOY is 211.0, B02 is 289.0 309.0469']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 730.0, DOY is 211.0, B04 is 534.0, PID is 5564.0, B02 is']\n",
      "prompt: B03 is 730.0, DOY is 211.0, B04 is 534.0, PID is 5564.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '3', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '4', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '3', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '2', '1', '9', '.', '0', ',', '', 'PID', 'is']]\n",
      "decoded_data: ['B03 is 730.0, DOY is 211.0, B04 is 534.0, PID is 5564.0, B02 is 289.0219.0, PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 534.0, PID is 5564.0, B03 is 730.0, B02 is']\n",
      "prompt: DOY is 211.0, B04 is 534.0, PID is 5564.0, B03 is 730.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '0', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '0', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '2', '1', '1', '9', '4']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 534.0, PID is 5564.0, B03 is 730.0, B02 is 289.0 PID is 21194']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 730.0, PID is 5564.0, B04 is 534.0, DOY is 211.0, B02 is']\n",
      "prompt: B03 is 730.0, PID is 5564.0, B04 is 534.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '3', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|         | 61/829 [01:45<18:48,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B03', 'is', '', '7', '3', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '2', '1', '0', ',', '', 'PID', 'is', '', '2']]\n",
      "decoded_data: ['B03 is 730.0, PID is 5564.0, B04 is 534.0, DOY is 211.0, B02 is 289.0210, PID is 2']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5664.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 5664.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '4', '.', '0', ',', '', 'B04', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|         | 62/829 [01:46<14:49,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', '5', '8']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5664.0, B04 is 544.0, B02 is 306.0, B03 is 743.0 B04 is B04 is 58']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 544.0, PID is 5664.0, B02 is 306.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 544.0, PID is 5664.0, B02 is 306.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '4', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '4', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '2', '7', '9', '9', '4', '3', '1', '4', '0']]\n",
      "decoded_data: ['B04 is 544.0, PID is 5664.0, B02 is 306.0, DOY is 211.0, B03 is 705.0279943140']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5764.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 5764.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '7', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '7', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '7', '1']]\n",
      "decoded_data: ['PID is 5764.0, DOY is 211.0, B04 is 550.0, B02 is 304.0, B03 is 715.0 PID is B04 is 71']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 550.0, B02 is 304.0, PID is 5764.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 550.0, B02 is 304.0, PID is 5764.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '5', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '5', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '1', '5', '7', '3']]\n",
      "decoded_data: ['B04 is 550.0, B02 is 304.0, PID is 5764.0, DOY is 211.0, B03 is 715.0 PID is 71573']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 304.0, PID is 5764.0, DOY is 211.0, B04 is 550.0, B03 is']\n",
      "prompt: B02 is 304.0, PID is 5764.0, DOY is 211.0, B04 is 550.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '0', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '0', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|         | 63/829 [01:46<13:23,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B02', 'is', '', '3', '0', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '7', '8']]\n",
      "decoded_data: ['B02 is 304.0, PID is 5764.0, DOY is 211.0, B04 is 550.0, B03 is 715.0 PID is B04 is 78']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 304.0, PID is 5764.0, DOY is 211.0, B04 is 550.0, B03 is']\n",
      "prompt: B02 is 304.0, PID is 5764.0, DOY is 211.0, B04 is 550.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '0', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '0', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '0', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '9', '4', '7', '8', '9', '1', '5', '7', '6']]\n",
      "decoded_data: ['B02 is 304.0, PID is 5764.0, DOY is 211.0, B04 is 550.0, B03 is 715.0947891576']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5864.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 5864.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '8', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '8', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '2', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B03', 'is', '', '7', '8']]\n",
      "decoded_data: ['PID is 5864.0, DOY is 211.0, B04 is 538.0, B03 is 772.0, B02 is 303.0 PID is B03 is 78']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5864.0, B03 is 772.0, DOY is 211.0, B04 is 538.0, B02 is']\n",
      "prompt: PID is 5864.0, B03 is 772.0, DOY is 211.0, B04 is 538.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '8', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '8', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '8', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '3', '8', '3', '9']]\n",
      "decoded_data: ['PID is 5864.0, B03 is 772.0, DOY is 211.0, B04 is 538.0, B02 is 303.0 B04 is 53839']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5864.0, B04 is 538.0, B03 is 772.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 5864.0, B04 is 538.0, B03 is 772.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '2', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '2', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B03', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5864.0, B04 is 538.0, B03 is 772.0, B02 is 303.0 B04 is B03 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 772.0, PID is 5864.0, B04 is 538.0, DOY is 211.0, B02 is']\n",
      "prompt: B03 is 772.0, PID is 5864.0, B04 is 538.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '7', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '7', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '3', '0', '3', '0', '3']]\n",
      "decoded_data: ['B03 is 772.0, PID is 5864.0, B04 is 538.0, DOY is 211.0, B02 is 303.0 PID is 30303']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5864.0, B04 is 538.0, B03 is 772.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 5864.0, B04 is 538.0, B03 is 772.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '8', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '8', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'B04', 'is', '', '3', '9']]\n",
      "decoded_data: ['PID is 5864.0, B04 is 538.0, B03 is 772.0, DOY is 211.0, B02 is 303.0 B03 is B04 is 39']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5864.0, B04 is 538.0, DOY is 211.0, B03 is 772.0, B02 is']\n",
      "prompt: PID is 5864.0, B04 is 538.0, DOY is 211.0, B03 is 772.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '8', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '2', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '8', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '2', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '3', '9', '3', '9', '6', '9', '3', '.']]\n",
      "decoded_data: ['PID is 5864.0, B04 is 538.0, DOY is 211.0, B03 is 772.0, B02 is 303.0 3939693.']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 772.0, PID is 5864.0, DOY is 211.0, B04 is 538.0, B02 is']\n",
      "prompt: B03 is 772.0, PID is 5864.0, DOY is 211.0, B04 is 538.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '7', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '8', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '7', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '3', '9', '6', '6', '6', '.', '0', '3', '.']]\n",
      "decoded_data: ['B03 is 772.0, PID is 5864.0, DOY is 211.0, B04 is 538.0, B02 is 303.039666.03.']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 772.0, DOY is 211.0, B04 is 538.0, PID is 5864.0, B02 is']\n",
      "prompt: B03 is 772.0, DOY is 211.0, B04 is 538.0, PID is 5864.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '7', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '4', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '7', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '3', '2', '5', '3', '.', '0', ',', '']]\n",
      "decoded_data: ['B03 is 772.0, DOY is 211.0, B04 is 538.0, PID is 5864.0, B02 is 303.053253.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5864.0, DOY is 211.0, B04 is 538.0, B03 is 772.0, B02 is']\n",
      "prompt: PID is 5864.0, DOY is 211.0, B04 is 538.0, B03 is 772.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '8', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '2', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '8', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '2', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'B04', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['PID is 5864.0, DOY is 211.0, B04 is 538.0, B03 is 772.0, B02 is 303.0 B03 is B04 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5864.0, B04 is 538.0, DOY is 211.0, B03 is 772.0, B02 is']\n",
      "prompt: PID is 5864.0, B04 is 538.0, DOY is 211.0, B03 is 772.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '8', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '2', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '8', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '2', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '3', '0', '3', '9', '3', '.', '0', '3']]\n",
      "decoded_data: ['PID is 5864.0, B04 is 538.0, DOY is 211.0, B03 is 772.0, B02 is 303.0530393.03']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5864.0, B03 is 772.0, B04 is 538.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 5864.0, B03 is 772.0, B04 is 538.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '2', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '8', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '2', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '8', '2', '3', '9', '.', '0', '3', '.']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5864.0, B03 is 772.0, B04 is 538.0, B02 is 303.058239.03.']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 538.0, DOY is 211.0, B03 is 772.0, PID is 5864.0, B02 is']\n",
      "prompt: B04 is 538.0, DOY is 211.0, B03 is 772.0, PID is 5864.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '3', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '4', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '3', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'B04', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['B04 is 538.0, DOY is 211.0, B03 is 772.0, PID is 5864.0, B02 is 303.0 B03 is B04 is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 772.0, PID is 5864.0, B04 is 538.0, B02 is']\n",
      "prompt: DOY is 211.0, B03 is 772.0, PID is 5864.0, B04 is 538.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '8', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '5', '3']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 772.0, PID is 5864.0, B04 is 538.0, B02 is 303.0 B04 is PID is 53']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5864.0, B03 is 772.0, DOY is 211.0, B04 is 538.0, B02 is']\n",
      "prompt: PID is 5864.0, B03 is 772.0, DOY is 211.0, B04 is 538.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '8', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '8', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '8', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['PID is 5864.0, B03 is 772.0, DOY is 211.0, B04 is 538.0, B02 is 303.0 B04 is PID is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 772.0, PID is 5864.0, DOY is 211.0, B04 is 538.0, B02 is']\n",
      "prompt: B03 is 772.0, PID is 5864.0, DOY is 211.0, B04 is 538.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '7', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '8', '.', '0', ',', '', 'B02', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      "  8%|         | 64/829 [01:49<18:05,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B03', 'is', '', '7', '7', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '3', '9', '6', '8', '3']]\n",
      "decoded_data: ['B03 is 772.0, PID is 5864.0, DOY is 211.0, B04 is 538.0, B02 is 303.0 PID is 39683']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5964.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5964.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '9', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '9', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '2', '0', '7', '3']]\n",
      "decoded_data: ['PID is 5964.0, DOY is 211.0, B03 is 789.0, B02 is 298.0, B04 is 537.0 PID is 52073']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5964.0, B02 is 298.0, DOY is 211.0, B03 is 789.0, B04 is']\n",
      "prompt: PID is 5964.0, B02 is 298.0, DOY is 211.0, B03 is 789.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '9', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '9', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '2', '3', '1', '9']]\n",
      "decoded_data: ['PID is 5964.0, B02 is 298.0, DOY is 211.0, B03 is 789.0, B04 is 537.0 PID is 52319']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 298.0, PID is 5964.0, B03 is 789.0, B04 is']\n",
      "prompt: DOY is 211.0, B02 is 298.0, PID is 5964.0, B03 is 789.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B03', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 298.0, PID is 5964.0, B03 is 789.0, B04 is 537.0 PID is B03 is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 789.0, B02 is 298.0, PID is 5964.0, B04 is']\n",
      "prompt: DOY is 211.0, B03 is 789.0, B02 is 298.0, PID is 5964.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '4', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '5', '2']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 789.0, B02 is 298.0, PID is 5964.0, B04 is 537.0 PID is B04 is 52']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 789.0, B02 is 298.0, PID is 5964.0, DOY is 211.0, B04 is']\n",
      "prompt: B03 is 789.0, B02 is 298.0, PID is 5964.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '8', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '8', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '2', 'B02', 'is', '', '5', '2', '3', '7']]\n",
      "decoded_data: ['B03 is 789.0, B02 is 298.0, PID is 5964.0, DOY is 211.0, B04 is 537.052B02 is 5237']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 298.0, PID is 5964.0, DOY is 211.0, B03 is 789.0, B04 is']\n",
      "prompt: B02 is 298.0, PID is 5964.0, DOY is 211.0, B03 is 789.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '9', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '9', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '7', '3', '7', '5']]\n",
      "decoded_data: ['B02 is 298.0, PID is 5964.0, DOY is 211.0, B03 is 789.0, B04 is 537.0 PID is 57375']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5964.0, B03 is 789.0, B02 is 298.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 5964.0, B03 is 789.0, B02 is 298.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '9', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '9', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '3', '7', '3', '7', '5', '2', '.']]\n",
      "decoded_data: ['PID is 5964.0, B03 is 789.0, B02 is 298.0, DOY is 211.0, B04 is 537.0 5373752.']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 298.0, B03 is 789.0, PID is 5964.0, DOY is 211.0, B04 is']\n",
      "prompt: B02 is 298.0, B03 is 789.0, PID is 5964.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '9', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '9', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '9', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '9', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B02', 'is', '', 'PID', 'is', '', '5', '2']]\n",
      "decoded_data: ['B02 is 298.0, B03 is 789.0, PID is 5964.0, DOY is 211.0, B04 is 537.0 B02 is PID is 52']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5964.0, DOY is 211.0, B03 is 789.0, B02 is 298.0, B04 is']\n",
      "prompt: PID is 5964.0, DOY is 211.0, B03 is 789.0, B02 is 298.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '9', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '8', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '9', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '3', '7', '3', '8', '2', '.', '0', ',', '']]\n",
      "decoded_data: ['PID is 5964.0, DOY is 211.0, B03 is 789.0, B02 is 298.0, B04 is 537.037382.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5964.0, B02 is 298.0, B03 is 789.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 5964.0, B02 is 298.0, B03 is 789.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '2', '6', '.', '0', ',', '', 'B03']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5964.0, B02 is 298.0, B03 is 789.0, B04 is 537.0 526.0, B03']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5964.0, B02 is 298.0, B03 is 789.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 5964.0, B02 is 298.0, B03 is 789.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'DOY', 'is', '', 'B02', 'is', '', 'B03', 'is']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5964.0, B02 is 298.0, B03 is 789.0, B04 is 537.0 DOY is B02 is B03 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5964.0, DOY is 211.0, B03 is 789.0, B02 is 298.0, B04 is']\n",
      "prompt: PID is 5964.0, DOY is 211.0, B03 is 789.0, B02 is 298.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '9', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '8', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '9', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'PID', 'is', '', '5', '2']]\n",
      "decoded_data: ['PID is 5964.0, DOY is 211.0, B03 is 789.0, B02 is 298.0, B04 is 537.0 B03 is PID is 52']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 789.0, PID is 5964.0, B02 is 298.0, DOY is 211.0, B04 is']\n",
      "prompt: B03 is 789.0, PID is 5964.0, B02 is 298.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '8', '9', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|         | 65/829 [01:51<20:23,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B03', 'is', '', '7', '8', '9', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '2', '3', '7', '3', '7', '5', '3', '7']]\n",
      "decoded_data: ['B03 is 789.0, PID is 5964.0, B02 is 298.0, DOY is 211.0, B04 is 537.0523737537']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6064.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 6064.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '6', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '0', '4', '0', '1', '.', '0', '4']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6064.0, B03 is 652.0, B02 is 281.0, B04 is 435.0 40401.04']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 652.0, PID is 6064.0, DOY is 211.0, B02 is 281.0, B04 is']\n",
      "prompt: B03 is 652.0, PID is 6064.0, DOY is 211.0, B02 is 281.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '5', '2', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '6', '5', '2', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '4', '0', '1', '7', '2']]\n",
      "decoded_data: ['B03 is 652.0, PID is 6064.0, DOY is 211.0, B02 is 281.0, B04 is 435.0 PID is 40172']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 652.0, PID is 6064.0, B02 is 281.0, B04 is']\n",
      "prompt: DOY is 211.0, B03 is 652.0, PID is 6064.0, B02 is 281.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '5', '2', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '5', '2', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '4', '0', '1', '6', '2']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 652.0, PID is 6064.0, B02 is 281.0, B04 is 435.0 PID is 40162']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 652.0, B02 is 281.0, PID is 6064.0, B04 is']\n",
      "prompt: DOY is 211.0, B03 is 652.0, B02 is 281.0, PID is 6064.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '4', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'DOY', 'is', '', 'B02', 'is', '', '4', '0']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 652.0, B02 is 281.0, PID is 6064.0, B04 is 438.0 DOY is B02 is 40']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6064.0, DOY is 211.0, B03 is 652.0, B02 is 281.0, B04 is']\n",
      "prompt: PID is 6064.0, DOY is 211.0, B03 is 652.0, B02 is 281.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '0', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '0', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '0', '1', '.', '0', '1', '1', '6']]\n",
      "decoded_data: ['PID is 6064.0, DOY is 211.0, B03 is 652.0, B02 is 281.0, B04 is 435.0 401.0116']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 281.0, DOY is 211.0, B03 is 652.0, PID is 6064.0, B04 is']\n",
      "prompt: B02 is 281.0, DOY is 211.0, B03 is 652.0, PID is 6064.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '8', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '5', '2', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '4', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '8', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '5', '2', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'DOY', 'is', '', 'B02', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['B02 is 281.0, DOY is 211.0, B03 is 652.0, PID is 6064.0, B04 is 438.0 DOY is B02 is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6064.0, B03 is 652.0, DOY is 211.0, B02 is 281.0, B04 is']\n",
      "prompt: PID is 6064.0, B03 is 652.0, DOY is 211.0, B02 is 281.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '0', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '6', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '0', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '6', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '4', '0', '1', '6', '2', '0', '1']]\n",
      "decoded_data: ['PID is 6064.0, B03 is 652.0, DOY is 211.0, B02 is 281.0, B04 is 435.0 44016201']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6064.0, B02 is 281.0, B03 is 652.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 6064.0, B02 is 281.0, B03 is 652.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '5', '2', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'PID', 'is', '', '4', '4']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6064.0, B02 is 281.0, B03 is 652.0, B04 is 435.0 B03 is PID is 44']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 652.0, DOY is 211.0, B02 is 281.0, PID is 6064.0, B04 is']\n",
      "prompt: B03 is 652.0, DOY is 211.0, B02 is 281.0, PID is 6064.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '4', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '6', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '4', '0', '4', '1', '1']]\n",
      "decoded_data: ['B03 is 652.0, DOY is 211.0, B02 is 281.0, PID is 6064.0, B04 is 435.0 PID is 40411']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6064.0, B03 is 652.0, DOY is 211.0, B02 is 281.0, B04 is']\n",
      "prompt: PID is 6064.0, B03 is 652.0, DOY is 211.0, B02 is 281.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '0', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '6', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '0', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '6', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '4', '0', '1', '0', '1']]\n",
      "decoded_data: ['PID is 6064.0, B03 is 652.0, DOY is 211.0, B02 is 281.0, B04 is 435.0 PID is 40101']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 652.0, DOY is 211.0, B02 is 281.0, PID is 6064.0, B04 is']\n",
      "prompt: B03 is 652.0, DOY is 211.0, B02 is 281.0, PID is 6064.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '4', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '6', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B03', 'is', '', '4', '7']]\n",
      "decoded_data: ['B03 is 652.0, DOY is 211.0, B02 is 281.0, PID is 6064.0, B04 is 435.0 PID is B03 is 47']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6064.0, B03 is 652.0, B02 is 281.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 6064.0, B03 is 652.0, B02 is 281.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '6', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '6', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '.', '0', '4', '0', ',', '', 'B03']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6064.0, B03 is 652.0, B02 is 281.0, B04 is 438.0 4.040, B03']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 652.0, B02 is 281.0, PID is 6064.0, B04 is']\n",
      "prompt: DOY is 211.0, B03 is 652.0, B02 is 281.0, PID is 6064.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '4', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '4', '7', '9', '0', '1']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 652.0, B02 is 281.0, PID is 6064.0, B04 is 435.0 PID is 47901']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 281.0, DOY is 211.0, B03 is 652.0, PID is 6064.0, B04 is']\n",
      "prompt: B02 is 281.0, DOY is 211.0, B03 is 652.0, PID is 6064.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '8', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '5', '2', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '4', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '8', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '5', '2', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '.', '0', '4', '0', '.', '0', ',']]\n",
      "decoded_data: ['B02 is 281.0, DOY is 211.0, B03 is 652.0, PID is 6064.0, B04 is 435.0 4.040.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 652.0, B02 is 281.0, PID is 6064.0, B04 is']\n",
      "prompt: DOY is 211.0, B03 is 652.0, B02 is 281.0, PID is 6064.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '4', '.', '0', ',', '', 'B04', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      "  8%|         | 66/829 [01:53<23:04,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'DOY', 'is', '', '2', '0', '3', '7', '0']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 652.0, B02 is 281.0, PID is 6064.0, B04 is 438.0 DOY is 20370']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6164.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 6164.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '1', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '1', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '0', '1', '.', '0', ',', '', 'B04', 'is', '', '2', '8', '5', '.', '0', ',', '', 'B03', 'is', '', '4', '6', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'DOY', 'is', '', '4', '.']]\n",
      "decoded_data: ['PID is 6164.0, DOY is 211.0, B02 is 201.0, B04 is 285.0, B03 is 466.0 B04 is DOY is 4.']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 285.0, B02 is 201.0, PID is 6164.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 285.0, B02 is 201.0, PID is 6164.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '2', '8', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '2', '8', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '4', '6', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '6', '6', '6', '6', '6', '6', '9', '.']]\n",
      "decoded_data: ['B04 is 285.0, B02 is 201.0, PID is 6164.0, DOY is 211.0, B03 is 466.066666669.']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 201.0, B04 is 285.0, PID is 6164.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 201.0, B04 is 285.0, PID is 6164.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '0', '1', '.', '0', ',', '', 'B04', 'is', '', '2', '8', '5', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '0', '1', '.', '0', ',', '', 'B04', 'is', '', '2', '8', '5', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '4', '6', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '4', '.', '0', '3', '9']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 201.0, B04 is 285.0, PID is 6164.0, B03 is 466.0 B04 is 4.039']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 201.0, B04 is 285.0, PID is 6164.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 201.0, B04 is 285.0, PID is 6164.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '0', '1', '.', '0', ',', '', 'B04', 'is', '', '2', '8', '5', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '0', '1', '.', '0', ',', '', 'B04', 'is', '', '2', '8', '5', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '4', '6', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '6', '6', '6', '6', '.', '0', '.']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 201.0, B04 is 285.0, PID is 6164.0, B03 is 466.0 46666.0.']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 201.0, B04 is 285.0, DOY is 211.0, PID is 6164.0, B03 is']\n",
      "prompt: B02 is 201.0, B04 is 285.0, DOY is 211.0, PID is 6164.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '0', '1', '.', '0', ',', '', 'B04', 'is', '', '2', '8', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '0', '1', '.', '0', ',', '', 'B04', 'is', '', '2', '8', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '4', '6', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '4', '.', '0', '.', '0', '.', '0', ',', '']]\n",
      "decoded_data: ['B02 is 201.0, B04 is 285.0, DOY is 211.0, PID is 6164.0, B03 is 466.04.0.0.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 201.0, DOY is 211.0, PID is 6164.0, B04 is 285.0, B03 is']\n",
      "prompt: B02 is 201.0, DOY is 211.0, PID is 6164.0, B04 is 285.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '0', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '2', '8', '5', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '0', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '2', '8', '5', '.', '0', ',', '', 'B03', 'is', '', '4', '6', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '.', '0', '3', '9', '5', '9', '2']]\n",
      "decoded_data: ['B02 is 201.0, DOY is 211.0, PID is 6164.0, B04 is 285.0, B03 is 466.0 4.039592']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 285.0, B02 is 201.0, PID is 6164.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 285.0, B02 is 201.0, PID is 6164.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '2', '8', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '2', '8', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '4', '6', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'DOY', 'is', '', 'B04', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 285.0, B02 is 201.0, PID is 6164.0, B03 is 466.0 DOY is B04 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6164.0, DOY is 211.0, B02 is 201.0, B04 is 285.0, B03 is']\n",
      "prompt: PID is 6164.0, DOY is 211.0, B02 is 201.0, B04 is 285.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '1', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '0', '1', '.', '0', ',', '', 'B04', 'is', '', '2', '8', '5', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '1', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '0', '1', '.', '0', ',', '', 'B04', 'is', '', '2', '8', '5', '.', '0', ',', '', 'B03', 'is', '', '4', '6', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '6', '6', '6', '6', '9', '0', '5', '.']]\n",
      "decoded_data: ['PID is 6164.0, DOY is 211.0, B02 is 201.0, B04 is 285.0, B03 is 466.066666905.']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 201.0, B04 is 285.0, PID is 6164.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 201.0, B04 is 285.0, PID is 6164.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '0', '1', '.', '0', ',', '', 'B04', 'is', '', '2', '8', '5', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '0', '1', '.', '0', ',', '', 'B04', 'is', '', '2', '8', '5', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '4', '6', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '.', '0', '2', '5', '7', '4', '6']]\n",
      "decoded_data: ['B02 is 201.0, B04 is 285.0, PID is 6164.0, DOY is 211.0, B03 is 466.0 4.025746']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6164.0, B02 is 201.0, B04 is 285.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 6164.0, B02 is 201.0, B04 is 285.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '0', '1', '.', '0', ',', '', 'B04', 'is', '', '2', '8', '5', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '0', '1', '.', '0', ',', '', 'B04', 'is', '', '2', '8', '5', '.', '0', ',', '', 'B03', 'is', '', '4', '6', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '3', '9', '5', '0', '3']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6164.0, B02 is 201.0, B04 is 285.0, B03 is 466.0 B04 is 39503']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 201.0, DOY is 211.0, B04 is 285.0, PID is 6164.0, B03 is']\n",
      "prompt: B02 is 201.0, DOY is 211.0, B04 is 285.0, PID is 6164.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '0', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '2', '8', '5', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '0', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '2', '8', '5', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '4', '6', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B02', 'is', '', 'B04', 'is', '', '4', '6']]\n",
      "decoded_data: ['B02 is 201.0, DOY is 211.0, B04 is 285.0, PID is 6164.0, B03 is 466.0 B02 is B04 is 46']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6164.0, B04 is 285.0, DOY is 211.0, B02 is 201.0, B03 is']\n",
      "prompt: PID is 6164.0, B04 is 285.0, DOY is 211.0, B02 is 201.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '1', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '2', '8', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '0', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '1', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '2', '8', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '0', '1', '.', '0', ',', '', 'B03', 'is', '', '4', '6', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '4', '6', '6', '6', '6']]\n",
      "decoded_data: ['PID is 6164.0, B04 is 285.0, DOY is 211.0, B02 is 201.0, B03 is 466.0 B04 is 46666']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 201.0, B04 is 285.0, DOY is 211.0, PID is 6164.0, B03 is']\n",
      "prompt: B02 is 201.0, B04 is 285.0, DOY is 211.0, PID is 6164.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '0', '1', '.', '0', ',', '', 'B04', 'is', '', '2', '8', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '0', '1', '.', '0', ',', '', 'B04', 'is', '', '2', '8', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '4', '6', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '4', '6', '6', '9', '.']]\n",
      "decoded_data: ['B02 is 201.0, B04 is 285.0, DOY is 211.0, PID is 6164.0, B03 is 466.0 B04 is 4669.']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6164.0, B04 is 285.0, DOY is 211.0, B02 is 201.0, B03 is']\n",
      "prompt: PID is 6164.0, B04 is 285.0, DOY is 211.0, B02 is 201.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '1', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '2', '8', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '0', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '1', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '2', '8', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '0', '1', '.', '0', ',', '', 'B03', 'is', '', '4', '6', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B02', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['PID is 6164.0, B04 is 285.0, DOY is 211.0, B02 is 201.0, B03 is 466.0 B04 is B02 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 285.0, B02 is 201.0, PID is 6164.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 285.0, B02 is 201.0, PID is 6164.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '2', '8', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '4', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      "  8%|         | 67/829 [01:55<24:49,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '2', '8', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '4', '6', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'DOY', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 285.0, B02 is 201.0, PID is 6164.0, B03 is 466.0 B04 is DOY is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6264.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 6264.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '4', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '3', '8', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '3', '.', '0', ',', '', 'B03', 'is', '', '5', '7', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', '3', '2']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6264.0, B04 is 383.0, B02 is 283.0, B03 is 576.0 B04 is B04 is 32']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 383.0, PID is 6264.0, B02 is 283.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 383.0, PID is 6264.0, B02 is 283.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '3', '8', '3', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '3', '8', '3', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '3', '.', '0', ',', '', 'B03', 'is', '', '5', '7', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 383.0, PID is 6264.0, B02 is 283.0, B03 is 576.0 PID is B04 is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6264.0, B02 is 283.0, DOY is 211.0, B04 is 383.0, B03 is']\n",
      "prompt: PID is 6264.0, B02 is 283.0, DOY is 211.0, B04 is 383.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '2', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '3', '8', '3', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|         | 68/829 [01:56<20:10,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '6', '2', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '3', '8', '3', '.', '0', ',', '', 'B03', 'is', '', '5', '7', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '3', '2', '6', '1', '4']]\n",
      "decoded_data: ['PID is 6264.0, B02 is 283.0, DOY is 211.0, B04 is 383.0, B03 is 576.0 B04 is 32614']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 283.0, DOY is 211.0, PID is 6264.0, B04 is 383.0, B03 is']\n",
      "prompt: B02 is 283.0, DOY is 211.0, PID is 6264.0, B04 is 383.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '8', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '3', '8', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '8', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '3', '8', '3', '.', '0', ',', '', 'B03', 'is', '', '5', '7', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '3', '2', '1', '1', '0', ',', '', 'B04', 'is']]\n",
      "decoded_data: ['B02 is 283.0, DOY is 211.0, PID is 6264.0, B04 is 383.0, B03 is 576.032110, B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6364.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 6364.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '4', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|         | 69/829 [01:56<15:40,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '5', '3', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '0', '0', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '2', '3', '6', '6', '6', '6', '6', '6', '6']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6364.0, B03 is 531.0, B04 is 400.0, B02 is 266.0236666666']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6464.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 6464.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '4', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '4', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '0', '.', '0', ',', '', 'B03', 'is', '', '6', '2', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '2', '9', '0', '1', '4', '3', '7', '4']]\n",
      "decoded_data: ['PID is 6464.0, DOY is 211.0, B04 is 490.0, B03 is 629.0, B02 is 291.0 29014374']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6464.0, B04 is 490.0, B03 is 629.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 6464.0, B04 is 490.0, B03 is 629.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '0', '.', '0', ',', '', 'B03', 'is', '', '6', '2', '9', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '0', '.', '0', ',', '', 'B03', 'is', '', '6', '2', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '2', '9']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6464.0, B04 is 490.0, B03 is 629.0, B02 is 291.0 B04 is PID is 29']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6464.0, DOY is 211.0, B03 is 629.0, B04 is 490.0, B02 is']\n",
      "prompt: PID is 6464.0, DOY is 211.0, B03 is 629.0, B04 is 490.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '4', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '2', '9', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '0', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '4', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '2', '9', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '0', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '3', '1', '4', '3', '1', '.', '0', ',', '']]\n",
      "decoded_data: ['PID is 6464.0, DOY is 211.0, B03 is 629.0, B04 is 490.0, B02 is 281.031431.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6464.0, B04 is 490.0, B03 is 629.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 6464.0, B04 is 490.0, B03 is 629.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '4', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '0', '.', '0', ',', '', 'B03', 'is', '', '6', '2', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '4', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '0', '.', '0', ',', '', 'B03', 'is', '', '6', '2', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '2', '3', '5', '1', '4', '3', '7', '4']]\n",
      "decoded_data: ['PID is 6464.0, B04 is 490.0, B03 is 629.0, DOY is 211.0, B02 is 281.0 23514374']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 490.0, PID is 6464.0, B03 is 629.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 490.0, PID is 6464.0, B03 is 629.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '9', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '6', '2', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '9', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '6', '2', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '2', '1', '4', '3', '5']]\n",
      "decoded_data: ['B04 is 490.0, PID is 6464.0, B03 is 629.0, DOY is 211.0, B02 is 281.0 PID is 21435']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 629.0, B04 is 490.0, PID is 6464.0, B02 is']\n",
      "prompt: DOY is 211.0, B03 is 629.0, B04 is 490.0, PID is 6464.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '2', '9', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '4', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '2', '9', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '2', 'B03', 'is', '', 'B02']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 629.0, B04 is 490.0, PID is 6464.0, B02 is 284.0 B04 is 2B03 is B02']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6464.0, B04 is 490.0, B03 is 629.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 6464.0, B04 is 490.0, B03 is 629.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '4', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '0', '.', '0', ',', '', 'B03', 'is', '', '6', '2', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '4', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '0', '.', '0', ',', '', 'B03', 'is', '', '6', '2', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '2', '0', '1', '9', '0']]\n",
      "decoded_data: ['PID is 6464.0, B04 is 490.0, B03 is 629.0, DOY is 211.0, B02 is 281.0 B04 is 20190']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 490.0, PID is 6464.0, DOY is 211.0, B03 is 629.0, B02 is']\n",
      "prompt: B04 is 490.0, PID is 6464.0, DOY is 211.0, B03 is 629.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '9', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '2', '9', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '9', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '2', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '2', '3', '7', '4', '3', '9', '0', '1']]\n",
      "decoded_data: ['B04 is 490.0, PID is 6464.0, DOY is 211.0, B03 is 629.0, B02 is 281.0 23743901']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6464.0, B04 is 490.0, DOY is 211.0, B03 is 629.0, B02 is']\n",
      "prompt: PID is 6464.0, B04 is 490.0, DOY is 211.0, B03 is 629.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '4', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '2', '9', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '4', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '2', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '2', '9', '0', '1', '4', '3', '9', '2']]\n",
      "decoded_data: ['PID is 6464.0, B04 is 490.0, DOY is 211.0, B03 is 629.0, B02 is 284.0 29014392']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 629.0, DOY is 211.0, PID is 6464.0, B04 is 490.0, B02 is']\n",
      "prompt: B03 is 629.0, DOY is 211.0, PID is 6464.0, B04 is 490.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '2', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '0', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '6', '2', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '0', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '4', '3', '9', '0', '1']]\n",
      "decoded_data: ['B03 is 629.0, DOY is 211.0, PID is 6464.0, B04 is 490.0, B02 is 281.0 B04 is 43901']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 490.0, B03 is 629.0, PID is 6464.0, B02 is']\n",
      "prompt: DOY is 211.0, B04 is 490.0, B03 is 629.0, PID is 6464.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '0', '.', '0', ',', '', 'B03', 'is', '', '6', '2', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '4', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '0', '.', '0', ',', '', 'B03', 'is', '', '6', '2', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'B04', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 490.0, B03 is 629.0, PID is 6464.0, B02 is 281.0 B03 is B04 is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6464.0, B04 is 490.0, B03 is 629.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 6464.0, B04 is 490.0, B03 is 629.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '4', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '0', '.', '0', ',', '', 'B03', 'is', '', '6', '2', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '4', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '0', '.', '0', ',', '', 'B03', 'is', '', '6', '2', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', '2', '9', '0', '1', '.']]\n",
      "decoded_data: ['PID is 6464.0, B04 is 490.0, B03 is 629.0, DOY is 211.0, B02 is 284.0 B03 is 2901.']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 629.0, PID is 6464.0, B04 is 490.0, DOY is 211.0, B02 is']\n",
      "prompt: B03 is 629.0, PID is 6464.0, B04 is 490.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '2', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '6', '2', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '4', '3', '7', '2', 'B03']]\n",
      "decoded_data: ['B03 is 629.0, PID is 6464.0, B04 is 490.0, DOY is 211.0, B02 is 281.0 B04 is 4372B03']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 629.0, B04 is 490.0, PID is 6464.0, B02 is']\n",
      "prompt: DOY is 211.0, B03 is 629.0, B04 is 490.0, PID is 6464.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '2', '9', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '4', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '2', '9', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '1', '4', '3', '5', '.', '0', ',', '', 'B04']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 629.0, B04 is 490.0, PID is 6464.0, B02 is 284.01435.0, B04']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 490.0, B03 is 629.0, PID is 6464.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 490.0, B03 is 629.0, PID is 6464.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '9', '0', '.', '0', ',', '', 'B03', 'is', '', '6', '2', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      "  8%|         | 70/829 [01:59<20:01,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B04', 'is', '', '4', '9', '0', '.', '0', ',', '', 'B03', 'is', '', '6', '2', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '0', '0', '0', '1', '.', '0', ',', '', 'B03']]\n",
      "decoded_data: ['B04 is 490.0, B03 is 629.0, PID is 6464.0, DOY is 211.0, B02 is 281.00001.0, B03']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6564.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 6564.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '4', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|         | 71/829 [01:59<15:08,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '6', '4', '9', '.', '0', ',', '', 'B04', 'is', '', '4', '7', '0', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '8', '8', '8', '8', '8', '8', '8', '8']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6564.0, B03 is 649.0, B04 is 470.0, B02 is 288.0688888888']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6664.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 6664.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '6', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '6', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '2', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '7', '0', '4', '.', '0', '0', '0', '0']]\n",
      "decoded_data: ['PID is 6664.0, DOY is 211.0, B04 is 422.0, B03 is 677.0, B02 is 267.06704.0000']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6664.0, DOY is 211.0, B03 is 677.0, B04 is 422.0, B02 is']\n",
      "prompt: PID is 6664.0, DOY is 211.0, B03 is 677.0, B04 is 422.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '6', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '2', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '6', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '7', '5', '0', '2', '.', '0', ',', '']]\n",
      "decoded_data: ['PID is 6664.0, DOY is 211.0, B03 is 677.0, B04 is 422.0, B02 is 267.067502.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 422.0, DOY is 211.0, PID is 6664.0, B03 is 677.0, B02 is']\n",
      "prompt: B04 is 422.0, DOY is 211.0, PID is 6664.0, B03 is 677.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '2', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '2', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '2', '5', '0', '2', '.', '0', ',', '']]\n",
      "decoded_data: ['B04 is 422.0, DOY is 211.0, PID is 6664.0, B03 is 677.0, B02 is 267.0 2502.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 677.0, B04 is 422.0, PID is 6664.0, B02 is']\n",
      "prompt: DOY is 211.0, B03 is 677.0, B04 is 422.0, PID is 6664.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '2', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '4', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '2', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '2', '.', '0', ',', '', 'B04', 'is', '']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 677.0, B04 is 422.0, PID is 6664.0, B02 is 267.0 2.0, B04 is ']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6664.0, B03 is 677.0, B04 is 422.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 6664.0, B03 is 677.0, B04 is 422.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '6', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '6', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '2', '2', '7', '5', '0', '2', '.', '0', '0']]\n",
      "decoded_data: ['PID is 6664.0, B03 is 677.0, B04 is 422.0, DOY is 211.0, B02 is 267.0227502.00']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6664.0, B04 is 422.0, DOY is 211.0, B03 is 677.0, B02 is']\n",
      "prompt: PID is 6664.0, B04 is 422.0, DOY is 211.0, B03 is 677.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '6', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '6', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '2', '7', '5', '0', '0']]\n",
      "decoded_data: ['PID is 6664.0, B04 is 422.0, DOY is 211.0, B03 is 677.0, B02 is 267.0 PID is 27500']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 422.0, DOY is 211.0, PID is 6664.0, B03 is 677.0, B02 is']\n",
      "prompt: B04 is 422.0, DOY is 211.0, PID is 6664.0, B03 is 677.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '2', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '2', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '2', '7', '0', '4', '1']]\n",
      "decoded_data: ['B04 is 422.0, DOY is 211.0, PID is 6664.0, B03 is 677.0, B02 is 267.0 PID is 27041']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6664.0, DOY is 211.0, B03 is 677.0, B04 is 422.0, B02 is']\n",
      "prompt: PID is 6664.0, DOY is 211.0, B03 is 677.0, B04 is 422.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '6', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '2', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '6', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '2', '7', '5', '0', '2', '9', '0', '2', '.']]\n",
      "decoded_data: ['PID is 6664.0, DOY is 211.0, B03 is 677.0, B04 is 422.0, B02 is 267.027502902.']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6664.0, DOY is 211.0, B04 is 422.0, B03 is 677.0, B02 is']\n",
      "prompt: PID is 6664.0, DOY is 211.0, B04 is 422.0, B03 is 677.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '6', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '2', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '6', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '2', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '2', '.', '0', ',', '', 'B04', 'is', '']]\n",
      "decoded_data: ['PID is 6664.0, DOY is 211.0, B04 is 422.0, B03 is 677.0, B02 is 267.0 2.0, B04 is ']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 677.0, B04 is 422.0, PID is 6664.0, B02 is']\n",
      "prompt: DOY is 211.0, B03 is 677.0, B04 is 422.0, PID is 6664.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '2', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '4', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '2', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '2', '.', '0', ',', '', 'PID', 'is', '']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 677.0, B04 is 422.0, PID is 6664.0, B02 is 267.0 2.0, PID is ']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 422.0, B03 is 677.0, PID is 6664.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 422.0, B03 is 677.0, PID is 6664.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '2', '2', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '2', '2', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '7', '5', '0', '2', '.', '0', ',', '']]\n",
      "decoded_data: ['B04 is 422.0, B03 is 677.0, PID is 6664.0, DOY is 211.0, B02 is 267.067502.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 677.0, B04 is 422.0, DOY is 211.0, PID is 6664.0, B02 is']\n",
      "prompt: B03 is 677.0, B04 is 422.0, DOY is 211.0, PID is 6664.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '7', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '4', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '6', '7', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '3', '1', '7', '.', '0', ',', '', '2', '7']]\n",
      "decoded_data: ['B03 is 677.0, B04 is 422.0, DOY is 211.0, PID is 6664.0, B02 is 267.0317.0, 27']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 422.0, DOY is 211.0, B03 is 677.0, PID is 6664.0, B02 is']\n",
      "prompt: B04 is 422.0, DOY is 211.0, B03 is 677.0, PID is 6664.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '2', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '4', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '2', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '7', '.', '0', '.', '0', ',', '', 'B03']]\n",
      "decoded_data: ['B04 is 422.0, DOY is 211.0, B03 is 677.0, PID is 6664.0, B02 is 267.067.0.0, B03']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 422.0, B03 is 677.0, PID is 6664.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 422.0, B03 is 677.0, PID is 6664.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '2', '2', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '2', '2', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '2', '7', '5', '0', '4']]\n",
      "decoded_data: ['B04 is 422.0, B03 is 677.0, PID is 6664.0, DOY is 211.0, B02 is 267.0 PID is 27504']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 677.0, DOY is 211.0, B04 is 422.0, PID is 6664.0, B02 is']\n",
      "prompt: B03 is 677.0, DOY is 211.0, B04 is 422.0, PID is 6664.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '7', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '2', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '4', '.', '0', ',', '', 'B02', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      "  9%|         | 72/829 [02:01<19:11,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B03', 'is', '', '6', '7', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '2', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '2', '.', '0', ',', '', 'B04', 'is', '', 'DOY']]\n",
      "decoded_data: ['B03 is 677.0, DOY is 211.0, B04 is 422.0, PID is 6664.0, B02 is 267.02.0, B04 is DOY']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6764.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 6764.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '4', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '2', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '4', '.', '0', ',', '', 'B04', 'is', '']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6764.0, B04 is 466.0, B02 is 262.0, B03 is 681.064.0, B04 is ']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 466.0, DOY is 211.0, PID is 6764.0, B02 is 262.0, B03 is']\n",
      "prompt: B04 is 466.0, DOY is 211.0, PID is 6764.0, B02 is 262.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '2', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B02', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['B04 is 466.0, DOY is 211.0, PID is 6764.0, B02 is 262.0, B03 is 681.0 B04 is B02 is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 262.0, DOY is 211.0, PID is 6764.0, B04 is 466.0, B03 is']\n",
      "prompt: B02 is 262.0, DOY is 211.0, PID is 6764.0, B04 is 466.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '6', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '6', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '4', '2', '3', '.', '0', '3', '.', '0']]\n",
      "decoded_data: ['B02 is 262.0, DOY is 211.0, PID is 6764.0, B04 is 466.0, B03 is 681.06423.03.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 466.0, PID is 6764.0, DOY is 211.0, B02 is 262.0, B03 is']\n",
      "prompt: B04 is 466.0, PID is 6764.0, DOY is 211.0, B02 is 262.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '2', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '6', '4', '2', '8', '1']]\n",
      "decoded_data: ['B04 is 466.0, PID is 6764.0, DOY is 211.0, B02 is 262.0, B03 is 681.0 PID is 64281']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 466.0, PID is 6764.0, DOY is 211.0, B02 is 262.0, B03 is']\n",
      "prompt: B04 is 466.0, PID is 6764.0, DOY is 211.0, B02 is 262.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '2', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '6', '4', '5', '8', '4']]\n",
      "decoded_data: ['B04 is 466.0, PID is 6764.0, DOY is 211.0, B02 is 262.0, B03 is 681.0 B04 is 64584']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6764.0, B02 is 262.0, DOY is 211.0, B04 is 466.0, B03 is']\n",
      "prompt: PID is 6764.0, B02 is 262.0, DOY is 211.0, B04 is 466.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '7', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '7', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '4', '6', '4', '6', '6']]\n",
      "decoded_data: ['PID is 6764.0, B02 is 262.0, DOY is 211.0, B04 is 466.0, B03 is 681.0 B04 is 46466']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 466.0, B02 is 262.0, PID is 6764.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 466.0, B02 is 262.0, PID is 6764.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '2', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '2', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '6', '4', '2', '.', '0']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 466.0, B02 is 262.0, PID is 6764.0, B03 is 681.0 B04 is 642.0']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6764.0, B04 is 466.0, DOY is 211.0, B02 is 262.0, B03 is']\n",
      "prompt: PID is 6764.0, B04 is 466.0, DOY is 211.0, B02 is 262.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '7', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '7', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '2', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '6', '4', '2', '8', '1', '0', '3', '.']]\n",
      "decoded_data: ['PID is 6764.0, B04 is 466.0, DOY is 211.0, B02 is 262.0, B03 is 681.0 6428103.']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 262.0, DOY is 211.0, B04 is 466.0, PID is 6764.0, B03 is']\n",
      "prompt: B02 is 262.0, DOY is 211.0, B04 is 466.0, PID is 6764.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '6', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '6', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '6', '4', '.', '0', '3', '.', '0', '.']]\n",
      "decoded_data: ['B02 is 262.0, DOY is 211.0, B04 is 466.0, PID is 6764.0, B03 is 681.0 64.03.0.']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6764.0, B04 is 466.0, B02 is 262.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 6764.0, B04 is 466.0, B02 is 262.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '2', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'DOY', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6764.0, B04 is 466.0, B02 is 262.0, B03 is 681.0 B04 is DOY is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 466.0, DOY is 211.0, PID is 6764.0, B02 is 262.0, B03 is']\n",
      "prompt: B04 is 466.0, DOY is 211.0, PID is 6764.0, B02 is 262.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '2', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B02', 'is', '', '6', '8']]\n",
      "decoded_data: ['B04 is 466.0, DOY is 211.0, PID is 6764.0, B02 is 262.0, B03 is 681.0 B04 is B02 is 68']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 466.0, PID is 6764.0, B02 is 262.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 466.0, PID is 6764.0, B02 is 262.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '2', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B02', 'is', '', '6', '4']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 466.0, PID is 6764.0, B02 is 262.0, B03 is 681.0 B04 is B02 is 64']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 466.0, DOY is 211.0, B02 is 262.0, PID is 6764.0, B03 is']\n",
      "prompt: B04 is 466.0, DOY is 211.0, B02 is 262.0, PID is 6764.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '2', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '2', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '6', '4', '.', '0', '3']]\n",
      "decoded_data: ['B04 is 466.0, DOY is 211.0, B02 is 262.0, PID is 6764.0, B03 is 681.0 B04 is 64.03']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6764.0, B02 is 262.0, B04 is 466.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 6764.0, B02 is 262.0, B04 is 466.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '2', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '2', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '6', '4', '6', '8', '1', '.', '0', '.']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6764.0, B02 is 262.0, B04 is 466.0, B03 is 681.0 64681.0.']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 262.0, B04 is 466.0, PID is 6764.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 262.0, B04 is 466.0, PID is 6764.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '6', '2', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      "  9%|         | 73/829 [02:04<22:08,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B02', 'is', '', '2', '6', '2', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '6', '4', '9', '5', '8', '0', '.', '0']]\n",
      "decoded_data: ['B02 is 262.0, B04 is 466.0, PID is 6764.0, DOY is 211.0, B03 is 681.0 649580.0']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6864.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 6864.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '8', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '8', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '6', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '7', '5', '7', '7', '5']]\n",
      "decoded_data: ['PID is 6864.0, DOY is 211.0, B02 is 287.0, B04 is 447.0, B03 is 668.0 B04 is 75775']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 447.0, PID is 6864.0, DOY is 211.0, B02 is 287.0, B03 is']\n",
      "prompt: B04 is 447.0, PID is 6864.0, DOY is 211.0, B02 is 287.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '4', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '4', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '6', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '2', '8', '9', '2']]\n",
      "decoded_data: ['B04 is 447.0, PID is 6864.0, DOY is 211.0, B02 is 287.0, B03 is 668.0 PID is 72892']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 287.0, PID is 6864.0, B04 is 447.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 287.0, PID is 6864.0, B04 is 447.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '8', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|         | 74/829 [02:04<17:50,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B02', 'is', '', '2', '8', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '6', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '5', '8', '7', '7', '7', '7', '0', '7']]\n",
      "decoded_data: ['B02 is 287.0, PID is 6864.0, B04 is 447.0, DOY is 211.0, B03 is 668.0758777707']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6964.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 6964.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '2', '4', '3', '3', '3', '.', '0', '0']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6964.0, B03 is 691.0, B04 is 447.0, B02 is 274.0 24333.00']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 691.0, DOY is 211.0, B04 is 447.0, PID is 6964.0, B02 is']\n",
      "prompt: B03 is 691.0, DOY is 211.0, B04 is 447.0, PID is 6964.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '4', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '2', '4', '3', '1', '9', '2', '8', '.', '0']]\n",
      "decoded_data: ['B03 is 691.0, DOY is 211.0, B04 is 447.0, PID is 6964.0, B02 is 274.02431928.0']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 447.0, B03 is 691.0, PID is 6964.0, B02 is']\n",
      "prompt: DOY is 211.0, B04 is 447.0, B03 is 691.0, PID is 6964.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '4', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'B04', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 447.0, B03 is 691.0, PID is 6964.0, B02 is 254.0 B03 is B04 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6964.0, B04 is 447.0, B03 is 691.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 6964.0, B04 is 447.0, B03 is 691.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '2', '6', '2', '9', '2']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6964.0, B04 is 447.0, B03 is 691.0, B02 is 254.0 B04 is 26292']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6964.0, B03 is 691.0, B04 is 447.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 6964.0, B03 is 691.0, B04 is 447.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '9', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '9', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '2', '9', '2', '8', '1', '9', '2', '4', '.']]\n",
      "decoded_data: ['PID is 6964.0, B03 is 691.0, B04 is 447.0, DOY is 211.0, B02 is 254.029281924.']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 447.0, B03 is 691.0, PID is 6964.0, B02 is']\n",
      "prompt: DOY is 211.0, B04 is 447.0, B03 is 691.0, PID is 6964.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '4', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B02', 'is', '', '2', '.']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 447.0, B03 is 691.0, PID is 6964.0, B02 is 254.0 B04 is B02 is 2.']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 691.0, B04 is 447.0, DOY is 211.0, PID is 6964.0, B02 is']\n",
      "prompt: B03 is 691.0, B04 is 447.0, DOY is 211.0, PID is 6964.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '4', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'B04', 'is', '', '2', '9']]\n",
      "decoded_data: ['B03 is 691.0, B04 is 447.0, DOY is 211.0, PID is 6964.0, B02 is 254.0 B03 is B04 is 29']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6964.0, B03 is 691.0, B04 is 447.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 6964.0, B03 is 691.0, B04 is 447.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '9', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '9', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B02', 'is', '', '2', '7']]\n",
      "decoded_data: ['PID is 6964.0, B03 is 691.0, B04 is 447.0, DOY is 211.0, B02 is 254.0 B04 is B02 is 27']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 691.0, PID is 6964.0, DOY is 211.0, B04 is 447.0, B02 is']\n",
      "prompt: B03 is 691.0, PID is 6964.0, DOY is 211.0, B04 is 447.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '4', '3', '3', '3']]\n",
      "decoded_data: ['B03 is 691.0, PID is 6964.0, DOY is 211.0, B04 is 447.0, B02 is 274.0 B04 is 54333']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 691.0, B04 is 447.0, DOY is 211.0, PID is 6964.0, B02 is']\n",
      "prompt: B03 is 691.0, B04 is 447.0, DOY is 211.0, PID is 6964.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '4', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B02', 'is', '', '2', '5', '4', '3', '1']]\n",
      "decoded_data: ['B03 is 691.0, B04 is 447.0, DOY is 211.0, PID is 6964.0, B02 is 274.0 B02 is 25431']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 691.0, DOY is 211.0, PID is 6964.0, B04 is 447.0, B02 is']\n",
      "prompt: B03 is 691.0, DOY is 211.0, PID is 6964.0, B04 is 447.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '2', '4', '3', '3', '7', '4', '3', '.']]\n",
      "decoded_data: ['B03 is 691.0, DOY is 211.0, PID is 6964.0, B04 is 447.0, B02 is 274.0 2433743.']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 691.0, PID is 6964.0, B04 is 447.0, B02 is']\n",
      "prompt: DOY is 211.0, B03 is 691.0, PID is 6964.0, B04 is 447.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '4', '7', '4', '7', '2']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 691.0, PID is 6964.0, B04 is 447.0, B02 is 254.0 B04 is 47472']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 447.0, B03 is 691.0, PID is 6964.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 447.0, B03 is 691.0, PID is 6964.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '4', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '4', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '2', '7', '4', '7', '4']]\n",
      "decoded_data: ['B04 is 447.0, B03 is 691.0, PID is 6964.0, DOY is 211.0, B02 is 254.0 B04 is 27474']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 691.0, DOY is 211.0, PID is 6964.0, B04 is 447.0, B02 is']\n",
      "prompt: B03 is 691.0, DOY is 211.0, PID is 6964.0, B04 is 447.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '4', '3', '3', '3']]\n",
      "decoded_data: ['B03 is 691.0, DOY is 211.0, PID is 6964.0, B04 is 447.0, B02 is 274.0 B04 is 54333']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 691.0, B04 is 447.0, PID is 6964.0, B02 is']\n",
      "prompt: DOY is 211.0, B03 is 691.0, B04 is 447.0, PID is 6964.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '4', '.', '0', ',', '', 'B02', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      "  9%|         | 75/829 [02:07<21:24,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '2', '9', '2', '0', '2', '3', '6', '.']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 691.0, B04 is 447.0, PID is 6964.0, B02 is 254.0 2920236.']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5265.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 5265.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '2', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|         | 76/829 [02:07<16:05,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '5', '2', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '8', '8', '8', '8', '8', '8', '8', '8']]\n",
      "decoded_data: ['PID is 5265.0, DOY is 211.0, B04 is 552.0, B02 is 329.0, B03 is 788.0788888888']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5365.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 5365.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '5', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '9', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5365.0, B02 is 322.0, B04 is 573.0, B03 is 796.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5365.0, B04 is 573.0, DOY is 211.0, B02 is 322.0, B03 is']\n",
      "prompt: PID is 5365.0, B04 is 573.0, DOY is 211.0, B02 is 322.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '3', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '3', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '9', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '9']]\n",
      "decoded_data: ['PID is 5365.0, B04 is 573.0, DOY is 211.0, B02 is 322.0, B03 is 796.0 B04 is PID is 79']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5365.0, DOY is 211.0, B02 is 322.0, B04 is 573.0, B03 is']\n",
      "prompt: PID is 5365.0, DOY is 211.0, B02 is 322.0, B04 is 573.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '3', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '3', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '9', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '8', '9', '6', '0']]\n",
      "decoded_data: ['PID is 5365.0, DOY is 211.0, B02 is 322.0, B04 is 573.0, B03 is 796.0 B04 is 58960']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5365.0, B02 is 322.0, B04 is 573.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5365.0, B02 is 322.0, B04 is 573.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '3', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '3', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '9', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['PID is 5365.0, B02 is 322.0, B04 is 573.0, DOY is 211.0, B03 is 796.0 PID is B04 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 573.0, PID is 5365.0, B02 is 322.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 573.0, PID is 5365.0, B02 is 322.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '9', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '7', '9', '6', '6', '8']]\n",
      "decoded_data: ['B04 is 573.0, PID is 5365.0, B02 is 322.0, DOY is 211.0, B03 is 796.0 B04 is 79668']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5365.0, B04 is 573.0, B02 is 322.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5365.0, B04 is 573.0, B02 is 322.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '3', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '3', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '9', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', '5', '8']]\n",
      "decoded_data: ['PID is 5365.0, B04 is 573.0, B02 is 322.0, DOY is 211.0, B03 is 796.0 B04 is B04 is 58']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5365.0, B02 is 322.0, DOY is 211.0, B04 is 573.0, B03 is']\n",
      "prompt: PID is 5365.0, B02 is 322.0, DOY is 211.0, B04 is 573.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '3', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '3', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '9', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '5', '8']]\n",
      "decoded_data: ['PID is 5365.0, B02 is 322.0, DOY is 211.0, B04 is 573.0, B03 is 796.0 B04 is PID is 58']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5365.0, DOY is 211.0, B04 is 573.0, B02 is 322.0, B03 is']\n",
      "prompt: PID is 5365.0, DOY is 211.0, B04 is 573.0, B02 is 322.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '3', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '3', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '9', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['PID is 5365.0, DOY is 211.0, B04 is 573.0, B02 is 322.0, B03 is 796.0 PID is B04 is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 573.0, PID is 5365.0, B02 is 322.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 573.0, PID is 5365.0, B02 is 322.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '9', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '7', '9', '6', '.', '0', ',', '', 'PID']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 573.0, PID is 5365.0, B02 is 322.0, B03 is 796.0 796.0, PID']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 573.0, DOY is 211.0, PID is 5365.0, B02 is 322.0, B03 is']\n",
      "prompt: B04 is 573.0, DOY is 211.0, PID is 5365.0, B02 is 322.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '9', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '8', '.', '0', '0']]\n",
      "decoded_data: ['B04 is 573.0, DOY is 211.0, PID is 5365.0, B02 is 322.0, B03 is 796.0 B04 is 58.00']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5365.0, DOY is 211.0, B02 is 322.0, B04 is 573.0, B03 is']\n",
      "prompt: PID is 5365.0, DOY is 211.0, B02 is 322.0, B04 is 573.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '3', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '3', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '9', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'DOY', 'is']]\n",
      "decoded_data: ['PID is 5365.0, DOY is 211.0, B02 is 322.0, B04 is 573.0, B03 is 796.0 B04 is PID is DOY is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5365.0, B02 is 322.0, DOY is 211.0, B04 is 573.0, B03 is']\n",
      "prompt: PID is 5365.0, B02 is 322.0, DOY is 211.0, B04 is 573.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '3', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '3', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '9', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '9']]\n",
      "decoded_data: ['PID is 5365.0, B02 is 322.0, DOY is 211.0, B04 is 573.0, B03 is 796.0 B04 is PID is 79']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5365.0, B04 is 573.0, B02 is 322.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5365.0, B04 is 573.0, B02 is 322.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '3', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '3', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '9', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '8', '9', '6', '5', '6', '.', '0', 'B02']]\n",
      "decoded_data: ['PID is 5365.0, B04 is 573.0, B02 is 322.0, DOY is 211.0, B03 is 796.0689656.0B02']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5365.0, B04 is 573.0, DOY is 211.0, B02 is 322.0, B03 is']\n",
      "prompt: PID is 5365.0, B04 is 573.0, DOY is 211.0, B02 is 322.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '3', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '3', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '9', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '9', '6', '6', '5', '8', '6', '.', '0', ',']]\n",
      "decoded_data: ['PID is 5365.0, B04 is 573.0, DOY is 211.0, B02 is 322.0, B03 is 796.0966586.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 322.0, DOY is 211.0, B04 is 573.0, PID is 5365.0, B03 is']\n",
      "prompt: B02 is 322.0, DOY is 211.0, B04 is 573.0, PID is 5365.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '5', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      "  9%|         | 77/829 [02:09<20:20,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '9', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '9', '6', '.', '0', ',', '', 'B04', 'is']]\n",
      "decoded_data: ['B02 is 322.0, DOY is 211.0, B04 is 573.0, PID is 5365.0, B03 is 796.0796.0, B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5465.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 5465.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '4', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '4', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '6', '2', '7', '8', '7']]\n",
      "decoded_data: ['PID is 5465.0, DOY is 211.0, B02 is 322.0, B04 is 606.0, B03 is 766.0 B04 is 62787']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5465.0, B04 is 606.0, B02 is 322.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 5465.0, B04 is 606.0, B02 is 322.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '6', '6', '.', '0', '9', '6', '.', '0']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5465.0, B04 is 606.0, B02 is 322.0, B03 is 766.0766.096.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 606.0, PID is 5465.0, B02 is 322.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 606.0, PID is 5465.0, B02 is 322.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '6', '0', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '6', '0', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', '6', '.']]\n",
      "decoded_data: ['B04 is 606.0, PID is 5465.0, B02 is 322.0, DOY is 211.0, B03 is 766.0 B04 is B04 is 6.']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 606.0, B02 is 322.0, PID is 5465.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 606.0, B02 is 322.0, PID is 5465.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '5', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '.', '0', ',', '', 'B04', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 606.0, B02 is 322.0, PID is 5465.0, B03 is 766.0.0, B04 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 606.0, B02 is 322.0, PID is 5465.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 606.0, B02 is 322.0, PID is 5465.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '6', '0', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '6', '0', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '6', '6', '6', '.', '0', '.', '0', ',']]\n",
      "decoded_data: ['B04 is 606.0, B02 is 322.0, PID is 5465.0, DOY is 211.0, B03 is 766.07666.0.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 322.0, B04 is 606.0, DOY is 211.0, PID is 5465.0, B03 is']\n",
      "prompt: B02 is 322.0, B04 is 606.0, DOY is 211.0, PID is 5465.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '5', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', '6', '6']]\n",
      "decoded_data: ['B02 is 322.0, B04 is 606.0, DOY is 211.0, PID is 5465.0, B03 is 766.0 B04 is B04 is 66']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 606.0, B02 is 322.0, DOY is 211.0, PID is 5465.0, B03 is']\n",
      "prompt: B04 is 606.0, B02 is 322.0, DOY is 211.0, PID is 5465.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '6', '0', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '5', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '6', '0', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '7', '6', '6', '6', '6']]\n",
      "decoded_data: ['B04 is 606.0, B02 is 322.0, DOY is 211.0, PID is 5465.0, B03 is 766.0 B04 is 76666']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 322.0, PID is 5465.0, B04 is 606.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 322.0, PID is 5465.0, B04 is 606.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '6', '2', '.', '0', '9']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 322.0, PID is 5465.0, B04 is 606.0, B03 is 766.0 B04 is 62.09']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5465.0, DOY is 211.0, B04 is 606.0, B02 is 322.0, B03 is']\n",
      "prompt: PID is 5465.0, DOY is 211.0, B04 is 606.0, B02 is 322.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '4', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '4', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '9', '6', '.', '0', ',', '', 'B04', 'is']]\n",
      "decoded_data: ['PID is 5465.0, DOY is 211.0, B04 is 606.0, B02 is 322.0, B03 is 766.0796.0, B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 322.0, PID is 5465.0, B04 is 606.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 322.0, PID is 5465.0, B04 is 606.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '7', '6', '6', '6', '.', '0', '9', '6']]\n",
      "decoded_data: ['B02 is 322.0, PID is 5465.0, B04 is 606.0, DOY is 211.0, B03 is 766.0 7666.096']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 322.0, B04 is 606.0, PID is 5465.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 322.0, B04 is 606.0, PID is 5465.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', '6', '6']]\n",
      "decoded_data: ['B02 is 322.0, B04 is 606.0, PID is 5465.0, DOY is 211.0, B03 is 766.0 B04 is B04 is 66']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 606.0, PID is 5465.0, DOY is 211.0, B02 is 322.0, B03 is']\n",
      "prompt: B04 is 606.0, PID is 5465.0, DOY is 211.0, B02 is 322.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '6', '0', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '6', '0', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '6', '6', '.', '0', ',', '', 'B04', 'is']]\n",
      "decoded_data: ['B04 is 606.0, PID is 5465.0, DOY is 211.0, B02 is 322.0, B03 is 766.0766.0, B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5465.0, B02 is 322.0, B04 is 606.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 5465.0, B02 is 322.0, B04 is 606.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '9', '6', '2', '.', '0', ',', '', 'B04']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5465.0, B02 is 322.0, B04 is 606.0, B03 is 766.07962.0, B04']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 606.0, B02 is 322.0, PID is 5465.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 606.0, B02 is 322.0, PID is 5465.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '6', '0', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '6', '0', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '.', '0', ',', '', 'B04', 'is', '', 'B04']]\n",
      "decoded_data: ['B04 is 606.0, B02 is 322.0, PID is 5465.0, DOY is 211.0, B03 is 766.06.0, B04 is B04']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 322.0, B04 is 606.0, PID is 5465.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 322.0, B04 is 606.0, PID is 5465.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '5', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      "  9%|         | 78/829 [02:12<23:14,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '9', '2', '.', '0', '.', '0', '9', '6']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 322.0, B04 is 606.0, PID is 5465.0, B03 is 766.0792.0.096']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5565.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 5565.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '5', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '5', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '4']]\n",
      "decoded_data: ['PID is 5565.0, DOY is 211.0, B02 is 314.0, B04 is 585.0, B03 is 745.0 B04 is PID is 74']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 314.0, B04 is 585.0, PID is 5565.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 314.0, B04 is 585.0, PID is 5565.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '2', '5', '5', '5', '.', '0', '6', '5']]\n",
      "decoded_data: ['B02 is 314.0, B04 is 585.0, PID is 5565.0, DOY is 211.0, B03 is 745.072555.065']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5565.0, B02 is 314.0, B04 is 585.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 5565.0, B02 is 314.0, B04 is 585.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '5', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '2', '5', '2', '5', '.', '0', '6', '.']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5565.0, B02 is 314.0, B04 is 585.0, B03 is 745.072525.06.']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 314.0, B04 is 585.0, PID is 5565.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 314.0, B04 is 585.0, PID is 5565.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '7', '7', '2', '4', '5', '8', '.', '0']]\n",
      "decoded_data: ['B02 is 314.0, B04 is 585.0, PID is 5565.0, DOY is 211.0, B03 is 745.07772458.0']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 585.0, B02 is 314.0, PID is 5565.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 585.0, B02 is 314.0, PID is 5565.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '5', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '2', '4', '5', '7']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 585.0, B02 is 314.0, PID is 5565.0, B03 is 745.0 PID is 72457']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5565.0, B04 is 585.0, DOY is 211.0, B02 is 314.0, B03 is']\n",
      "prompt: PID is 5565.0, B04 is 585.0, DOY is 211.0, B02 is 314.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '5', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '5', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '2']]\n",
      "decoded_data: ['PID is 5565.0, B04 is 585.0, DOY is 211.0, B02 is 314.0, B03 is 745.0 B04 is PID is 72']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5565.0, B02 is 314.0, B04 is 585.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5565.0, B02 is 314.0, B04 is 585.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '5', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '5', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '7', '2']]\n",
      "decoded_data: ['PID is 5565.0, B02 is 314.0, B04 is 585.0, DOY is 211.0, B03 is 745.0 PID is B04 is 72']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 585.0, PID is 5565.0, B02 is 314.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 585.0, PID is 5565.0, B02 is 314.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '8', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '8', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '7', '2', '4', '5', '8', '2', '.', '0']]\n",
      "decoded_data: ['B04 is 585.0, PID is 5565.0, B02 is 314.0, DOY is 211.0, B03 is 745.0 724582.0']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 314.0, B04 is 585.0, PID is 5565.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 314.0, B04 is 585.0, PID is 5565.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '5', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '5', '.', '0', ',', '', 'B04', 'is', '']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 314.0, B04 is 585.0, PID is 5565.0, B03 is 745.065.0, B04 is ']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5565.0, B04 is 585.0, B02 is 314.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5565.0, B04 is 585.0, B02 is 314.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '5', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '5', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '7', '2', '4', '5', '7', '2', '.', '0']]\n",
      "decoded_data: ['PID is 5565.0, B04 is 585.0, B02 is 314.0, DOY is 211.0, B03 is 745.0 724572.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 314.0, B04 is 585.0, DOY is 211.0, PID is 5565.0, B03 is']\n",
      "prompt: B02 is 314.0, B04 is 585.0, DOY is 211.0, PID is 5565.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '5', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '7', '7', '2', '.', '0', '.', '0', ',']]\n",
      "decoded_data: ['B02 is 314.0, B04 is 585.0, DOY is 211.0, PID is 5565.0, B03 is 745.07772.0.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 314.0, B04 is 585.0, PID is 5565.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 314.0, B04 is 585.0, PID is 5565.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['B02 is 314.0, B04 is 585.0, PID is 5565.0, DOY is 211.0, B03 is 745.0 B04 is PID is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5565.0, DOY is 211.0, B04 is 585.0, B02 is 314.0, B03 is']\n",
      "prompt: PID is 5565.0, DOY is 211.0, B04 is 585.0, B02 is 314.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '5', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '5', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['PID is 5565.0, DOY is 211.0, B04 is 585.0, B02 is 314.0, B03 is 745.0 B04 is PID is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5565.0, B04 is 585.0, B02 is 314.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5565.0, B04 is 585.0, B02 is 314.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '5', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '5', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '7', '2', '5', '5', '5', '5', '5', '.']]\n",
      "decoded_data: ['PID is 5565.0, B04 is 585.0, B02 is 314.0, DOY is 211.0, B03 is 745.0 7255555.']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5565.0, B02 is 314.0, B04 is 585.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5565.0, B02 is 314.0, B04 is 585.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '5', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 10%|         | 79/829 [02:14<25:23,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '5', '5', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '3', '.', '0', ',', '', 'B04', 'is', '']]\n",
      "decoded_data: ['PID is 5565.0, B02 is 314.0, B04 is 585.0, DOY is 211.0, B03 is 745.073.0, B04 is ']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5665.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 5665.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '6', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '6', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '6', '2', '9', '5']]\n",
      "decoded_data: ['PID is 5665.0, DOY is 211.0, B04 is 534.0, B02 is 303.0, B03 is 695.0 B04 is 56295']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5665.0, B02 is 303.0, B04 is 534.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5665.0, B02 is 303.0, B04 is 534.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '6', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '6', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '6', '2', '.', '0', '6', '2', '.', '0']]\n",
      "decoded_data: ['PID is 5665.0, B02 is 303.0, B04 is 534.0, DOY is 211.0, B03 is 695.0662.062.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 534.0, DOY is 211.0, B02 is 303.0, PID is 5665.0, B03 is']\n",
      "prompt: B04 is 534.0, DOY is 211.0, B02 is 303.0, PID is 5665.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '3', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '5', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '3', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '6', '2', '.', '0', ',', '', 'B03', 'is']]\n",
      "decoded_data: ['B04 is 534.0, DOY is 211.0, B02 is 303.0, PID is 5665.0, B03 is 695.0562.0, B03 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 303.0, B04 is 534.0, PID is 5665.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 303.0, B04 is 534.0, PID is 5665.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '5', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '2', '.', '0', '5', '6', '2', '.', '0']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 303.0, B04 is 534.0, PID is 5665.0, B03 is 695.062.0562.0']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5665.0, B04 is 534.0, B02 is 303.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 5665.0, B04 is 534.0, B02 is 303.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', '5', '6']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5665.0, B04 is 534.0, B02 is 303.0, B03 is 742.0 B04 is B04 is 56']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5665.0, B02 is 303.0, B04 is 534.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5665.0, B02 is 303.0, B04 is 534.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '6', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '6', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '2', '4', '2', '4', '2', '4', '2', '.']]\n",
      "decoded_data: ['PID is 5665.0, B02 is 303.0, B04 is 534.0, DOY is 211.0, B03 is 742.072424242.']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5665.0, B04 is 534.0, B02 is 303.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 5665.0, B04 is 534.0, B02 is 303.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'DOY', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5665.0, B04 is 534.0, B02 is 303.0, B03 is 695.0 B04 is DOY is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5665.0, B04 is 534.0, B02 is 303.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5665.0, B04 is 534.0, B02 is 303.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '6', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '6', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '0', '2', '4', '2']]\n",
      "decoded_data: ['PID is 5665.0, B04 is 534.0, B02 is 303.0, DOY is 211.0, B03 is 742.0 PID is 70242']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 303.0, B04 is 534.0, PID is 5665.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 303.0, B04 is 534.0, PID is 5665.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '5', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B02', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 303.0, B04 is 534.0, PID is 5665.0, B03 is 695.0 B04 is B02 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 534.0, B02 is 303.0, PID is 5665.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 534.0, B02 is 303.0, PID is 5665.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '3', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '3', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '2', '.', '0', '2', '.', '0', ',', '']]\n",
      "decoded_data: ['B04 is 534.0, B02 is 303.0, PID is 5665.0, DOY is 211.0, B03 is 742.062.02.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 303.0, PID is 5665.0, B04 is 534.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 303.0, PID is 5665.0, B04 is 534.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 80/829 [02:16<25:09,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', '5', '3']]\n",
      "decoded_data: ['B02 is 303.0, PID is 5665.0, B04 is 534.0, DOY is 211.0, B03 is 742.0 B04 is B04 is 53']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5665.0, B02 is 303.0, B04 is 534.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5665.0, B02 is 303.0, B04 is 534.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '6', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '6', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '2', '9', '5', '8', '5', '8', '9', '5']]\n",
      "decoded_data: ['PID is 5665.0, B02 is 303.0, B04 is 534.0, DOY is 211.0, B03 is 742.0729585895']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5765.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5765.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '7', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '7', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '3', '8', '5', '8', '5']]\n",
      "decoded_data: ['PID is 5765.0, DOY is 211.0, B03 is 776.0, B04 is 566.0, B02 is 315.0 PID is 38585']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5765.0, B04 is 566.0, DOY is 211.0, B03 is 776.0, B02 is']\n",
      "prompt: PID is 5765.0, B04 is 566.0, DOY is 211.0, B03 is 776.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '7', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '6', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '7', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '3', '8', '5', '5', '8', '5', '5', '.', '0']]\n",
      "decoded_data: ['PID is 5765.0, B04 is 566.0, DOY is 211.0, B03 is 776.0, B02 is 315.03855855.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 566.0, PID is 5765.0, B03 is 776.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 566.0, PID is 5765.0, B03 is 776.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '3', '8', '5', '7', '8', '5', '.', '0', '8']]\n",
      "decoded_data: ['B04 is 566.0, PID is 5765.0, B03 is 776.0, DOY is 211.0, B02 is 315.0385785.08']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 566.0, PID is 5765.0, DOY is 211.0, B03 is 776.0, B02 is']\n",
      "prompt: B04 is 566.0, PID is 5765.0, DOY is 211.0, B03 is 776.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '6', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '3', '8', '5', '4', '6']]\n",
      "decoded_data: ['B04 is 566.0, PID is 5765.0, DOY is 211.0, B03 is 776.0, B02 is 315.0 PID is 38546']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 566.0, PID is 5765.0, DOY is 211.0, B03 is 776.0, B02 is']\n",
      "prompt: B04 is 566.0, PID is 5765.0, DOY is 211.0, B03 is 776.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '6', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '5', '3', '8', '5', '7', '.', '0', ',']]\n",
      "decoded_data: ['B04 is 566.0, PID is 5765.0, DOY is 211.0, B03 is 776.0, B02 is 315.0553857.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5765.0, B04 is 566.0, DOY is 211.0, B03 is 776.0, B02 is']\n",
      "prompt: PID is 5765.0, B04 is 566.0, DOY is 211.0, B03 is 776.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '7', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '6', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '7', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '3', '8', '5', '3', '9']]\n",
      "decoded_data: ['PID is 5765.0, B04 is 566.0, DOY is 211.0, B03 is 776.0, B02 is 315.0 PID is 38539']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 566.0, DOY is 211.0, PID is 5765.0, B03 is 776.0, B02 is']\n",
      "prompt: B04 is 566.0, DOY is 211.0, PID is 5765.0, B03 is 776.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '6', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '3', '8', '5', '5', '4']]\n",
      "decoded_data: ['B04 is 566.0, DOY is 211.0, PID is 5765.0, B03 is 776.0, B02 is 315.0 PID is 38554']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 776.0, B04 is 566.0, DOY is 211.0, PID is 5765.0, B02 is']\n",
      "prompt: B03 is 776.0, B04 is 566.0, DOY is 211.0, PID is 5765.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '7', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '5', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '7', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B02', 'is', '', '3', '.', '0', '8', '3']]\n",
      "decoded_data: ['B03 is 776.0, B04 is 566.0, DOY is 211.0, PID is 5765.0, B02 is 315.0 B02 is 3.083']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 776.0, PID is 5765.0, DOY is 211.0, B04 is 566.0, B02 is']\n",
      "prompt: B03 is 776.0, PID is 5765.0, DOY is 211.0, B04 is 566.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '7', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '7', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '3', '8', '5', '8', '5', '3', '.', '0', ',']]\n",
      "decoded_data: ['B03 is 776.0, PID is 5765.0, DOY is 211.0, B04 is 566.0, B02 is 315.0385853.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5765.0, B03 is 776.0, B04 is 566.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 5765.0, B03 is 776.0, B04 is 566.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '5', '7', '5', '6']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5765.0, B03 is 776.0, B04 is 566.0, B02 is 315.0 B04 is 55756']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 566.0, B03 is 776.0, PID is 5765.0, B02 is']\n",
      "prompt: DOY is 211.0, B04 is 566.0, B03 is 776.0, PID is 5765.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '5', '.', '0', ',', '', 'B02', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 81/829 [02:18<24:52,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '7', '7', '8', '.']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 566.0, B03 is 776.0, PID is 5765.0, B02 is 315.0 B04 is 5778.']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5765.0, B04 is 566.0, DOY is 211.0, B03 is 776.0, B02 is']\n",
      "prompt: PID is 5765.0, B04 is 566.0, DOY is 211.0, B03 is 776.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '7', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '6', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '7', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '3', '9', '2', '2', '0', '8', '0', '8', '5']]\n",
      "decoded_data: ['PID is 5765.0, B04 is 566.0, DOY is 211.0, B03 is 776.0, B02 is 315.0392208085']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5865.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 5865.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '8', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '8', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '6', '7', '6', '7']]\n",
      "decoded_data: ['PID is 5865.0, DOY is 211.0, B02 is 328.0, B04 is 547.0, B03 is 781.0 PID is 76767']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 547.0, PID is 5865.0, B02 is 328.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 547.0, PID is 5865.0, B02 is 328.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '7', '2', '7', '2', '7']]\n",
      "decoded_data: ['B04 is 547.0, PID is 5865.0, B02 is 328.0, DOY is 211.0, B03 is 781.0 B04 is 72727']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 328.0, PID is 5865.0, B04 is 547.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 328.0, PID is 5865.0, B04 is 547.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '2', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '2', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '2', '5', '6', '6', '6', '6', '6', '.']]\n",
      "decoded_data: ['B02 is 328.0, PID is 5865.0, B04 is 547.0, DOY is 211.0, B03 is 781.072566666.']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5865.0, DOY is 211.0, B04 is 547.0, B02 is 328.0, B03 is']\n",
      "prompt: PID is 5865.0, DOY is 211.0, B04 is 547.0, B02 is 328.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '8', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '8', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '2', '8', '1', '.', '0', ',', '', 'B04']]\n",
      "decoded_data: ['PID is 5865.0, DOY is 211.0, B04 is 547.0, B02 is 328.0, B03 is 781.07281.0, B04']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5865.0, B04 is 547.0, DOY is 211.0, B02 is 328.0, B03 is']\n",
      "prompt: PID is 5865.0, B04 is 547.0, DOY is 211.0, B02 is 328.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '8', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '8', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '1', '0', '7', '9', '6', '.', '0', '7']]\n",
      "decoded_data: ['PID is 5865.0, B04 is 547.0, DOY is 211.0, B02 is 328.0, B03 is 781.0710796.07']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 328.0, DOY is 211.0, PID is 5865.0, B04 is 547.0, B03 is']\n",
      "prompt: B02 is 328.0, DOY is 211.0, PID is 5865.0, B04 is 547.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '2', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '2', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '6', '6', '7', '2', '.', '0', ',', '']]\n",
      "decoded_data: ['B02 is 328.0, DOY is 211.0, PID is 5865.0, B04 is 547.0, B03 is 781.066672.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 328.0, B04 is 547.0, PID is 5865.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 328.0, B04 is 547.0, PID is 5865.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '5', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '8', '1', '0', '4', '7', '9', '.', '0', ',']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 328.0, B04 is 547.0, PID is 5865.0, B03 is 781.0810479.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 328.0, B04 is 547.0, PID is 5865.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 328.0, B04 is 547.0, PID is 5865.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '2', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '2', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '3', '5', '2', '.', '0', '1', '0', ',', '']]\n",
      "decoded_data: ['B02 is 328.0, B04 is 547.0, PID is 5865.0, DOY is 211.0, B03 is 781.0352.010, ']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 547.0, DOY is 211.0, B02 is 328.0, PID is 5865.0, B03 is']\n",
      "prompt: B04 is 547.0, DOY is 211.0, B02 is 328.0, PID is 5865.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '5', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '2']]\n",
      "decoded_data: ['B04 is 547.0, DOY is 211.0, B02 is 328.0, PID is 5865.0, B03 is 781.0 B04 is PID is 72']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5865.0, B02 is 328.0, B04 is 547.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 5865.0, B02 is 328.0, B04 is 547.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '6', '.', '0', '8']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5865.0, B02 is 328.0, B04 is 547.0, B03 is 781.0 B04 is 56.08']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5865.0, B04 is 547.0, B02 is 328.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5865.0, B04 is 547.0, B02 is 328.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '8', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '8', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '2']]\n",
      "decoded_data: ['PID is 5865.0, B04 is 547.0, B02 is 328.0, DOY is 211.0, B03 is 781.0 B04 is PID is 72']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 547.0, B02 is 328.0, PID is 5865.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 547.0, B02 is 328.0, PID is 5865.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '5', '6', '6', '6', '.', '0', ',', '']]\n",
      "decoded_data: ['B04 is 547.0, B02 is 328.0, PID is 5865.0, DOY is 211.0, B03 is 781.065666.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 547.0, B02 is 328.0, PID is 5865.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 547.0, B02 is 328.0, PID is 5865.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '5', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '7', '2', '5', '2', '.', '0', ',', '']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 547.0, B02 is 328.0, PID is 5865.0, B03 is 781.0 7252.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 547.0, PID is 5865.0, B02 is 328.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 547.0, PID is 5865.0, B02 is 328.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '8', '1', '9', '6', '7', '2', '8', '.', '0']]\n",
      "decoded_data: ['B04 is 547.0, PID is 5865.0, B02 is 328.0, DOY is 211.0, B03 is 781.08196728.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 547.0, DOY is 211.0, PID is 5865.0, B02 is 328.0, B03 is']\n",
      "prompt: B04 is 547.0, DOY is 211.0, PID is 5865.0, B02 is 328.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '8', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 10%|         | 82/829 [02:21<25:58,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '2', '.', '0', ',', '', 'B04', 'is', '']]\n",
      "decoded_data: ['B04 is 547.0, DOY is 211.0, PID is 5865.0, B02 is 328.0, B03 is 781.072.0, B04 is ']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5965.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 5965.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '5', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '2', '.', '0', '7', '2', '8', '4', '6']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5965.0, B04 is 547.0, B02 is 328.0, B03 is 781.072.072846']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 547.0, B02 is 328.0, PID is 5965.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 547.0, B02 is 328.0, PID is 5965.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '2', '8', '1', '.', '0', ',', '', 'B04']]\n",
      "decoded_data: ['B04 is 547.0, B02 is 328.0, PID is 5965.0, DOY is 211.0, B03 is 696.06281.0, B04']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5965.0, B04 is 547.0, DOY is 211.0, B02 is 328.0, B03 is']\n",
      "prompt: PID is 5965.0, B04 is 547.0, DOY is 211.0, B02 is 328.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '9', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '9', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '8', '.', '0', ',', '', 'B03', 'is', '', '6', '4', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '1', '.', '0', '.', '0', ',', '', 'PID']]\n",
      "decoded_data: ['PID is 5965.0, B04 is 547.0, DOY is 211.0, B02 is 328.0, B03 is 647.061.0.0, PID']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5965.0, B04 is 547.0, DOY is 211.0, B02 is 328.0, B03 is']\n",
      "prompt: PID is 5965.0, B04 is 547.0, DOY is 211.0, B02 is 328.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '9', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '9', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '8', '.', '0', ',', '', 'B03', 'is', '', '6', '4', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '5', '5', '8', '7', '6', '.', '0', '8']]\n",
      "decoded_data: ['PID is 5965.0, B04 is 547.0, DOY is 211.0, B02 is 328.0, B03 is 647.0755876.08']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5965.0, B02 is 328.0, B04 is 547.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5965.0, B02 is 328.0, B04 is 547.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '9', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '9', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '4', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '6', '1', '6', '2', '6']]\n",
      "decoded_data: ['PID is 5965.0, B02 is 328.0, B04 is 547.0, DOY is 211.0, B03 is 647.0 PID is 61626']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 328.0, B04 is 547.0, DOY is 211.0, PID is 5965.0, B03 is']\n",
      "prompt: B02 is 328.0, B04 is 547.0, DOY is 211.0, PID is 5965.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '2', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '5', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '2', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '6', '1']]\n",
      "decoded_data: ['B02 is 328.0, B04 is 547.0, DOY is 211.0, PID is 5965.0, B03 is 692.0 B04 is PID is 61']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 328.0, B04 is 547.0, PID is 5965.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 328.0, B04 is 547.0, PID is 5965.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '2', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '2', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '4', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['B02 is 328.0, B04 is 547.0, PID is 5965.0, DOY is 211.0, B03 is 647.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 547.0, PID is 5965.0, B02 is 328.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 547.0, PID is 5965.0, B02 is 328.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '7', '8', '6', '7', '2', '.', '0', ',']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 547.0, PID is 5965.0, B02 is 328.0, B03 is 786.0678672.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 547.0, B02 is 328.0, DOY is 211.0, PID is 5965.0, B03 is']\n",
      "prompt: B04 is 547.0, B02 is 328.0, DOY is 211.0, PID is 5965.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '5', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '6', '2', '6', '7', '2']]\n",
      "decoded_data: ['B04 is 547.0, B02 is 328.0, DOY is 211.0, PID is 5965.0, B03 is 781.0 PID is 62672']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5965.0, B04 is 547.0, B02 is 328.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 5965.0, B04 is 547.0, B02 is 328.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5965.0, B04 is 547.0, B02 is 328.0, B03 is 784.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 328.0, PID is 5965.0, B04 is 547.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 328.0, PID is 5965.0, B04 is 547.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '2', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '2', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['B02 is 328.0, PID is 5965.0, B04 is 547.0, DOY is 211.0, B03 is 789.0 B04 is PID is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 328.0, B04 is 547.0, PID is 5965.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 328.0, B04 is 547.0, PID is 5965.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '5', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '6', '4', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 328.0, B04 is 547.0, PID is 5965.0, B03 is 647.0 PID is B04 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5965.0, DOY is 211.0, B04 is 547.0, B02 is 328.0, B03 is']\n",
      "prompt: PID is 5965.0, DOY is 211.0, B04 is 547.0, B02 is 328.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '9', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '9', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '8', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['PID is 5965.0, DOY is 211.0, B04 is 547.0, B02 is 328.0, B03 is 696.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 547.0, DOY is 211.0, B02 is 328.0, PID is 5965.0, B03 is']\n",
      "prompt: B04 is 547.0, DOY is 211.0, B02 is 328.0, PID is 5965.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '5', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '6', '4', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '1', '.', '0', '.', '0', '.', '0', ',']]\n",
      "decoded_data: ['B04 is 547.0, DOY is 211.0, B02 is 328.0, PID is 5965.0, B03 is 647.061.0.0.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 328.0, B04 is 547.0, PID is 5965.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 328.0, B04 is 547.0, PID is 5965.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '5', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 10%|         | 83/829 [02:23<27:04,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '6', '2']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 328.0, B04 is 547.0, PID is 5965.0, B03 is 781.0 B04 is PID is 62']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6065.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 6065.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '0', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '0', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '2', '7', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '2', '6', '.', '0', ',', '', 'B03', 'is', '', '4', '4', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '4', '7']]\n",
      "decoded_data: ['PID is 6065.0, DOY is 211.0, B04 is 279.0, B02 is 226.0, B03 is 447.0 B04 is PID is 47']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 279.0, PID is 6065.0, DOY is 211.0, B02 is 226.0, B03 is']\n",
      "prompt: B04 is 279.0, PID is 6065.0, DOY is 211.0, B02 is 226.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '2', '7', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '2', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '2', '7', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '2', '6', '.', '0', ',', '', 'B03', 'is', '', '4', '4', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '4', '7', '3', '4', '7']]\n",
      "decoded_data: ['B04 is 279.0, PID is 6065.0, DOY is 211.0, B02 is 226.0, B03 is 447.0 PID is 47347']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6065.0, B02 is 226.0, B04 is 279.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 6065.0, B02 is 226.0, B04 is 279.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '0', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '2', '6', '.', '0', ',', '', 'B04', 'is', '', '2', '7', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '0', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '2', '6', '.', '0', ',', '', 'B04', 'is', '', '2', '7', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '4', '4', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '4', '7', '3', '4', '7']]\n",
      "decoded_data: ['PID is 6065.0, B02 is 226.0, B04 is 279.0, DOY is 211.0, B03 is 447.0 B04 is 47347']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 226.0, PID is 6065.0, DOY is 211.0, B04 is 279.0, B03 is']\n",
      "prompt: B02 is 226.0, PID is 6065.0, DOY is 211.0, B04 is 279.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '2', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '2', '7', '9', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '2', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '2', '7', '9', '.', '0', ',', '', 'B03', 'is', '', '4', '4', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '2', '7']]\n",
      "decoded_data: ['B02 is 226.0, PID is 6065.0, DOY is 211.0, B04 is 279.0, B03 is 447.0 B04 is PID is 27']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 279.0, DOY is 211.0, B02 is 226.0, PID is 6065.0, B03 is']\n",
      "prompt: B04 is 279.0, DOY is 211.0, B02 is 226.0, PID is 6065.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '2', '7', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '2', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '5', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '2', '7', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '2', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '4', '4', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'DOY', 'is', '', '4', '7']]\n",
      "decoded_data: ['B04 is 279.0, DOY is 211.0, B02 is 226.0, PID is 6065.0, B03 is 447.0 B04 is DOY is 47']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6065.0, B04 is 279.0, DOY is 211.0, B02 is 226.0, B03 is']\n",
      "prompt: PID is 6065.0, B04 is 279.0, DOY is 211.0, B02 is 226.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '0', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '2', '7', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '2', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '0', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '2', '7', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '2', '6', '.', '0', ',', '', 'B03', 'is', '', '4', '4', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '4', '7']]\n",
      "decoded_data: ['PID is 6065.0, B04 is 279.0, DOY is 211.0, B02 is 226.0, B03 is 447.0 B04 is PID is 47']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6065.0, B02 is 226.0, B04 is 279.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 6065.0, B02 is 226.0, B04 is 279.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '0', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '2', '6', '.', '0', ',', '', 'B04', 'is', '', '2', '7', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '0', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '2', '6', '.', '0', ',', '', 'B04', 'is', '', '2', '7', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '4', '4', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '4', '7', '0', '1', '7']]\n",
      "decoded_data: ['PID is 6065.0, B02 is 226.0, B04 is 279.0, DOY is 211.0, B03 is 447.0 B04 is 47017']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 279.0, B02 is 226.0, PID is 6065.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 279.0, B02 is 226.0, PID is 6065.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '2', '7', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '2', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '5', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '2', '7', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '2', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '4', '4', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '4', '7']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 279.0, B02 is 226.0, PID is 6065.0, B03 is 447.0 B04 is PID is 47']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6065.0, B02 is 226.0, B04 is 279.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 6065.0, B02 is 226.0, B04 is 279.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '2', '6', '.', '0', ',', '', 'B04', 'is', '', '2', '7', '9', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '2', '6', '.', '0', ',', '', 'B04', 'is', '', '2', '7', '9', '.', '0', ',', '', 'B03', 'is', '', '4', '4', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '2', '5', '9', '4', '4']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6065.0, B02 is 226.0, B04 is 279.0, B03 is 447.0 B04 is 25944']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6065.0, DOY is 211.0, B02 is 226.0, B04 is 279.0, B03 is']\n",
      "prompt: PID is 6065.0, DOY is 211.0, B02 is 226.0, B04 is 279.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '0', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '2', '6', '.', '0', ',', '', 'B04', 'is', '', '2', '7', '9', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '0', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '2', '6', '.', '0', ',', '', 'B04', 'is', '', '2', '7', '9', '.', '0', ',', '', 'B03', 'is', '', '4', '4', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '2', '6']]\n",
      "decoded_data: ['PID is 6065.0, DOY is 211.0, B02 is 226.0, B04 is 279.0, B03 is 447.0 PID is B04 is 26']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6065.0, B02 is 226.0, DOY is 211.0, B04 is 279.0, B03 is']\n",
      "prompt: PID is 6065.0, B02 is 226.0, DOY is 211.0, B04 is 279.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '0', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '2', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '2', '7', '9', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '0', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '2', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '2', '7', '9', '.', '0', ',', '', 'B03', 'is', '', '4', '4', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '4', '7', '0', '1', '2']]\n",
      "decoded_data: ['PID is 6065.0, B02 is 226.0, DOY is 211.0, B04 is 279.0, B03 is 447.0 B04 is 47012']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 279.0, DOY is 211.0, PID is 6065.0, B02 is 226.0, B03 is']\n",
      "prompt: B04 is 279.0, DOY is 211.0, PID is 6065.0, B02 is 226.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '2', '7', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '2', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '2', '7', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '2', '6', '.', '0', ',', '', 'B03', 'is', '', '4', '4', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '.', '0', '1', '7', '3', '.', '0', ',']]\n",
      "decoded_data: ['B04 is 279.0, DOY is 211.0, PID is 6065.0, B02 is 226.0, B03 is 447.05.0173.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 226.0, B04 is 279.0, PID is 6065.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 226.0, B04 is 279.0, PID is 6065.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '2', '6', '.', '0', ',', '', 'B04', 'is', '', '2', '7', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '2', '6', '.', '0', ',', '', 'B04', 'is', '', '2', '7', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '4', '4', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '4', '7', '0', '1', '0', '1', '.', '0', '1']]\n",
      "decoded_data: ['B02 is 226.0, B04 is 279.0, PID is 6065.0, DOY is 211.0, B03 is 447.0470101.01']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 226.0, B04 is 279.0, PID is 6065.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 226.0, B04 is 279.0, PID is 6065.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '2', '6', '.', '0', ',', '', 'B04', 'is', '', '2', '7', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '2', '6', '.', '0', ',', '', 'B04', 'is', '', '2', '7', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '4', '4', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '4', '7', '2', '0', '.']]\n",
      "decoded_data: ['B02 is 226.0, B04 is 279.0, PID is 6065.0, DOY is 211.0, B03 is 447.0 B04 is 4720.']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 226.0, DOY is 211.0, B04 is 279.0, PID is 6065.0, B03 is']\n",
      "prompt: B02 is 226.0, DOY is 211.0, B04 is 279.0, PID is 6065.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '2', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '2', '7', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '5', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 10%|         | 84/829 [02:25<27:29,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B02', 'is', '', '2', '2', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '2', '7', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '4', '4', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'DOY', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['B02 is 226.0, DOY is 211.0, B04 is 279.0, PID is 6065.0, B03 is 447.0 B04 is DOY is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6165.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 6165.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '1', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '1', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '3', '3', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '6', '.', '0', ',', '', 'B03', 'is', '', '4', '3', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '7', '3', '9', '3', '9', '3', '9']]\n",
      "decoded_data: ['PID is 6165.0, DOY is 211.0, B04 is 339.0, B02 is 246.0, B03 is 439.0 47393939']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 339.0, DOY is 211.0, B02 is 246.0, PID is 6165.0, B03 is']\n",
      "prompt: B04 is 339.0, DOY is 211.0, B02 is 246.0, PID is 6165.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '3', '3', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '5', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '3', '3', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '4', '3', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '4', '.', '0', ',', '', 'B04', 'is', '', 'PID']]\n",
      "decoded_data: ['B04 is 339.0, DOY is 211.0, B02 is 246.0, PID is 6165.0, B03 is 439.04.0, B04 is PID']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 246.0, PID is 6165.0, B04 is 339.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 246.0, PID is 6165.0, B04 is 339.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '4', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '3', '3', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '4', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '3', '3', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '4', '3', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '4', '7', '3', '9', '3', '9', '3']]\n",
      "decoded_data: ['B02 is 246.0, PID is 6165.0, B04 is 339.0, DOY is 211.0, B03 is 439.0 44739393']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 339.0, PID is 6165.0, B02 is 246.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 339.0, PID is 6165.0, B02 is 246.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '3', '3', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '3', '3', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '6', '.', '0', ',', '', 'B03', 'is', '', '4', '3', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', '4', '7', '3', '9', '3']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 339.0, PID is 6165.0, B02 is 246.0, B03 is 439.0 B03 is 47393']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 339.0, PID is 6165.0, B02 is 246.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 339.0, PID is 6165.0, B02 is 246.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '3', '3', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '3', '3', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '6', '.', '0', ',', '', 'B03', 'is', '', '4', '3', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', '4', '3', '9', '3', '.']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 339.0, PID is 6165.0, B02 is 246.0, B03 is 439.0 B03 is 4393.']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 339.0, B02 is 246.0, PID is 6165.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 339.0, B02 is 246.0, PID is 6165.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '3', '3', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '5', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '3', '3', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '4', '3', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '3', '9', '3', '9', '3']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 339.0, B02 is 246.0, PID is 6165.0, B03 is 439.0 B04 is 39393']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 246.0, B04 is 339.0, DOY is 211.0, PID is 6165.0, B03 is']\n",
      "prompt: B02 is 246.0, B04 is 339.0, DOY is 211.0, PID is 6165.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '4', '6', '.', '0', ',', '', 'B04', 'is', '', '3', '3', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '5', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '4', '6', '.', '0', ',', '', 'B04', 'is', '', '3', '3', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '4', '3', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', '3', '9']]\n",
      "decoded_data: ['B02 is 246.0, B04 is 339.0, DOY is 211.0, PID is 6165.0, B03 is 439.0 B04 is B04 is 39']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 246.0, DOY is 211.0, B04 is 339.0, PID is 6165.0, B03 is']\n",
      "prompt: B02 is 246.0, DOY is 211.0, B04 is 339.0, PID is 6165.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '4', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '3', '3', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '5', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '4', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '3', '3', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '4', '3', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '3', '9', '3', '9', '3']]\n",
      "decoded_data: ['B02 is 246.0, DOY is 211.0, B04 is 339.0, PID is 6165.0, B03 is 439.0 B04 is 39393']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6165.0, B04 is 339.0, B02 is 246.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 6165.0, B04 is 339.0, B02 is 246.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '1', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '3', '3', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '1', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '3', '3', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '4', '3', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '4', '3', '9', '3', '9', '3', '9']]\n",
      "decoded_data: ['PID is 6165.0, B04 is 339.0, B02 is 246.0, DOY is 211.0, B03 is 439.0 44393939']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 339.0, B02 is 246.0, DOY is 211.0, PID is 6165.0, B03 is']\n",
      "prompt: B04 is 339.0, B02 is 246.0, DOY is 211.0, PID is 6165.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '3', '3', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '5', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '3', '3', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '4', '3', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '3', '9', '3', '9', '3', '9', '3']]\n",
      "decoded_data: ['B04 is 339.0, B02 is 246.0, DOY is 211.0, PID is 6165.0, B03 is 439.0 43939393']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 246.0, PID is 6165.0, B04 is 339.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 246.0, PID is 6165.0, B04 is 339.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '4', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '3', '3', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '4', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '3', '3', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '4', '3', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '3', '9', '3', '9', '3']]\n",
      "decoded_data: ['B02 is 246.0, PID is 6165.0, B04 is 339.0, DOY is 211.0, B03 is 439.0 B04 is 39393']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 246.0, B04 is 339.0, DOY is 211.0, PID is 6165.0, B03 is']\n",
      "prompt: B02 is 246.0, B04 is 339.0, DOY is 211.0, PID is 6165.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '4', '6', '.', '0', ',', '', 'B04', 'is', '', '3', '3', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '5', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '4', '6', '.', '0', ',', '', 'B04', 'is', '', '3', '3', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '4', '3', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '3', '9', '3', '9', '3']]\n",
      "decoded_data: ['B02 is 246.0, B04 is 339.0, DOY is 211.0, PID is 6165.0, B03 is 439.0 B04 is 39393']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 339.0, PID is 6165.0, B02 is 246.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 339.0, PID is 6165.0, B02 is 246.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '3', '3', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '3', '3', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '4', '3', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '4', '7', '3', '9', '0']]\n",
      "decoded_data: ['B04 is 339.0, PID is 6165.0, B02 is 246.0, DOY is 211.0, B03 is 439.0 B04 is 47390']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 339.0, PID is 6165.0, B02 is 246.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 339.0, PID is 6165.0, B02 is 246.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '3', '3', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '3', '3', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '4', '3', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '3', '9', '3', '9', '3', '.', '0']]\n",
      "decoded_data: ['B04 is 339.0, PID is 6165.0, B02 is 246.0, DOY is 211.0, B03 is 439.0 439393.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 339.0, PID is 6165.0, DOY is 211.0, B02 is 246.0, B03 is']\n",
      "prompt: B04 is 339.0, PID is 6165.0, DOY is 211.0, B02 is 246.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '3', '3', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '6', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 10%|         | 85/829 [02:28<27:43,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B04', 'is', '', '3', '3', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '6', '.', '0', ',', '', 'B03', 'is', '', '4', '3', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '4', '7']]\n",
      "decoded_data: ['B04 is 339.0, PID is 6165.0, DOY is 211.0, B02 is 246.0, B03 is 439.0 B04 is PID is 47']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6265.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 6265.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '5', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'B03', 'is', '', '5', '7', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B03', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6265.0, B02 is 331.0, B03 is 575.0, B04 is 568.0 PID is B03 is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 331.0, PID is 6265.0, DOY is 211.0, B03 is 575.0, B04 is']\n",
      "prompt: B02 is 331.0, PID is 6265.0, DOY is 211.0, B03 is 575.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '5', '7', '5', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '5', '7', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '3', '4', '0', '7']]\n",
      "decoded_data: ['B02 is 331.0, PID is 6265.0, DOY is 211.0, B03 is 575.0, B04 is 540.0 PID is 53407']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 575.0, DOY is 211.0, B02 is 331.0, PID is 6265.0, B04 is']\n",
      "prompt: B03 is 575.0, DOY is 211.0, B02 is 331.0, PID is 6265.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '5', '7', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '5', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '5', '7', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '8', '7', '4', '8', '5', '.', '0']]\n",
      "decoded_data: ['B03 is 575.0, DOY is 211.0, B02 is 331.0, PID is 6265.0, B04 is 487.0 487485.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 331.0, B03 is 575.0, PID is 6265.0, DOY is 211.0, B04 is']\n",
      "prompt: B02 is 331.0, B03 is 575.0, PID is 6265.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'B03', 'is', '', '5', '7', '5', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'B03', 'is', '', '5', '7', '5', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '8', '6', '8', '6', '.', '0', '.', '0']]\n",
      "decoded_data: ['B02 is 331.0, B03 is 575.0, PID is 6265.0, DOY is 211.0, B04 is 548.058686.0.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 575.0, DOY is 211.0, PID is 6265.0, B02 is 331.0, B04 is']\n",
      "prompt: B03 is 575.0, DOY is 211.0, PID is 6265.0, B02 is 331.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '5', '7', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '5', '7', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '3', '1', '.', '0', ',', '', 'B02', 'is']]\n",
      "decoded_data: ['B03 is 575.0, DOY is 211.0, PID is 6265.0, B02 is 331.0, B04 is 548.0531.0, B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 331.0, B03 is 575.0, PID is 6265.0, DOY is 211.0, B04 is']\n",
      "prompt: B02 is 331.0, B03 is 575.0, PID is 6265.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'B03', 'is', '', '5', '7', '5', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'B03', 'is', '', '5', '7', '5', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '0', '2', '4', '8', '.', '0', '1', '.', '0']]\n",
      "decoded_data: ['B02 is 331.0, B03 is 575.0, PID is 6265.0, DOY is 211.0, B04 is 540.00248.01.0']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6265.0, DOY is 211.0, B02 is 331.0, B03 is 575.0, B04 is']\n",
      "prompt: PID is 6265.0, DOY is 211.0, B02 is 331.0, B03 is 575.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '2', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'B03', 'is', '', '5', '7', '5', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '2', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'B03', 'is', '', '5', '7', '5', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '4', '8', '7', '0', '6']]\n",
      "decoded_data: ['PID is 6265.0, DOY is 211.0, B02 is 331.0, B03 is 575.0, B04 is 431.0 PID is 48706']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 575.0, PID is 6265.0, DOY is 211.0, B02 is 331.0, B04 is']\n",
      "prompt: B03 is 575.0, PID is 6265.0, DOY is 211.0, B02 is 331.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '5', '7', '5', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '5', '7', '5', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '7', '9', '9', '9', '.', '0', ',']]\n",
      "decoded_data: ['B03 is 575.0, PID is 6265.0, DOY is 211.0, B02 is 331.0, B04 is 506.0 47999.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6265.0, B03 is 575.0, B02 is 331.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 6265.0, B03 is 575.0, B02 is 331.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '5', '7', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '5', '7', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '8', '7', '0', '6']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6265.0, B03 is 575.0, B02 is 331.0, B04 is 431.0 PID is 58706']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 575.0, PID is 6265.0, B02 is 331.0, B04 is']\n",
      "prompt: DOY is 211.0, B03 is 575.0, PID is 6265.0, B02 is 331.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '5', '7', '5', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '5', '7', '5', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '6', '4', '8', '7', '5', '.', '0']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 575.0, PID is 6265.0, B02 is 331.0, B04 is 431.0 564875.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 331.0, DOY is 211.0, PID is 6265.0, B03 is 575.0, B04 is']\n",
      "prompt: B02 is 331.0, DOY is 211.0, PID is 6265.0, B03 is 575.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '5', '7', '5', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '5', '7', '5', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '8', '7', '3', '1', '8', '.', '0']]\n",
      "decoded_data: ['B02 is 331.0, DOY is 211.0, PID is 6265.0, B03 is 575.0, B04 is 431.0 587318.0']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6265.0, B03 is 575.0, B02 is 331.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 6265.0, B03 is 575.0, B02 is 331.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '2', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '5', '7', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '2', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '5', '7', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B03', 'is', '', '4', '8']]\n",
      "decoded_data: ['PID is 6265.0, B03 is 575.0, B02 is 331.0, DOY is 211.0, B04 is 540.0 PID is B03 is 48']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 575.0, DOY is 211.0, PID is 6265.0, B02 is 331.0, B04 is']\n",
      "prompt: B03 is 575.0, DOY is 211.0, PID is 6265.0, B02 is 331.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '5', '7', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '5', '7', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '3', '.', '0', '5', '9', '9', '9', '9', '.']]\n",
      "decoded_data: ['B03 is 575.0, DOY is 211.0, PID is 6265.0, B02 is 331.0, B04 is 568.03.059999.']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6265.0, B02 is 331.0, B03 is 575.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 6265.0, B02 is 331.0, B03 is 575.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '2', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'B03', 'is', '', '5', '7', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '2', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'B03', 'is', '', '5', '7', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B03', 'is', '', '5', '9']]\n",
      "decoded_data: ['PID is 6265.0, B02 is 331.0, B03 is 575.0, DOY is 211.0, B04 is 490.0 PID is B03 is 59']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 575.0, DOY is 211.0, PID is 6265.0, B02 is 331.0, B04 is']\n",
      "prompt: B03 is 575.0, DOY is 211.0, PID is 6265.0, B02 is 331.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '5', '7', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'B04', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 10%|         | 86/829 [02:30<27:57,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B03', 'is', '', '5', '7', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '4', '8', '7', '0', '1']]\n",
      "decoded_data: ['B03 is 575.0, DOY is 211.0, PID is 6265.0, B02 is 331.0, B04 is 431.0 PID is 48701']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6365.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 6365.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '3', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '3', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '5', '.', '0', ',', '', 'B03', 'is', '', '6', '6', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '6', '3', '8', '2', '8', '2', '8', '2']]\n",
      "decoded_data: ['PID is 6365.0, DOY is 211.0, B02 is 266.0, B04 is 445.0, B03 is 663.0 63828282']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6365.0, B04 is 445.0, B02 is 266.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 6365.0, B04 is 445.0, B02 is 266.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '3', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '3', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '6', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'DOY', 'is', '', '2', '8']]\n",
      "decoded_data: ['PID is 6365.0, B04 is 445.0, B02 is 266.0, DOY is 211.0, B03 is 663.0 B04 is DOY is 28']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 445.0, B02 is 266.0, PID is 6365.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 445.0, B02 is 266.0, PID is 6365.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '4', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '4', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '6', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B02', 'is', '', 'DOY', 'is']]\n",
      "decoded_data: ['B04 is 445.0, B02 is 266.0, PID is 6365.0, DOY is 211.0, B03 is 663.0 B04 is B02 is DOY is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 266.0, B04 is 445.0, PID is 6365.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 266.0, B04 is 445.0, PID is 6365.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '5', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '5', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '6', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '6', '3', '8', '6', '3', '8', '6', '.']]\n",
      "decoded_data: ['B02 is 266.0, B04 is 445.0, PID is 6365.0, DOY is 211.0, B03 is 663.0 6386386.']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 445.0, PID is 6365.0, B02 is 266.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 445.0, PID is 6365.0, B02 is 266.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '5', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '5', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '6', '6', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'DOY', 'is', '', 'B02', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 445.0, PID is 6365.0, B02 is 266.0, B03 is 663.0 DOY is B02 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 266.0, PID is 6365.0, B04 is 445.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 266.0, PID is 6365.0, B04 is 445.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '6', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '6', '3', '8', '6', '3', '.', '0', '.']]\n",
      "decoded_data: ['B02 is 266.0, PID is 6365.0, B04 is 445.0, DOY is 211.0, B03 is 663.0 63863.0.']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 445.0, B02 is 266.0, PID is 6365.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 445.0, B02 is 266.0, PID is 6365.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '5', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '6', '6', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '6', '3', '.', '0', ',']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 445.0, B02 is 266.0, PID is 6365.0, B03 is 663.0 B04 is 63.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6365.0, B02 is 266.0, B04 is 445.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 6365.0, B02 is 266.0, B04 is 445.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '5', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '5', '.', '0', ',', '', 'B03', 'is', '', '6', '6', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '4', '0', '0', '.', '0']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6365.0, B02 is 266.0, B04 is 445.0, B03 is 663.0 B04 is 400.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 266.0, B04 is 445.0, PID is 6365.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 266.0, B04 is 445.0, PID is 6365.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '5', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '5', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '6', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '3', '8', '6', '3', '.', '0', '.', '0']]\n",
      "decoded_data: ['B02 is 266.0, B04 is 445.0, PID is 6365.0, DOY is 211.0, B03 is 663.063863.0.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 445.0, PID is 6365.0, DOY is 211.0, B02 is 266.0, B03 is']\n",
      "prompt: B04 is 445.0, PID is 6365.0, DOY is 211.0, B02 is 266.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '4', '5', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '4', '5', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '6', '6', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '6', '3', '8', '6', '3']]\n",
      "decoded_data: ['B04 is 445.0, PID is 6365.0, DOY is 211.0, B02 is 266.0, B03 is 663.0 B04 is 63863']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 445.0, B02 is 266.0, PID is 6365.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 445.0, B02 is 266.0, PID is 6365.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '5', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '6', '6', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '6', '3', '9', '0', '5', '.', '0', '.']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 445.0, B02 is 266.0, PID is 6365.0, B03 is 663.0 63905.0.']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 445.0, B02 is 266.0, PID is 6365.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 445.0, B02 is 266.0, PID is 6365.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '4', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '4', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '6', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '6', '3', '9', '0', '.']]\n",
      "decoded_data: ['B04 is 445.0, B02 is 266.0, PID is 6365.0, DOY is 211.0, B03 is 663.0 B04 is 6390.']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6365.0, B04 is 445.0, B02 is 266.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 6365.0, B04 is 445.0, B02 is 266.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '3', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '3', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '6', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'DOY', 'is', '', '2', '1', '9', '0', ',']]\n",
      "decoded_data: ['PID is 6365.0, B04 is 445.0, B02 is 266.0, DOY is 211.0, B03 is 663.0 DOY is 2190,']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 445.0, PID is 6365.0, B02 is 266.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 445.0, PID is 6365.0, B02 is 266.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '4', '5', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '4', '5', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '6', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'DOY', 'is', '', '2', '8', '6', '3', '8']]\n",
      "decoded_data: ['B04 is 445.0, PID is 6365.0, B02 is 266.0, DOY is 211.0, B03 is 663.0 DOY is 28638']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6365.0, DOY is 211.0, B04 is 445.0, B02 is 266.0, B03 is']\n",
      "prompt: PID is 6365.0, DOY is 211.0, B04 is 445.0, B02 is 266.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '3', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '6', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 10%|         | 87/829 [02:32<28:19,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '6', '3', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '6', '6', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '6', '3', '8', '0', '0']]\n",
      "decoded_data: ['PID is 6365.0, DOY is 211.0, B04 is 445.0, B02 is 266.0, B03 is 663.0 B04 is 63800']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6465.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 6465.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '4', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '4', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'PID', 'is', '', '4', '8']]\n",
      "decoded_data: ['PID is 6465.0, DOY is 211.0, B02 is 280.0, B03 is 691.0, B04 is 462.0 B03 is PID is 48']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 280.0, PID is 6465.0, B03 is 691.0, DOY is 211.0, B04 is']\n",
      "prompt: B02 is 280.0, PID is 6465.0, B03 is 691.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'DOY', 'is', '', 'PID', 'is', '', '2', '4']]\n",
      "decoded_data: ['B02 is 280.0, PID is 6465.0, B03 is 691.0, DOY is 211.0, B04 is 462.0 DOY is PID is 24']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6465.0, B03 is 691.0, DOY is 211.0, B02 is 280.0, B04 is']\n",
      "prompt: PID is 6465.0, B03 is 691.0, DOY is 211.0, B02 is 280.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '4', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '4', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '8', '9', '0', '9', '0', '9', '0']]\n",
      "decoded_data: ['PID is 6465.0, B03 is 691.0, DOY is 211.0, B02 is 280.0, B04 is 462.0 48909090']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6465.0, DOY is 211.0, B02 is 280.0, B03 is 691.0, B04 is']\n",
      "prompt: PID is 6465.0, DOY is 211.0, B02 is 280.0, B03 is 691.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '4', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '4', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '8', '9', '0', '9', '0', '4', '.']]\n",
      "decoded_data: ['PID is 6465.0, DOY is 211.0, B02 is 280.0, B03 is 691.0, B04 is 462.0 4890904.']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 691.0, PID is 6465.0, DOY is 211.0, B02 is 280.0, B04 is']\n",
      "prompt: B03 is 691.0, PID is 6465.0, DOY is 211.0, B02 is 280.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '4', '8', '9', '0', '9']]\n",
      "decoded_data: ['B03 is 691.0, PID is 6465.0, DOY is 211.0, B02 is 280.0, B04 is 462.0 PID is 48909']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 280.0, DOY is 211.0, B03 is 691.0, PID is 6465.0, B04 is']\n",
      "prompt: B02 is 280.0, DOY is 211.0, B03 is 691.0, PID is 6465.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '5', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'DOY', 'is', '', '2', '1', '.', '0', ',']]\n",
      "decoded_data: ['B02 is 280.0, DOY is 211.0, B03 is 691.0, PID is 6465.0, B04 is 462.0 DOY is 21.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 691.0, B02 is 280.0, PID is 6465.0, DOY is 211.0, B04 is']\n",
      "prompt: B03 is 691.0, B02 is 280.0, PID is 6465.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '4', '8', '9', '0', '9']]\n",
      "decoded_data: ['B03 is 691.0, B02 is 280.0, PID is 6465.0, DOY is 211.0, B04 is 462.0 PID is 48909']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6465.0, B02 is 280.0, B03 is 691.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 6465.0, B02 is 280.0, B03 is 691.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '4', '5', '2', '4', '8']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6465.0, B02 is 280.0, B03 is 691.0, B04 is 462.0 PID is 45248']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 691.0, PID is 6465.0, B02 is 280.0, DOY is 211.0, B04 is']\n",
      "prompt: B03 is 691.0, PID is 6465.0, B02 is 280.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '4', '8', '5', '2', '4', '8', '1', '.', '0']]\n",
      "decoded_data: ['B03 is 691.0, PID is 6465.0, B02 is 280.0, DOY is 211.0, B04 is 462.04852481.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 280.0, DOY is 211.0, PID is 6465.0, B03 is 691.0, B04 is']\n",
      "prompt: B02 is 280.0, DOY is 211.0, PID is 6465.0, B03 is 691.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '5', '8', '9', '1', '.', '0', '1']]\n",
      "decoded_data: ['B02 is 280.0, DOY is 211.0, PID is 6465.0, B03 is 691.0, B04 is 462.0 45891.01']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 280.0, PID is 6465.0, B03 is 691.0, B04 is']\n",
      "prompt: DOY is 211.0, B02 is 280.0, PID is 6465.0, B03 is 691.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'B04', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|         | 88/829 [02:34<26:52,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '4', '5', '8', '9', '1']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 280.0, PID is 6465.0, B03 is 691.0, B04 is 462.0 B04 is 45891']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6465.0, B03 is 691.0, B02 is 280.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 6465.0, B03 is 691.0, B02 is 280.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '4', '8', '9', '0', '4', '3', '7', '4', '8']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6465.0, B03 is 691.0, B02 is 280.0, B04 is 462.0489043748']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6565.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 6565.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '5', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '6', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'DOY', 'is', '', 'B02', 'is', '', '4', '6']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6565.0, B03 is 666.0, B02 is 268.0, B04 is 446.0 DOY is B02 is 46']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 666.0, B02 is 268.0, PID is 6565.0, B04 is']\n",
      "prompt: DOY is 211.0, B03 is 666.0, B02 is 268.0, PID is 6565.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '8', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '5', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '8', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'DOY', 'is', '', 'B02', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 666.0, B02 is 268.0, PID is 6565.0, B04 is 446.0 DOY is B02 is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 268.0, B03 is 666.0, DOY is 211.0, PID is 6565.0, B04 is']\n",
      "prompt: B02 is 268.0, B03 is 666.0, DOY is 211.0, PID is 6565.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '6', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '5', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '6', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B02', 'is', '', 'DOY', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['B02 is 268.0, B03 is 666.0, DOY is 211.0, PID is 6565.0, B04 is 446.0 B02 is DOY is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 666.0, B02 is 268.0, DOY is 211.0, PID is 6565.0, B04 is']\n",
      "prompt: B03 is 666.0, B02 is 268.0, DOY is 211.0, PID is 6565.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '5', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '6', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '6', '6', '4', '6', '2', '.', '0']]\n",
      "decoded_data: ['B03 is 666.0, B02 is 268.0, DOY is 211.0, PID is 6565.0, B04 is 446.0 466462.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 268.0, B03 is 666.0, PID is 6565.0, DOY is 211.0, B04 is']\n",
      "prompt: B02 is 268.0, B03 is 666.0, PID is 6565.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '6', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|         | 89/829 [02:35<22:24,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B02', 'is', '', '2', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '6', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '4', '6', '6', '6', '6']]\n",
      "decoded_data: ['B02 is 268.0, B03 is 666.0, PID is 6565.0, DOY is 211.0, B04 is 446.0 PID is 46666']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6565.0, DOY is 211.0, B03 is 666.0, B02 is 268.0, B04 is']\n",
      "prompt: PID is 6565.0, DOY is 211.0, B03 is 666.0, B02 is 268.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '5', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '8', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '5', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '6', '6', '6', '6', '6', '6', '6', '6']]\n",
      "decoded_data: ['PID is 6565.0, DOY is 211.0, B03 is 666.0, B02 is 268.0, B04 is 446.0666666666']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6665.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 6665.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '5', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '3', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '2', '2', '2', '2', '2', '2', '2', '2']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6665.0, B04 is 493.0, B03 is 697.0, B02 is 310.0 22222222']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6665.0, B04 is 493.0, DOY is 211.0, B03 is 697.0, B02 is']\n",
      "prompt: PID is 6665.0, B04 is 493.0, DOY is 211.0, B03 is 697.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '6', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '6', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B02', 'is', '', '3', '2', '2', '2', '2']]\n",
      "decoded_data: ['PID is 6665.0, B04 is 493.0, DOY is 211.0, B03 is 697.0, B02 is 310.0 B02 is 32222']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 697.0, PID is 6665.0, B04 is 493.0, DOY is 211.0, B02 is']\n",
      "prompt: B03 is 697.0, PID is 6665.0, B04 is 493.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '9', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|         | 90/829 [02:36<17:46,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B03', 'is', '', '6', '9', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '2', '8', '0', '0', ',', '', 'PID', 'is', '']]\n",
      "decoded_data: ['B03 is 697.0, PID is 6665.0, B04 is 493.0, DOY is 211.0, B02 is 310.02800, PID is ']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6765.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 6765.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '7', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|         | 91/829 [02:36<13:32,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '6', '7', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '2', '7', '2', '7', '0', '1', '2', '7', '3']]\n",
      "decoded_data: ['PID is 6765.0, DOY is 211.0, B02 is 273.0, B04 is 424.0, B03 is 727.0272701273']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6865.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 6865.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '5', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '4', '3', '9', '9', '9']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6865.0, B02 is 263.0, B04 is 437.0, B03 is 699.0 B04 is 43999']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 263.0, PID is 6865.0, DOY is 211.0, B04 is 437.0, B03 is']\n",
      "prompt: B02 is 263.0, PID is 6865.0, DOY is 211.0, B04 is 437.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '6', '3', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '6', '3', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '4', '6', '1', '0', '8']]\n",
      "decoded_data: ['B02 is 263.0, PID is 6865.0, DOY is 211.0, B04 is 437.0, B03 is 699.0 B04 is 46108']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 437.0, DOY is 211.0, PID is 6865.0, B02 is 263.0, B03 is']\n",
      "prompt: B04 is 437.0, DOY is 211.0, PID is 6865.0, B02 is 263.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '3', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '3', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '3', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', '6', '.', '0', '.', '0']]\n",
      "decoded_data: ['B04 is 437.0, DOY is 211.0, PID is 6865.0, B02 is 263.0, B03 is 699.0 B03 is 6.0.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 263.0, PID is 6865.0, DOY is 211.0, B04 is 437.0, B03 is']\n",
      "prompt: B02 is 263.0, PID is 6865.0, DOY is 211.0, B04 is 437.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '6', '3', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '6', '3', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '4', '3', '9', '9', '9']]\n",
      "decoded_data: ['B02 is 263.0, PID is 6865.0, DOY is 211.0, B04 is 437.0, B03 is 699.0 B04 is 43999']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 263.0, PID is 6865.0, B04 is 437.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 263.0, PID is 6865.0, B04 is 437.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '3', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '3', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '4', '3', '.', '0', ',']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 263.0, PID is 6865.0, B04 is 437.0, B03 is 699.0 B04 is 43.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 263.0, B04 is 437.0, DOY is 211.0, PID is 6865.0, B03 is']\n",
      "prompt: B02 is 263.0, B04 is 437.0, DOY is 211.0, PID is 6865.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '6', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '5', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '6', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B03', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['B02 is 263.0, B04 is 437.0, DOY is 211.0, PID is 6865.0, B03 is 699.0 B04 is B03 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 437.0, B02 is 263.0, PID is 6865.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 437.0, B02 is 263.0, PID is 6865.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '3', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '5', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '3', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', '4', '6']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 437.0, B02 is 263.0, PID is 6865.0, B03 is 699.0 B04 is B04 is 46']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 437.0, B02 is 263.0, DOY is 211.0, PID is 6865.0, B03 is']\n",
      "prompt: B04 is 437.0, B02 is 263.0, DOY is 211.0, PID is 6865.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '3', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '5', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '3', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '9', '9', '9', '9', '9', '9', '.', '0', '.']]\n",
      "decoded_data: ['B04 is 437.0, B02 is 263.0, DOY is 211.0, PID is 6865.0, B03 is 699.0999999.0.']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 437.0, PID is 6865.0, B02 is 263.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 437.0, PID is 6865.0, B02 is 263.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '3', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 437.0, PID is 6865.0, B02 is 263.0, B03 is 699.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 437.0, DOY is 211.0, B02 is 263.0, PID is 6865.0, B03 is']\n",
      "prompt: B04 is 437.0, DOY is 211.0, B02 is 263.0, PID is 6865.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '3', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '3', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '5', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '3', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '3', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', '6', '3', '9', '9', '9']]\n",
      "decoded_data: ['B04 is 437.0, DOY is 211.0, B02 is 263.0, PID is 6865.0, B03 is 699.0 B03 is 63999']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6865.0, B04 is 437.0, B02 is 263.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 6865.0, B04 is 437.0, B02 is 263.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '3', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6865.0, B04 is 437.0, B02 is 263.0, B03 is 699.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6865.0, DOY is 211.0, B02 is 263.0, B04 is 437.0, B03 is']\n",
      "prompt: PID is 6865.0, DOY is 211.0, B02 is 263.0, B04 is 437.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '8', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '8', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['PID is 6865.0, DOY is 211.0, B02 is 263.0, B04 is 437.0, B03 is 699.0 PID is B04 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 263.0, DOY is 211.0, B04 is 437.0, PID is 6865.0, B03 is']\n",
      "prompt: B02 is 263.0, DOY is 211.0, B04 is 437.0, PID is 6865.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '6', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '5', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '6', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '.', '0', ',', '', 'B04', 'is', '', 'PID']]\n",
      "decoded_data: ['B02 is 263.0, DOY is 211.0, B04 is 437.0, PID is 6865.0, B03 is 699.07.0, B04 is PID']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6865.0, B02 is 263.0, B04 is 437.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 6865.0, B02 is 263.0, B04 is 437.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'DOY', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6865.0, B02 is 263.0, B04 is 437.0, B03 is 699.0 B04 is DOY is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 437.0, DOY is 211.0, PID is 6865.0, B02 is 263.0, B03 is']\n",
      "prompt: B04 is 437.0, DOY is 211.0, PID is 6865.0, B02 is 263.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '3', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '3', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 11%|         | 92/829 [02:38<17:45,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B04', 'is', '', '4', '3', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '3', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'DOY', 'is', '', 'DOY', 'is']]\n",
      "decoded_data: ['B04 is 437.0, DOY is 211.0, PID is 6865.0, B02 is 263.0, B03 is 699.0 B04 is DOY is DOY is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6965.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 6965.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '9', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '9', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '6', '8']]\n",
      "decoded_data: ['PID is 6965.0, DOY is 211.0, B04 is 507.0, B02 is 280.0, B03 is 687.0 B04 is PID is 68']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 507.0, B02 is 280.0, PID is 6965.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 507.0, B02 is 280.0, PID is 6965.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '5', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '6', '6']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 507.0, B02 is 280.0, PID is 6965.0, B03 is 687.0 B04 is PID is 66']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 280.0, PID is 6965.0, DOY is 211.0, B04 is 507.0, B03 is']\n",
      "prompt: B02 is 280.0, PID is 6965.0, DOY is 211.0, B04 is 507.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '4', '4', '6', '6', '1', '.', '0', '6']]\n",
      "decoded_data: ['B02 is 280.0, PID is 6965.0, DOY is 211.0, B04 is 507.0, B03 is 687.0644661.06']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 507.0, PID is 6965.0, B02 is 280.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 507.0, PID is 6965.0, B02 is 280.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '0', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '0', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'DOY', 'is']]\n",
      "decoded_data: ['B04 is 507.0, PID is 6965.0, B02 is 280.0, DOY is 211.0, B03 is 687.0 B04 is PID is DOY is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6965.0, B02 is 280.0, DOY is 211.0, B04 is 507.0, B03 is']\n",
      "prompt: PID is 6965.0, B02 is 280.0, DOY is 211.0, B04 is 507.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '9', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '9', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '6', '0']]\n",
      "decoded_data: ['PID is 6965.0, B02 is 280.0, DOY is 211.0, B04 is 507.0, B03 is 687.0 B04 is PID is 60']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 280.0, DOY is 211.0, PID is 6965.0, B04 is 507.0, B03 is']\n",
      "prompt: B02 is 280.0, DOY is 211.0, PID is 6965.0, B04 is 507.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '6', '0']]\n",
      "decoded_data: ['B02 is 280.0, DOY is 211.0, PID is 6965.0, B04 is 507.0, B03 is 687.0 PID is B04 is 60']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 507.0, PID is 6965.0, B02 is 280.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 507.0, PID is 6965.0, B02 is 280.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '0', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '0', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['B04 is 507.0, PID is 6965.0, B02 is 280.0, DOY is 211.0, B03 is 687.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6965.0, B02 is 280.0, DOY is 211.0, B04 is 507.0, B03 is']\n",
      "prompt: PID is 6965.0, B02 is 280.0, DOY is 211.0, B04 is 507.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '9', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '9', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '6', '6', '2', '6', '0']]\n",
      "decoded_data: ['PID is 6965.0, B02 is 280.0, DOY is 211.0, B04 is 507.0, B03 is 687.0 PID is 66260']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6965.0, DOY is 211.0, B04 is 507.0, B02 is 280.0, B03 is']\n",
      "prompt: PID is 6965.0, DOY is 211.0, B04 is 507.0, B02 is 280.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '9', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '9', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['PID is 6965.0, DOY is 211.0, B04 is 507.0, B02 is 280.0, B03 is 687.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 507.0, B02 is 280.0, PID is 6965.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 507.0, B02 is 280.0, PID is 6965.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '0', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '0', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '6', '8']]\n",
      "decoded_data: ['B04 is 507.0, B02 is 280.0, PID is 6965.0, DOY is 211.0, B03 is 687.0 B04 is PID is 68']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 507.0, B02 is 280.0, PID is 6965.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 507.0, B02 is 280.0, PID is 6965.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '5', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', 'DOY', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 507.0, B02 is 280.0, PID is 6965.0, B03 is 687.0 B04 is B04 is DOY is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 280.0, B04 is 507.0, PID is 6965.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 280.0, B04 is 507.0, PID is 6965.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '6', '8', '7', '6', '6']]\n",
      "decoded_data: ['B02 is 280.0, B04 is 507.0, PID is 6965.0, DOY is 211.0, B03 is 687.0 PID is 68766']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 280.0, B04 is 507.0, DOY is 211.0, PID is 6965.0, B03 is']\n",
      "prompt: B02 is 280.0, B04 is 507.0, DOY is 211.0, PID is 6965.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '5', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'DOY', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['B02 is 280.0, B04 is 507.0, DOY is 211.0, PID is 6965.0, B03 is 687.0 B04 is DOY is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 507.0, B02 is 280.0, PID is 6965.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 507.0, B02 is 280.0, PID is 6965.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '5', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '6', '0']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 507.0, B02 is 280.0, PID is 6965.0, B03 is 687.0 B04 is PID is 60']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 280.0, DOY is 211.0, PID is 6965.0, B04 is 507.0, B03 is']\n",
      "prompt: B02 is 280.0, DOY is 211.0, PID is 6965.0, B04 is 507.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '7', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 11%|         | 93/829 [02:41<21:02,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '2', '.', '0', '6']]\n",
      "decoded_data: ['B02 is 280.0, DOY is 211.0, PID is 6965.0, B04 is 507.0, B03 is 687.0 B04 is 52.06']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7065.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 7065.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '0', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '0', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '0', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '2', '9', '6', '6', '6']]\n",
      "decoded_data: ['PID is 7065.0, DOY is 211.0, B03 is 747.0, B04 is 540.0, B02 is 296.0 PID is 29666']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7065.0, DOY is 211.0, B04 is 540.0, B03 is 747.0, B02 is']\n",
      "prompt: PID is 7065.0, DOY is 211.0, B04 is 540.0, B03 is 747.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '0', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '0', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '2', '9', '6', '6', '6']]\n",
      "decoded_data: ['PID is 7065.0, DOY is 211.0, B04 is 540.0, B03 is 747.0, B02 is 296.0 PID is 29666']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 540.0, B03 is 747.0, PID is 7065.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 540.0, B03 is 747.0, PID is 7065.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '4', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '7', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '4', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '7', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '5', '6', '2', '9']]\n",
      "decoded_data: ['B04 is 540.0, B03 is 747.0, PID is 7065.0, DOY is 211.0, B02 is 296.0 PID is 75629']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 7065.0, B04 is 540.0, B03 is 747.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 7065.0, B04 is 540.0, B03 is 747.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '2', '9', '6', '6', '2', '9', '6', '.', '0']]\n",
      "decoded_data: ['DOY is 211.0, PID is 7065.0, B04 is 540.0, B03 is 747.0, B02 is 296.02966296.0']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 7065.0, B04 is 540.0, B03 is 747.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 7065.0, B04 is 540.0, B03 is 747.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '6', '6', '6', '.', '0', ',', '', 'PID']]\n",
      "decoded_data: ['DOY is 211.0, PID is 7065.0, B04 is 540.0, B03 is 747.0, B02 is 296.07666.0, PID']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7065.0, B04 is 540.0, DOY is 211.0, B03 is 747.0, B02 is']\n",
      "prompt: PID is 7065.0, B04 is 540.0, DOY is 211.0, B03 is 747.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '0', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '0', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '2', '9']]\n",
      "decoded_data: ['PID is 7065.0, B04 is 540.0, DOY is 211.0, B03 is 747.0, B02 is 296.0 B04 is PID is 29']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7065.0, DOY is 211.0, B03 is 747.0, B04 is 540.0, B02 is']\n",
      "prompt: PID is 7065.0, DOY is 211.0, B03 is 747.0, B04 is 540.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '0', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '0', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '0', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '0', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '6', '6', '2', '9']]\n",
      "decoded_data: ['PID is 7065.0, DOY is 211.0, B03 is 747.0, B04 is 540.0, B02 is 296.0 B04 is 56629']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 747.0, B04 is 540.0, PID is 7065.0, B02 is']\n",
      "prompt: DOY is 211.0, B03 is 747.0, B04 is 540.0, PID is 7065.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '0', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '5', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '0', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '2', '9']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 747.0, B04 is 540.0, PID is 7065.0, B02 is 296.0 PID is B04 is 29']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 540.0, B03 is 747.0, PID is 7065.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 540.0, B03 is 747.0, PID is 7065.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '4', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '7', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '4', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '7', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['B04 is 540.0, B03 is 747.0, PID is 7065.0, DOY is 211.0, B02 is 296.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 540.0, PID is 7065.0, DOY is 211.0, B03 is 747.0, B02 is']\n",
      "prompt: B04 is 540.0, PID is 7065.0, DOY is 211.0, B03 is 747.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '4', '0', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '4', '0', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['B04 is 540.0, PID is 7065.0, DOY is 211.0, B03 is 747.0, B02 is 296.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 540.0, B03 is 747.0, DOY is 211.0, PID is 7065.0, B02 is']\n",
      "prompt: B04 is 540.0, B03 is 747.0, DOY is 211.0, PID is 7065.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '4', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '5', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '4', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '2', '9', '6', '2', '9']]\n",
      "decoded_data: ['B04 is 540.0, B03 is 747.0, DOY is 211.0, PID is 7065.0, B02 is 296.0 PID is 29629']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7065.0, DOY is 211.0, B04 is 540.0, B03 is 747.0, B02 is']\n",
      "prompt: PID is 7065.0, DOY is 211.0, B04 is 540.0, B03 is 747.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '0', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '0', '6', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '6', '6', '6', '6', '.', '0', ',', '']]\n",
      "decoded_data: ['PID is 7065.0, DOY is 211.0, B04 is 540.0, B03 is 747.0, B02 is 296.076666.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 540.0, PID is 7065.0, B03 is 747.0, B02 is']\n",
      "prompt: DOY is 211.0, B04 is 540.0, PID is 7065.0, B03 is 747.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '0', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '0', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '2', '9']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 540.0, PID is 7065.0, B03 is 747.0, B02 is 296.0 PID is B04 is 29']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7065.0, B04 is 540.0, B03 is 747.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 7065.0, B04 is 540.0, B03 is 747.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '0', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '0', '6', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['PID is 7065.0, B04 is 540.0, B03 is 747.0, DOY is 211.0, B02 is 296.0 B04 is PID is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 540.0, PID is 7065.0, B03 is 747.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 540.0, PID is 7065.0, B03 is 747.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '4', '0', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 11%|        | 94/829 [02:43<22:57,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B04', 'is', '', '5', '4', '0', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '2', '9', '6', '6', '6']]\n",
      "decoded_data: ['B04 is 540.0, PID is 7065.0, B03 is 747.0, DOY is 211.0, B02 is 296.0 PID is 29666']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5266.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 5266.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '6', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B03', 'is', '', '5', '8']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5266.0, B02 is 355.0, B03 is 784.0, B04 is 586.0 PID is B03 is 58']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 784.0, DOY is 211.0, B02 is 355.0, PID is 5266.0, B04 is']\n",
      "prompt: B03 is 784.0, DOY is 211.0, B02 is 355.0, PID is 5266.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '8', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '6', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '8', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '8', '6', '6', '.']]\n",
      "decoded_data: ['B03 is 784.0, DOY is 211.0, B02 is 355.0, PID is 5266.0, B04 is 586.0 PID is 5866.']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 784.0, DOY is 211.0, PID is 5266.0, B02 is 355.0, B04 is']\n",
      "prompt: B03 is 784.0, DOY is 211.0, PID is 5266.0, B02 is 355.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '8', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '5', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '8', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '8', '6', '6', '.']]\n",
      "decoded_data: ['B03 is 784.0, DOY is 211.0, PID is 5266.0, B02 is 355.0, B04 is 586.0 PID is 5866.']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 784.0, PID is 5266.0, B02 is 355.0, B04 is']\n",
      "prompt: DOY is 211.0, B03 is 784.0, PID is 5266.0, B02 is 355.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '5', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '8', '6', '6', '.']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 784.0, PID is 5266.0, B02 is 355.0, B04 is 586.0 PID is 5866.']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5266.0, B02 is 355.0, B03 is 784.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 5266.0, B02 is 355.0, B03 is 784.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '4', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '8', '6', '6', '6']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5266.0, B02 is 355.0, B03 is 784.0, B04 is 586.0 PID is 58666']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5266.0, B03 is 784.0, B02 is 355.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 5266.0, B03 is 784.0, B02 is 355.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '5', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '8', '6', '.', '0', ',', '', 'PID', 'is']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5266.0, B03 is 784.0, B02 is 355.0, B04 is 586.0586.0, PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5266.0, B03 is 784.0, B02 is 355.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 5266.0, B03 is 784.0, B02 is 355.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '5', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '8', '6', '.', '0', '6', '.', '0', '.']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5266.0, B03 is 784.0, B02 is 355.0, B04 is 586.0586.06.0.']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 355.0, B03 is 784.0, PID is 5266.0, B04 is']\n",
      "prompt: DOY is 211.0, B02 is 355.0, B03 is 784.0, PID is 5266.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '6', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '8', '6', '6', '.']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 355.0, B03 is 784.0, PID is 5266.0, B04 is 586.0 PID is 5866.']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5266.0, DOY is 211.0, B02 is 355.0, B03 is 784.0, B04 is']\n",
      "prompt: PID is 5266.0, DOY is 211.0, B02 is 355.0, B03 is 784.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '2', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '4', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '2', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'PID', 'is', '', '5', '8']]\n",
      "decoded_data: ['PID is 5266.0, DOY is 211.0, B02 is 355.0, B03 is 784.0, B04 is 586.0 PID is PID is 58']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 784.0, B02 is 355.0, DOY is 211.0, PID is 5266.0, B04 is']\n",
      "prompt: B03 is 784.0, B02 is 355.0, DOY is 211.0, PID is 5266.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '8', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '6', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '8', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '8', '6', '6', '.']]\n",
      "decoded_data: ['B03 is 784.0, B02 is 355.0, DOY is 211.0, PID is 5266.0, B04 is 586.0 PID is 5866.']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 784.0, DOY is 211.0, PID is 5266.0, B02 is 355.0, B04 is']\n",
      "prompt: B03 is 784.0, DOY is 211.0, PID is 5266.0, B02 is 355.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '8', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '5', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '8', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '2', '7', '8', '6', '.', '0', ',', '']]\n",
      "decoded_data: ['B03 is 784.0, DOY is 211.0, PID is 5266.0, B02 is 355.0, B04 is 586.052786.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5266.0, DOY is 211.0, B03 is 784.0, B02 is 355.0, B04 is']\n",
      "prompt: PID is 5266.0, DOY is 211.0, B03 is 784.0, B02 is 355.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '2', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '5', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '2', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '8', '6', '6', '6']]\n",
      "decoded_data: ['PID is 5266.0, DOY is 211.0, B03 is 784.0, B02 is 355.0, B04 is 586.0 PID is 58666']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5266.0, B02 is 355.0, B03 is 784.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 5266.0, B02 is 355.0, B03 is 784.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '2', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '2', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B03', 'is', '', '5', '8']]\n",
      "decoded_data: ['PID is 5266.0, B02 is 355.0, B03 is 784.0, DOY is 211.0, B04 is 586.0 PID is B03 is 58']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 784.0, PID is 5266.0, B02 is 355.0, DOY is 211.0, B04 is']\n",
      "prompt: B03 is 784.0, PID is 5266.0, B02 is 355.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '8', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '8', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '8', '6', '.', '0', '9', '9', '6', '.']]\n",
      "decoded_data: ['B03 is 784.0, PID is 5266.0, B02 is 355.0, DOY is 211.0, B04 is 586.0586.0996.']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 355.0, B03 is 784.0, PID is 5266.0, DOY is 211.0, B04 is']\n",
      "prompt: B02 is 355.0, B03 is 784.0, PID is 5266.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '5', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 11%|        | 95/829 [02:45<24:23,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B02', 'is', '', '3', '5', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '2', '7', '8', '6']]\n",
      "decoded_data: ['B02 is 355.0, B03 is 784.0, PID is 5266.0, DOY is 211.0, B04 is 586.0 PID is 52786']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5366.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5366.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '3', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|        | 96/829 [02:45<18:10,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '5', '3', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '3', '7', '1', '8', '0', ',', '', 'PID', 'is']]\n",
      "decoded_data: ['PID is 5366.0, DOY is 211.0, B03 is 780.0, B04 is 588.0, B02 is 337.037180, PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5466.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 5466.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '6', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '6', '1', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '1', '1', '7', '1', '7', '.', '0', '.']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5466.0, B04 is 617.0, B02 is 331.0, B03 is 771.0711717.0.']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 617.0, B02 is 331.0, PID is 5466.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 617.0, B02 is 331.0, PID is 5466.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '1', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '1', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '1', '7', '1', '.', '0', ',', '', 'B04']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 617.0, B02 is 331.0, PID is 5466.0, B03 is 771.07171.0, B04']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 617.0, PID is 5466.0, DOY is 211.0, B02 is 331.0, B03 is']\n",
      "prompt: B04 is 617.0, PID is 5466.0, DOY is 211.0, B02 is 331.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '6', '1', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '6', '1', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '1', '7', '1', '7', '9', '0', '7', '9', '.']]\n",
      "decoded_data: ['B04 is 617.0, PID is 5466.0, DOY is 211.0, B02 is 331.0, B03 is 771.017179079.']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 617.0, DOY is 211.0, B02 is 331.0, PID is 5466.0, B03 is']\n",
      "prompt: B04 is 617.0, DOY is 211.0, B02 is 331.0, PID is 5466.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '6', '1', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '6', '1', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '1', '7', '1', '7', 'B02', 'is', '', '7']]\n",
      "decoded_data: ['B04 is 617.0, DOY is 211.0, B02 is 331.0, PID is 5466.0, B03 is 771.071717B02 is 7']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 617.0, B02 is 331.0, PID is 5466.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 617.0, B02 is 331.0, PID is 5466.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '6', '1', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|        | 97/829 [02:46<15:53,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B04', 'is', '', '6', '1', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '8', '3', '0', '2', '0', '7', '1', '7', '1']]\n",
      "decoded_data: ['B04 is 617.0, B02 is 331.0, PID is 5466.0, DOY is 211.0, B03 is 771.0830207171']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5566.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5566.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '5', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '5', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '9', '3', '5', '8', '.', '0', '7', '0']]\n",
      "decoded_data: ['PID is 5566.0, DOY is 211.0, B03 is 721.0, B02 is 287.0, B04 is 570.059358.070']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 287.0, DOY is 211.0, PID is 5566.0, B03 is 721.0, B04 is']\n",
      "prompt: B02 is 287.0, DOY is 211.0, PID is 5566.0, B03 is 721.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '8', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '8', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '9', '8', '7', '0']]\n",
      "decoded_data: ['B02 is 287.0, DOY is 211.0, PID is 5566.0, B03 is 721.0, B04 is 570.0 PID is 59870']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 721.0, B02 is 287.0, PID is 5566.0, B04 is']\n",
      "prompt: DOY is 211.0, B03 is 721.0, B02 is 287.0, PID is 5566.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '6', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '9', '6', '2', '1']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 721.0, B02 is 287.0, PID is 5566.0, B04 is 570.0 PID is 59621']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5566.0, B02 is 287.0, B03 is 721.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 5566.0, B02 is 287.0, B03 is 721.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'B04', 'is', '', '5', '2']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5566.0, B02 is 287.0, B03 is 721.0, B04 is 570.0 B03 is B04 is 52']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5566.0, B03 is 721.0, B02 is 287.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 5566.0, B03 is 721.0, B02 is 287.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '7', '0', '8', '7']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5566.0, B03 is 721.0, B02 is 287.0, B04 is 570.0 PID is 57087']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 287.0, B03 is 721.0, PID is 5566.0, DOY is 211.0, B04 is']\n",
      "prompt: B02 is 287.0, B03 is 721.0, PID is 5566.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '8', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '8', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '6', '2', '1', '.', '0', '.', '0']]\n",
      "decoded_data: ['B02 is 287.0, B03 is 721.0, PID is 5566.0, DOY is 211.0, B04 is 570.0 5621.0.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 721.0, DOY is 211.0, B02 is 287.0, PID is 5566.0, B04 is']\n",
      "prompt: B03 is 721.0, DOY is 211.0, B02 is 287.0, PID is 5566.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '2', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '6', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '2', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'PID', 'is', '', '5', '9']]\n",
      "decoded_data: ['B03 is 721.0, DOY is 211.0, B02 is 287.0, PID is 5566.0, B04 is 570.0 B03 is PID is 59']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5566.0, B03 is 721.0, B02 is 287.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 5566.0, B03 is 721.0, B02 is 287.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'PID', 'is', '', 'B03', 'is']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5566.0, B03 is 721.0, B02 is 287.0, B04 is 570.0 B03 is PID is B03 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5566.0, B02 is 287.0, DOY is 211.0, B03 is 721.0, B04 is']\n",
      "prompt: PID is 5566.0, B02 is 287.0, DOY is 211.0, B03 is 721.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '5', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '5', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '2', '1', '0', '8', '7', '0', '0']]\n",
      "decoded_data: ['PID is 5566.0, B02 is 287.0, DOY is 211.0, B03 is 721.0, B04 is 570.0 52108700']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5566.0, B02 is 287.0, B03 is 721.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 5566.0, B02 is 287.0, B03 is 721.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '5', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '5', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'PID', 'is', '', '5', '8']]\n",
      "decoded_data: ['PID is 5566.0, B02 is 287.0, B03 is 721.0, DOY is 211.0, B04 is 570.0 B03 is PID is 58']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5566.0, B02 is 287.0, B03 is 721.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 5566.0, B02 is 287.0, B03 is 721.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '5', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '5', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'PID', 'is', '', '5', '9']]\n",
      "decoded_data: ['PID is 5566.0, B02 is 287.0, B03 is 721.0, DOY is 211.0, B04 is 570.0 B03 is PID is 59']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5566.0, B02 is 287.0, DOY is 211.0, B03 is 721.0, B04 is']\n",
      "prompt: PID is 5566.0, B02 is 287.0, DOY is 211.0, B03 is 721.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '5', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '5', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '8', '0', '7', '0']]\n",
      "decoded_data: ['PID is 5566.0, B02 is 287.0, DOY is 211.0, B03 is 721.0, B04 is 570.0 PID is 58070']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 721.0, DOY is 211.0, B02 is 287.0, PID is 5566.0, B04 is']\n",
      "prompt: B03 is 721.0, DOY is 211.0, B02 is 287.0, PID is 5566.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '2', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '6', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '2', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B02', 'is', '', 'PID', 'is', '', '5', '1']]\n",
      "decoded_data: ['B03 is 721.0, DOY is 211.0, B02 is 287.0, PID is 5566.0, B04 is 570.0 B02 is PID is 51']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5566.0, B03 is 721.0, B02 is 287.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 5566.0, B03 is 721.0, B02 is 287.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'PID', 'is', '', 'DOY', 'is']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5566.0, B03 is 721.0, B02 is 287.0, B04 is 570.0 B03 is PID is DOY is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 287.0, PID is 5566.0, B03 is 721.0, DOY is 211.0, B04 is']\n",
      "prompt: B02 is 287.0, PID is 5566.0, B03 is 721.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '8', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 12%|        | 98/829 [02:49<19:24,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B02', 'is', '', '2', '8', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B03', 'is', '', '5', '7']]\n",
      "decoded_data: ['B02 is 287.0, PID is 5566.0, B03 is 721.0, DOY is 211.0, B04 is 570.0 PID is B03 is 57']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5666.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 5666.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '6', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '8', '4', '6', '.', '0', '3', '9']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5666.0, B02 is 297.0, B03 is 728.0, B04 is 546.0 5846.039']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 728.0, PID is 5666.0, B02 is 297.0, B04 is']\n",
      "prompt: DOY is 211.0, B03 is 728.0, PID is 5666.0, B02 is 297.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '8', '4', '6', '4']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 728.0, PID is 5666.0, B02 is 297.0, B04 is 546.0 PID is 58464']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 728.0, PID is 5666.0, B02 is 297.0, DOY is 211.0, B04 is']\n",
      "prompt: B03 is 728.0, PID is 5666.0, B02 is 297.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '2', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '2', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B03', 'is', '', '5', '8']]\n",
      "decoded_data: ['B03 is 728.0, PID is 5666.0, B02 is 297.0, DOY is 211.0, B04 is 546.0 PID is B03 is 58']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 297.0, PID is 5666.0, B03 is 728.0, DOY is 211.0, B04 is']\n",
      "prompt: B02 is 297.0, PID is 5666.0, B03 is 728.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '9', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '9', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '1', '8', '4', '6']]\n",
      "decoded_data: ['B02 is 297.0, PID is 5666.0, B03 is 728.0, DOY is 211.0, B04 is 546.0 PID is 51846']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5666.0, DOY is 211.0, B02 is 297.0, B03 is 728.0, B04 is']\n",
      "prompt: PID is 5666.0, DOY is 211.0, B02 is 297.0, B03 is 728.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '6', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '8', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '6', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'DOY', 'is', '', '5', '1', '9', '6', '.']]\n",
      "decoded_data: ['PID is 5666.0, DOY is 211.0, B02 is 297.0, B03 is 728.0, B04 is 546.0 DOY is 5196.']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 297.0, B03 is 728.0, PID is 5666.0, DOY is 211.0, B04 is']\n",
      "prompt: B02 is 297.0, B03 is 728.0, PID is 5666.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '9', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '9', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '9', '9', '9', '9']]\n",
      "decoded_data: ['B02 is 297.0, B03 is 728.0, PID is 5666.0, DOY is 211.0, B04 is 546.0 PID is 59999']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5666.0, B03 is 728.0, DOY is 211.0, B02 is 297.0, B04 is']\n",
      "prompt: PID is 5666.0, B03 is 728.0, DOY is 211.0, B02 is 297.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '6', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '6', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'DOY', 'is', '', '2', '3']]\n",
      "decoded_data: ['PID is 5666.0, B03 is 728.0, DOY is 211.0, B02 is 297.0, B04 is 546.0 PID is DOY is 23']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 728.0, DOY is 211.0, PID is 5666.0, B02 is 297.0, B04 is']\n",
      "prompt: B03 is 728.0, DOY is 211.0, PID is 5666.0, B02 is 297.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '2', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '2', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '8', '4', '6', '.']]\n",
      "decoded_data: ['B03 is 728.0, DOY is 211.0, PID is 5666.0, B02 is 297.0, B04 is 546.0 PID is 5846.']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 728.0, B02 is 297.0, PID is 5666.0, B04 is']\n",
      "prompt: DOY is 211.0, B03 is 728.0, B02 is 297.0, PID is 5666.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '8', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '6', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '8', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '7', '8', '8', '4']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 728.0, B02 is 297.0, PID is 5666.0, B04 is 546.0 PID is 57884']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 728.0, PID is 5666.0, B02 is 297.0, B04 is']\n",
      "prompt: DOY is 211.0, B03 is 728.0, PID is 5666.0, B02 is 297.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '8', '4', '6', '4']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 728.0, PID is 5666.0, B02 is 297.0, B04 is 546.0 PID is 58464']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5666.0, B03 is 728.0, B02 is 297.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 5666.0, B03 is 728.0, B02 is 297.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '8', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '8', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '8', '6', '4', '6']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5666.0, B03 is 728.0, B02 is 297.0, B04 is 546.0 PID is 58646']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 728.0, DOY is 211.0, PID is 5666.0, B02 is 297.0, B04 is']\n",
      "prompt: B03 is 728.0, DOY is 211.0, PID is 5666.0, B02 is 297.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '2', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '2', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '5', '5', '8', '4']]\n",
      "decoded_data: ['B03 is 728.0, DOY is 211.0, PID is 5666.0, B02 is 297.0, B04 is 546.0 PID is 55584']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5666.0, B02 is 297.0, B03 is 728.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 5666.0, B02 is 297.0, B03 is 728.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '6', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '6', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '4', '6', '4', '6']]\n",
      "decoded_data: ['PID is 5666.0, B02 is 297.0, B03 is 728.0, DOY is 211.0, B04 is 546.0 PID is 54646']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 297.0, PID is 5666.0, DOY is 211.0, B03 is 728.0, B04 is']\n",
      "prompt: B02 is 297.0, PID is 5666.0, DOY is 211.0, B03 is 728.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '9', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '8', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '9', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '5', '1', '3', '4']]\n",
      "decoded_data: ['B02 is 297.0, PID is 5666.0, DOY is 211.0, B03 is 728.0, B04 is 546.0 PID is 55134']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 728.0, DOY is 211.0, PID is 5666.0, B02 is 297.0, B04 is']\n",
      "prompt: B03 is 728.0, DOY is 211.0, PID is 5666.0, B02 is 297.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '2', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '7', '.', '0', ',', '', 'B04', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 12%|        | 99/829 [02:51<21:56,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B03', 'is', '', '7', '2', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '8', '2', '3', '.', '0', '3', '.']]\n",
      "decoded_data: ['B03 is 728.0, DOY is 211.0, PID is 5666.0, B02 is 297.0, B04 is 546.0 5823.03.']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5766.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 5766.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '6', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'PID', 'is', '', '5', '9']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5766.0, B02 is 319.0, B03 is 744.0, B04 is 545.0 B03 is PID is 59']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5766.0, DOY is 211.0, B02 is 319.0, B03 is 744.0, B04 is']\n",
      "prompt: PID is 5766.0, DOY is 211.0, B02 is 319.0, B03 is 744.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '7', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '4', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '7', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '7', '6', '5', '7']]\n",
      "decoded_data: ['PID is 5766.0, DOY is 211.0, B02 is 319.0, B03 is 744.0, B04 is 545.0 PID is 57657']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 319.0, PID is 5766.0, DOY is 211.0, B03 is 744.0, B04 is']\n",
      "prompt: B02 is 319.0, PID is 5766.0, DOY is 211.0, B03 is 744.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '1', '9', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '4', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '1', '9', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '3', '8', '7', '9']]\n",
      "decoded_data: ['B02 is 319.0, PID is 5766.0, DOY is 211.0, B03 is 744.0, B04 is 545.0 PID is 53879']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 744.0, PID is 5766.0, DOY is 211.0, B02 is 319.0, B04 is']\n",
      "prompt: B03 is 744.0, PID is 5766.0, DOY is 211.0, B02 is 319.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '4', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '4', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '7', '8', '7', '.', '0', '5', '8']]\n",
      "decoded_data: ['B03 is 744.0, PID is 5766.0, DOY is 211.0, B02 is 319.0, B04 is 545.0 5787.058']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5766.0, DOY is 211.0, B02 is 319.0, B03 is 744.0, B04 is']\n",
      "prompt: PID is 5766.0, DOY is 211.0, B02 is 319.0, B03 is 744.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '7', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '4', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '7', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '8', '7', '1', '4']]\n",
      "decoded_data: ['PID is 5766.0, DOY is 211.0, B02 is 319.0, B03 is 744.0, B04 is 545.0 PID is 58714']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5766.0, B02 is 319.0, B03 is 744.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 5766.0, B02 is 319.0, B03 is 744.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '7', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '7', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '9', '7', '1', '.', '0', '.', '0', '4']]\n",
      "decoded_data: ['PID is 5766.0, B02 is 319.0, B03 is 744.0, DOY is 211.0, B04 is 545.05971.0.04']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 319.0, PID is 5766.0, B03 is 744.0, DOY is 211.0, B04 is']\n",
      "prompt: B02 is 319.0, PID is 5766.0, B03 is 744.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '1', '9', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '1', '9', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '7', '9', '9', '8', '7', '3', '.', '0']]\n",
      "decoded_data: ['B02 is 319.0, PID is 5766.0, B03 is 744.0, DOY is 211.0, B04 is 545.05799873.0']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5766.0, B03 is 744.0, B02 is 319.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 5766.0, B03 is 744.0, B02 is 319.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B02', 'is', '', '5', '7']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5766.0, B03 is 744.0, B02 is 319.0, B04 is 545.0 PID is B02 is 57']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5766.0, B03 is 744.0, B02 is 319.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 5766.0, B03 is 744.0, B02 is 319.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '1', '.', '0', ',', '', 'PID', 'is', '', 'B03']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5766.0, B03 is 744.0, B02 is 319.0, B04 is 545.01.0, PID is B03']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5766.0, B02 is 319.0, DOY is 211.0, B03 is 744.0, B04 is']\n",
      "prompt: PID is 5766.0, B02 is 319.0, DOY is 211.0, B03 is 744.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '7', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '4', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '7', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '7', '1', '.', '0', '4', '5', '9', '.']]\n",
      "decoded_data: ['PID is 5766.0, B02 is 319.0, DOY is 211.0, B03 is 744.0, B04 is 545.0571.0459.']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 744.0, DOY is 211.0, PID is 5766.0, B02 is 319.0, B04 is']\n",
      "prompt: B03 is 744.0, DOY is 211.0, PID is 5766.0, B02 is 319.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '4', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '4', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '8', '7', '9', '9', '9', '.', '0', '.']]\n",
      "decoded_data: ['B03 is 744.0, DOY is 211.0, PID is 5766.0, B02 is 319.0, B04 is 545.0587999.0.']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 319.0, B03 is 744.0, PID is 5766.0, B04 is']\n",
      "prompt: DOY is 211.0, B02 is 319.0, B03 is 744.0, PID is 5766.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '6', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '8', '7', '.', '0', '.', '0', '.', '0', ',']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 319.0, B03 is 744.0, PID is 5766.0, B04 is 545.087.0.0.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 319.0, B03 is 744.0, DOY is 211.0, PID is 5766.0, B04 is']\n",
      "prompt: B02 is 319.0, B03 is 744.0, DOY is 211.0, PID is 5766.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '1', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '6', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '1', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', 'DOY', 'is', '', 'B02', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['B02 is 319.0, B03 is 744.0, DOY is 211.0, PID is 5766.0, B04 is 545.05DOY is B02 is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5766.0, B02 is 319.0, DOY is 211.0, B03 is 744.0, B04 is']\n",
      "prompt: PID is 5766.0, B02 is 319.0, DOY is 211.0, B03 is 744.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '7', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '4', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '7', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '8', '7', '1', '4']]\n",
      "decoded_data: ['PID is 5766.0, B02 is 319.0, DOY is 211.0, B03 is 744.0, B04 is 545.0 PID is 58714']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 744.0, PID is 5766.0, B02 is 319.0, B04 is']\n",
      "prompt: DOY is 211.0, B03 is 744.0, PID is 5766.0, B02 is 319.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '9', '.', '0', ',', '', 'B04', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 12%|        | 100/829 [02:53<23:50,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '1', '0', '5', '.', '0', ',', '', 'PID', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 744.0, PID is 5766.0, B02 is 319.0, B04 is 545.0105.0, PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5866.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 5866.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '6', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '5', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5866.0, B04 is 521.0, B02 is 325.0, B03 is 672.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 521.0, PID is 5866.0, B02 is 325.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 521.0, PID is 5866.0, B02 is 325.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '2', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '2', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '6', '9']]\n",
      "decoded_data: ['B04 is 521.0, PID is 5866.0, B02 is 325.0, DOY is 211.0, B03 is 672.0 B04 is PID is 69']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 325.0, PID is 5866.0, B04 is 521.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 325.0, PID is 5866.0, B04 is 521.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '2', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '2', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '6', '7', '9', '3', '9']]\n",
      "decoded_data: ['B02 is 325.0, PID is 5866.0, B04 is 521.0, DOY is 211.0, B03 is 696.0 B04 is 67939']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 521.0, DOY is 211.0, PID is 5866.0, B02 is 325.0, B03 is']\n",
      "prompt: B04 is 521.0, DOY is 211.0, PID is 5866.0, B02 is 325.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '2', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '5', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '2', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '5', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '0', '6', '4', '0', '6', '0', '6', '.']]\n",
      "decoded_data: ['B04 is 521.0, DOY is 211.0, PID is 5866.0, B02 is 325.0, B03 is 695.060640606.']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5866.0, B02 is 325.0, DOY is 211.0, B04 is 521.0, B03 is']\n",
      "prompt: PID is 5866.0, B02 is 325.0, DOY is 211.0, B04 is 521.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '8', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '8', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '2', '.', '0', ',', '', 'B04', 'is', '']]\n",
      "decoded_data: ['PID is 5866.0, B02 is 325.0, DOY is 211.0, B04 is 521.0, B03 is 695.062.0, B04 is ']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 521.0, B02 is 325.0, PID is 5866.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 521.0, B02 is 325.0, PID is 5866.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '6', '2', '0', '5', '6']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 521.0, B02 is 325.0, PID is 5866.0, B03 is 679.0 PID is 62056']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 325.0, DOY is 211.0, B04 is 521.0, PID is 5866.0, B03 is']\n",
      "prompt: B02 is 325.0, DOY is 211.0, B04 is 521.0, PID is 5866.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '2', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '2', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '0', '6', '0', '6', '0', '6', '.', '0']]\n",
      "decoded_data: ['B02 is 325.0, DOY is 211.0, B04 is 521.0, PID is 5866.0, B03 is 695.06060606.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 325.0, DOY is 211.0, B04 is 521.0, PID is 5866.0, B03 is']\n",
      "prompt: B02 is 325.0, DOY is 211.0, B04 is 521.0, PID is 5866.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '2', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '2', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '6', '2', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', '4', '.']]\n",
      "decoded_data: ['B02 is 325.0, DOY is 211.0, B04 is 521.0, PID is 5866.0, B03 is 629.0 B04 is B04 is 4.']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 325.0, PID is 5866.0, B04 is 521.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 325.0, PID is 5866.0, B04 is 521.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '1', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|        | 101/829 [02:55<21:59,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '2', '0', ',', '', 'PID', 'is', '', '6', '9']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 325.0, PID is 5866.0, B04 is 521.0, B03 is 672.020, PID is 69']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5966.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 5966.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '6', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '3', '3', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '2', '.', '0', ',', '', 'B03', 'is', '', '4', '5', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'DOY', 'is', '', 'B04', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5966.0, B04 is 332.0, B02 is 252.0, B03 is 456.0 DOY is B04 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 332.0, DOY is 211.0, B02 is 252.0, PID is 5966.0, B03 is']\n",
      "prompt: B04 is 332.0, DOY is 211.0, B02 is 252.0, PID is 5966.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '3', '3', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '3', '3', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '4', '5', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '4', '5', '6', '.', '0']]\n",
      "decoded_data: ['B04 is 332.0, DOY is 211.0, B02 is 252.0, PID is 5966.0, B03 is 456.0 B04 is 456.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 252.0, DOY is 211.0, B04 is 332.0, PID is 5966.0, B03 is']\n",
      "prompt: B02 is 252.0, DOY is 211.0, B04 is 332.0, PID is 5966.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '3', '3', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '3', '3', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '4', '5', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '4', '7', 'is', '', 'PID']]\n",
      "decoded_data: ['B02 is 252.0, DOY is 211.0, B04 is 332.0, PID is 5966.0, B03 is 456.0 B04 is 47 is PID']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5966.0, B04 is 332.0, B02 is 252.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 5966.0, B04 is 332.0, B02 is 252.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '3', '3', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '3', '3', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '2', '.', '0', ',', '', 'B03', 'is', '', '4', '5', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '4', '5']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5966.0, B04 is 332.0, B02 is 252.0, B03 is 456.0 B04 is PID is 45']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 332.0, B02 is 252.0, DOY is 211.0, PID is 5966.0, B03 is']\n",
      "prompt: B04 is 332.0, B02 is 252.0, DOY is 211.0, PID is 5966.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '3', '3', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '3', '3', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '4', '5', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '6', '.', '0', '6']]\n",
      "decoded_data: ['B04 is 332.0, B02 is 252.0, DOY is 211.0, PID is 5966.0, B03 is 456.0 B04 is 56.06']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 332.0, B02 is 252.0, PID is 5966.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 332.0, B02 is 252.0, PID is 5966.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '3', '3', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '3', '3', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '4', '5', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '6', '.', '0', '6', '.', '0', '6', '.']]\n",
      "decoded_data: ['B04 is 332.0, B02 is 252.0, PID is 5966.0, DOY is 211.0, B03 is 456.056.06.06.']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 252.0, B04 is 332.0, DOY is 211.0, PID is 5966.0, B03 is']\n",
      "prompt: B02 is 252.0, B04 is 332.0, DOY is 211.0, PID is 5966.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '3', '3', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '3', '3', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '4', '5', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '6', '.', '0', ',', '', 'B04', 'is', '']]\n",
      "decoded_data: ['B02 is 252.0, B04 is 332.0, DOY is 211.0, PID is 5966.0, B03 is 456.056.0, B04 is ']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5966.0, DOY is 211.0, B04 is 332.0, B02 is 252.0, B03 is']\n",
      "prompt: PID is 5966.0, DOY is 211.0, B04 is 332.0, B02 is 252.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '9', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '3', '3', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '9', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '3', '3', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '2', '.', '0', ',', '', 'B03', 'is', '', '4', '5', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '4', '5', '6', '.', '0', ',', '', 'B04', 'is']]\n",
      "decoded_data: ['PID is 5966.0, DOY is 211.0, B04 is 332.0, B02 is 252.0, B03 is 456.0456.0, B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 252.0, DOY is 211.0, PID is 5966.0, B04 is 332.0, B03 is']\n",
      "prompt: B02 is 252.0, DOY is 211.0, PID is 5966.0, B04 is 332.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '3', '3', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '3', '3', '2', '.', '0', ',', '', 'B03', 'is', '', '4', '5', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '5', '6', '3', '.', '0', '.', '0']]\n",
      "decoded_data: ['B02 is 252.0, DOY is 211.0, PID is 5966.0, B04 is 332.0, B03 is 456.0 4563.0.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 252.0, B04 is 332.0, DOY is 211.0, PID is 5966.0, B03 is']\n",
      "prompt: B02 is 252.0, B04 is 332.0, DOY is 211.0, PID is 5966.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '3', '3', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '3', '3', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '4', '5', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '4', '.', '0', '2', '.']]\n",
      "decoded_data: ['B02 is 252.0, B04 is 332.0, DOY is 211.0, PID is 5966.0, B03 is 456.0 B04 is 4.02.']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 332.0, B02 is 252.0, DOY is 211.0, PID is 5966.0, B03 is']\n",
      "prompt: B04 is 332.0, B02 is 252.0, DOY is 211.0, PID is 5966.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '3', '3', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '3', '3', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '4', '5', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '6', '5', '6', '.']]\n",
      "decoded_data: ['B04 is 332.0, B02 is 252.0, DOY is 211.0, PID is 5966.0, B03 is 456.0 PID is 5656.']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 252.0, B04 is 332.0, DOY is 211.0, PID is 5966.0, B03 is']\n",
      "prompt: B02 is 252.0, B04 is 332.0, DOY is 211.0, PID is 5966.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '3', '3', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '3', '3', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '4', '5', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '.', '0', '.', '0', ',', '', 'B04']]\n",
      "decoded_data: ['B02 is 252.0, B04 is 332.0, DOY is 211.0, PID is 5966.0, B03 is 456.0 4.0.0, B04']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 252.0, PID is 5966.0, B04 is 332.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 252.0, PID is 5966.0, B04 is 332.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '5', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '3', '3', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '5', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '3', '3', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '4', '5', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '5', '6', '3', '.', '0', ',', '']]\n",
      "decoded_data: ['B02 is 252.0, PID is 5966.0, B04 is 332.0, DOY is 211.0, B03 is 456.0 4563.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 332.0, PID is 5966.0, DOY is 211.0, B02 is 252.0, B03 is']\n",
      "prompt: B04 is 332.0, PID is 5966.0, DOY is 211.0, B02 is 252.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '3', '3', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '3', '3', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '2', '.', '0', ',', '', 'B03', 'is', '', '4', '5', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '4', '7', '6', '5', '6']]\n",
      "decoded_data: ['B04 is 332.0, PID is 5966.0, DOY is 211.0, B02 is 252.0, B03 is 456.0 B04 is 47656']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5966.0, B02 is 252.0, DOY is 211.0, B04 is 332.0, B03 is']\n",
      "prompt: PID is 5966.0, B02 is 252.0, DOY is 211.0, B04 is 332.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '9', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '3', '3', '2', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 12%|        | 102/829 [02:57<23:29,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '5', '9', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '3', '3', '2', '.', '0', ',', '', 'B03', 'is', '', '4', '5', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '5', '6', '5', '6', '3', '.', '0']]\n",
      "decoded_data: ['PID is 5966.0, B02 is 252.0, DOY is 211.0, B04 is 332.0, B03 is 456.0 456563.0']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6066.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 6066.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '6', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '6', '.', '0', ',', '', 'B03', 'is', '', '5', '0', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B03', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6066.0, B04 is 526.0, B03 is 507.0, B02 is 321.0 B04 is B03 is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 507.0, PID is 6066.0, DOY is 211.0, B04 is 526.0, B02 is']\n",
      "prompt: B03 is 507.0, PID is 6066.0, DOY is 211.0, B04 is 526.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '5', '0', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '6', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '5', '0', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '3', '7', '.', '0', ',', '', 'PID', 'is', '']]\n",
      "decoded_data: ['B03 is 507.0, PID is 6066.0, DOY is 211.0, B04 is 526.0, B02 is 327.037.0, PID is ']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 526.0, B03 is 507.0, PID is 6066.0, B02 is']\n",
      "prompt: DOY is 211.0, B04 is 526.0, B03 is 507.0, PID is 6066.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '6', '.', '0', ',', '', 'B03', 'is', '', '5', '0', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '6', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '6', '.', '0', ',', '', 'B03', 'is', '', '5', '0', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '3', '2', '7', '9', '1']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 526.0, B03 is 507.0, PID is 6066.0, B02 is 321.0 PID is 32791']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 526.0, B03 is 507.0, PID is 6066.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 526.0, B03 is 507.0, PID is 6066.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '2', '6', '.', '0', ',', '', 'B03', 'is', '', '5', '0', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '2', '6', '.', '0', ',', '', 'B03', 'is', '', '5', '0', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '3', '7', '1', '2', '1']]\n",
      "decoded_data: ['B04 is 526.0, B03 is 507.0, PID is 6066.0, DOY is 211.0, B02 is 327.0 PID is 37121']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 507.0, B04 is 526.0, PID is 6066.0, DOY is 211.0, B02 is']\n",
      "prompt: B03 is 507.0, B04 is 526.0, PID is 6066.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '5', '0', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '5', '0', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '2', '7']]\n",
      "decoded_data: ['B03 is 507.0, B04 is 526.0, PID is 6066.0, DOY is 211.0, B02 is 327.0 PID is B04 is 27']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6066.0, DOY is 211.0, B03 is 507.0, B04 is 526.0, B02 is']\n",
      "prompt: PID is 6066.0, DOY is 211.0, B03 is 507.0, B04 is 526.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '0', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '5', '0', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '6', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '0', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '5', '0', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '3', '.', '0', ',', '', 'PID', 'is', '', 'B04']]\n",
      "decoded_data: ['PID is 6066.0, DOY is 211.0, B03 is 507.0, B04 is 526.0, B02 is 327.03.0, PID is B04']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 526.0, DOY is 211.0, B03 is 507.0, PID is 6066.0, B02 is']\n",
      "prompt: B04 is 526.0, DOY is 211.0, B03 is 507.0, PID is 6066.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '2', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '5', '0', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '6', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '2', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '5', '0', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '3', '.', '0', ',', '', 'PID', 'is', '', '2']]\n",
      "decoded_data: ['B04 is 526.0, DOY is 211.0, B03 is 507.0, PID is 6066.0, B02 is 327.03.0, PID is 2']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 526.0, DOY is 211.0, B03 is 507.0, PID is 6066.0, B02 is']\n",
      "prompt: B04 is 526.0, DOY is 211.0, B03 is 507.0, PID is 6066.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '2', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '5', '0', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '6', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '2', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '5', '0', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '3', '.', '0', ',', '', 'PID', 'is', '', 'B04']]\n",
      "decoded_data: ['B04 is 526.0, DOY is 211.0, B03 is 507.0, PID is 6066.0, B02 is 327.03.0, PID is B04']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 507.0, DOY is 211.0, PID is 6066.0, B04 is 526.0, B02 is']\n",
      "prompt: B03 is 507.0, DOY is 211.0, PID is 6066.0, B04 is 526.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '5', '0', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '6', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '5', '0', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '3', '7', '4', '3', '.', '0', ',', '', 'PID']]\n",
      "decoded_data: ['B03 is 507.0, DOY is 211.0, PID is 6066.0, B04 is 526.0, B02 is 327.03743.0, PID']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6066.0, B04 is 526.0, B03 is 507.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 6066.0, B04 is 526.0, B03 is 507.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '0', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '6', '.', '0', ',', '', 'B03', 'is', '', '5', '0', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '0', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '6', '.', '0', ',', '', 'B03', 'is', '', '5', '0', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'PID', 'is', '', '3', '1']]\n",
      "decoded_data: ['PID is 6066.0, B04 is 526.0, B03 is 507.0, DOY is 211.0, B02 is 327.0 B03 is PID is 31']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 526.0, DOY is 211.0, PID is 6066.0, B03 is 507.0, B02 is']\n",
      "prompt: B04 is 526.0, DOY is 211.0, PID is 6066.0, B03 is 507.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '2', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '5', '0', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '2', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '5', '0', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '3', '1', '4', '3', '1', '9', '1', '.']]\n",
      "decoded_data: ['B04 is 526.0, DOY is 211.0, PID is 6066.0, B03 is 507.0, B02 is 327.0 3143191.']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 526.0, DOY is 211.0, B03 is 507.0, PID is 6066.0, B02 is']\n",
      "prompt: B04 is 526.0, DOY is 211.0, B03 is 507.0, PID is 6066.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '2', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '5', '0', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '6', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '2', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '5', '0', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '4', '3', '.', '0', ',', '', 'PID', 'is', '']]\n",
      "decoded_data: ['B04 is 526.0, DOY is 211.0, B03 is 507.0, PID is 6066.0, B02 is 327.043.0, PID is ']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 526.0, B03 is 507.0, PID is 6066.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 526.0, B03 is 507.0, PID is 6066.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '2', '6', '.', '0', ',', '', 'B03', 'is', '', '5', '0', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '2', '6', '.', '0', ',', '', 'B03', 'is', '', '5', '0', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '3', '1', '4', '9', '1', '.', '0', ',', '']]\n",
      "decoded_data: ['B04 is 526.0, B03 is 507.0, PID is 6066.0, DOY is 211.0, B02 is 327.031491.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 507.0, DOY is 211.0, PID is 6066.0, B04 is 526.0, B02 is']\n",
      "prompt: B03 is 507.0, DOY is 211.0, PID is 6066.0, B04 is 526.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '5', '0', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '6', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '5', '0', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '3', '7', '1', '9', '1', '2', '1', '9', '.']]\n",
      "decoded_data: ['B03 is 507.0, DOY is 211.0, PID is 6066.0, B04 is 526.0, B02 is 327.037191219.']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 526.0, B03 is 507.0, DOY is 211.0, PID is 6066.0, B02 is']\n",
      "prompt: B04 is 526.0, B03 is 507.0, DOY is 211.0, PID is 6066.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '2', '6', '.', '0', ',', '', 'B03', 'is', '', '5', '0', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '6', '.', '0', ',', '', 'B02', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 12%|        | 103/829 [02:59<24:57,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B04', 'is', '', '5', '2', '6', '.', '0', ',', '', 'B03', 'is', '', '5', '0', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '3', '4']]\n",
      "decoded_data: ['B04 is 526.0, B03 is 507.0, DOY is 211.0, PID is 6066.0, B02 is 327.0 B04 is PID is 34']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6166.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 6166.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '6', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '5', '.', '0', ',', '', 'B03', 'is', '', '6', '4', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '3', '8', '4', '3', '8']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6166.0, B04 is 525.0, B03 is 640.0, B02 is 343.0 B04 is 38438']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 525.0, PID is 6166.0, DOY is 211.0, B03 is 640.0, B02 is']\n",
      "prompt: B04 is 525.0, PID is 6166.0, DOY is 211.0, B03 is 640.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '2', '5', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '4', '0', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '2', '5', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '4', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['B04 is 525.0, PID is 6166.0, DOY is 211.0, B03 is 640.0, B02 is 343.0 PID is B04 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6166.0, DOY is 211.0, B04 is 525.0, B03 is 640.0, B02 is']\n",
      "prompt: PID is 6166.0, DOY is 211.0, B04 is 525.0, B03 is 640.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '1', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '5', '.', '0', ',', '', 'B03', 'is', '', '6', '4', '0', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '1', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '5', '.', '0', ',', '', 'B03', 'is', '', '6', '4', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B03', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['PID is 6166.0, DOY is 211.0, B04 is 525.0, B03 is 640.0, B02 is 343.0 B04 is B03 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 525.0, B03 is 640.0, PID is 6166.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 525.0, B03 is 640.0, PID is 6166.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '2', '5', '.', '0', ',', '', 'B03', 'is', '', '6', '4', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '2', '5', '.', '0', ',', '', 'B03', 'is', '', '6', '4', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '3', '4', '3', '4', '3']]\n",
      "decoded_data: ['B04 is 525.0, B03 is 640.0, PID is 6166.0, DOY is 211.0, B02 is 343.0 PID is 34343']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6166.0, DOY is 211.0, B04 is 525.0, B03 is 640.0, B02 is']\n",
      "prompt: PID is 6166.0, DOY is 211.0, B04 is 525.0, B03 is 640.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '1', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '5', '.', '0', ',', '', 'B03', 'is', '', '6', '4', '0', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '1', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '5', '.', '0', ',', '', 'B03', 'is', '', '6', '4', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '3', '9', '0', '.', '0', ',', '', 'B04']]\n",
      "decoded_data: ['PID is 6166.0, DOY is 211.0, B04 is 525.0, B03 is 640.0, B02 is 343.0 390.0, B04']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 525.0, PID is 6166.0, B03 is 640.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 525.0, PID is 6166.0, B03 is 640.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '2', '5', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '6', '4', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '2', '5', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '6', '4', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '3', '5', '4', '3', '4', '3', '4', '3']]\n",
      "decoded_data: ['B04 is 525.0, PID is 6166.0, B03 is 640.0, DOY is 211.0, B02 is 343.0 35434343']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6166.0, B03 is 640.0, B04 is 525.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 6166.0, B03 is 640.0, B04 is 525.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '6', '4', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '5', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '6', '4', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B03', 'is', '', '5', '4']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6166.0, B03 is 640.0, B04 is 525.0, B02 is 343.0 B04 is B03 is 54']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 640.0, B04 is 525.0, DOY is 211.0, PID is 6166.0, B02 is']\n",
      "prompt: B03 is 640.0, B04 is 525.0, DOY is 211.0, PID is 6166.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '4', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '6', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '6', '4', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '3', '.', '0', ',', '']]\n",
      "decoded_data: ['B03 is 640.0, B04 is 525.0, DOY is 211.0, PID is 6166.0, B02 is 343.0 B04 is 3.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 525.0, PID is 6166.0, DOY is 211.0, B03 is 640.0, B02 is']\n",
      "prompt: B04 is 525.0, PID is 6166.0, DOY is 211.0, B03 is 640.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '2', '5', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '4', '0', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '2', '5', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '4', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '3', '4', '3', '1', '4']]\n",
      "decoded_data: ['B04 is 525.0, PID is 6166.0, DOY is 211.0, B03 is 640.0, B02 is 343.0 PID is 34314']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 640.0, DOY is 211.0, B04 is 525.0, PID is 6166.0, B02 is']\n",
      "prompt: B03 is 640.0, DOY is 211.0, B04 is 525.0, PID is 6166.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '4', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '5', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '6', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '6', '4', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '5', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '6', '4']]\n",
      "decoded_data: ['B03 is 640.0, DOY is 211.0, B04 is 525.0, PID is 6166.0, B02 is 343.0 B04 is PID is 64']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6166.0, B04 is 525.0, B03 is 640.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 6166.0, B04 is 525.0, B03 is 640.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '1', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '5', '.', '0', ',', '', 'B03', 'is', '', '6', '4', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '1', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '5', '.', '0', ',', '', 'B03', 'is', '', '6', '4', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '.', '0', '7', '8', '4', '3', '.', '0', ',']]\n",
      "decoded_data: ['PID is 6166.0, B04 is 525.0, B03 is 640.0, DOY is 211.0, B02 is 343.0.07843.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 640.0, B04 is 525.0, DOY is 211.0, PID is 6166.0, B02 is']\n",
      "prompt: B03 is 640.0, B04 is 525.0, DOY is 211.0, PID is 6166.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '4', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '6', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '6', '4', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B03', 'is', '', 'DOY', 'is']]\n",
      "decoded_data: ['B03 is 640.0, B04 is 525.0, DOY is 211.0, PID is 6166.0, B02 is 343.0 B04 is B03 is DOY is']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 640.0, PID is 6166.0, B04 is 525.0, DOY is 211.0, B02 is']\n",
      "prompt: B03 is 640.0, PID is 6166.0, B04 is 525.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '4', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '6', '4', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '5', '4']]\n",
      "decoded_data: ['B03 is 640.0, PID is 6166.0, B04 is 525.0, DOY is 211.0, B02 is 343.0 B04 is PID is 54']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 525.0, B03 is 640.0, DOY is 211.0, PID is 6166.0, B02 is']\n",
      "prompt: B04 is 525.0, B03 is 640.0, DOY is 211.0, PID is 6166.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '2', '5', '.', '0', ',', '', 'B03', 'is', '', '6', '4', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '6', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '2', '5', '.', '0', ',', '', 'B03', 'is', '', '6', '4', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '.', '0', ',', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['B04 is 525.0, B03 is 640.0, DOY is 211.0, PID is 6166.0, B02 is 343.0.0, PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 525.0, B03 is 640.0, DOY is 211.0, PID is 6166.0, B02 is']\n",
      "prompt: B04 is 525.0, B03 is 640.0, DOY is 211.0, PID is 6166.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '2', '5', '.', '0', ',', '', 'B03', 'is', '', '6', '4', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '6', '.', '0', ',', '', 'B02', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 13%|        | 104/829 [03:01<25:48,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B04', 'is', '', '5', '2', '5', '.', '0', ',', '', 'B03', 'is', '', '6', '4', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '4', '3', '.', '0', '.', '0', ',', '', 'B03']]\n",
      "decoded_data: ['B04 is 525.0, B03 is 640.0, DOY is 211.0, PID is 6166.0, B02 is 343.043.0.0, B03']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6266.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 6266.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '2', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '2', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '6', '4', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B02', 'is', '', '6', '2', '8', '6', '2']]\n",
      "decoded_data: ['PID is 6266.0, DOY is 211.0, B04 is 449.0, B02 is 264.0, B03 is 642.0 B02 is 62862']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 264.0, PID is 6266.0, B04 is 449.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 264.0, PID is 6266.0, B04 is 449.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '6', '4', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '6', '4', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '4', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '6', '2', '.', '0', ',', '', 'B04', 'is']]\n",
      "decoded_data: ['B02 is 264.0, PID is 6266.0, B04 is 449.0, DOY is 211.0, B03 is 642.0 62.0, B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6266.0, B04 is 449.0, DOY is 211.0, B02 is 264.0, B03 is']\n",
      "prompt: PID is 6266.0, B04 is 449.0, DOY is 211.0, B02 is 264.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '2', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '2', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '6', '4', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '6', '2', '8', '6', '2', '.', '0', ',']]\n",
      "decoded_data: ['PID is 6266.0, B04 is 449.0, DOY is 211.0, B02 is 264.0, B03 is 642.0 62862.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 264.0, B04 is 449.0, PID is 6266.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 264.0, B04 is 449.0, PID is 6266.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '6', '4', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '6', '9', '6', '2', '.', '0', ',', '']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 264.0, B04 is 449.0, PID is 6266.0, B03 is 642.0 6962.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 449.0, PID is 6266.0, DOY is 211.0, B02 is 264.0, B03 is']\n",
      "prompt: B04 is 449.0, PID is 6266.0, DOY is 211.0, B02 is 264.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '4', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '4', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '6', '4', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B02', 'is', '', 'B04', 'is', '', 'DOY', 'is']]\n",
      "decoded_data: ['B04 is 449.0, PID is 6266.0, DOY is 211.0, B02 is 264.0, B03 is 642.0 B02 is B04 is DOY is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 264.0, PID is 6266.0, DOY is 211.0, B04 is 449.0, B03 is']\n",
      "prompt: B02 is 264.0, PID is 6266.0, DOY is 211.0, B04 is 449.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '6', '4', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '9', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '6', '4', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '9', '.', '0', ',', '', 'B03', 'is', '', '6', '4', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '6', '4']]\n",
      "decoded_data: ['B02 is 264.0, PID is 6266.0, DOY is 211.0, B04 is 449.0, B03 is 642.0 PID is B04 is 64']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6266.0, B02 is 264.0, B04 is 449.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 6266.0, B02 is 264.0, B04 is 449.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '9', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '9', '.', '0', ',', '', 'B03', 'is', '', '6', '4', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '3', '.', '0', '8', '6']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6266.0, B02 is 264.0, B04 is 449.0, B03 is 642.0 B04 is 3.086']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 264.0, B04 is 449.0, PID is 6266.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 264.0, B04 is 449.0, PID is 6266.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '4', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B02', 'is', '', 'B03', 'is']]\n",
      "decoded_data: ['B02 is 264.0, B04 is 449.0, PID is 6266.0, DOY is 211.0, B03 is 642.0 B04 is B02 is B03 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6266.0, DOY is 211.0, B04 is 449.0, B02 is 264.0, B03 is']\n",
      "prompt: PID is 6266.0, DOY is 211.0, B04 is 449.0, B02 is 264.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '2', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '2', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '4', '.', '0', ',', '', 'B03', 'is', '', '6', '4', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '6', '2', '8', '6', '2']]\n",
      "decoded_data: ['PID is 6266.0, DOY is 211.0, B04 is 449.0, B02 is 264.0, B03 is 642.0 B04 is 62862']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 264.0, DOY is 211.0, PID is 6266.0, B04 is 449.0, B03 is']\n",
      "prompt: B02 is 264.0, DOY is 211.0, PID is 6266.0, B04 is 449.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '9', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '9', '.', '0', ',', '', 'B03', 'is', '', '6', '4', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '6', '2', '.', '0', '8', '6', '8', '.']]\n",
      "decoded_data: ['B02 is 264.0, DOY is 211.0, PID is 6266.0, B04 is 449.0, B03 is 642.0 62.0868.']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6266.0, B02 is 264.0, B04 is 449.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 6266.0, B02 is 264.0, B04 is 449.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '9', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '9', '.', '0', ',', '', 'B03', 'is', '', '6', '4', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '2', '.', '0', '.', '0', ',', '', 'B04']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6266.0, B02 is 264.0, B04 is 449.0, B03 is 642.062.0.0, B04']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6266.0, B04 is 449.0, B02 is 264.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 6266.0, B04 is 449.0, B02 is 264.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '2', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '2', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '4', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '2', '8', '6', '4', '2', '.', '0', ',']]\n",
      "decoded_data: ['PID is 6266.0, B04 is 449.0, B02 is 264.0, DOY is 211.0, B03 is 642.0628642.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 264.0, B04 is 449.0, PID is 6266.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 264.0, B04 is 449.0, PID is 6266.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '6', '4', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '6', '4', '2', '.', '0', '.', '0', ',']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 264.0, B04 is 449.0, PID is 6266.0, B03 is 642.0 642.0.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 449.0, B02 is 264.0, PID is 6266.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 449.0, B02 is 264.0, PID is 6266.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '4', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '4', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '6', '4', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '6', '2', '.', '0', ',', '', 'B02', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 449.0, B02 is 264.0, PID is 6266.0, B03 is 642.0 62.0, B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 264.0, PID is 6266.0, B04 is 449.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 264.0, PID is 6266.0, B04 is 449.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '4', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '9', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 13%|        | 105/829 [03:04<26:05,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '4', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '9', '.', '0', ',', '', 'B03', 'is', '', '6', '4', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'DOY', 'is', '', 'B04', 'is', '', '4', '0']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 264.0, PID is 6266.0, B04 is 449.0, B03 is 642.0 DOY is B04 is 40']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6366.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 6366.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '6', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'DOY', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6366.0, B02 is 243.0, B04 is 426.0, B03 is 706.0 B04 is DOY is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 243.0, PID is 6366.0, B04 is 426.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 243.0, PID is 6366.0, B04 is 426.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '3', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '3', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'DOY', 'is', '', 'DOY', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 243.0, PID is 6366.0, B04 is 426.0, B03 is 706.0 B04 is DOY is DOY is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 243.0, B04 is 426.0, PID is 6366.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 243.0, B04 is 426.0, PID is 6366.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '4', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '4', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B02', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['B02 is 243.0, B04 is 426.0, PID is 6366.0, DOY is 211.0, B03 is 706.0 B04 is B02 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6366.0, B02 is 243.0, B04 is 426.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 6366.0, B02 is 243.0, B04 is 426.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', '4', '2']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6366.0, B02 is 243.0, B04 is 426.0, B03 is 706.0 B04 is B04 is 42']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 243.0, B04 is 426.0, DOY is 211.0, PID is 6366.0, B03 is']\n",
      "prompt: B02 is 243.0, B04 is 426.0, DOY is 211.0, PID is 6366.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '4', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '4', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', '4', '7']]\n",
      "decoded_data: ['B02 is 243.0, B04 is 426.0, DOY is 211.0, PID is 6366.0, B03 is 706.0 B04 is B04 is 47']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 426.0, B02 is 243.0, PID is 6366.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 426.0, B02 is 243.0, PID is 6366.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '3', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '3', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', '4', '2']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 426.0, B02 is 243.0, PID is 6366.0, B03 is 706.0 B04 is B04 is 42']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6366.0, B04 is 426.0, B02 is 243.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 6366.0, B04 is 426.0, B02 is 243.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '7', '0', '6', '.', '0', ',', '', 'B04']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6366.0, B04 is 426.0, B02 is 243.0, B03 is 706.0 706.0, B04']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 426.0, PID is 6366.0, DOY is 211.0, B02 is 243.0, B03 is']\n",
      "prompt: B04 is 426.0, PID is 6366.0, DOY is 211.0, B02 is 243.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '2', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '2', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '6', '7', '0', '6', '7']]\n",
      "decoded_data: ['B04 is 426.0, PID is 6366.0, DOY is 211.0, B02 is 243.0, B03 is 706.0 PID is 67067']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6366.0, B02 is 243.0, B04 is 426.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 6366.0, B02 is 243.0, B04 is 426.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'DOY', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6366.0, B02 is 243.0, B04 is 426.0, B03 is 706.0 B04 is DOY is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 426.0, B02 is 243.0, PID is 6366.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 426.0, B02 is 243.0, PID is 6366.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '2', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '3', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '2', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '3', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '9']]\n",
      "decoded_data: ['B04 is 426.0, B02 is 243.0, PID is 6366.0, DOY is 211.0, B03 is 706.0 B04 is PID is 79']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6366.0, DOY is 211.0, B02 is 243.0, B04 is 426.0, B03 is']\n",
      "prompt: PID is 6366.0, DOY is 211.0, B02 is 243.0, B04 is 426.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '3', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '3', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '1']]\n",
      "decoded_data: ['PID is 6366.0, DOY is 211.0, B02 is 243.0, B04 is 426.0, B03 is 706.0 B04 is PID is 71']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 426.0, PID is 6366.0, DOY is 211.0, B02 is 243.0, B03 is']\n",
      "prompt: B04 is 426.0, PID is 6366.0, DOY is 211.0, B02 is 243.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '2', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '2', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', '4', '3']]\n",
      "decoded_data: ['B04 is 426.0, PID is 6366.0, DOY is 211.0, B02 is 243.0, B03 is 706.0 B04 is B04 is 43']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 243.0, B04 is 426.0, DOY is 211.0, PID is 6366.0, B03 is']\n",
      "prompt: B02 is 243.0, B04 is 426.0, DOY is 211.0, PID is 6366.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '4', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '4', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '7', '9', '4', '7', '9']]\n",
      "decoded_data: ['B02 is 243.0, B04 is 426.0, DOY is 211.0, PID is 6366.0, B03 is 706.0 B04 is 79479']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 243.0, B04 is 426.0, PID is 6366.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 243.0, B04 is 426.0, PID is 6366.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', '4', '.']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 243.0, B04 is 426.0, PID is 6366.0, B03 is 706.0 B04 is B04 is 4.']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 243.0, DOY is 211.0, PID is 6366.0, B04 is 426.0, B03 is']\n",
      "prompt: B02 is 243.0, DOY is 211.0, PID is 6366.0, B04 is 426.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '4', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '6', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 13%|        | 106/829 [03:06<26:30,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B02', 'is', '', '2', '4', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '1', '4', '6', '4']]\n",
      "decoded_data: ['B02 is 243.0, DOY is 211.0, PID is 6366.0, B04 is 426.0, B03 is 706.0 PID is 71464']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6466.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 6466.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '4', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '4', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '8', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'PID', 'is', '', 'DOY', 'is']]\n",
      "decoded_data: ['PID is 6466.0, DOY is 211.0, B03 is 737.0, B02 is 278.0, B04 is 458.0 B03 is PID is DOY is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6466.0, B02 is 278.0, B03 is 737.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 6466.0, B02 is 278.0, B03 is 737.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '4', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '4', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '4', '5', '8', '2', '3']]\n",
      "decoded_data: ['PID is 6466.0, B02 is 278.0, B03 is 737.0, DOY is 211.0, B04 is 458.0 PID is 45823']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 737.0, PID is 6466.0, DOY is 211.0, B02 is 278.0, B04 is']\n",
      "prompt: B03 is 737.0, PID is 6466.0, DOY is 211.0, B02 is 278.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '3', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '8', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '3', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '8', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B02', 'is', '', '4', '5']]\n",
      "decoded_data: ['B03 is 737.0, PID is 6466.0, DOY is 211.0, B02 is 278.0, B04 is 458.0 PID is B02 is 45']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6466.0, B02 is 278.0, DOY is 211.0, B03 is 737.0, B04 is']\n",
      "prompt: PID is 6466.0, B02 is 278.0, DOY is 211.0, B03 is 737.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '4', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '4', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'DOY', 'is', '', 'B02', 'is', '', 'B03', 'is']]\n",
      "decoded_data: ['PID is 6466.0, B02 is 278.0, DOY is 211.0, B03 is 737.0, B04 is 458.0 DOY is B02 is B03 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 737.0, DOY is 211.0, PID is 6466.0, B02 is 278.0, B04 is']\n",
      "prompt: B03 is 737.0, DOY is 211.0, PID is 6466.0, B02 is 278.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '3', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '8', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '3', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '8', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', '4', '5', '8', '3', '.']]\n",
      "decoded_data: ['B03 is 737.0, DOY is 211.0, PID is 6466.0, B02 is 278.0, B04 is 458.0 B03 is 4583.']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 737.0, DOY is 211.0, PID is 6466.0, B02 is 278.0, B04 is']\n",
      "prompt: B03 is 737.0, DOY is 211.0, PID is 6466.0, B02 is 278.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '3', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '8', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '3', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '8', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '8', '7', '2', '3']]\n",
      "decoded_data: ['B03 is 737.0, DOY is 211.0, PID is 6466.0, B02 is 278.0, B04 is 458.0 PID is 58723']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 278.0, DOY is 211.0, PID is 6466.0, B03 is 737.0, B04 is']\n",
      "prompt: B02 is 278.0, DOY is 211.0, PID is 6466.0, B03 is 737.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '7', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '7', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'DOY', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['B02 is 278.0, DOY is 211.0, PID is 6466.0, B03 is 737.0, B04 is 458.0 B03 is DOY is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6466.0, B02 is 278.0, DOY is 211.0, B03 is 737.0, B04 is']\n",
      "prompt: PID is 6466.0, B02 is 278.0, DOY is 211.0, B03 is 737.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '4', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '4', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'DOY', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['PID is 6466.0, B02 is 278.0, DOY is 211.0, B03 is 737.0, B04 is 458.0 PID is DOY is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6466.0, B02 is 278.0, B03 is 737.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 6466.0, B02 is 278.0, B03 is 737.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'DOY', 'is', '', '5', '8']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6466.0, B02 is 278.0, B03 is 737.0, B04 is 458.0 B03 is DOY is 58']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 278.0, PID is 6466.0, B03 is 737.0, DOY is 211.0, B04 is']\n",
      "prompt: B02 is 278.0, PID is 6466.0, B03 is 737.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '7', '8', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '7', '8', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B03', 'is', '', '4', '2']]\n",
      "decoded_data: ['B02 is 278.0, PID is 6466.0, B03 is 737.0, DOY is 211.0, B04 is 458.0 PID is B03 is 42']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 737.0, DOY is 211.0, B02 is 278.0, PID is 6466.0, B04 is']\n",
      "prompt: B03 is 737.0, DOY is 211.0, B02 is 278.0, PID is 6466.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '3', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '8', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '6', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '3', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '8', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'B03', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['B03 is 737.0, DOY is 211.0, B02 is 278.0, PID is 6466.0, B04 is 458.0 B03 is B03 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 737.0, B02 is 278.0, DOY is 211.0, PID is 6466.0, B04 is']\n",
      "prompt: B03 is 737.0, B02 is 278.0, DOY is 211.0, PID is 6466.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '3', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '6', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '3', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'DOY', 'is', '', 'B02', 'is', '', '5', '8']]\n",
      "decoded_data: ['B03 is 737.0, B02 is 278.0, DOY is 211.0, PID is 6466.0, B04 is 458.0 DOY is B02 is 58']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6466.0, B03 is 737.0, B02 is 278.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 6466.0, B03 is 737.0, B02 is 278.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '4', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '4', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B03', 'is', '', 'B03', 'is']]\n",
      "decoded_data: ['PID is 6466.0, B03 is 737.0, B02 is 278.0, DOY is 211.0, B04 is 458.0 PID is B03 is B03 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6466.0, B03 is 737.0, B02 is 278.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 6466.0, B03 is 737.0, B02 is 278.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '4', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '4', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B03', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['PID is 6466.0, B03 is 737.0, B02 is 278.0, DOY is 211.0, B04 is 458.0 PID is B03 is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 278.0, PID is 6466.0, B03 is 737.0, B04 is']\n",
      "prompt: DOY is 211.0, B02 is 278.0, PID is 6466.0, B03 is 737.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '8', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '7', '.', '0', ',', '', 'B04', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 13%|        | 107/829 [03:08<26:45,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '8', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'B04', 'is', '', '4', '5']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 278.0, PID is 6466.0, B03 is 737.0, B04 is 458.0 B03 is B04 is 45']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6566.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 6566.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '7', '0', ',', '', 'B03', 'is', '']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6566.0, B03 is 700.0, B02 is 317.0, B04 is 517.0 570, B03 is ']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 317.0, B03 is 700.0, PID is 6566.0, DOY is 211.0, B04 is']\n",
      "prompt: B02 is 317.0, B03 is 700.0, PID is 6566.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '1', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '1', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '1', '0', '5', '7', '8', '9', '.']]\n",
      "decoded_data: ['B02 is 317.0, B03 is 700.0, PID is 6566.0, DOY is 211.0, B04 is 517.0 5105789.']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6566.0, DOY is 211.0, B02 is 317.0, B03 is 700.0, B04 is']\n",
      "prompt: PID is 6566.0, DOY is 211.0, B02 is 317.0, B03 is 700.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '5', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '5', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '0', '5', '0', '5']]\n",
      "decoded_data: ['PID is 6566.0, DOY is 211.0, B02 is 317.0, B03 is 700.0, B04 is 508.0 PID is 50505']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6566.0, B03 is 700.0, DOY is 211.0, B02 is 317.0, B04 is']\n",
      "prompt: PID is 6566.0, B03 is 700.0, DOY is 211.0, B02 is 317.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '5', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '5', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '2', '8', '2', '8']]\n",
      "decoded_data: ['PID is 6566.0, B03 is 700.0, DOY is 211.0, B02 is 317.0, B04 is 517.0 PID is 52828']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 317.0, DOY is 211.0, PID is 6566.0, B03 is 700.0, B04 is']\n",
      "prompt: B02 is 317.0, DOY is 211.0, PID is 6566.0, B03 is 700.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '1', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '1', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'DOY', 'is', '', 'B03', 'is']]\n",
      "decoded_data: ['B02 is 317.0, DOY is 211.0, PID is 6566.0, B03 is 700.0, B04 is 492.0 PID is DOY is B03 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 700.0, PID is 6566.0, DOY is 211.0, B02 is 317.0, B04 is']\n",
      "prompt: B03 is 700.0, PID is 6566.0, DOY is 211.0, B02 is 317.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '4', '5', '5', '8', '.', '0', ',', '', 'PID']]\n",
      "decoded_data: ['B03 is 700.0, PID is 6566.0, DOY is 211.0, B02 is 317.0, B04 is 512.04558.0, PID']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 700.0, DOY is 211.0, B02 is 317.0, PID is 6566.0, B04 is']\n",
      "prompt: B03 is 700.0, DOY is 211.0, B02 is 317.0, PID is 6566.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '6', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', '5', '7', '8', '7', '.']]\n",
      "decoded_data: ['B03 is 700.0, DOY is 211.0, B02 is 317.0, PID is 6566.0, B04 is 517.0 B03 is 5787.']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6566.0, B03 is 700.0, B02 is 317.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 6566.0, B03 is 700.0, B02 is 317.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '5', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '5', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '7', '8', '7', '8', '7', '8', '2']]\n",
      "decoded_data: ['PID is 6566.0, B03 is 700.0, B02 is 317.0, DOY is 211.0, B04 is 517.0 57878782']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 700.0, DOY is 211.0, PID is 6566.0, B02 is 317.0, B04 is']\n",
      "prompt: B03 is 700.0, DOY is 211.0, PID is 6566.0, B02 is 317.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '1', '7', '4', '4']]\n",
      "decoded_data: ['B03 is 700.0, DOY is 211.0, PID is 6566.0, B02 is 317.0, B04 is 510.0 PID is 51744']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 700.0, B02 is 317.0, DOY is 211.0, PID is 6566.0, B04 is']\n",
      "prompt: B03 is 700.0, B02 is 317.0, DOY is 211.0, PID is 6566.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '6', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '7', '8', '7', '8']]\n",
      "decoded_data: ['B03 is 700.0, B02 is 317.0, DOY is 211.0, PID is 6566.0, B04 is 517.0 PID is 57878']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 317.0, PID is 6566.0, DOY is 211.0, B03 is 700.0, B04 is']\n",
      "prompt: B02 is 317.0, PID is 6566.0, DOY is 211.0, B03 is 700.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '1', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '1', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '1', '7', '2', '8']]\n",
      "decoded_data: ['B02 is 317.0, PID is 6566.0, DOY is 211.0, B03 is 700.0, B04 is 510.0 PID is 51728']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 700.0, DOY is 211.0, PID is 6566.0, B02 is 317.0, B04 is']\n",
      "prompt: B03 is 700.0, DOY is 211.0, PID is 6566.0, B02 is 317.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '2', '4', '5', '1']]\n",
      "decoded_data: ['B03 is 700.0, DOY is 211.0, PID is 6566.0, B02 is 317.0, B04 is 510.0 PID is 52451']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 700.0, DOY is 211.0, B02 is 317.0, PID is 6566.0, B04 is']\n",
      "prompt: B03 is 700.0, DOY is 211.0, B02 is 317.0, PID is 6566.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '6', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '7', '0', '.', '0', 'is', '', 'PID']]\n",
      "decoded_data: ['B03 is 700.0, DOY is 211.0, B02 is 317.0, PID is 6566.0, B04 is 517.0 570.0 is PID']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6566.0, DOY is 211.0, B03 is 700.0, B02 is 317.0, B04 is']\n",
      "prompt: PID is 6566.0, DOY is 211.0, B03 is 700.0, B02 is 317.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '5', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '5', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'PID', 'is', '', '5', '8']]\n",
      "decoded_data: ['PID is 6566.0, DOY is 211.0, B03 is 700.0, B02 is 317.0, B04 is 517.0 B03 is PID is 58']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6566.0, B03 is 700.0, DOY is 211.0, B02 is 317.0, B04 is']\n",
      "prompt: PID is 6566.0, B03 is 700.0, DOY is 211.0, B02 is 317.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '5', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '7', '.', '0', ',', '', 'B04', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 13%|        | 108/829 [03:11<27:16,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '6', '5', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '5', '5', '5', '5']]\n",
      "decoded_data: ['PID is 6566.0, B03 is 700.0, DOY is 211.0, B02 is 317.0, B04 is 455.0 PID is 55555']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6666.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 6666.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '6', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'PID', 'is', '', 'DOY', 'is']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6666.0, B02 is 314.0, B03 is 687.0, B04 is 519.0 B03 is PID is DOY is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6666.0, B02 is 314.0, DOY is 211.0, B03 is 687.0, B04 is']\n",
      "prompt: PID is 6666.0, B02 is 314.0, DOY is 211.0, B03 is 687.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '6', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '6', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', '6', '4', '8', '1', '.']]\n",
      "decoded_data: ['PID is 6666.0, B02 is 314.0, DOY is 211.0, B03 is 687.0, B04 is 482.0 B03 is 6481.']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 314.0, PID is 6666.0, B03 is 687.0, B04 is']\n",
      "prompt: DOY is 211.0, B02 is 314.0, PID is 6666.0, B03 is 687.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', '5', '8', '5', '2', '7']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 314.0, PID is 6666.0, B03 is 687.0, B04 is 501.0 B03 is 58527']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 314.0, B03 is 687.0, PID is 6666.0, DOY is 211.0, B04 is']\n",
      "prompt: B02 is 314.0, B03 is 687.0, PID is 6666.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '.', '0', '1', '.', '0', ',', '', 'B02', 'is']]\n",
      "decoded_data: ['B02 is 314.0, B03 is 687.0, PID is 6666.0, DOY is 211.0, B04 is 501.0.01.0, B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 687.0, B02 is 314.0, DOY is 211.0, PID is 6666.0, B04 is']\n",
      "prompt: B03 is 687.0, B02 is 314.0, DOY is 211.0, PID is 6666.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '8', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '6', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '6', '8', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B02', 'is', '', '5', '6', '9', '2', '.']]\n",
      "decoded_data: ['B03 is 687.0, B02 is 314.0, DOY is 211.0, PID is 6666.0, B04 is 487.0 B02 is 5692.']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 687.0, B02 is 314.0, PID is 6666.0, DOY is 211.0, B04 is']\n",
      "prompt: B03 is 687.0, B02 is 314.0, PID is 6666.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '8', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '6', '8', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B02', 'is', '', '5', '6', '8', '1', '.']]\n",
      "decoded_data: ['B03 is 687.0, B02 is 314.0, PID is 6666.0, DOY is 211.0, B04 is 487.0 B02 is 5681.']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6666.0, B03 is 687.0, B02 is 314.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 6666.0, B03 is 687.0, B02 is 314.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '6', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '6', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', '5', '1', '.', '0', ',']]\n",
      "decoded_data: ['PID is 6666.0, B03 is 687.0, B02 is 314.0, DOY is 211.0, B04 is 501.0 B03 is 51.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 314.0, PID is 6666.0, B03 is 687.0, B04 is']\n",
      "prompt: DOY is 211.0, B02 is 314.0, PID is 6666.0, B03 is 687.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', '5', '1', '.', '0', ',']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 314.0, PID is 6666.0, B03 is 687.0, B04 is 501.0 B03 is 51.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 687.0, B02 is 314.0, PID is 6666.0, DOY is 211.0, B04 is']\n",
      "prompt: B03 is 687.0, B02 is 314.0, PID is 6666.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '8', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '6', '8', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '2', '3', '1', '9']]\n",
      "decoded_data: ['B03 is 687.0, B02 is 314.0, PID is 6666.0, DOY is 211.0, B04 is 501.0 PID is 52319']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 314.0, PID is 6666.0, B03 is 687.0, DOY is 211.0, B04 is']\n",
      "prompt: B02 is 314.0, PID is 6666.0, B03 is 687.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '2', '6', '2', '.', '0', '1', '.']]\n",
      "decoded_data: ['B02 is 314.0, PID is 6666.0, B03 is 687.0, DOY is 211.0, B04 is 501.0 5262.01.']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 687.0, PID is 6666.0, B02 is 314.0, B04 is']\n",
      "prompt: DOY is 211.0, B03 is 687.0, PID is 6666.0, B02 is 314.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '6', '9', '1', '8']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 687.0, PID is 6666.0, B02 is 314.0, B04 is 448.0 PID is 56918']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6666.0, DOY is 211.0, B02 is 314.0, B03 is 687.0, B04 is']\n",
      "prompt: PID is 6666.0, DOY is 211.0, B02 is 314.0, B03 is 687.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '6', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '6', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', '5', '7', '9', '.', '0']]\n",
      "decoded_data: ['PID is 6666.0, DOY is 211.0, B02 is 314.0, B03 is 687.0, B04 is 501.0 B03 is 579.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 314.0, B03 is 687.0, PID is 6666.0, DOY is 211.0, B04 is']\n",
      "prompt: B02 is 314.0, B03 is 687.0, PID is 6666.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '1', '9', '.', '0', ',', '', 'B02', 'is']]\n",
      "decoded_data: ['B02 is 314.0, B03 is 687.0, PID is 6666.0, DOY is 211.0, B04 is 501.0519.0, B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6666.0, B02 is 314.0, DOY is 211.0, B03 is 687.0, B04 is']\n",
      "prompt: PID is 6666.0, B02 is 314.0, DOY is 211.0, B03 is 687.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '6', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '6', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'PID', 'is', '', '7', '1']]\n",
      "decoded_data: ['PID is 6666.0, B02 is 314.0, DOY is 211.0, B03 is 687.0, B04 is 501.0 B03 is PID is 71']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6666.0, DOY is 211.0, B03 is 687.0, B02 is 314.0, B04 is']\n",
      "prompt: PID is 6666.0, DOY is 211.0, B03 is 687.0, B02 is 314.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '6', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B04', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 13%|        | 109/829 [03:13<27:47,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '6', '6', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '4', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '1', '.', '0', ',']]\n",
      "decoded_data: ['PID is 6666.0, DOY is 211.0, B03 is 687.0, B02 is 314.0, B04 is 448.0 PID is 51.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6766.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 6766.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '6', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '1', '4', '2', '.', '0', '0', '.', '0']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6766.0, B04 is 492.0, B02 is 290.0, B03 is 694.06142.00.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 492.0, PID is 6766.0, DOY is 211.0, B02 is 290.0, B03 is']\n",
      "prompt: B04 is 492.0, PID is 6766.0, DOY is 211.0, B02 is 290.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '6', '9', '4', '4', '4']]\n",
      "decoded_data: ['B04 is 492.0, PID is 6766.0, DOY is 211.0, B02 is 290.0, B03 is 694.0 PID is 69444']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 492.0, B02 is 290.0, PID is 6766.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 492.0, B02 is 290.0, PID is 6766.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', '6', '.', '0', '8', '0']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 492.0, B02 is 290.0, PID is 6766.0, B03 is 694.0 B03 is 6.080']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 492.0, PID is 6766.0, B02 is 290.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 492.0, PID is 6766.0, B02 is 290.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '6', '9']]\n",
      "decoded_data: ['B04 is 492.0, PID is 6766.0, B02 is 290.0, DOY is 211.0, B03 is 694.0 B04 is PID is 69']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 290.0, DOY is 211.0, PID is 6766.0, B04 is 492.0, B03 is']\n",
      "prompt: B02 is 290.0, DOY is 211.0, PID is 6766.0, B04 is 492.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '4', '0', '0', '0', '0']]\n",
      "decoded_data: ['B02 is 290.0, DOY is 211.0, PID is 6766.0, B04 is 492.0, B03 is 694.0 B04 is 40000']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 290.0, PID is 6766.0, DOY is 211.0, B04 is 492.0, B03 is']\n",
      "prompt: B02 is 290.0, PID is 6766.0, DOY is 211.0, B04 is 492.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '4', '8', '0', '0', '0']]\n",
      "decoded_data: ['B02 is 290.0, PID is 6766.0, DOY is 211.0, B04 is 492.0, B03 is 694.0 B04 is 48000']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6766.0, B02 is 290.0, DOY is 211.0, B04 is 492.0, B03 is']\n",
      "prompt: PID is 6766.0, B02 is 290.0, DOY is 211.0, B04 is 492.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '7', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '7', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '6', '4', '8', '0', '0']]\n",
      "decoded_data: ['PID is 6766.0, B02 is 290.0, DOY is 211.0, B04 is 492.0, B03 is 694.0 B04 is 64800']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 492.0, B02 is 290.0, PID is 6766.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 492.0, B02 is 290.0, PID is 6766.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '6', '1', '4', '5', '4']]\n",
      "decoded_data: ['B04 is 492.0, B02 is 290.0, PID is 6766.0, DOY is 211.0, B03 is 694.0 B04 is 61454']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 492.0, B02 is 290.0, DOY is 211.0, PID is 6766.0, B03 is']\n",
      "prompt: B04 is 492.0, B02 is 290.0, DOY is 211.0, PID is 6766.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '6', '1', '8', '.', '0', ',', '', 'B04']]\n",
      "decoded_data: ['B04 is 492.0, B02 is 290.0, DOY is 211.0, PID is 6766.0, B03 is 694.0 618.0, B04']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 492.0, B02 is 290.0, PID is 6766.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 492.0, B02 is 290.0, PID is 6766.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '6', '4', '8', '0', '3']]\n",
      "decoded_data: ['B04 is 492.0, B02 is 290.0, PID is 6766.0, DOY is 211.0, B03 is 694.0 B04 is 64803']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 290.0, B04 is 492.0, PID is 6766.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 290.0, B04 is 492.0, PID is 6766.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B02', 'is', '', 'B04', 'is', '', '6', '4']]\n",
      "decoded_data: ['B02 is 290.0, B04 is 492.0, PID is 6766.0, DOY is 211.0, B03 is 694.0 B02 is B04 is 64']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 492.0, B02 is 290.0, PID is 6766.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 492.0, B02 is 290.0, PID is 6766.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '6', '5', '4', 'DOY', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['B04 is 492.0, B02 is 290.0, PID is 6766.0, DOY is 211.0, B03 is 694.0 654DOY is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 492.0, PID is 6766.0, B02 is 290.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 492.0, PID is 6766.0, B02 is 290.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', '4', '8']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 492.0, PID is 6766.0, B02 is 290.0, B03 is 690.0 B04 is B04 is 48']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 492.0, PID is 6766.0, B02 is 290.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 492.0, PID is 6766.0, B02 is 290.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '6', '9']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 492.0, PID is 6766.0, B02 is 290.0, B03 is 694.0 B04 is PID is 69']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6766.0, B02 is 290.0, DOY is 211.0, B04 is 492.0, B03 is']\n",
      "prompt: PID is 6766.0, B02 is 290.0, DOY is 211.0, B04 is 492.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '7', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 13%|        | 110/829 [03:15<28:04,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '6', '7', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '2', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '4', '8', '0', '0', '.']]\n",
      "decoded_data: ['PID is 6766.0, B02 is 290.0, DOY is 211.0, B04 is 492.0, B03 is 694.0 B04 is 4800.']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6866.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 6866.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '8', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '8', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '5', '2']]\n",
      "decoded_data: ['PID is 6866.0, DOY is 211.0, B02 is 287.0, B04 is 507.0, B03 is 707.0 B04 is PID is 52']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6866.0, B04 is 507.0, B02 is 287.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 6866.0, B04 is 507.0, B02 is 287.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '8', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '8', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '7', '2', '7', '2', '7']]\n",
      "decoded_data: ['PID is 6866.0, B04 is 507.0, B02 is 287.0, DOY is 211.0, B03 is 707.0 B04 is 72727']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6866.0, B04 is 507.0, B02 is 287.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 6866.0, B04 is 507.0, B02 is 287.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '8', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '8', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['PID is 6866.0, B04 is 507.0, B02 is 287.0, DOY is 211.0, B03 is 707.0 PID is B04 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 287.0, B04 is 507.0, PID is 6866.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 287.0, B04 is 507.0, PID is 6866.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '8', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '8', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '7', '2', '7', '2', '7']]\n",
      "decoded_data: ['B02 is 287.0, B04 is 507.0, PID is 6866.0, DOY is 211.0, B03 is 707.0 B04 is 72727']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 507.0, B02 is 287.0, DOY is 211.0, PID is 6866.0, B03 is']\n",
      "prompt: B04 is 507.0, B02 is 287.0, DOY is 211.0, PID is 6866.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '0', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '6', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|        | 111/829 [03:17<23:30,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B04', 'is', '', '5', '0', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', '5', '2']]\n",
      "decoded_data: ['B04 is 507.0, B02 is 287.0, DOY is 211.0, PID is 6866.0, B03 is 707.0 B04 is B04 is 52']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6866.0, B02 is 287.0, B04 is 507.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 6866.0, B02 is 287.0, B04 is 507.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '2', '7', '2', '7', '0', '7', '2', '7']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6866.0, B02 is 287.0, B04 is 507.0, B03 is 707.0727270727']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6966.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 6966.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '6', '.', '0', ',', '', 'B04', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|        | 112/829 [03:17<17:36,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '4', '2', '4', '2', '4', '2', '4', '2']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6966.0, B04 is 503.0, B02 is 286.0, B03 is 752.0742424242']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7066.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 7066.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '0', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '0', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '7', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '2', '7', '8', '1', '4', '3', '.', '0', ',']]\n",
      "decoded_data: ['PID is 7066.0, DOY is 211.0, B03 is 766.0, B04 is 479.0, B02 is 291.0278143.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 479.0, PID is 7066.0, B03 is 766.0, B02 is']\n",
      "prompt: DOY is 211.0, B04 is 479.0, PID is 7066.0, B03 is 766.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '7', '9', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '6', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '7', '9', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B02', 'is', '', '2', '7', '1', '.', '0']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 479.0, PID is 7066.0, B03 is 766.0, B02 is 291.0 B02 is 271.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 479.0, PID is 7066.0, DOY is 211.0, B03 is 766.0, B02 is']\n",
      "prompt: B04 is 479.0, PID is 7066.0, DOY is 211.0, B03 is 766.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '7', '9', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '6', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '7', '9', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '2', '9', '1', '4', '0', '1', '0', '2']]\n",
      "decoded_data: ['B04 is 479.0, PID is 7066.0, DOY is 211.0, B03 is 766.0, B02 is 291.0 29140102']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7066.0, B03 is 766.0, B04 is 479.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 7066.0, B03 is 766.0, B04 is 479.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '0', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '7', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '0', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '7', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '2', '7', '7', '1', '.']]\n",
      "decoded_data: ['PID is 7066.0, B03 is 766.0, B04 is 479.0, DOY is 211.0, B02 is 291.0 B04 is 2771.']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 766.0, DOY is 211.0, B04 is 479.0, PID is 7066.0, B02 is']\n",
      "prompt: B03 is 766.0, DOY is 211.0, B04 is 479.0, PID is 7066.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '7', '9', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '6', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '7', '9', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '2', '7', '1', '0', ',', '', 'B04', 'is']]\n",
      "decoded_data: ['B03 is 766.0, DOY is 211.0, B04 is 479.0, PID is 7066.0, B02 is 291.0 2710, B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 766.0, B04 is 479.0, PID is 7066.0, B02 is']\n",
      "prompt: DOY is 211.0, B03 is 766.0, B04 is 479.0, PID is 7066.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '7', '9', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '6', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '7', '9', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'DOY', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 766.0, B04 is 479.0, PID is 7066.0, B02 is 291.0 B04 is DOY is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 7066.0, B04 is 479.0, B03 is 766.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 7066.0, B04 is 479.0, B03 is 766.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '7', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '6', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '7', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '4', '3', '.', '0', '2']]\n",
      "decoded_data: ['DOY is 211.0, PID is 7066.0, B04 is 479.0, B03 is 766.0, B02 is 291.0 B04 is 43.02']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 766.0, PID is 7066.0, B04 is 479.0, DOY is 211.0, B02 is']\n",
      "prompt: B03 is 766.0, PID is 7066.0, B04 is 479.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '7', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '7', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '2', '1', '1', '1', '.', '0', ',', '']]\n",
      "decoded_data: ['B03 is 766.0, PID is 7066.0, B04 is 479.0, DOY is 211.0, B02 is 291.0 2111.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 766.0, DOY is 211.0, B04 is 479.0, PID is 7066.0, B02 is']\n",
      "prompt: B03 is 766.0, DOY is 211.0, B04 is 479.0, PID is 7066.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '7', '9', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '6', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '7', '9', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '2', '9', '1', '4', '7', '8', '.', '0']]\n",
      "decoded_data: ['B03 is 766.0, DOY is 211.0, B04 is 479.0, PID is 7066.0, B02 is 291.0 291478.0']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7066.0, B04 is 479.0, B03 is 766.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 7066.0, B04 is 479.0, B03 is 766.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '0', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '7', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '0', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '7', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '2', '7', '1', '0', '2']]\n",
      "decoded_data: ['PID is 7066.0, B04 is 479.0, B03 is 766.0, DOY is 211.0, B02 is 291.0 B04 is 27102']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7066.0, B04 is 479.0, B03 is 766.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 7066.0, B04 is 479.0, B03 is 766.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '0', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '7', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|        | 113/829 [03:19<19:24,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '7', '0', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '7', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '2', '9', '1', '9', '1', '0', ',', '', 'B04']]\n",
      "decoded_data: ['PID is 7066.0, B04 is 479.0, B03 is 766.0, DOY is 211.0, B02 is 291.0291910, B04']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7166.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 7166.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '1', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '1', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '6', '.', '0', ',', '', 'B04', 'is', '']]\n",
      "decoded_data: ['PID is 7166.0, DOY is 211.0, B02 is 303.0, B04 is 483.0, B03 is 706.076.0, B04 is ']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 303.0, B04 is 483.0, PID is 7166.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 303.0, B04 is 483.0, PID is 7166.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '3', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '3', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '7', '6', '.', '0', '6', '.', '0', ',']]\n",
      "decoded_data: ['B02 is 303.0, B04 is 483.0, PID is 7166.0, DOY is 211.0, B03 is 706.0 76.06.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7166.0, DOY is 211.0, B02 is 303.0, B04 is 483.0, B03 is']\n",
      "prompt: PID is 7166.0, DOY is 211.0, B02 is 303.0, B04 is 483.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '1', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '1', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '7', '6', '.', '0', '6']]\n",
      "decoded_data: ['PID is 7166.0, DOY is 211.0, B02 is 303.0, B04 is 483.0, B03 is 706.0 B04 is 76.06']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 7166.0, B02 is 303.0, B04 is 483.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 7166.0, B02 is 303.0, B04 is 483.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '7', '6', '.', '0', '6', '.', '0', ',']]\n",
      "decoded_data: ['DOY is 211.0, PID is 7166.0, B02 is 303.0, B04 is 483.0, B03 is 706.0 76.06.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7166.0, B04 is 483.0, DOY is 211.0, B02 is 303.0, B03 is']\n",
      "prompt: PID is 7166.0, B04 is 483.0, DOY is 211.0, B02 is 303.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '1', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '1', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '7', '6', '1', '5', '3']]\n",
      "decoded_data: ['PID is 7166.0, B04 is 483.0, DOY is 211.0, B02 is 303.0, B03 is 706.0 B04 is 76153']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 303.0, PID is 7166.0, B04 is 483.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 303.0, PID is 7166.0, B04 is 483.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '9', '.', '0', ',', '', 'B04', 'is', '']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 303.0, PID is 7166.0, B04 is 483.0, B03 is 706.079.0, B04 is ']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 303.0, B04 is 483.0, DOY is 211.0, PID is 7166.0, B03 is']\n",
      "prompt: B02 is 303.0, B04 is 483.0, DOY is 211.0, PID is 7166.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '7', '6', '.', '0', '6']]\n",
      "decoded_data: ['B02 is 303.0, B04 is 483.0, DOY is 211.0, PID is 7166.0, B03 is 706.0 B04 is 76.06']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7166.0, B02 is 303.0, DOY is 211.0, B04 is 483.0, B03 is']\n",
      "prompt: PID is 7166.0, B02 is 303.0, DOY is 211.0, B04 is 483.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '1', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '1', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', '4', 'PID']]\n",
      "decoded_data: ['PID is 7166.0, B02 is 303.0, DOY is 211.0, B04 is 483.0, B03 is 706.0 B04 is B04 is 4PID']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 483.0, DOY is 211.0, PID is 7166.0, B02 is 303.0, B03 is']\n",
      "prompt: B04 is 483.0, DOY is 211.0, PID is 7166.0, B02 is 303.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '8', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '8', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B02', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['B04 is 483.0, DOY is 211.0, PID is 7166.0, B02 is 303.0, B03 is 706.0 B04 is B02 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 483.0, DOY is 211.0, B02 is 303.0, PID is 7166.0, B03 is']\n",
      "prompt: B04 is 483.0, DOY is 211.0, B02 is 303.0, PID is 7166.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '8', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '8', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B02', 'is', '', 'DOY', 'is']]\n",
      "decoded_data: ['B04 is 483.0, DOY is 211.0, B02 is 303.0, PID is 7166.0, B03 is 706.0 B04 is B02 is DOY is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7166.0, DOY is 211.0, B02 is 303.0, B04 is 483.0, B03 is']\n",
      "prompt: PID is 7166.0, DOY is 211.0, B02 is 303.0, B04 is 483.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '1', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '1', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', '4', '7']]\n",
      "decoded_data: ['PID is 7166.0, DOY is 211.0, B02 is 303.0, B04 is 483.0, B03 is 706.0 B04 is B04 is 47']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 483.0, PID is 7166.0, B02 is 303.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 483.0, PID is 7166.0, B02 is 303.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '3', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '3', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B02', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 483.0, PID is 7166.0, B02 is 303.0, B03 is 706.0 B04 is B02 is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 483.0, DOY is 211.0, B02 is 303.0, PID is 7166.0, B03 is']\n",
      "prompt: B04 is 483.0, DOY is 211.0, B02 is 303.0, PID is 7166.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '8', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '8', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', '4', '.']]\n",
      "decoded_data: ['B04 is 483.0, DOY is 211.0, B02 is 303.0, PID is 7166.0, B03 is 706.0 B04 is B04 is 4.']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 483.0, PID is 7166.0, DOY is 211.0, B02 is 303.0, B03 is']\n",
      "prompt: B04 is 483.0, PID is 7166.0, DOY is 211.0, B02 is 303.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '8', '3', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '8', '3', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '7', '3', '3', '.', '0']]\n",
      "decoded_data: ['B04 is 483.0, PID is 7166.0, DOY is 211.0, B02 is 303.0, B03 is 706.0 B04 is 733.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 483.0, B02 is 303.0, DOY is 211.0, PID is 7166.0, B03 is']\n",
      "prompt: B04 is 483.0, B02 is 303.0, DOY is 211.0, PID is 7166.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '8', '3', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '6', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 14%|        | 114/829 [03:21<22:18,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B04', 'is', '', '4', '8', '3', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', '4', '.']]\n",
      "decoded_data: ['B04 is 483.0, B02 is 303.0, DOY is 211.0, PID is 7166.0, B03 is 706.0 B04 is B04 is 4.']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5267.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 5267.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '4', '.', '0', ',', '', 'B04', 'is', '', '6', '6', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'PID', 'is', '', '6', '3']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5267.0, B03 is 778.0, B02 is 394.0, B04 is 663.0 B03 is PID is 63']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 394.0, PID is 5267.0, DOY is 211.0, B03 is 778.0, B04 is']\n",
      "prompt: B02 is 394.0, PID is 5267.0, DOY is 211.0, B03 is 778.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '9', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '8', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '9', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '8', '.', '0', ',', '', 'B04', 'is', '', '6', '6', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '6', '3', '0', '9', '2', '0', '9', '0']]\n",
      "decoded_data: ['B02 is 394.0, PID is 5267.0, DOY is 211.0, B03 is 778.0, B04 is 663.0 63092090']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 394.0, B03 is 778.0, PID is 5267.0, DOY is 211.0, B04 is']\n",
      "prompt: B02 is 394.0, B03 is 778.0, PID is 5267.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '9', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '9', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '6', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '6', '3', '0', '9', '0', '0', '9', '.']]\n",
      "decoded_data: ['B02 is 394.0, B03 is 778.0, PID is 5267.0, DOY is 211.0, B04 is 663.0 6309009.']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 394.0, PID is 5267.0, DOY is 211.0, B03 is 778.0, B04 is']\n",
      "prompt: B02 is 394.0, PID is 5267.0, DOY is 211.0, B03 is 778.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '9', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '8', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '9', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '8', '.', '0', ',', '', 'B04', 'is', '', '6', '6', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'DOY', 'is', '', 'PID', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['B02 is 394.0, PID is 5267.0, DOY is 211.0, B03 is 778.0, B04 is 663.0 DOY is PID is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 394.0, DOY is 211.0, PID is 5267.0, B03 is 778.0, B04 is']\n",
      "prompt: B02 is 394.0, DOY is 211.0, PID is 5267.0, B03 is 778.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '9', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '8', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '9', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '8', '.', '0', ',', '', 'B04', 'is', '', '6', '6', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '6', '3', '6', '3', '0', '0', '4', '2']]\n",
      "decoded_data: ['B02 is 394.0, DOY is 211.0, PID is 5267.0, B03 is 778.0, B04 is 663.0 63630042']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 394.0, DOY is 211.0, B03 is 778.0, PID is 5267.0, B04 is']\n",
      "prompt: B02 is 394.0, DOY is 211.0, B03 is 778.0, PID is 5267.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '9', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '9', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '6', '6', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'PID', 'is', '', 'DOY', 'is']]\n",
      "decoded_data: ['B02 is 394.0, DOY is 211.0, B03 is 778.0, PID is 5267.0, B04 is 663.0 B03 is PID is DOY is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5267.0, B03 is 778.0, B02 is 394.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 5267.0, B03 is 778.0, B02 is 394.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '4', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '4', '.', '0', ',', '', 'B04', 'is', '', '6', '6', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '3', '9', '8', '0', '1', '8', '.', '0']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5267.0, B03 is 778.0, B02 is 394.0, B04 is 663.06398018.0']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 778.0, B02 is 394.0, PID is 5267.0, B04 is']\n",
      "prompt: DOY is 211.0, B03 is 778.0, B02 is 394.0, PID is 5267.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '6', '6', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'PID', 'is', '', '6', '3']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 778.0, B02 is 394.0, PID is 5267.0, B04 is 663.0 B03 is PID is 63']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5267.0, B03 is 778.0, B02 is 394.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 5267.0, B03 is 778.0, B02 is 394.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '4', '.', '0', ',', '', 'B04', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|        | 115/829 [03:23<20:47,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '4', '.', '0', ',', '', 'B04', 'is', '', '6', '6', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '3', '0', '1', '0', '8', '0', '8', '8']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5267.0, B03 is 778.0, B02 is 394.0, B04 is 663.0630108088']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5367.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 5367.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '3', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '3', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '8', '8', '4', '5']]\n",
      "decoded_data: ['PID is 5367.0, DOY is 211.0, B02 is 337.0, B04 is 588.0, B03 is 768.0 B04 is 58845']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 337.0, DOY is 211.0, B04 is 588.0, PID is 5367.0, B03 is']\n",
      "prompt: B02 is 337.0, DOY is 211.0, B04 is 588.0, PID is 5367.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '3', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '3', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '6', '8', '4', '8']]\n",
      "decoded_data: ['B02 is 337.0, DOY is 211.0, B04 is 588.0, PID is 5367.0, B03 is 768.0 PID is 76848']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5367.0, B04 is 588.0, B02 is 337.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 5367.0, B04 is 588.0, B02 is 337.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '8', '4', '8', '0', '7', '9', '0', '.']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5367.0, B04 is 588.0, B02 is 337.0, B03 is 768.068480790.']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 588.0, DOY is 211.0, B02 is 337.0, PID is 5367.0, B03 is']\n",
      "prompt: B04 is 588.0, DOY is 211.0, B02 is 337.0, PID is 5367.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '8', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '8', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '6', '8', '4', '8']]\n",
      "decoded_data: ['B04 is 588.0, DOY is 211.0, B02 is 337.0, PID is 5367.0, B03 is 768.0 PID is 76848']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 588.0, DOY is 211.0, PID is 5367.0, B02 is 337.0, B03 is']\n",
      "prompt: B04 is 588.0, DOY is 211.0, PID is 5367.0, B02 is 337.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '8', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '8', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['B04 is 588.0, DOY is 211.0, PID is 5367.0, B02 is 337.0, B03 is 768.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5367.0, B02 is 337.0, DOY is 211.0, B04 is 588.0, B03 is']\n",
      "prompt: PID is 5367.0, B02 is 337.0, DOY is 211.0, B04 is 588.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '3', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '3', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '8', '4', '9', '0']]\n",
      "decoded_data: ['PID is 5367.0, B02 is 337.0, DOY is 211.0, B04 is 588.0, B03 is 768.0 B04 is 58490']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5367.0, B04 is 588.0, B02 is 337.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 5367.0, B04 is 588.0, B02 is 337.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5367.0, B04 is 588.0, B02 is 337.0, B03 is 768.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5367.0, DOY is 211.0, B04 is 588.0, B02 is 337.0, B03 is']\n",
      "prompt: PID is 5367.0, DOY is 211.0, B04 is 588.0, B02 is 337.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '3', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '3', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '7', '8', '4', '8', '.']]\n",
      "decoded_data: ['PID is 5367.0, DOY is 211.0, B04 is 588.0, B02 is 337.0, B03 is 768.0 B04 is 7848.']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 588.0, DOY is 211.0, PID is 5367.0, B02 is 337.0, B03 is']\n",
      "prompt: B04 is 588.0, DOY is 211.0, PID is 5367.0, B02 is 337.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '8', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '8', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['B04 is 588.0, DOY is 211.0, PID is 5367.0, B02 is 337.0, B03 is 768.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 337.0, PID is 5367.0, DOY is 211.0, B04 is 588.0, B03 is']\n",
      "prompt: B02 is 337.0, PID is 5367.0, DOY is 211.0, B04 is 588.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '3', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '3', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '8', '0', '0', '0']]\n",
      "decoded_data: ['B02 is 337.0, PID is 5367.0, DOY is 211.0, B04 is 588.0, B03 is 768.0 B04 is 58000']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 337.0, B04 is 588.0, DOY is 211.0, PID is 5367.0, B03 is']\n",
      "prompt: B02 is 337.0, B04 is 588.0, DOY is 211.0, PID is 5367.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '3', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '3', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '7', '.', '0', ',', '']]\n",
      "decoded_data: ['B02 is 337.0, B04 is 588.0, DOY is 211.0, PID is 5367.0, B03 is 768.0 B04 is 7.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 337.0, B04 is 588.0, PID is 5367.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 337.0, B04 is 588.0, PID is 5367.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '3', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '3', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '1']]\n",
      "decoded_data: ['B02 is 337.0, B04 is 588.0, PID is 5367.0, DOY is 211.0, B03 is 768.0 B04 is PID is 71']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 588.0, DOY is 211.0, B02 is 337.0, PID is 5367.0, B03 is']\n",
      "prompt: B04 is 588.0, DOY is 211.0, B02 is 337.0, PID is 5367.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '8', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '8', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '4']]\n",
      "decoded_data: ['B04 is 588.0, DOY is 211.0, B02 is 337.0, PID is 5367.0, B03 is 768.0 B04 is PID is 74']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 588.0, B02 is 337.0, PID is 5367.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 588.0, B02 is 337.0, PID is 5367.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '8', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '8', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B02', 'is', '', '7', '0', '0', '6', '8']]\n",
      "decoded_data: ['B04 is 588.0, B02 is 337.0, PID is 5367.0, DOY is 211.0, B03 is 768.0 B02 is 70068']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5367.0, B04 is 588.0, B02 is 337.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 5367.0, B04 is 588.0, B02 is 337.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '7', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 14%|        | 116/829 [03:25<22:46,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5367.0, B04 is 588.0, B02 is 337.0, B03 is 768.0 B04 is PID is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5467.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 5467.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '4', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '4', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '5', '6']]\n",
      "decoded_data: ['PID is 5467.0, DOY is 211.0, B04 is 571.0, B02 is 301.0, B03 is 748.0 B04 is PID is 56']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 301.0, PID is 5467.0, DOY is 211.0, B04 is 571.0, B03 is']\n",
      "prompt: B02 is 301.0, PID is 5467.0, DOY is 211.0, B04 is 571.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '8', 'is', '', '5']]\n",
      "decoded_data: ['B02 is 301.0, PID is 5467.0, DOY is 211.0, B04 is 571.0, B03 is 748.0 B04 is 58 is 5']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 301.0, PID is 5467.0, B04 is 571.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 301.0, PID is 5467.0, B04 is 571.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '0', '0', '0', '.', '0', '4', '8', '.', '0']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 301.0, PID is 5467.0, B04 is 571.0, B03 is 748.0000.048.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 571.0, DOY is 211.0, PID is 5467.0, B02 is 301.0, B03 is']\n",
      "prompt: B04 is 571.0, DOY is 211.0, PID is 5467.0, B02 is 301.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '7', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '7', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '5', '8']]\n",
      "decoded_data: ['B04 is 571.0, DOY is 211.0, PID is 5467.0, B02 is 301.0, B03 is 748.0 B04 is PID is 58']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 301.0, B04 is 571.0, PID is 5467.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 301.0, B04 is 571.0, PID is 5467.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', '5', '7']]\n",
      "decoded_data: ['B02 is 301.0, B04 is 571.0, PID is 5467.0, DOY is 211.0, B03 is 748.0 B04 is B04 is 57']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5467.0, B02 is 301.0, B04 is 571.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 5467.0, B02 is 301.0, B04 is 571.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '2', '1', '.', '0']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5467.0, B02 is 301.0, B04 is 571.0, B03 is 748.0 B04 is 521.0']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 301.0, PID is 5467.0, B04 is 571.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 301.0, PID is 5467.0, B04 is 571.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', '5', '6']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 301.0, PID is 5467.0, B04 is 571.0, B03 is 748.0 B04 is B04 is 56']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 571.0, DOY is 211.0, PID is 5467.0, B02 is 301.0, B03 is']\n",
      "prompt: B04 is 571.0, DOY is 211.0, PID is 5467.0, B02 is 301.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '7', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '7', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B02', 'is', '', '5', '4']]\n",
      "decoded_data: ['B04 is 571.0, DOY is 211.0, PID is 5467.0, B02 is 301.0, B03 is 748.0 B04 is B02 is 54']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5467.0, B04 is 571.0, DOY is 211.0, B02 is 301.0, B03 is']\n",
      "prompt: PID is 5467.0, B04 is 571.0, DOY is 211.0, B02 is 301.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '4', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '4', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '1']]\n",
      "decoded_data: ['PID is 5467.0, B04 is 571.0, DOY is 211.0, B02 is 301.0, B03 is 748.0 B04 is PID is 71']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 571.0, PID is 5467.0, B02 is 301.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 571.0, PID is 5467.0, B02 is 301.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '1', '4', '8', '0']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 571.0, PID is 5467.0, B02 is 301.0, B03 is 748.0 PID is 71480']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 571.0, DOY is 211.0, B02 is 301.0, PID is 5467.0, B03 is']\n",
      "prompt: B04 is 571.0, DOY is 211.0, B02 is 301.0, PID is 5467.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '7', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '7', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '7', '1']]\n",
      "decoded_data: ['B04 is 571.0, DOY is 211.0, B02 is 301.0, PID is 5467.0, B03 is 748.0 PID is B04 is 71']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5467.0, B04 is 571.0, B02 is 301.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5467.0, B04 is 571.0, B02 is 301.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '4', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '4', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B02', 'is', '', 'B04', 'is', '', '7', '1']]\n",
      "decoded_data: ['PID is 5467.0, B04 is 571.0, B02 is 301.0, DOY is 211.0, B03 is 748.0 B02 is B04 is 71']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 571.0, DOY is 211.0, PID is 5467.0, B02 is 301.0, B03 is']\n",
      "prompt: B04 is 571.0, DOY is 211.0, PID is 5467.0, B02 is 301.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '7', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '7', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '1']]\n",
      "decoded_data: ['B04 is 571.0, DOY is 211.0, PID is 5467.0, B02 is 301.0, B03 is 748.0 B04 is PID is 71']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 571.0, PID is 5467.0, B02 is 301.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 571.0, PID is 5467.0, B02 is 301.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '7', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '7', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', '5', '7']]\n",
      "decoded_data: ['B04 is 571.0, PID is 5467.0, B02 is 301.0, DOY is 211.0, B03 is 748.0 B04 is B04 is 57']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 301.0, DOY is 211.0, B04 is 571.0, PID is 5467.0, B03 is']\n",
      "prompt: B02 is 301.0, DOY is 211.0, B04 is 571.0, PID is 5467.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '7', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 14%|        | 117/829 [03:27<23:57,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['B02 is 301.0, DOY is 211.0, B04 is 571.0, PID is 5467.0, B03 is 748.0 B04 is B04 is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5567.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 5567.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '7', '.', '0', ',', '', 'B04', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|        | 118/829 [03:28<17:48,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '6', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '0', '.', '0', ',', '', 'B03', 'is', '', '8', '3', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '8', '4', '0', '0', ',', '', 'B04', 'is', '']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5567.0, B04 is 611.0, B02 is 340.0, B03 is 830.08400, B04 is ']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5667.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 5667.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '2', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '9', '6', '1', '8', '0', '5', '3']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5667.0, B03 is 722.0, B02 is 305.0, B04 is 561.0 59618053']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 722.0, DOY is 211.0, PID is 5667.0, B02 is 305.0, B04 is']\n",
      "prompt: B03 is 722.0, DOY is 211.0, PID is 5667.0, B02 is 305.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '2', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '5', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '2', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '6', '1', '5', '3']]\n",
      "decoded_data: ['B03 is 722.0, DOY is 211.0, PID is 5667.0, B02 is 305.0, B04 is 561.0 PID is 56153']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 305.0, PID is 5667.0, B03 is 722.0, B04 is']\n",
      "prompt: DOY is 211.0, B02 is 305.0, PID is 5667.0, B03 is 722.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '2', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '2', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '3', '4', '5', '.']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 305.0, PID is 5667.0, B03 is 722.0, B04 is 561.0 B04 is 5345.']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 722.0, B02 is 305.0, PID is 5667.0, DOY is 211.0, B04 is']\n",
      "prompt: B03 is 722.0, B02 is 305.0, PID is 5667.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '2', '2', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '2', '2', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '8', '6', '1', '9', '9', '9', '7']]\n",
      "decoded_data: ['B03 is 722.0, B02 is 305.0, PID is 5667.0, DOY is 211.0, B04 is 561.0 58619997']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 722.0, B02 is 305.0, PID is 5667.0, B04 is']\n",
      "prompt: DOY is 211.0, B03 is 722.0, B02 is 305.0, PID is 5667.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '2', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '2', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '9', '6', '1', '.', '0', ',', '']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 722.0, B02 is 305.0, PID is 5667.0, B04 is 561.0 5961.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5667.0, DOY is 211.0, B02 is 305.0, B03 is 722.0, B04 is']\n",
      "prompt: PID is 5667.0, DOY is 211.0, B02 is 305.0, B03 is 722.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '6', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '2', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '6', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '2', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '3', '4', '9', '6']]\n",
      "decoded_data: ['PID is 5667.0, DOY is 211.0, B02 is 305.0, B03 is 722.0, B04 is 561.0 PID is 53496']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 722.0, B02 is 305.0, PID is 5667.0, DOY is 211.0, B04 is']\n",
      "prompt: B03 is 722.0, B02 is 305.0, PID is 5667.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '2', '2', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '2', '2', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', '5', '3', '0', '1', '5']]\n",
      "decoded_data: ['B03 is 722.0, B02 is 305.0, PID is 5667.0, DOY is 211.0, B04 is 561.0 B03 is 53015']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5667.0, B02 is 305.0, B03 is 722.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 5667.0, B02 is 305.0, B03 is 722.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '2', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '2', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '3', '4', '9', '8', '2', '.', '0']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5667.0, B02 is 305.0, B03 is 722.0, B04 is 561.0 534982.0']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5667.0, DOY is 211.0, B03 is 722.0, B02 is 305.0, B04 is']\n",
      "prompt: PID is 5667.0, DOY is 211.0, B03 is 722.0, B02 is 305.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '6', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '2', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '5', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '6', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '2', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '3', '9', '9', '6', '7', '8', '2']]\n",
      "decoded_data: ['PID is 5667.0, DOY is 211.0, B03 is 722.0, B02 is 305.0, B04 is 561.0 53996782']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 305.0, PID is 5667.0, DOY is 211.0, B03 is 722.0, B04 is']\n",
      "prompt: B02 is 305.0, PID is 5667.0, DOY is 211.0, B03 is 722.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '0', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '2', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '0', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '2', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '3', '4', '9', '8', '.', '0', '3']]\n",
      "decoded_data: ['B02 is 305.0, PID is 5667.0, DOY is 211.0, B03 is 722.0, B04 is 561.0 53498.03']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 305.0, B03 is 722.0, PID is 5667.0, B04 is']\n",
      "prompt: DOY is 211.0, B02 is 305.0, B03 is 722.0, PID is 5667.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'B04', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 305.0, B03 is 722.0, PID is 5667.0, B04 is 561.0 B03 is B04 is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 722.0, B02 is 305.0, PID is 5667.0, B04 is']\n",
      "prompt: DOY is 211.0, B03 is 722.0, B02 is 305.0, PID is 5667.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '2', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '2', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '6', '1', '5', '3']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 722.0, B02 is 305.0, PID is 5667.0, B04 is 561.0 PID is 56153']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 722.0, B02 is 305.0, PID is 5667.0, DOY is 211.0, B04 is']\n",
      "prompt: B03 is 722.0, B02 is 305.0, PID is 5667.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '2', '2', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '2', '2', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '3', '0', '5', '9', '1', '9', '0']]\n",
      "decoded_data: ['B03 is 722.0, B02 is 305.0, PID is 5667.0, DOY is 211.0, B04 is 561.0 53059190']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 722.0, PID is 5667.0, B02 is 305.0, B04 is']\n",
      "prompt: DOY is 211.0, B03 is 722.0, PID is 5667.0, B02 is 305.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '5', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '3', '9', '9', '9']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 722.0, PID is 5667.0, B02 is 305.0, B04 is 561.0 PID is 53999']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5667.0, B02 is 305.0, B03 is 722.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 5667.0, B02 is 305.0, B03 is 722.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '2', '.', '0', ',', '', 'B04', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 14%|        | 119/829 [03:30<20:49,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '2', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '6', '1', '5', '8']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5667.0, B02 is 305.0, B03 is 722.0, B04 is 561.0 PID is 56158']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5767.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 5767.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '7', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '7', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '0', '.', '0', ',', '', 'B03', 'is', '', '5', '0', '9', '.', '0', ',', '', 'B04', 'is', '', '3', '9', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B03', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['PID is 5767.0, DOY is 211.0, B02 is 260.0, B03 is 509.0, B04 is 392.0 PID is B03 is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5767.0, B02 is 260.0, B03 is 509.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 5767.0, B02 is 260.0, B03 is 509.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '0', '.', '0', ',', '', 'B03', 'is', '', '5', '0', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '0', '.', '0', ',', '', 'B03', 'is', '', '5', '0', '9', '.', '0', ',', '', 'B04', 'is', '', '3', '9', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '3', '2', '.', '0', '8', '8', '8', '0']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5767.0, B02 is 260.0, B03 is 509.0, B04 is 392.0 32.08880']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5767.0, B03 is 509.0, B02 is 260.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 5767.0, B03 is 509.0, B02 is 260.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '7', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '5', '0', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '7', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '5', '0', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '3', '9', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '3', '4', '0', '7', '4']]\n",
      "decoded_data: ['PID is 5767.0, B03 is 509.0, B02 is 260.0, DOY is 211.0, B04 is 392.0 PID is 34074']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5767.0, B02 is 260.0, B03 is 509.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 5767.0, B02 is 260.0, B03 is 509.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '0', '.', '0', ',', '', 'B03', 'is', '', '5', '0', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '0', '.', '0', ',', '', 'B03', 'is', '', '5', '0', '9', '.', '0', ',', '', 'B04', 'is', '', '3', '9', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '3', '8', '7', '4', '0']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5767.0, B02 is 260.0, B03 is 509.0, B04 is 392.0 PID is 38740']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 509.0, B02 is 260.0, DOY is 211.0, PID is 5767.0, B04 is']\n",
      "prompt: B03 is 509.0, B02 is 260.0, DOY is 211.0, PID is 5767.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '5', '0', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '5', '0', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '3', '9', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '3', '6', '5', '5', '5']]\n",
      "decoded_data: ['B03 is 509.0, B02 is 260.0, DOY is 211.0, PID is 5767.0, B04 is 392.0 B04 is 36555']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5767.0, B02 is 260.0, DOY is 211.0, B03 is 509.0, B04 is']\n",
      "prompt: PID is 5767.0, B02 is 260.0, DOY is 211.0, B03 is 509.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '7', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '5', '0', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '7', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '5', '0', '9', '.', '0', ',', '', 'B04', 'is', '', '3', '9', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B03', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['PID is 5767.0, B02 is 260.0, DOY is 211.0, B03 is 509.0, B04 is 392.0 PID is B03 is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5767.0, DOY is 211.0, B03 is 509.0, B02 is 260.0, B04 is']\n",
      "prompt: PID is 5767.0, DOY is 211.0, B03 is 509.0, B02 is 260.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '7', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '5', '0', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '7', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '5', '0', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '0', '.', '0', ',', '', 'B04', 'is', '', '3', '9', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'PID', 'is', '', '3', '8']]\n",
      "decoded_data: ['PID is 5767.0, DOY is 211.0, B03 is 509.0, B02 is 260.0, B04 is 392.0 B03 is PID is 38']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5767.0, B02 is 260.0, DOY is 211.0, B03 is 509.0, B04 is']\n",
      "prompt: PID is 5767.0, B02 is 260.0, DOY is 211.0, B03 is 509.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '7', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '5', '0', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '7', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '5', '0', '9', '.', '0', ',', '', 'B04', 'is', '', '3', '9', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '3', '7', '4', '0', '7']]\n",
      "decoded_data: ['PID is 5767.0, B02 is 260.0, DOY is 211.0, B03 is 509.0, B04 is 392.0 PID is 37407']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 509.0, B02 is 260.0, PID is 5767.0, DOY is 211.0, B04 is']\n",
      "prompt: B03 is 509.0, B02 is 260.0, PID is 5767.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '5', '0', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '5', '0', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '3', '9', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '3', '8', '2', '0', '3']]\n",
      "decoded_data: ['B03 is 509.0, B02 is 260.0, PID is 5767.0, DOY is 211.0, B04 is 392.0 PID is 38203']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 509.0, B02 is 260.0, PID is 5767.0, B04 is']\n",
      "prompt: DOY is 211.0, B03 is 509.0, B02 is 260.0, PID is 5767.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '5', '0', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '5', '0', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '3', '9', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'DOY', 'is', '', 'DOY', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 509.0, B02 is 260.0, PID is 5767.0, B04 is 392.0 B04 is DOY is DOY is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 260.0, B03 is 509.0, PID is 5767.0, DOY is 211.0, B04 is']\n",
      "prompt: B02 is 260.0, B03 is 509.0, PID is 5767.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '6', '0', '.', '0', ',', '', 'B03', 'is', '', '5', '0', '9', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '6', '0', '.', '0', ',', '', 'B03', 'is', '', '5', '0', '9', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '3', '9', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '.', '0', ',', '', 'PID', 'is', '', '3', '6']]\n",
      "decoded_data: ['B02 is 260.0, B03 is 509.0, PID is 5767.0, DOY is 211.0, B04 is 392.0.0, PID is 36']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 509.0, B02 is 260.0, DOY is 211.0, PID is 5767.0, B04 is']\n",
      "prompt: B03 is 509.0, B02 is 260.0, DOY is 211.0, PID is 5767.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '5', '0', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '5', '0', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '3', '9', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '0', '7', '.', '0', ',', '', 'B03', 'is', '']]\n",
      "decoded_data: ['B03 is 509.0, B02 is 260.0, DOY is 211.0, PID is 5767.0, B04 is 392.007.0, B03 is ']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 509.0, DOY is 211.0, B02 is 260.0, PID is 5767.0, B04 is']\n",
      "prompt: B03 is 509.0, DOY is 211.0, B02 is 260.0, PID is 5767.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '5', '0', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '5', '0', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '3', '9', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'PID', 'is', '', 'DOY', 'is']]\n",
      "decoded_data: ['B03 is 509.0, DOY is 211.0, B02 is 260.0, PID is 5767.0, B04 is 392.0 B03 is PID is DOY is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5767.0, B02 is 260.0, B03 is 509.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 5767.0, B02 is 260.0, B03 is 509.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '0', '.', '0', ',', '', 'B03', 'is', '', '5', '0', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '0', '.', '0', ',', '', 'B03', 'is', '', '5', '0', '9', '.', '0', ',', '', 'B04', 'is', '', '3', '9', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'PID', 'is', '', '3', '2']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5767.0, B02 is 260.0, B03 is 509.0, B04 is 392.0 B03 is PID is 32']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5767.0, DOY is 211.0, B02 is 260.0, B03 is 509.0, B04 is']\n",
      "prompt: PID is 5767.0, DOY is 211.0, B02 is 260.0, B03 is 509.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '7', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '0', '.', '0', ',', '', 'B03', 'is', '', '5', '0', '9', '.', '0', ',', '', 'B04', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 14%|        | 120/829 [03:32<22:52,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '5', '7', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '0', '.', '0', ',', '', 'B03', 'is', '', '5', '0', '9', '.', '0', ',', '', 'B04', 'is', '', '3', '9', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B03', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['PID is 5767.0, DOY is 211.0, B02 is 260.0, B03 is 509.0, B04 is 392.0 PID is B03 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5867.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 5867.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '3', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '4', '.', '0', ',', '', 'B03', 'is', '', '4', '9', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5867.0, B04 is 543.0, B02 is 324.0, B03 is 492.0 B04 is B04 is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 543.0, B02 is 324.0, DOY is 211.0, PID is 5867.0, B03 is']\n",
      "prompt: B04 is 543.0, B02 is 324.0, DOY is 211.0, PID is 5867.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '4', '3', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '4', '3', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '4', '9', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '6', '3', '.', '0']]\n",
      "decoded_data: ['B04 is 543.0, B02 is 324.0, DOY is 211.0, PID is 5867.0, B03 is 492.0 B04 is 563.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 324.0, B04 is 543.0, PID is 5867.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 324.0, B04 is 543.0, PID is 5867.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '2', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '2', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '4', '9', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B02', 'is', '', '4', '7']]\n",
      "decoded_data: ['B02 is 324.0, B04 is 543.0, PID is 5867.0, DOY is 211.0, B03 is 492.0 B04 is B02 is 47']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 324.0, PID is 5867.0, B04 is 543.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 324.0, PID is 5867.0, B04 is 543.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '3', '.', '0', ',', '', 'B03', 'is', '', '4', '9', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '4', '7', '3', '8', '9', '0', '3', '.', '0']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 324.0, PID is 5867.0, B04 is 543.0, B03 is 492.04738903.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 324.0, DOY is 211.0, B04 is 543.0, PID is 5867.0, B03 is']\n",
      "prompt: B02 is 324.0, DOY is 211.0, B04 is 543.0, PID is 5867.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '2', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '2', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '4', '9', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '4', '7', '9', '0', 'B04']]\n",
      "decoded_data: ['B02 is 324.0, DOY is 211.0, B04 is 543.0, PID is 5867.0, B03 is 492.0 B04 is 4790B04']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 543.0, DOY is 211.0, PID is 5867.0, B02 is 324.0, B03 is']\n",
      "prompt: B04 is 543.0, DOY is 211.0, PID is 5867.0, B02 is 324.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '4', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '4', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '4', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['B04 is 543.0, DOY is 211.0, PID is 5867.0, B02 is 324.0, B03 is 696.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 543.0, PID is 5867.0, B02 is 324.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 543.0, PID is 5867.0, B02 is 324.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '4', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 543.0, PID is 5867.0, B02 is 324.0, B03 is 696.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5867.0, B02 is 324.0, DOY is 211.0, B04 is 543.0, B03 is']\n",
      "prompt: PID is 5867.0, B02 is 324.0, DOY is 211.0, B04 is 543.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '8', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '8', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '3', '.', '0', ',', '', 'B03', 'is', '', '4', '9', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '6', '3', '9', '0', '8', '2', '.', '0']]\n",
      "decoded_data: ['PID is 5867.0, B02 is 324.0, DOY is 211.0, B04 is 543.0, B03 is 492.0 639082.0']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5867.0, B04 is 543.0, DOY is 211.0, B02 is 324.0, B03 is']\n",
      "prompt: PID is 5867.0, B04 is 543.0, DOY is 211.0, B02 is 324.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '8', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '8', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '4', '.', '0', ',', '', 'B03', 'is', '', '4', '9', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['PID is 5867.0, B04 is 543.0, DOY is 211.0, B02 is 324.0, B03 is 492.0 B04 is PID is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 324.0, PID is 5867.0, B04 is 543.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 324.0, PID is 5867.0, B04 is 543.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '3', '.', '0', ',', '', 'B03', 'is', '', '4', '9', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '4', '7', '0', '2', '4']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 324.0, PID is 5867.0, B04 is 543.0, B03 is 492.0 B04 is 47024']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 324.0, B04 is 543.0, DOY is 211.0, PID is 5867.0, B03 is']\n",
      "prompt: B02 is 324.0, B04 is 543.0, DOY is 211.0, PID is 5867.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '2', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '2', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '4', '9', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', '5', '0']]\n",
      "decoded_data: ['B02 is 324.0, B04 is 543.0, DOY is 211.0, PID is 5867.0, B03 is 492.0 B04 is B04 is 50']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 543.0, DOY is 211.0, B02 is 324.0, PID is 5867.0, B03 is']\n",
      "prompt: B04 is 543.0, DOY is 211.0, B02 is 324.0, PID is 5867.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '4', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '4', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '4', '9', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', '4', '7', '3', '6', '0']]\n",
      "decoded_data: ['B04 is 543.0, DOY is 211.0, B02 is 324.0, PID is 5867.0, B03 is 492.0 B03 is 47360']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 543.0, DOY is 211.0, PID is 5867.0, B02 is 324.0, B03 is']\n",
      "prompt: B04 is 543.0, DOY is 211.0, PID is 5867.0, B02 is 324.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '4', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '4', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '4', '.', '0', ',', '', 'B03', 'is', '', '4', '9', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '4', '7', '3', '.', '0', ',', '', 'B04', 'is']]\n",
      "decoded_data: ['B04 is 543.0, DOY is 211.0, PID is 5867.0, B02 is 324.0, B03 is 492.0473.0, B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 324.0, PID is 5867.0, B04 is 543.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 324.0, PID is 5867.0, B04 is 543.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '2', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '2', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '4', '9', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '7', '3', '6', '3', '5', '6', '3']]\n",
      "decoded_data: ['B02 is 324.0, PID is 5867.0, B04 is 543.0, DOY is 211.0, B03 is 492.0 47363563']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 543.0, PID is 5867.0, B02 is 324.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 543.0, PID is 5867.0, B02 is 324.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '4', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|        | 121/829 [03:35<24:23,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B04', 'is', '', '5', '4', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '4', '8', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '4', '7', '2', '8', '2', '8', '7', '3', '2']]\n",
      "decoded_data: ['B04 is 543.0, PID is 5867.0, B02 is 324.0, DOY is 211.0, B03 is 488.0472828732']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5967.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 5967.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '9', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|        | 122/829 [03:35<18:11,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '5', '9', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '5', '.', '0', ',', '', 'B03', 'is', '', '6', '3', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '3', '3', '3', '3', '3', '3', '3', '3', '3']]\n",
      "decoded_data: ['PID is 5967.0, DOY is 211.0, B02 is 360.0, B04 is 585.0, B03 is 633.0333333333']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6067.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 6067.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B03', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6067.0, B02 is 357.0, B03 is 697.0, B04 is 558.0 PID is B03 is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6067.0, B03 is 697.0, DOY is 211.0, B02 is 357.0, B04 is']\n",
      "prompt: PID is 6067.0, B03 is 697.0, DOY is 211.0, B02 is 357.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '0', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '0', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'DOY', 'is', '', 'PID', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['PID is 6067.0, B03 is 697.0, DOY is 211.0, B02 is 357.0, B04 is 558.0 DOY is PID is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 357.0, B03 is 697.0, PID is 6067.0, B04 is']\n",
      "prompt: DOY is 211.0, B02 is 357.0, B03 is 697.0, PID is 6067.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'PID', 'is', '', '5', '6']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 357.0, B03 is 697.0, PID is 6067.0, B04 is 558.0 B03 is PID is 56']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 357.0, PID is 6067.0, DOY is 211.0, B03 is 697.0, B04 is']\n",
      "prompt: B02 is 357.0, PID is 6067.0, DOY is 211.0, B03 is 697.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '5', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '5', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '8', '4', '9', '7', '3', '7', '4']]\n",
      "decoded_data: ['B02 is 357.0, PID is 6067.0, DOY is 211.0, B03 is 697.0, B04 is 558.0 58497374']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 357.0, PID is 6067.0, B03 is 697.0, B04 is']\n",
      "prompt: DOY is 211.0, B02 is 357.0, PID is 6067.0, B03 is 697.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '8', '7', '8', '0', '6', '.', '0']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 357.0, PID is 6067.0, B03 is 697.0, B04 is 558.0 587806.0']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6067.0, B02 is 357.0, B03 is 697.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 6067.0, B02 is 357.0, B03 is 697.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', '5', '8', '2', '9', '8']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6067.0, B02 is 357.0, B03 is 697.0, B04 is 558.0 B03 is 58298']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6067.0, B02 is 357.0, B03 is 697.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 6067.0, B02 is 357.0, B03 is 697.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B03', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6067.0, B02 is 357.0, B03 is 697.0, B04 is 558.0 PID is B03 is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6067.0, B02 is 357.0, B03 is 697.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 6067.0, B02 is 357.0, B03 is 697.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '0', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '0', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '8', '2', '9', '7', '4', '5', '8']]\n",
      "decoded_data: ['PID is 6067.0, B02 is 357.0, B03 is 697.0, DOY is 211.0, B04 is 558.0 58297458']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 697.0, B02 is 357.0, DOY is 211.0, PID is 6067.0, B04 is']\n",
      "prompt: B03 is 697.0, B02 is 357.0, DOY is 211.0, PID is 6067.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '9', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '6', '9', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'DOY', 'is', '', 'PID', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['B03 is 697.0, B02 is 357.0, DOY is 211.0, PID is 6067.0, B04 is 552.0 DOY is PID is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 697.0, B02 is 357.0, DOY is 211.0, PID is 6067.0, B04 is']\n",
      "prompt: B03 is 697.0, B02 is 357.0, DOY is 211.0, PID is 6067.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '9', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '6', '9', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'PID', 'is', '', '5', '8']]\n",
      "decoded_data: ['B03 is 697.0, B02 is 357.0, DOY is 211.0, PID is 6067.0, B04 is 558.0 B03 is PID is 58']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6067.0, B03 is 697.0, B02 is 357.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 6067.0, B03 is 697.0, B02 is 357.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '0', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|        | 123/829 [03:37<19:27,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '6', '0', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '8', '2', '1', '0', '6', '3', '5', '8']]\n",
      "decoded_data: ['PID is 6067.0, B03 is 697.0, B02 is 357.0, DOY is 211.0, B04 is 558.0582106358']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6167.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 6167.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6167.0, B04 is 566.0, B03 is 715.0, B02 is 355.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6167.0, DOY is 211.0, B03 is 715.0, B04 is 566.0, B02 is']\n",
      "prompt: PID is 6167.0, DOY is 211.0, B03 is 715.0, B04 is 566.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '1', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '1', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '5', '6']]\n",
      "decoded_data: ['PID is 6167.0, DOY is 211.0, B03 is 715.0, B04 is 566.0, B02 is 355.0 PID is B04 is 56']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 566.0, DOY is 211.0, PID is 6167.0, B03 is 715.0, B02 is']\n",
      "prompt: B04 is 566.0, DOY is 211.0, PID is 6167.0, B03 is 715.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '5', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '3', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['B04 is 566.0, DOY is 211.0, PID is 6167.0, B03 is 715.0, B02 is 355.0 3 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 715.0, PID is 6167.0, DOY is 211.0, B04 is 566.0, B02 is']\n",
      "prompt: B03 is 715.0, PID is 6167.0, DOY is 211.0, B04 is 566.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '1', '5', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '1', '5', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '5', '5', '5', '5', '5', '4', '0', '.']]\n",
      "decoded_data: ['B03 is 715.0, PID is 6167.0, DOY is 211.0, B04 is 566.0, B02 is 355.055555540.']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 715.0, PID is 6167.0, B04 is 566.0, B02 is']\n",
      "prompt: DOY is 211.0, B03 is 715.0, PID is 6167.0, B04 is 566.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '5', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'B02', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|        | 124/829 [03:38<17:10,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '5', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '5', '5', '5', '3', '.', '0', ',', '']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 715.0, PID is 6167.0, B04 is 566.0, B02 is 355.055553.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6167.0, DOY is 211.0, B04 is 566.0, B03 is 715.0, B02 is']\n",
      "prompt: PID is 6167.0, DOY is 211.0, B04 is 566.0, B03 is 715.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '1', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '5', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '1', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '5', '5', '5', '1', '0', ',', '', 'B04']]\n",
      "decoded_data: ['PID is 6167.0, DOY is 211.0, B04 is 566.0, B03 is 715.0, B02 is 355.0555510, B04']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6267.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 6267.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '2', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '2', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B03', 'is', '', '5', '1']]\n",
      "decoded_data: ['PID is 6267.0, DOY is 211.0, B03 is 709.0, B02 is 346.0, B04 is 519.0 PID is B03 is 51']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 346.0, PID is 6267.0, B03 is 709.0, B04 is']\n",
      "prompt: DOY is 211.0, B02 is 346.0, PID is 6267.0, B03 is 709.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '8', '4', '.', '0', '.', '0', ',']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 346.0, PID is 6267.0, B03 is 709.0, B04 is 519.0 584.0.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 346.0, PID is 6267.0, B03 is 709.0, DOY is 211.0, B04 is']\n",
      "prompt: B02 is 346.0, PID is 6267.0, B03 is 709.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '4', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '4', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '9', '5', '7', '4']]\n",
      "decoded_data: ['B02 is 346.0, PID is 6267.0, B03 is 709.0, DOY is 211.0, B04 is 519.0 PID is 59574']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 346.0, B03 is 709.0, PID is 6267.0, DOY is 211.0, B04 is']\n",
      "prompt: B02 is 346.0, B03 is 709.0, PID is 6267.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '4', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '4', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '4', '8', '6', '.', '0', '1', '8']]\n",
      "decoded_data: ['B02 is 346.0, B03 is 709.0, PID is 6267.0, DOY is 211.0, B04 is 547.0 5486.018']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 346.0, PID is 6267.0, DOY is 211.0, B03 is 709.0, B04 is']\n",
      "prompt: B02 is 346.0, PID is 6267.0, DOY is 211.0, B03 is 709.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '4', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '4', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '7', '5', '7', '5', '7', '8', '4']]\n",
      "decoded_data: ['B02 is 346.0, PID is 6267.0, DOY is 211.0, B03 is 709.0, B04 is 519.0 57575784']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 346.0, DOY is 211.0, B03 is 709.0, PID is 6267.0, B04 is']\n",
      "prompt: B02 is 346.0, DOY is 211.0, B03 is 709.0, PID is 6267.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '4', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '4', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', '5', '8', '9', '8', '4']]\n",
      "decoded_data: ['B02 is 346.0, DOY is 211.0, B03 is 709.0, PID is 6267.0, B04 is 544.0 B03 is 58984']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 346.0, DOY is 211.0, B03 is 709.0, PID is 6267.0, B04 is']\n",
      "prompt: B02 is 346.0, DOY is 211.0, B03 is 709.0, PID is 6267.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '4', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '4', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'DOY', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['B02 is 346.0, DOY is 211.0, B03 is 709.0, PID is 6267.0, B04 is 519.0 B03 is DOY is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 346.0, PID is 6267.0, DOY is 211.0, B03 is 709.0, B04 is']\n",
      "prompt: B02 is 346.0, PID is 6267.0, DOY is 211.0, B03 is 709.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '4', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '4', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '4', '4', '4', '4']]\n",
      "decoded_data: ['B02 is 346.0, PID is 6267.0, DOY is 211.0, B03 is 709.0, B04 is 519.0 PID is 54444']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 346.0, PID is 6267.0, DOY is 211.0, B03 is 709.0, B04 is']\n",
      "prompt: B02 is 346.0, PID is 6267.0, DOY is 211.0, B03 is 709.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '4', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '4', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'PID', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['B02 is 346.0, PID is 6267.0, DOY is 211.0, B03 is 709.0, B04 is 519.0 PID is PID is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 709.0, PID is 6267.0, DOY is 211.0, B02 is 346.0, B04 is']\n",
      "prompt: B03 is 709.0, PID is 6267.0, DOY is 211.0, B02 is 346.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '0', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '6', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '0', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B02', 'is', '', 'PID', 'is', '', '5', '4']]\n",
      "decoded_data: ['B03 is 709.0, PID is 6267.0, DOY is 211.0, B02 is 346.0, B04 is 519.0 B02 is PID is 54']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 346.0, PID is 6267.0, B03 is 709.0, DOY is 211.0, B04 is']\n",
      "prompt: B02 is 346.0, PID is 6267.0, B03 is 709.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '4', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '4', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '7', '4', '4', '4']]\n",
      "decoded_data: ['B02 is 346.0, PID is 6267.0, B03 is 709.0, DOY is 211.0, B04 is 519.0 PID is 57444']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 346.0, B03 is 709.0, DOY is 211.0, PID is 6267.0, B04 is']\n",
      "prompt: B02 is 346.0, B03 is 709.0, DOY is 211.0, PID is 6267.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '4', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '4', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'DOY', 'is', '', 'B03', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['B02 is 346.0, B03 is 709.0, DOY is 211.0, PID is 6267.0, B04 is 519.0 DOY is B03 is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6267.0, B03 is 709.0, B02 is 346.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 6267.0, B03 is 709.0, B02 is 346.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '6', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '4', '5', '6', '6', '.', '0', ',', '']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6267.0, B03 is 709.0, B02 is 346.0, B04 is 519.054566.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 346.0, PID is 6267.0, DOY is 211.0, B03 is 709.0, B04 is']\n",
      "prompt: B02 is 346.0, PID is 6267.0, DOY is 211.0, B03 is 709.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '4', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '4', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '7', '4', '4', '4', '.', '0', ',']]\n",
      "decoded_data: ['B02 is 346.0, PID is 6267.0, DOY is 211.0, B03 is 709.0, B04 is 519.0 57444.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6267.0, B03 is 709.0, B02 is 346.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 6267.0, B03 is 709.0, B02 is 346.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '6', '.', '0', ',', '', 'B04', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 15%|        | 125/829 [03:40<20:10,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B02', 'is', '', 'PID', 'is', '', '5', '4']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6267.0, B03 is 709.0, B02 is 346.0, B04 is 519.0 B02 is PID is 54']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6367.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 6367.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '3', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '3', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '7', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'DOY', 'is', '', 'B02', 'is', '', '4', '7']]\n",
      "decoded_data: ['PID is 6367.0, DOY is 211.0, B03 is 716.0, B02 is 266.0, B04 is 477.0 DOY is B02 is 47']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 266.0, PID is 6367.0, DOY is 211.0, B03 is 716.0, B04 is']\n",
      "prompt: B02 is 266.0, PID is 6367.0, DOY is 211.0, B03 is 716.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '7', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '7', '7', '7', '7', '7', '7', '.']]\n",
      "decoded_data: ['B02 is 266.0, PID is 6367.0, DOY is 211.0, B03 is 716.0, B04 is 477.0 4777777.']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6367.0, DOY is 211.0, B02 is 266.0, B03 is 716.0, B04 is']\n",
      "prompt: PID is 6367.0, DOY is 211.0, B02 is 266.0, B03 is 716.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '3', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '3', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '7', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '4', '3', '6', '6', '0']]\n",
      "decoded_data: ['PID is 6367.0, DOY is 211.0, B02 is 266.0, B03 is 716.0, B04 is 477.0 PID is 43660']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6367.0, B03 is 716.0, B02 is 266.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 6367.0, B03 is 716.0, B02 is 266.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '3', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '3', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '7', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '7', '7', '7', '7', '7', '7', '.']]\n",
      "decoded_data: ['PID is 6367.0, B03 is 716.0, B02 is 266.0, DOY is 211.0, B04 is 477.0 4777777.']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 716.0, DOY is 211.0, B02 is 266.0, PID is 6367.0, B04 is']\n",
      "prompt: B03 is 716.0, DOY is 211.0, B02 is 266.0, PID is 6367.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '7', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '3', '8', '4', '.', '0', 'is', '']]\n",
      "decoded_data: ['B03 is 716.0, DOY is 211.0, B02 is 266.0, PID is 6367.0, B04 is 477.0 4384.0 is ']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 716.0, B02 is 266.0, PID is 6367.0, DOY is 211.0, B04 is']\n",
      "prompt: B03 is 716.0, B02 is 266.0, PID is 6367.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '7', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'DOY', 'is', '', '2', '1', '9', '4', '7']]\n",
      "decoded_data: ['B03 is 716.0, B02 is 266.0, PID is 6367.0, DOY is 211.0, B04 is 477.0 DOY is 21947']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 716.0, DOY is 211.0, B02 is 266.0, PID is 6367.0, B04 is']\n",
      "prompt: B03 is 716.0, DOY is 211.0, B02 is 266.0, PID is 6367.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '7', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '.', '0', 'is', '', 'B02', 'is', '']]\n",
      "decoded_data: ['B03 is 716.0, DOY is 211.0, B02 is 266.0, PID is 6367.0, B04 is 477.0 4.0 is B02 is ']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6367.0, B02 is 266.0, B03 is 716.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 6367.0, B02 is 266.0, B03 is 716.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '3', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '3', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '7', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '4', '3', '6', '4', '3', '8', '4']]\n",
      "decoded_data: ['PID is 6367.0, B02 is 266.0, B03 is 716.0, DOY is 211.0, B04 is 477.0 44364384']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 266.0, PID is 6367.0, B03 is 716.0, DOY is 211.0, B04 is']\n",
      "prompt: B02 is 266.0, PID is 6367.0, B03 is 716.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '7', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '7', '7', '7', '7', '7', '.', '0']]\n",
      "decoded_data: ['B02 is 266.0, PID is 6367.0, B03 is 716.0, DOY is 211.0, B04 is 477.0 477777.0']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 266.0, B03 is 716.0, PID is 6367.0, B04 is']\n",
      "prompt: DOY is 211.0, B02 is 266.0, B03 is 716.0, PID is 6367.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '7', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '.', '0', ',', '', 'B03', 'is', '']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 266.0, B03 is 716.0, PID is 6367.0, B04 is 477.0 4.0, B03 is ']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6367.0, B02 is 266.0, B03 is 716.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 6367.0, B02 is 266.0, B03 is 716.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '7', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '7', '7', '7', '7', '7', '7', '7']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6367.0, B02 is 266.0, B03 is 716.0, B04 is 477.0 47777777']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 716.0, B02 is 266.0, DOY is 211.0, PID is 6367.0, B04 is']\n",
      "prompt: B03 is 716.0, B02 is 266.0, DOY is 211.0, PID is 6367.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '7', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'DOY', 'is', '', 'B02', 'is', '', 'B03', 'is']]\n",
      "decoded_data: ['B03 is 716.0, B02 is 266.0, DOY is 211.0, PID is 6367.0, B04 is 477.0 DOY is B02 is B03 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 716.0, B02 is 266.0, PID is 6367.0, DOY is 211.0, B04 is']\n",
      "prompt: B03 is 716.0, B02 is 266.0, PID is 6367.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '7', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '7', '7', '7', '7', '7', '.', '0']]\n",
      "decoded_data: ['B03 is 716.0, B02 is 266.0, PID is 6367.0, DOY is 211.0, B04 is 477.0 477777.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 716.0, B02 is 266.0, PID is 6367.0, DOY is 211.0, B04 is']\n",
      "prompt: B03 is 716.0, B02 is 266.0, PID is 6367.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '7', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '4', '3', '9', '.', '0', ',', '', 'B03', 'is']]\n",
      "decoded_data: ['B03 is 716.0, B02 is 266.0, PID is 6367.0, DOY is 211.0, B04 is 477.0439.0, B03 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6367.0, B02 is 266.0, DOY is 211.0, B03 is 716.0, B04 is']\n",
      "prompt: PID is 6367.0, B02 is 266.0, DOY is 211.0, B03 is 716.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '3', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'B04', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 15%|        | 126/829 [03:43<22:04,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '6', '3', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '7', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '6', '4', '7', '7', '7', '7', '7']]\n",
      "decoded_data: ['PID is 6367.0, B02 is 266.0, DOY is 211.0, B03 is 716.0, B04 is 477.0 46477777']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6467.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 6467.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'DOY', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6467.0, B04 is 493.0, B02 is 292.0, B03 is 715.0 B04 is DOY is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 292.0, B04 is 493.0, DOY is 211.0, PID is 6467.0, B03 is']\n",
      "prompt: B02 is 292.0, B04 is 493.0, DOY is 211.0, PID is 6467.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '9', '2', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '9', '2', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '9', '2', '.', '0', ',', '', 'B04', 'is', '']]\n",
      "decoded_data: ['B02 is 292.0, B04 is 493.0, DOY is 211.0, PID is 6467.0, B03 is 715.092.0, B04 is ']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 493.0, DOY is 211.0, B02 is 292.0, PID is 6467.0, B03 is']\n",
      "prompt: B04 is 493.0, DOY is 211.0, B02 is 292.0, PID is 6467.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '9', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '2', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '9', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '2', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B02', 'is', '', 'B04', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['B04 is 493.0, DOY is 211.0, B02 is 292.0, PID is 6467.0, B03 is 715.0 B02 is B04 is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6467.0, DOY is 211.0, B02 is 292.0, B04 is 493.0, B03 is']\n",
      "prompt: PID is 6467.0, DOY is 211.0, B02 is 292.0, B04 is 493.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '4', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '2', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '4', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '2', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '4', '8', '1', '8', '1']]\n",
      "decoded_data: ['PID is 6467.0, DOY is 211.0, B02 is 292.0, B04 is 493.0, B03 is 715.0 B04 is 48181']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 493.0, B02 is 292.0, PID is 6467.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 493.0, B02 is 292.0, PID is 6467.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '2', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '2', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B02', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 493.0, B02 is 292.0, PID is 6467.0, B03 is 715.0 B04 is B02 is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6467.0, B02 is 292.0, B04 is 493.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 6467.0, B02 is 292.0, B04 is 493.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '2', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '2', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '5', '5', '8', '9']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6467.0, B02 is 292.0, B04 is 493.0, B03 is 715.0 B04 is 55589']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 292.0, DOY is 211.0, PID is 6467.0, B04 is 493.0, B03 is']\n",
      "prompt: B02 is 292.0, DOY is 211.0, PID is 6467.0, B04 is 493.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '9', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '9', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '7', '8', '4', '.']]\n",
      "decoded_data: ['B02 is 292.0, DOY is 211.0, PID is 6467.0, B04 is 493.0, B03 is 715.0 B04 is 5784.']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 292.0, B04 is 493.0, PID is 6467.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 292.0, B04 is 493.0, PID is 6467.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '2', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '3', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '2', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '3', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'DOY', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 292.0, B04 is 493.0, PID is 6467.0, B03 is 715.0 B04 is DOY is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 292.0, DOY is 211.0, PID is 6467.0, B04 is 493.0, B03 is']\n",
      "prompt: B02 is 292.0, DOY is 211.0, PID is 6467.0, B04 is 493.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '9', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '9', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '2', '8', '0', '5', '2', '5', '2', '1', '.']]\n",
      "decoded_data: ['B02 is 292.0, DOY is 211.0, PID is 6467.0, B04 is 493.0, B03 is 715.028052521.']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6467.0, B04 is 493.0, B02 is 292.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 6467.0, B04 is 493.0, B02 is 292.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '4', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '4', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['PID is 6467.0, B04 is 493.0, B02 is 292.0, DOY is 211.0, B03 is 715.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 292.0, PID is 6467.0, B04 is 493.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 292.0, PID is 6467.0, B04 is 493.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '9', '2', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '9', '2', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '4', '5', '1', '5', '8']]\n",
      "decoded_data: ['B02 is 292.0, PID is 6467.0, B04 is 493.0, DOY is 211.0, B03 is 715.0 B04 is 45158']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 493.0, B02 is 292.0, DOY is 211.0, PID is 6467.0, B03 is']\n",
      "prompt: B04 is 493.0, B02 is 292.0, DOY is 211.0, PID is 6467.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '9', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '9', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B02', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['B04 is 493.0, B02 is 292.0, DOY is 211.0, PID is 6467.0, B03 is 715.0 B04 is B02 is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 292.0, DOY is 211.0, PID is 6467.0, B04 is 493.0, B03 is']\n",
      "prompt: B02 is 292.0, DOY is 211.0, PID is 6467.0, B04 is 493.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '9', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '9', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '4', '5', '1', '5', '9']]\n",
      "decoded_data: ['B02 is 292.0, DOY is 211.0, PID is 6467.0, B04 is 493.0, B03 is 715.0 B04 is 45159']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 292.0, DOY is 211.0, B04 is 493.0, PID is 6467.0, B03 is']\n",
      "prompt: B02 is 292.0, DOY is 211.0, B04 is 493.0, PID is 6467.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '9', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '3', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '9', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '3', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '7', '8', '5', '2', '5']]\n",
      "decoded_data: ['B02 is 292.0, DOY is 211.0, B04 is 493.0, PID is 6467.0, B03 is 715.0 B04 is 78525']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 493.0, DOY is 211.0, B02 is 292.0, PID is 6467.0, B03 is']\n",
      "prompt: B04 is 493.0, DOY is 211.0, B02 is 292.0, PID is 6467.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '9', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '2', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '7', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 15%|        | 127/829 [03:45<23:31,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B04', 'is', '', '4', '9', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '2', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B02', 'is', '', 'B02', 'is', '', '2', '.']]\n",
      "decoded_data: ['B04 is 493.0, DOY is 211.0, B02 is 292.0, PID is 6467.0, B03 is 715.0 B02 is B02 is 2.']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6567.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 6567.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'B04', 'is', '', '5', '4']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6567.0, B03 is 700.0, B04 is 528.0, B02 is 312.0 B03 is B04 is 54']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 700.0, PID is 6567.0, B04 is 528.0, B02 is']\n",
      "prompt: DOY is 211.0, B03 is 700.0, PID is 6567.0, B04 is 528.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '0', '7', '3', '.', '0', ',', '', 'PID']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 700.0, PID is 6567.0, B04 is 528.0, B02 is 312.07073.0, PID']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6567.0, DOY is 211.0, B04 is 528.0, B03 is 700.0, B02 is']\n",
      "prompt: PID is 6567.0, DOY is 211.0, B04 is 528.0, B03 is 700.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '5', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '5', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '0', '0', '7', '0']]\n",
      "decoded_data: ['PID is 6567.0, DOY is 211.0, B04 is 528.0, B03 is 700.0, B02 is 312.0 B04 is 50070']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6567.0, B03 is 700.0, DOY is 211.0, B04 is 528.0, B02 is']\n",
      "prompt: PID is 6567.0, B03 is 700.0, DOY is 211.0, B04 is 528.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '5', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '5', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '3', '.', '0', '0']]\n",
      "decoded_data: ['PID is 6567.0, B03 is 700.0, DOY is 211.0, B04 is 528.0, B02 is 312.0 B04 is 53.00']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6567.0, B04 is 528.0, B03 is 700.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 6567.0, B04 is 528.0, B03 is 700.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B03', 'is', '', '6', '7']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6567.0, B04 is 528.0, B03 is 700.0, B02 is 312.0 B04 is B03 is 67']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 700.0, B04 is 528.0, DOY is 211.0, PID is 6567.0, B02 is']\n",
      "prompt: B03 is 700.0, B04 is 528.0, DOY is 211.0, PID is 6567.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '1', '2', '0', '2', '0', '2', '2', '0', '.']]\n",
      "decoded_data: ['B03 is 700.0, B04 is 528.0, DOY is 211.0, PID is 6567.0, B02 is 312.012020220.']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 528.0, PID is 6567.0, B03 is 700.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 528.0, PID is 6567.0, B03 is 700.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '3', '1', '2', '.', '0', '2', '0', '0']]\n",
      "decoded_data: ['B04 is 528.0, PID is 6567.0, B03 is 700.0, DOY is 211.0, B02 is 312.0 312.0200']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 700.0, B04 is 528.0, DOY is 211.0, PID is 6567.0, B02 is']\n",
      "prompt: B03 is 700.0, B04 is 528.0, DOY is 211.0, PID is 6567.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '1', '2', '.', '0', '2', '0', '2', '0', ',']]\n",
      "decoded_data: ['B03 is 700.0, B04 is 528.0, DOY is 211.0, PID is 6567.0, B02 is 312.012.02020,']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 700.0, DOY is 211.0, PID is 6567.0, B04 is 528.0, B02 is']\n",
      "prompt: B03 is 700.0, DOY is 211.0, PID is 6567.0, B04 is 528.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '3', '2', '3', '1', '2']]\n",
      "decoded_data: ['B03 is 700.0, DOY is 211.0, PID is 6567.0, B04 is 528.0, B02 is 312.0 PID is 32312']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 528.0, PID is 6567.0, B03 is 700.0, B02 is']\n",
      "prompt: DOY is 211.0, B04 is 528.0, PID is 6567.0, B03 is 700.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '3', '9']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 528.0, PID is 6567.0, B03 is 700.0, B02 is 312.0 PID is B04 is 39']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 700.0, PID is 6567.0, B04 is 528.0, DOY is 211.0, B02 is']\n",
      "prompt: B03 is 700.0, PID is 6567.0, B04 is 528.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '3', '0', '7', '0', '1', '2', '0', '2']]\n",
      "decoded_data: ['B03 is 700.0, PID is 6567.0, B04 is 528.0, DOY is 211.0, B02 is 312.0 30701202']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6567.0, B03 is 700.0, B04 is 528.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 6567.0, B03 is 700.0, B04 is 528.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6567.0, B03 is 700.0, B04 is 528.0, B02 is 312.0 B03 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 528.0, DOY is 211.0, B03 is 700.0, PID is 6567.0, B02 is']\n",
      "prompt: B04 is 528.0, DOY is 211.0, B03 is 700.0, PID is 6567.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'DOY', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['B04 is 528.0, DOY is 211.0, B03 is 700.0, PID is 6567.0, B02 is 312.0 B04 is DOY is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 700.0, B04 is 528.0, DOY is 211.0, PID is 6567.0, B02 is']\n",
      "prompt: B03 is 700.0, B04 is 528.0, DOY is 211.0, PID is 6567.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'B04', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['B03 is 700.0, B04 is 528.0, DOY is 211.0, PID is 6567.0, B02 is 312.0 B03 is B04 is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 700.0, PID is 6567.0, DOY is 211.0, B04 is 528.0, B02 is']\n",
      "prompt: B03 is 700.0, PID is 6567.0, DOY is 211.0, B04 is 528.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'B02', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 15%|        | 128/829 [03:47<24:27,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '3', '1', '2', '7', '9']]\n",
      "decoded_data: ['B03 is 700.0, PID is 6567.0, DOY is 211.0, B04 is 528.0, B02 is 312.0 B04 is 31279']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6667.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 6667.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '3', '0', '8', '0', '8', '5', '0', '8']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6667.0, B03 is 683.0, B04 is 519.0, B02 is 308.0 30808508']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6667.0, B03 is 683.0, DOY is 211.0, B04 is 519.0, B02 is']\n",
      "prompt: PID is 6667.0, B03 is 683.0, DOY is 211.0, B04 is 519.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '6', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '9', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '6', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '3', '0', '8', '4', '1', '0', '8', '5']]\n",
      "decoded_data: ['PID is 6667.0, B03 is 683.0, DOY is 211.0, B04 is 519.0, B02 is 308.0 30841085']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6667.0, DOY is 211.0, B03 is 683.0, B04 is 519.0, B02 is']\n",
      "prompt: PID is 6667.0, DOY is 211.0, B03 is 683.0, B04 is 519.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '6', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '9', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '6', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'PID', 'is', '', '6', '6']]\n",
      "decoded_data: ['PID is 6667.0, DOY is 211.0, B03 is 683.0, B04 is 519.0, B02 is 308.0 B03 is PID is 66']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 519.0, PID is 6667.0, B03 is 683.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 519.0, PID is 6667.0, B03 is 683.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '1', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '1', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '0', '8', '5', '0']]\n",
      "decoded_data: ['B04 is 519.0, PID is 6667.0, B03 is 683.0, DOY is 211.0, B02 is 308.0 B04 is 50850']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 683.0, DOY is 211.0, B04 is 519.0, PID is 6667.0, B02 is']\n",
      "prompt: B03 is 683.0, DOY is 211.0, B04 is 519.0, PID is 6667.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '8', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '6', '8', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '3', '0', '8', '6', '9']]\n",
      "decoded_data: ['B03 is 683.0, DOY is 211.0, B04 is 519.0, PID is 6667.0, B02 is 308.0 PID is 30869']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6667.0, B04 is 519.0, B03 is 683.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 6667.0, B04 is 519.0, B03 is 683.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '6', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '9', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '6', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '9', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', '3', '0', '8', 'B04', 'is']]\n",
      "decoded_data: ['PID is 6667.0, B04 is 519.0, B03 is 683.0, DOY is 211.0, B02 is 308.0 B03 is 308B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 519.0, PID is 6667.0, B03 is 683.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 519.0, PID is 6667.0, B03 is 683.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '1', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '1', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '3', '0', '8', '6', '6']]\n",
      "decoded_data: ['B04 is 519.0, PID is 6667.0, B03 is 683.0, DOY is 211.0, B02 is 308.0 B04 is 30866']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 683.0, B04 is 519.0, PID is 6667.0, B02 is']\n",
      "prompt: DOY is 211.0, B03 is 683.0, B04 is 519.0, PID is 6667.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B03', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 683.0, B04 is 519.0, PID is 6667.0, B02 is 308.0 B04 is B03 is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6667.0, B04 is 519.0, B03 is 683.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 6667.0, B04 is 519.0, B03 is 683.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '9', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '3', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '9', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '3', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'B04', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6667.0, B04 is 519.0, B03 is 683.0, B02 is 308.0 B03 is B04 is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 683.0, B04 is 519.0, PID is 6667.0, DOY is 211.0, B02 is']\n",
      "prompt: B03 is 683.0, B04 is 519.0, PID is 6667.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '8', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '6', '8', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '3', '0', '8', '8', '6', '.', '0', '8']]\n",
      "decoded_data: ['B03 is 683.0, B04 is 519.0, PID is 6667.0, DOY is 211.0, B02 is 308.0 30886.08']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 519.0, B03 is 683.0, DOY is 211.0, PID is 6667.0, B02 is']\n",
      "prompt: B04 is 519.0, B03 is 683.0, DOY is 211.0, PID is 6667.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '1', '9', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '1', '9', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['B04 is 519.0, B03 is 683.0, DOY is 211.0, PID is 6667.0, B02 is 308.0 B03 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6667.0, B03 is 683.0, B04 is 519.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 6667.0, B03 is 683.0, B04 is 519.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '9', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'B04', 'is', '', '5', '0']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6667.0, B03 is 683.0, B04 is 519.0, B02 is 308.0 B03 is B04 is 50']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 519.0, PID is 6667.0, B03 is 683.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 519.0, PID is 6667.0, B03 is 683.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '1', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '1', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['B04 is 519.0, PID is 6667.0, B03 is 683.0, DOY is 211.0, B02 is 308.0 B03 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6667.0, B04 is 519.0, B03 is 683.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 6667.0, B04 is 519.0, B03 is 683.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '9', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '3', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '9', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '3', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '3', '0', ',', '', 'B04', 'is', '', 'B04']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6667.0, B04 is 519.0, B03 is 683.0, B02 is 308.0 30, B04 is B04']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 683.0, B04 is 519.0, PID is 6667.0, DOY is 211.0, B02 is']\n",
      "prompt: B03 is 683.0, B04 is 519.0, PID is 6667.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '8', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 16%|        | 129/829 [03:50<25:17,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B03', 'is', '', '6', '8', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B03', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['B03 is 683.0, B04 is 519.0, PID is 6667.0, DOY is 211.0, B02 is 308.0 B04 is B03 is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6767.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 6767.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '7', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '7', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '8', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B03', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['PID is 6767.0, DOY is 211.0, B04 is 548.0, B03 is 694.0, B02 is 310.0 B04 is B03 is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 548.0, B03 is 694.0, PID is 6767.0, B02 is']\n",
      "prompt: DOY is 211.0, B04 is 548.0, B03 is 694.0, PID is 6767.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '8', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '4', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '8', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '4', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '3', '0', '4', '3', '0', '.', '0', ',', '']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 548.0, B03 is 694.0, PID is 6767.0, B02 is 310.030430.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 548.0, B03 is 694.0, PID is 6767.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 548.0, B03 is 694.0, PID is 6767.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '4', '8', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '4', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '4', '8', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '4', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '3', '0', '4', '.', '0', '4', '1', '0']]\n",
      "decoded_data: ['B04 is 548.0, B03 is 694.0, PID is 6767.0, DOY is 211.0, B02 is 310.0 304.0410']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6767.0, B03 is 694.0, B04 is 548.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 6767.0, B03 is 694.0, B04 is 548.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '8', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '3', '.', '0', ',', '', 'B03', 'is', '', 'PID']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6767.0, B03 is 694.0, B04 is 548.0, B02 is 310.03.0, B03 is PID']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 548.0, B03 is 694.0, DOY is 211.0, PID is 6767.0, B02 is']\n",
      "prompt: B04 is 548.0, B03 is 694.0, DOY is 211.0, PID is 6767.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '4', '8', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '4', '8', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B03', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['B04 is 548.0, B03 is 694.0, DOY is 211.0, PID is 6767.0, B02 is 310.0 B04 is B03 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 694.0, DOY is 211.0, B04 is 548.0, PID is 6767.0, B02 is']\n",
      "prompt: B03 is 694.0, DOY is 211.0, B04 is 548.0, PID is 6767.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '9', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '8', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '6', '9', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '8', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B03', 'is', '', '3', '0']]\n",
      "decoded_data: ['B03 is 694.0, DOY is 211.0, B04 is 548.0, PID is 6767.0, B02 is 310.0 B04 is B03 is 30']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 694.0, DOY is 211.0, B04 is 548.0, PID is 6767.0, B02 is']\n",
      "prompt: B03 is 694.0, DOY is 211.0, B04 is 548.0, PID is 6767.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '9', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '8', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '6', '9', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '8', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B03', 'is']]\n",
      "decoded_data: ['B03 is 694.0, DOY is 211.0, B04 is 548.0, PID is 6767.0, B02 is 310.0 B04 is PID is B03 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 694.0, DOY is 211.0, B04 is 548.0, PID is 6767.0, B02 is']\n",
      "prompt: B03 is 694.0, DOY is 211.0, B04 is 548.0, PID is 6767.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '9', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '8', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '6', '9', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '8', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['B03 is 694.0, DOY is 211.0, B04 is 548.0, PID is 6767.0, B02 is 310.0 PID is B04 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 694.0, PID is 6767.0, B04 is 548.0, DOY is 211.0, B02 is']\n",
      "prompt: B03 is 694.0, PID is 6767.0, B04 is 548.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '9', '4', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '6', '9', '4', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['B03 is 694.0, PID is 6767.0, B04 is 548.0, DOY is 211.0, B02 is 310.0 B04 is PID is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 548.0, PID is 6767.0, DOY is 211.0, B03 is 694.0, B02 is']\n",
      "prompt: B04 is 548.0, PID is 6767.0, DOY is 211.0, B03 is 694.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '4', '8', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '4', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '4', '8', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['B04 is 548.0, PID is 6767.0, DOY is 211.0, B03 is 694.0, B02 is 310.0 PID is B04 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 548.0, B03 is 694.0, PID is 6767.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 548.0, B03 is 694.0, PID is 6767.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '4', '8', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '4', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '4', '8', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '4', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B03', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['B04 is 548.0, B03 is 694.0, PID is 6767.0, DOY is 211.0, B02 is 310.0 B04 is B03 is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6767.0, B04 is 548.0, B03 is 694.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 6767.0, B04 is 548.0, B03 is 694.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '7', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '8', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '7', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '8', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B03', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['PID is 6767.0, B04 is 548.0, B03 is 694.0, DOY is 211.0, B02 is 310.0 B04 is B03 is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 694.0, PID is 6767.0, DOY is 211.0, B04 is 548.0, B02 is']\n",
      "prompt: B03 is 694.0, PID is 6767.0, DOY is 211.0, B04 is 548.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '9', '4', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '8', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '6', '9', '4', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '5', '3']]\n",
      "decoded_data: ['B03 is 694.0, PID is 6767.0, DOY is 211.0, B04 is 548.0, B02 is 310.0 B04 is PID is 53']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 548.0, B03 is 694.0, DOY is 211.0, PID is 6767.0, B02 is']\n",
      "prompt: B04 is 548.0, B03 is 694.0, DOY is 211.0, PID is 6767.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '4', '8', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '4', '8', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '3', '0', '4', '0', '4', '7', '8', '0']]\n",
      "decoded_data: ['B04 is 548.0, B03 is 694.0, DOY is 211.0, PID is 6767.0, B02 is 310.0 30404780']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 694.0, B04 is 548.0, PID is 6767.0, B02 is']\n",
      "prompt: DOY is 211.0, B03 is 694.0, B04 is 548.0, PID is 6767.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '8', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '7', '.', '0', ',', '', 'B02', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 16%|        | 130/829 [03:52<26:06,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '8', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '5', '3']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 694.0, B04 is 548.0, PID is 6767.0, B02 is 310.0 B04 is PID is 53']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6867.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 6867.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '3', '6', '6', '5', '1', '6', '.', '0']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6867.0, B04 is 587.0, B03 is 716.0, B02 is 316.0 366516.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 716.0, B04 is 587.0, PID is 6867.0, DOY is 211.0, B02 is']\n",
      "prompt: B03 is 716.0, B04 is 587.0, PID is 6867.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '1', '6', '6', '6', '6', '6', '6', '.']]\n",
      "decoded_data: ['B03 is 716.0, B04 is 587.0, PID is 6867.0, DOY is 211.0, B02 is 316.071666666.']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6867.0, B03 is 716.0, DOY is 211.0, B04 is 587.0, B02 is']\n",
      "prompt: PID is 6867.0, B03 is 716.0, DOY is 211.0, B04 is 587.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '8', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '8', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '3', '6', '6', '6', '.', '0', ',', '', 'B04']]\n",
      "decoded_data: ['PID is 6867.0, B03 is 716.0, DOY is 211.0, B04 is 587.0, B02 is 316.03666.0, B04']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6867.0, B03 is 716.0, B04 is 587.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 6867.0, B03 is 716.0, B04 is 587.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '8', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '8', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '3', '7', '1', '6', '6', '.', '0', ',', '']]\n",
      "decoded_data: ['PID is 6867.0, B03 is 716.0, B04 is 587.0, DOY is 211.0, B02 is 316.037166.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 716.0, B04 is 587.0, DOY is 211.0, PID is 6867.0, B02 is']\n",
      "prompt: B03 is 716.0, B04 is 587.0, DOY is 211.0, PID is 6867.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '1', '6', '6', '6', '6', '.', '0', ',']]\n",
      "decoded_data: ['B03 is 716.0, B04 is 587.0, DOY is 211.0, PID is 6867.0, B02 is 316.0716666.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 716.0, B04 is 587.0, PID is 6867.0, DOY is 211.0, B02 is']\n",
      "prompt: B03 is 716.0, B04 is 587.0, PID is 6867.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B02', 'is', '', '3', '7', '1', '6', '6']]\n",
      "decoded_data: ['B03 is 716.0, B04 is 587.0, PID is 6867.0, DOY is 211.0, B02 is 316.0 B02 is 37166']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6867.0, B04 is 587.0, B03 is 716.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 6867.0, B04 is 587.0, B03 is 716.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '8', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '8', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '1', '6', '6', '6', '6', '.', '0', ',', '']]\n",
      "decoded_data: ['PID is 6867.0, B04 is 587.0, B03 is 716.0, DOY is 211.0, B02 is 316.016666.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 587.0, DOY is 211.0, PID is 6867.0, B03 is 716.0, B02 is']\n",
      "prompt: B04 is 587.0, DOY is 211.0, PID is 6867.0, B03 is 716.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '8', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '8', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '3', '9', '2', '7', '1', '6', '6', '6']]\n",
      "decoded_data: ['B04 is 587.0, DOY is 211.0, PID is 6867.0, B03 is 716.0, B02 is 316.0 39271666']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 587.0, B03 is 716.0, PID is 6867.0, B02 is']\n",
      "prompt: DOY is 211.0, B04 is 587.0, B03 is 716.0, PID is 6867.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '3', '7', '.', '0', ',', '', '3', '7']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 587.0, B03 is 716.0, PID is 6867.0, B02 is 316.0 37.0, 37']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 587.0, B03 is 716.0, PID is 6867.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 587.0, B03 is 716.0, PID is 6867.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '8', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '8', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '1', '6', '6', '6', '6', '6', '6', '.', '0']]\n",
      "decoded_data: ['B04 is 587.0, B03 is 716.0, PID is 6867.0, DOY is 211.0, B02 is 316.01666666.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 716.0, DOY is 211.0, B04 is 587.0, PID is 6867.0, B02 is']\n",
      "prompt: B03 is 716.0, DOY is 211.0, B04 is 587.0, PID is 6867.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '3', '5', '1', '6', '6', '6', '6', '.', '0']]\n",
      "decoded_data: ['B03 is 716.0, DOY is 211.0, B04 is 587.0, PID is 6867.0, B02 is 316.03516666.0']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 716.0, PID is 6867.0, B04 is 587.0, B02 is']\n",
      "prompt: DOY is 211.0, B03 is 716.0, PID is 6867.0, B04 is 587.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '3', '9', '2', '7', '.', '0', ',', '']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 716.0, PID is 6867.0, B04 is 587.0, B02 is 316.0 3927.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 716.0, B04 is 587.0, PID is 6867.0, DOY is 211.0, B02 is']\n",
      "prompt: B03 is 716.0, B04 is 587.0, PID is 6867.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '3', '7', '1', '6', '6']]\n",
      "decoded_data: ['B03 is 716.0, B04 is 587.0, PID is 6867.0, DOY is 211.0, B02 is 316.0 PID is 37166']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 716.0, B04 is 587.0, PID is 6867.0, B02 is']\n",
      "prompt: DOY is 211.0, B03 is 716.0, B04 is 587.0, PID is 6867.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '3', '5', '1', '6', '6', '6', '6', '6']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 716.0, B04 is 587.0, PID is 6867.0, B02 is 316.0 35166666']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6867.0, DOY is 211.0, B03 is 716.0, B04 is 587.0, B02 is']\n",
      "prompt: PID is 6867.0, DOY is 211.0, B03 is 716.0, B04 is 587.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '8', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '7', '.', '0', ',', '', 'B02', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 16%|        | 131/829 [03:54<26:33,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '6', '8', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '3', '5', '1', '6', '6', '6', '6', '6']]\n",
      "decoded_data: ['PID is 6867.0, DOY is 211.0, B03 is 716.0, B04 is 587.0, B02 is 316.0 35166666']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6967.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 6967.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '9', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '9', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['PID is 6967.0, DOY is 211.0, B04 is 528.0, B02 is 301.0, B03 is 741.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 528.0, B02 is 301.0, DOY is 211.0, PID is 6967.0, B03 is']\n",
      "prompt: B04 is 528.0, B02 is 301.0, DOY is 211.0, PID is 6967.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B02', 'is', '', 'B04', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['B04 is 528.0, B02 is 301.0, DOY is 211.0, PID is 6967.0, B03 is 741.0 B02 is B04 is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 301.0, DOY is 211.0, PID is 6967.0, B04 is 528.0, B03 is']\n",
      "prompt: B02 is 301.0, DOY is 211.0, PID is 6967.0, B04 is 528.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '4']]\n",
      "decoded_data: ['B02 is 301.0, DOY is 211.0, PID is 6967.0, B04 is 528.0, B03 is 741.0 B04 is PID is 74']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 301.0, DOY is 211.0, PID is 6967.0, B04 is 528.0, B03 is']\n",
      "prompt: B02 is 301.0, DOY is 211.0, PID is 6967.0, B04 is 528.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '2', '4', '1', '0']]\n",
      "decoded_data: ['B02 is 301.0, DOY is 211.0, PID is 6967.0, B04 is 528.0, B03 is 741.0 B04 is 52410']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 301.0, PID is 6967.0, DOY is 211.0, B04 is 528.0, B03 is']\n",
      "prompt: B02 is 301.0, PID is 6967.0, DOY is 211.0, B04 is 528.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '7', '4', '1', '0', '2', '.', '0', 'DOY']]\n",
      "decoded_data: ['B02 is 301.0, PID is 6967.0, DOY is 211.0, B04 is 528.0, B03 is 741.0 74102.0DOY']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 528.0, B02 is 301.0, PID is 6967.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 528.0, B02 is 301.0, PID is 6967.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '6', '4']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 528.0, B02 is 301.0, PID is 6967.0, B03 is 741.0 B04 is PID is 64']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6967.0, B04 is 528.0, B02 is 301.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 6967.0, B04 is 528.0, B02 is 301.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '9', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '9', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '7', '9', '0', ',', '', 'B04', 'is', '']]\n",
      "decoded_data: ['PID is 6967.0, B04 is 528.0, B02 is 301.0, DOY is 211.0, B03 is 741.0 790, B04 is ']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 301.0, PID is 6967.0, B04 is 528.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 301.0, PID is 6967.0, B04 is 528.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '4']]\n",
      "decoded_data: ['B02 is 301.0, PID is 6967.0, B04 is 528.0, DOY is 211.0, B03 is 741.0 B04 is PID is 74']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 301.0, PID is 6967.0, B04 is 528.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 301.0, PID is 6967.0, B04 is 528.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '7', '8']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 301.0, PID is 6967.0, B04 is 528.0, B03 is 741.0 PID is B04 is 78']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 301.0, PID is 6967.0, B04 is 528.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 301.0, PID is 6967.0, B04 is 528.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '4', '1', 'B02', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 301.0, PID is 6967.0, B04 is 528.0, B03 is 741.0 PID is 741B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 528.0, PID is 6967.0, B02 is 301.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 528.0, PID is 6967.0, B02 is 301.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B02', 'is', '', '3', '5', '2', '8', '7']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 528.0, PID is 6967.0, B02 is 301.0, B03 is 741.0 B02 is 35287']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 301.0, PID is 6967.0, B04 is 528.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 301.0, PID is 6967.0, B04 is 528.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '4', '1', '3', '5']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 301.0, PID is 6967.0, B04 is 528.0, B03 is 741.0 PID is 74135']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6967.0, B04 is 528.0, B02 is 301.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 6967.0, B04 is 528.0, B02 is 301.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B02', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6967.0, B04 is 528.0, B02 is 301.0, B03 is 741.0 B04 is B02 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 301.0, PID is 6967.0, B04 is 528.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 301.0, PID is 6967.0, B04 is 528.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '7', '4', '1', '0', '0']]\n",
      "decoded_data: ['B02 is 301.0, PID is 6967.0, B04 is 528.0, DOY is 211.0, B03 is 741.0 B04 is 74100']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 528.0, PID is 6967.0, DOY is 211.0, B02 is 301.0, B03 is']\n",
      "prompt: B04 is 528.0, PID is 6967.0, DOY is 211.0, B02 is 301.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 16%|        | 132/829 [03:57<26:50,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '1', '7', '4', '1']]\n",
      "decoded_data: ['B04 is 528.0, PID is 6967.0, DOY is 211.0, B02 is 301.0, B03 is 741.0 PID is 71741']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7067.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 7067.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '0', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '0', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '6', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', '4', '7']]\n",
      "decoded_data: ['PID is 7067.0, DOY is 211.0, B04 is 463.0, B02 is 296.0, B03 is 679.0 B04 is B04 is 47']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 296.0, DOY is 211.0, B04 is 463.0, PID is 7067.0, B03 is']\n",
      "prompt: B02 is 296.0, DOY is 211.0, B04 is 463.0, PID is 7067.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '9', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '3', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '9', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '3', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'DOY', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['B02 is 296.0, DOY is 211.0, B04 is 463.0, PID is 7067.0, B03 is 679.0 B04 is DOY is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 7067.0, B02 is 296.0, B04 is 463.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 7067.0, B02 is 296.0, B04 is 463.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', '4', '1']]\n",
      "decoded_data: ['DOY is 211.0, PID is 7067.0, B02 is 296.0, B04 is 463.0, B03 is 727.0 B04 is B04 is 41']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 296.0, PID is 7067.0, B04 is 463.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 296.0, PID is 7067.0, B04 is 463.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '6', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '6', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '3', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '4', '6', '1', '6', '8']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 296.0, PID is 7067.0, B04 is 463.0, B03 is 679.0 B04 is 46168']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 296.0, DOY is 211.0, B04 is 463.0, PID is 7067.0, B03 is']\n",
      "prompt: B02 is 296.0, DOY is 211.0, B04 is 463.0, PID is 7067.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '9', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '3', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '9', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '3', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '2', '7', '.', '0', ',', '', 'B04', 'is', '']]\n",
      "decoded_data: ['B02 is 296.0, DOY is 211.0, B04 is 463.0, PID is 7067.0, B03 is 727.027.0, B04 is ']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7067.0, DOY is 211.0, B02 is 296.0, B04 is 463.0, B03 is']\n",
      "prompt: PID is 7067.0, DOY is 211.0, B02 is 296.0, B04 is 463.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '0', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '0', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', '4', '1']]\n",
      "decoded_data: ['PID is 7067.0, DOY is 211.0, B02 is 296.0, B04 is 463.0, B03 is 727.0 B04 is B04 is 41']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 296.0, DOY is 211.0, B04 is 463.0, PID is 7067.0, B03 is']\n",
      "prompt: B02 is 296.0, DOY is 211.0, B04 is 463.0, PID is 7067.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '9', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '3', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '9', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '3', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'DOY', 'is']]\n",
      "decoded_data: ['B02 is 296.0, DOY is 211.0, B04 is 463.0, PID is 7067.0, B03 is 679.0 B04 is PID is DOY is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 296.0, PID is 7067.0, B04 is 463.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 296.0, PID is 7067.0, B04 is 463.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '6', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '6', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '3', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '4', '6', '6', '.', '0']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 296.0, PID is 7067.0, B04 is 463.0, B03 is 679.0 B04 is 466.0']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 463.0, B02 is 296.0, PID is 7067.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 463.0, B02 is 296.0, PID is 7067.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '6', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '6', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'B04', 'is', '', 'DOY', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 463.0, B02 is 296.0, PID is 7067.0, B03 is 679.0 B03 is B04 is DOY is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 296.0, B04 is 463.0, PID is 7067.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 296.0, B04 is 463.0, PID is 7067.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '9', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '3', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '9', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '3', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '9']]\n",
      "decoded_data: ['B02 is 296.0, B04 is 463.0, PID is 7067.0, DOY is 211.0, B03 is 679.0 B04 is PID is 79']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 296.0, B04 is 463.0, PID is 7067.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 296.0, B04 is 463.0, PID is 7067.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '3', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '3', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'DOY', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 296.0, B04 is 463.0, PID is 7067.0, B03 is 679.0 B04 is DOY is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7067.0, B04 is 463.0, DOY is 211.0, B02 is 296.0, B03 is']\n",
      "prompt: PID is 7067.0, B04 is 463.0, DOY is 211.0, B02 is 296.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '0', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '0', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '2', '7', '9', '7', '8', '3', '.', '0', ',']]\n",
      "decoded_data: ['PID is 7067.0, B04 is 463.0, DOY is 211.0, B02 is 296.0, B03 is 727.0279783.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 296.0, DOY is 211.0, PID is 7067.0, B04 is 463.0, B03 is']\n",
      "prompt: B02 is 296.0, DOY is 211.0, PID is 7067.0, B04 is 463.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '9', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '9', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '2', '7', '.', '0', ',', '', 'B04', 'is', '']]\n",
      "decoded_data: ['B02 is 296.0, DOY is 211.0, PID is 7067.0, B04 is 463.0, B03 is 727.027.0, B04 is ']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 296.0, PID is 7067.0, DOY is 211.0, B04 is 463.0, B03 is']\n",
      "prompt: B02 is 296.0, PID is 7067.0, DOY is 211.0, B04 is 463.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '9', '6', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '9', '6', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '3', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '4', '6', '3', '6', '3']]\n",
      "decoded_data: ['B02 is 296.0, PID is 7067.0, DOY is 211.0, B04 is 463.0, B03 is 679.0 B04 is 46363']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 296.0, PID is 7067.0, DOY is 211.0, B04 is 463.0, B03 is']\n",
      "prompt: B02 is 296.0, PID is 7067.0, DOY is 211.0, B04 is 463.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '9', '6', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '3', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 16%|        | 133/829 [03:59<26:55,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B02', 'is', '', '2', '9', '6', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', '4', '8']]\n",
      "decoded_data: ['B02 is 296.0, PID is 7067.0, DOY is 211.0, B04 is 463.0, B03 is 727.0 B04 is B04 is 48']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 7167.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 7167.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'B02', 'is', '', '5', '7']]\n",
      "decoded_data: ['DOY is 211.0, PID is 7167.0, B03 is 687.0, B02 is 314.0, B04 is 501.0 B03 is B02 is 57']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 687.0, PID is 7167.0, DOY is 211.0, B02 is 314.0, B04 is']\n",
      "prompt: B03 is 687.0, PID is 7167.0, DOY is 211.0, B02 is 314.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '8', '7', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '6', '8', '7', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '7', '6', '6', '6']]\n",
      "decoded_data: ['B03 is 687.0, PID is 7167.0, DOY is 211.0, B02 is 314.0, B04 is 501.0 PID is 57666']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 687.0, PID is 7167.0, B02 is 314.0, B04 is']\n",
      "prompt: DOY is 211.0, B03 is 687.0, PID is 7167.0, B02 is 314.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B02', 'is', '', 'B02', 'is', '', '3', '0']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 687.0, PID is 7167.0, B02 is 314.0, B04 is 501.0 B02 is B02 is 30']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 687.0, B02 is 314.0, PID is 7167.0, DOY is 211.0, B04 is']\n",
      "prompt: B03 is 687.0, B02 is 314.0, PID is 7167.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '8', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '6', '8', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '7', '6', '9', '5', '.', '0', '1']]\n",
      "decoded_data: ['B03 is 687.0, B02 is 314.0, PID is 7167.0, DOY is 211.0, B04 is 501.0 57695.01']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 687.0, DOY is 211.0, PID is 7167.0, B02 is 314.0, B04 is']\n",
      "prompt: B03 is 687.0, DOY is 211.0, PID is 7167.0, B02 is 314.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '8', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '6', '8', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '1', '1', '.', '0', '1', '1', '.', '0', ',']]\n",
      "decoded_data: ['B03 is 687.0, DOY is 211.0, PID is 7167.0, B02 is 314.0, B04 is 501.011.011.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7167.0, B02 is 314.0, B03 is 687.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 7167.0, B02 is 314.0, B03 is 687.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '1', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '1', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '7', '1', '1', '1', '1', '1', '.']]\n",
      "decoded_data: ['PID is 7167.0, B02 is 314.0, B03 is 687.0, DOY is 211.0, B04 is 501.0 5711111.']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 314.0, PID is 7167.0, B03 is 687.0, DOY is 211.0, B04 is']\n",
      "prompt: B02 is 314.0, PID is 7167.0, B03 is 687.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '0', '1', '1', '7']]\n",
      "decoded_data: ['B02 is 314.0, PID is 7167.0, B03 is 687.0, DOY is 211.0, B04 is 501.0 PID is 50117']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7167.0, B03 is 687.0, B02 is 314.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 7167.0, B03 is 687.0, B02 is 314.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '1', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '1', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '3', '7', '1', '6', '.', '0', '1', '1']]\n",
      "decoded_data: ['PID is 7167.0, B03 is 687.0, B02 is 314.0, DOY is 211.0, B04 is 501.053716.011']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7167.0, DOY is 211.0, B02 is 314.0, B03 is 687.0, B04 is']\n",
      "prompt: PID is 7167.0, DOY is 211.0, B02 is 314.0, B03 is 687.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '1', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '1', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '0', '1', '7', '6']]\n",
      "decoded_data: ['PID is 7167.0, DOY is 211.0, B02 is 314.0, B03 is 687.0, B04 is 501.0 PID is 50176']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7167.0, B02 is 314.0, DOY is 211.0, B03 is 687.0, B04 is']\n",
      "prompt: PID is 7167.0, B02 is 314.0, DOY is 211.0, B03 is 687.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '1', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '1', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '7', '6', '3', '7']]\n",
      "decoded_data: ['PID is 7167.0, B02 is 314.0, DOY is 211.0, B03 is 687.0, B04 is 501.0 PID is 57637']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7167.0, B03 is 687.0, DOY is 211.0, B02 is 314.0, B04 is']\n",
      "prompt: PID is 7167.0, B03 is 687.0, DOY is 211.0, B02 is 314.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '1', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '1', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B02', 'is', '', '5', '0', '1', '1', '7']]\n",
      "decoded_data: ['PID is 7167.0, B03 is 687.0, DOY is 211.0, B02 is 314.0, B04 is 501.0 B02 is 50117']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 687.0, PID is 7167.0, DOY is 211.0, B02 is 314.0, B04 is']\n",
      "prompt: B03 is 687.0, PID is 7167.0, DOY is 211.0, B02 is 314.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '8', '7', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '6', '8', '7', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '0', '1', '7', '6', '9', '2', '1']]\n",
      "decoded_data: ['B03 is 687.0, PID is 7167.0, DOY is 211.0, B02 is 314.0, B04 is 501.0 50176921']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7167.0, B02 is 314.0, DOY is 211.0, B03 is 687.0, B04 is']\n",
      "prompt: PID is 7167.0, B02 is 314.0, DOY is 211.0, B03 is 687.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '1', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '1', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '7', '6', '9', '7', '6', '9', '2']]\n",
      "decoded_data: ['PID is 7167.0, B02 is 314.0, DOY is 211.0, B03 is 687.0, B04 is 501.0 57697692']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7167.0, B02 is 314.0, B03 is 687.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 7167.0, B02 is 314.0, B03 is 687.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '1', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '1', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '7', '6', '6', '.', '0', '8', '9']]\n",
      "decoded_data: ['PID is 7167.0, B02 is 314.0, B03 is 687.0, DOY is 211.0, B04 is 501.0 4766.089']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 687.0, PID is 7167.0, B02 is 314.0, B04 is']\n",
      "prompt: DOY is 211.0, B03 is 687.0, PID is 7167.0, B02 is 314.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B04', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 16%|        | 134/829 [04:01<27:01,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '7', '6', '.', '0', '1', '6', '.']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 687.0, PID is 7167.0, B02 is 314.0, B04 is 501.0 576.016.']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7267.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 7267.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '2', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '2', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'PID', 'is', '', '7', '9']]\n",
      "decoded_data: ['PID is 7267.0, DOY is 211.0, B03 is 700.0, B02 is 347.0, B04 is 566.0 PID is PID is 79']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 700.0, B02 is 347.0, PID is 7267.0, B04 is']\n",
      "prompt: DOY is 211.0, B03 is 700.0, B02 is 347.0, PID is 7267.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '7', '.', '0', ',', '', 'PID', 'is', '', '7', '2', '6', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '7', '.', '0', ',', '', 'PID', 'is', '', '7', '2', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'DOY', 'is', '', '5', '6', '6', '.', '0']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 700.0, B02 is 347.0, PID is 7267.0, B04 is 566.0 DOY is 566.0']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7267.0, B02 is 347.0, DOY is 211.0, B03 is 700.0, B04 is']\n",
      "prompt: PID is 7267.0, B02 is 347.0, DOY is 211.0, B03 is 700.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '2', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '2', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '6', '6', '6', '6']]\n",
      "decoded_data: ['PID is 7267.0, B02 is 347.0, DOY is 211.0, B03 is 700.0, B04 is 566.0 PID is 56666']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7267.0, DOY is 211.0, B02 is 347.0, B03 is 700.0, B04 is']\n",
      "prompt: PID is 7267.0, DOY is 211.0, B02 is 347.0, B03 is 700.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '2', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '2', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'DOY', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['PID is 7267.0, DOY is 211.0, B02 is 347.0, B03 is 700.0, B04 is 566.0 PID is DOY is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7267.0, B03 is 700.0, DOY is 211.0, B02 is 347.0, B04 is']\n",
      "prompt: PID is 7267.0, B03 is 700.0, DOY is 211.0, B02 is 347.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '2', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '2', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '6', '6', '6', '6']]\n",
      "decoded_data: ['PID is 7267.0, B03 is 700.0, DOY is 211.0, B02 is 347.0, B04 is 566.0 PID is 56666']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 347.0, DOY is 211.0, B03 is 700.0, PID is 7267.0, B04 is']\n",
      "prompt: B02 is 347.0, DOY is 211.0, B03 is 700.0, PID is 7267.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'PID', 'is', '', '7', '2', '6', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'PID', 'is', '', '7', '2', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '4', '9', '.', '0', '8', '8', '8']]\n",
      "decoded_data: ['B02 is 347.0, DOY is 211.0, B03 is 700.0, PID is 7267.0, B04 is 566.0 549.0888']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 700.0, B02 is 347.0, PID is 7267.0, DOY is 211.0, B04 is']\n",
      "prompt: B03 is 700.0, B02 is 347.0, PID is 7267.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '7', '.', '0', ',', '', 'PID', 'is', '', '7', '2', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '7', '.', '0', ',', '', 'PID', 'is', '', '7', '2', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '6', '6', '6', '6']]\n",
      "decoded_data: ['B03 is 700.0, B02 is 347.0, PID is 7267.0, DOY is 211.0, B04 is 566.0 PID is 56666']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7267.0, DOY is 211.0, B02 is 347.0, B03 is 700.0, B04 is']\n",
      "prompt: PID is 7267.0, DOY is 211.0, B02 is 347.0, B03 is 700.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '2', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '2', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B03', 'is', '', '5', '6']]\n",
      "decoded_data: ['PID is 7267.0, DOY is 211.0, B02 is 347.0, B03 is 700.0, B04 is 566.0 PID is B03 is 56']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7267.0, B03 is 700.0, DOY is 211.0, B02 is 347.0, B04 is']\n",
      "prompt: PID is 7267.0, B03 is 700.0, DOY is 211.0, B02 is 347.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '2', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '2', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '6', '6', '6', '6']]\n",
      "decoded_data: ['PID is 7267.0, B03 is 700.0, DOY is 211.0, B02 is 347.0, B04 is 566.0 PID is 56666']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 700.0, B02 is 347.0, DOY is 211.0, PID is 7267.0, B04 is']\n",
      "prompt: B03 is 700.0, B02 is 347.0, DOY is 211.0, PID is 7267.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '2', '6', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '2', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '4', '.', '0', ',', '', 'B03', 'is']]\n",
      "decoded_data: ['B03 is 700.0, B02 is 347.0, DOY is 211.0, PID is 7267.0, B04 is 566.0 54.0, B03 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7267.0, B03 is 700.0, DOY is 211.0, B02 is 347.0, B04 is']\n",
      "prompt: PID is 7267.0, B03 is 700.0, DOY is 211.0, B02 is 347.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '2', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '2', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'DOY', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['PID is 7267.0, B03 is 700.0, DOY is 211.0, B02 is 347.0, B04 is 566.0 PID is DOY is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7267.0, B02 is 347.0, B03 is 700.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 7267.0, B02 is 347.0, B03 is 700.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '2', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '2', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '6', '6', '6', '6', '6', '.', '0']]\n",
      "decoded_data: ['PID is 7267.0, B02 is 347.0, B03 is 700.0, DOY is 211.0, B04 is 566.0 566666.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 347.0, B03 is 700.0, PID is 7267.0, DOY is 211.0, B04 is']\n",
      "prompt: B02 is 347.0, B03 is 700.0, PID is 7267.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '4', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'PID', 'is', '', '7', '2', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '4', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'PID', 'is', '', '7', '2', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '4', '9', '9', '9', '8', '8', '.']]\n",
      "decoded_data: ['B02 is 347.0, B03 is 700.0, PID is 7267.0, DOY is 211.0, B04 is 566.0 5499988.']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 347.0, PID is 7267.0, B03 is 700.0, B04 is']\n",
      "prompt: DOY is 211.0, B02 is 347.0, PID is 7267.0, B03 is 700.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '7', '.', '0', ',', '', 'PID', 'is', '', '7', '2', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '7', '.', '0', ',', '', 'PID', 'is', '', '7', '2', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '6', '6', '6', '6']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 347.0, PID is 7267.0, B03 is 700.0, B04 is 566.0 PID is 56666']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 347.0, PID is 7267.0, B03 is 700.0, B04 is']\n",
      "prompt: DOY is 211.0, B02 is 347.0, PID is 7267.0, B03 is 700.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '7', '.', '0', ',', '', 'PID', 'is', '', '7', '2', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B04', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 16%|        | 135/829 [04:04<26:56,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '7', '.', '0', ',', '', 'PID', 'is', '', '7', '2', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '6', '6', '6', '6']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 347.0, PID is 7267.0, B03 is 700.0, B04 is 566.0 PID is 56666']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7367.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 7367.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '3', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '3', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '8', '2', '.', '0', ',', '', 'B04', 'is', '', '6', '5', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'PID', 'is', '', '6', '3']]\n",
      "decoded_data: ['PID is 7367.0, DOY is 211.0, B03 is 739.0, B02 is 382.0, B04 is 653.0 B03 is PID is 63']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7367.0, B02 is 382.0, B03 is 739.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 7367.0, B02 is 382.0, B03 is 739.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '3', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '8', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '3', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '8', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '5', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '6', '3', '7', '7', '2', '8', '0', '4']]\n",
      "decoded_data: ['PID is 7367.0, B02 is 382.0, B03 is 739.0, DOY is 211.0, B04 is 653.0 63772804']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 382.0, PID is 7367.0, B03 is 739.0, B04 is']\n",
      "prompt: DOY is 211.0, B02 is 382.0, PID is 7367.0, B03 is 739.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '8', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '3', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '8', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '3', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '9', '.', '0', ',', '', 'B04', 'is', '', '6', '5', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '6', '3', '5', '4', '0', ',', '', 'B03']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 382.0, PID is 7367.0, B03 is 739.0, B04 is 653.0 63540, B03']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 382.0, B03 is 739.0, PID is 7367.0, DOY is 211.0, B04 is']\n",
      "prompt: B02 is 382.0, B03 is 739.0, PID is 7367.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '8', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '9', '.', '0', ',', '', 'PID', 'is', '', '7', '3', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '8', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '9', '.', '0', ',', '', 'PID', 'is', '', '7', '3', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '5', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '3', '8', '8', '8', '0', '8', '.', '0']]\n",
      "decoded_data: ['B02 is 382.0, B03 is 739.0, PID is 7367.0, DOY is 211.0, B04 is 653.06388808.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 739.0, DOY is 211.0, B02 is 382.0, PID is 7367.0, B04 is']\n",
      "prompt: B03 is 739.0, DOY is 211.0, B02 is 382.0, PID is 7367.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '3', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '8', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '3', '6', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '3', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '8', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '3', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '6', '5', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '6', '3', '8', '8', '8']]\n",
      "decoded_data: ['B03 is 739.0, DOY is 211.0, B02 is 382.0, PID is 7367.0, B04 is 653.0 B04 is 63888']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 7367.0, B02 is 382.0, B03 is 739.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 7367.0, B02 is 382.0, B03 is 739.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '3', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '8', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '3', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '8', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '9', '.', '0', ',', '', 'B04', 'is', '', '6', '5', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'DOY', 'is', '', '7', '2']]\n",
      "decoded_data: ['DOY is 211.0, PID is 7367.0, B02 is 382.0, B03 is 739.0, B04 is 653.0 B03 is DOY is 72']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 382.0, DOY is 211.0, PID is 7367.0, B03 is 739.0, B04 is']\n",
      "prompt: B02 is 382.0, DOY is 211.0, PID is 7367.0, B03 is 739.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '8', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '3', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '8', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '3', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '9', '.', '0', ',', '', 'B04', 'is', '', '6', '5', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '6', '3', '2', '3', '2', '3', '2', '.']]\n",
      "decoded_data: ['B02 is 382.0, DOY is 211.0, PID is 7367.0, B03 is 739.0, B04 is 653.0 6323232.']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7367.0, B02 is 382.0, DOY is 211.0, B03 is 739.0, B04 is']\n",
      "prompt: PID is 7367.0, B02 is 382.0, DOY is 211.0, B03 is 739.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '3', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '8', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '3', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '8', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '9', '.', '0', ',', '', 'B04', 'is', '', '6', '5', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '3', '8', '2', '9', '0', '8', '.', '0']]\n",
      "decoded_data: ['PID is 7367.0, B02 is 382.0, DOY is 211.0, B03 is 739.0, B04 is 653.06382908.0']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7367.0, DOY is 211.0, B02 is 382.0, B03 is 739.0, B04 is']\n",
      "prompt: PID is 7367.0, DOY is 211.0, B02 is 382.0, B03 is 739.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '3', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '8', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '3', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '8', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '9', '.', '0', ',', '', 'B04', 'is', '', '6', '5', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '6', '8', '0', '7', '9']]\n",
      "decoded_data: ['PID is 7367.0, DOY is 211.0, B02 is 382.0, B03 is 739.0, B04 is 653.0 PID is 68079']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 382.0, DOY is 211.0, B03 is 739.0, PID is 7367.0, B04 is']\n",
      "prompt: B02 is 382.0, DOY is 211.0, B03 is 739.0, PID is 7367.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '8', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '9', '.', '0', ',', '', 'PID', 'is', '', '7', '3', '6', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '8', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '9', '.', '0', ',', '', 'PID', 'is', '', '7', '3', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '6', '5', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', '6', '.', '0', ',', '']]\n",
      "decoded_data: ['B02 is 382.0, DOY is 211.0, B03 is 739.0, PID is 7367.0, B04 is 653.0 B03 is 6.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 382.0, B03 is 739.0, DOY is 211.0, PID is 7367.0, B04 is']\n",
      "prompt: B02 is 382.0, B03 is 739.0, DOY is 211.0, PID is 7367.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '8', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '3', '6', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '8', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '3', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '6', '5', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '8', '8', '8', '0', '.', '0', '.', '0', ',']]\n",
      "decoded_data: ['B02 is 382.0, B03 is 739.0, DOY is 211.0, PID is 7367.0, B04 is 653.08880.0.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 382.0, DOY is 211.0, PID is 7367.0, B03 is 739.0, B04 is']\n",
      "prompt: B02 is 382.0, DOY is 211.0, PID is 7367.0, B03 is 739.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '8', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '3', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '8', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '3', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '9', '.', '0', ',', '', 'B04', 'is', '', '6', '5', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '6', '3', '8', '2', '3']]\n",
      "decoded_data: ['B02 is 382.0, DOY is 211.0, PID is 7367.0, B03 is 739.0, B04 is 653.0 PID is 63823']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 7367.0, B02 is 382.0, B03 is 739.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 7367.0, B02 is 382.0, B03 is 739.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '3', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '8', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '3', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '8', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '9', '.', '0', ',', '', 'B04', 'is', '', '6', '5', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'DOY', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['DOY is 211.0, PID is 7367.0, B02 is 382.0, B03 is 739.0, B04 is 653.0 B03 is DOY is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 7367.0, B02 is 382.0, B03 is 739.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 7367.0, B02 is 382.0, B03 is 739.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '3', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '8', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '3', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '8', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '9', '.', '0', ',', '', 'B04', 'is', '', '6', '5', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '6', '3', '8', '2', '3', '8', '6', '3']]\n",
      "decoded_data: ['DOY is 211.0, PID is 7367.0, B02 is 382.0, B03 is 739.0, B04 is 653.0 63823863']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 739.0, DOY is 211.0, B02 is 382.0, PID is 7367.0, B04 is']\n",
      "prompt: B03 is 739.0, DOY is 211.0, B02 is 382.0, PID is 7367.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '3', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '8', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '3', '6', '7', '.', '0', ',', '', 'B04', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 16%|        | 136/829 [04:06<26:44,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B03', 'is', '', '7', '3', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '8', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '3', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '6', '5', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'PID', 'is', '', '6', '5']]\n",
      "decoded_data: ['B03 is 739.0, DOY is 211.0, B02 is 382.0, PID is 7367.0, B04 is 653.0 B03 is PID is 65']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7467.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 7467.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '4', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '4', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '6', '7', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'B04', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['PID is 7467.0, DOY is 211.0, B03 is 752.0, B04 is 677.0, B02 is 399.0 B03 is B04 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 677.0, PID is 7467.0, B03 is 752.0, B02 is']\n",
      "prompt: DOY is 211.0, B04 is 677.0, PID is 7467.0, B03 is 752.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '7', '7', '.', '0', ',', '', 'PID', 'is', '', '7', '4', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '2', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '7', '7', '.', '0', ',', '', 'PID', 'is', '', '7', '4', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B03', 'is', '', '3', '7']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 677.0, PID is 7467.0, B03 is 752.0, B02 is 399.0 PID is B03 is 37']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 7467.0, B03 is 752.0, B04 is 677.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 7467.0, B03 is 752.0, B04 is 677.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '4', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '6', '7', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '4', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '6', '7', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B03', 'is', '', 'DOY', 'is']]\n",
      "decoded_data: ['DOY is 211.0, PID is 7467.0, B03 is 752.0, B04 is 677.0, B02 is 399.0 B04 is B03 is DOY is']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 752.0, B04 is 677.0, DOY is 211.0, PID is 7467.0, B02 is']\n",
      "prompt: B03 is 752.0, B04 is 677.0, DOY is 211.0, PID is 7467.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '6', '7', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '4', '6', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '6', '7', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '4', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['B03 is 752.0, B04 is 677.0, DOY is 211.0, PID is 7467.0, B02 is 399.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 752.0, B04 is 677.0, DOY is 211.0, PID is 7467.0, B02 is']\n",
      "prompt: B03 is 752.0, B04 is 677.0, DOY is 211.0, PID is 7467.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '6', '7', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '4', '6', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '6', '7', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '4', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B03', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['B03 is 752.0, B04 is 677.0, DOY is 211.0, PID is 7467.0, B02 is 399.0 B04 is B03 is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 677.0, DOY is 211.0, B03 is 752.0, PID is 7467.0, B02 is']\n",
      "prompt: B04 is 677.0, DOY is 211.0, B03 is 752.0, PID is 7467.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '6', '7', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '4', '6', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '6', '7', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '4', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '3', '7']]\n",
      "decoded_data: ['B04 is 677.0, DOY is 211.0, B03 is 752.0, PID is 7467.0, B02 is 399.0 B04 is PID is 37']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 752.0, PID is 7467.0, B04 is 677.0, B02 is']\n",
      "prompt: DOY is 211.0, B03 is 752.0, PID is 7467.0, B04 is 677.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '4', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '6', '7', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '4', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '6', '7', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'DOY', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 752.0, PID is 7467.0, B04 is 677.0, B02 is 399.0 B04 is DOY is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7467.0, B04 is 677.0, DOY is 211.0, B03 is 752.0, B02 is']\n",
      "prompt: PID is 7467.0, B04 is 677.0, DOY is 211.0, B03 is 752.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '4', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '6', '7', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '2', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '4', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '6', '7', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B03', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['PID is 7467.0, B04 is 677.0, DOY is 211.0, B03 is 752.0, B02 is 399.0 B04 is B03 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 7467.0, B03 is 752.0, B04 is 677.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 7467.0, B03 is 752.0, B04 is 677.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '4', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '6', '7', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '4', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '6', '7', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '9', '9', '9', '9', '9', '9', '9', '.', '0']]\n",
      "decoded_data: ['DOY is 211.0, PID is 7467.0, B03 is 752.0, B04 is 677.0, B02 is 399.09999999.0']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7467.0, B03 is 752.0, B04 is 677.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 7467.0, B03 is 752.0, B04 is 677.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '4', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '6', '7', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '4', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '6', '7', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['PID is 7467.0, B03 is 752.0, B04 is 677.0, DOY is 211.0, B02 is 399.0 B04 is PID is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 752.0, PID is 7467.0, B04 is 677.0, B02 is']\n",
      "prompt: DOY is 211.0, B03 is 752.0, PID is 7467.0, B04 is 677.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '4', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '6', '7', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '4', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '6', '7', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '8', '8', '.', '0', ',', '', 'B04', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 752.0, PID is 7467.0, B04 is 677.0, B02 is 399.0788.0, B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 677.0, DOY is 211.0, PID is 7467.0, B03 is 752.0, B02 is']\n",
      "prompt: B04 is 677.0, DOY is 211.0, PID is 7467.0, B03 is 752.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '6', '7', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '4', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '2', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '6', '7', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '4', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '2', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B03', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['B04 is 677.0, DOY is 211.0, PID is 7467.0, B03 is 752.0, B02 is 399.0 B04 is B03 is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 752.0, PID is 7467.0, B04 is 677.0, DOY is 211.0, B02 is']\n",
      "prompt: B03 is 752.0, PID is 7467.0, B04 is 677.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '5', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '4', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '6', '7', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '5', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '4', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '6', '7', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B03', 'is']]\n",
      "decoded_data: ['B03 is 752.0, PID is 7467.0, B04 is 677.0, DOY is 211.0, B02 is 399.0 B04 is PID is B03 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 7467.0, B03 is 752.0, B04 is 677.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 7467.0, B03 is 752.0, B04 is 677.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '4', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '6', '7', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '4', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '2', '.', '0', ',', '', 'B04', 'is', '', '6', '7', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '6', '7', '8', '9', '9']]\n",
      "decoded_data: ['DOY is 211.0, PID is 7467.0, B03 is 752.0, B04 is 677.0, B02 is 399.0 B04 is 67899']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7467.0, B03 is 752.0, DOY is 211.0, B04 is 677.0, B02 is']\n",
      "prompt: PID is 7467.0, B03 is 752.0, DOY is 211.0, B04 is 677.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '4', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '7', '7', '.', '0', ',', '', 'B02', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 17%|        | 137/829 [04:08<26:31,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '7', '4', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '7', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '3', '7', '8', '8', '8']]\n",
      "decoded_data: ['PID is 7467.0, B03 is 752.0, DOY is 211.0, B04 is 677.0, B02 is 399.0 PID is 37888']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 7567.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 7567.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '5', '6', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '5', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '7', '3', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '4', '2', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', '7', '3']]\n",
      "decoded_data: ['DOY is 211.0, PID is 7567.0, B04 is 736.0, B03 is 768.0, B02 is 423.0 B04 is B04 is 73']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 736.0, B03 is 768.0, PID is 7567.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 736.0, B03 is 768.0, PID is 7567.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '7', '3', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '8', '.', '0', ',', '', 'PID', 'is', '', '7', '5', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '7', '3', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '8', '.', '0', ',', '', 'PID', 'is', '', '7', '5', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '4', '2', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '4', '0', '0', '0', '0']]\n",
      "decoded_data: ['B04 is 736.0, B03 is 768.0, PID is 7567.0, DOY is 211.0, B02 is 423.0 PID is 40000']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7567.0, B04 is 736.0, B03 is 768.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 7567.0, B04 is 736.0, B03 is 768.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '5', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '7', '3', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '5', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '7', '3', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '4', '2', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'DOY', 'is', '', '2', '3']]\n",
      "decoded_data: ['PID is 7567.0, B04 is 736.0, B03 is 768.0, DOY is 211.0, B02 is 429.0 B04 is DOY is 23']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 736.0, DOY is 211.0, PID is 7567.0, B03 is 768.0, B02 is']\n",
      "prompt: B04 is 736.0, DOY is 211.0, PID is 7567.0, B03 is 768.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '7', '3', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '5', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '8', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '7', '3', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '5', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '4', '2', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '4', '3', '3', '2', '3']]\n",
      "decoded_data: ['B04 is 736.0, DOY is 211.0, PID is 7567.0, B03 is 768.0, B02 is 427.0 PID is 43323']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 768.0, B04 is 736.0, DOY is 211.0, PID is 7567.0, B02 is']\n",
      "prompt: B03 is 768.0, B04 is 736.0, DOY is 211.0, PID is 7567.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '7', '3', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '5', '6', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '7', '3', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '5', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '4', '2', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '.', '0', ',', '', 'B04', 'is', '', 'DOY']]\n",
      "decoded_data: ['B03 is 768.0, B04 is 736.0, DOY is 211.0, PID is 7567.0, B02 is 424.07.0, B04 is DOY']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7567.0, B04 is 736.0, DOY is 211.0, B03 is 768.0, B02 is']\n",
      "prompt: PID is 7567.0, B04 is 736.0, DOY is 211.0, B03 is 768.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '5', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '7', '3', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '8', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '5', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '7', '3', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '4', '2', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '4', '0']]\n",
      "decoded_data: ['PID is 7567.0, B04 is 736.0, DOY is 211.0, B03 is 768.0, B02 is 424.0 B04 is PID is 40']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7567.0, B03 is 768.0, B04 is 736.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 7567.0, B03 is 768.0, B04 is 736.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '5', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '7', '3', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '5', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '7', '3', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '4', '2', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '4', '3', '3', '3', '2']]\n",
      "decoded_data: ['PID is 7567.0, B03 is 768.0, B04 is 736.0, DOY is 211.0, B02 is 423.0 B04 is 43332']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 736.0, PID is 7567.0, B03 is 768.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 736.0, PID is 7567.0, B03 is 768.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '7', '3', '6', '.', '0', ',', '', 'PID', 'is', '', '7', '5', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '7', '3', '6', '.', '0', ',', '', 'PID', 'is', '', '7', '5', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '4', '2', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '7', '9', '8', '4', '3']]\n",
      "decoded_data: ['B04 is 736.0, PID is 7567.0, B03 is 768.0, DOY is 211.0, B02 is 424.0 B04 is 79843']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 736.0, B03 is 768.0, PID is 7567.0, B02 is']\n",
      "prompt: DOY is 211.0, B04 is 736.0, B03 is 768.0, PID is 7567.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '7', '3', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '8', '.', '0', ',', '', 'PID', 'is', '', '7', '5', '6', '7', '.', '0', ',', '', 'B02', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|        | 138/829 [04:10<24:00,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '7', '3', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '6', '8', '.', '0', ',', '', 'PID', 'is', '', '7', '5', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '4', '2', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'B04', 'is', '', '7', '.']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 736.0, B03 is 768.0, PID is 7567.0, B02 is 424.0 B03 is B04 is 7.']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 768.0, B04 is 736.0, PID is 7567.0, DOY is 211.0, B02 is']\n",
      "prompt: B03 is 768.0, B04 is 736.0, PID is 7567.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '7', '3', '6', '.', '0', ',', '', 'PID', 'is', '', '7', '5', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '7', '3', '6', '.', '0', ',', '', 'PID', 'is', '', '7', '5', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '4', '2', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '4', '0', '0', '0', '0', '0', '0', '0', '0']]\n",
      "decoded_data: ['B03 is 768.0, B04 is 736.0, PID is 7567.0, DOY is 211.0, B02 is 429.0400000000']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7667.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 7667.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '6', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|        | 139/829 [04:10<17:51,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '7', '6', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '9', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '4', '7', '9', '2', '6', '7', '9', '4']]\n",
      "decoded_data: ['PID is 7667.0, DOY is 211.0, B04 is 597.0, B02 is 357.0, B03 is 711.0747926794']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7767.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 7767.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '7', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '7', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '9', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', '6', '3', '2', '3', '2']]\n",
      "decoded_data: ['PID is 7767.0, DOY is 211.0, B04 is 549.0, B03 is 698.0, B02 is 332.0 B03 is 63232']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 549.0, DOY is 211.0, B03 is 698.0, PID is 7767.0, B02 is']\n",
      "prompt: B04 is 549.0, DOY is 211.0, B03 is 698.0, PID is 7767.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '4', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '8', '.', '0', ',', '', 'PID', 'is', '', '7', '7', '6', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '4', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '8', '.', '0', ',', '', 'PID', 'is', '', '7', '7', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'B04', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['B04 is 549.0, DOY is 211.0, B03 is 698.0, PID is 7767.0, B02 is 332.0 B03 is B04 is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7767.0, B03 is 698.0, DOY is 211.0, B04 is 549.0, B02 is']\n",
      "prompt: PID is 7767.0, B03 is 698.0, DOY is 211.0, B04 is 549.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '7', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '9', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '7', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '3', '2', '9', '2']]\n",
      "decoded_data: ['PID is 7767.0, B03 is 698.0, DOY is 211.0, B04 is 549.0, B02 is 332.0 B04 is 53292']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7767.0, B03 is 698.0, DOY is 211.0, B04 is 549.0, B02 is']\n",
      "prompt: PID is 7767.0, B03 is 698.0, DOY is 211.0, B04 is 549.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '7', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '9', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '7', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '5', '0']]\n",
      "decoded_data: ['PID is 7767.0, B03 is 698.0, DOY is 211.0, B04 is 549.0, B02 is 332.0 PID is B04 is 50']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 549.0, DOY is 211.0, PID is 7767.0, B03 is 698.0, B02 is']\n",
      "prompt: B04 is 549.0, DOY is 211.0, PID is 7767.0, B03 is 698.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '4', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '7', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '8', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '4', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '7', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B02', 'is', '', '3', '2', '9', '2', '9']]\n",
      "decoded_data: ['B04 is 549.0, DOY is 211.0, PID is 7767.0, B03 is 698.0, B02 is 332.0 B02 is 32929']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 549.0, PID is 7767.0, B03 is 698.0, B02 is']\n",
      "prompt: DOY is 211.0, B04 is 549.0, PID is 7767.0, B03 is 698.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '9', '.', '0', ',', '', 'PID', 'is', '', '7', '7', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '8', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '9', '.', '0', ',', '', 'PID', 'is', '', '7', '7', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '9', '2', '9', '2', '2', '8', '.', '0', ',']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 549.0, PID is 7767.0, B03 is 698.0, B02 is 332.0929228.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7767.0, B03 is 698.0, DOY is 211.0, B04 is 549.0, B02 is']\n",
      "prompt: PID is 7767.0, B03 is 698.0, DOY is 211.0, B04 is 549.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '7', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '9', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '7', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B02', 'is', '', '3', '2']]\n",
      "decoded_data: ['PID is 7767.0, B03 is 698.0, DOY is 211.0, B04 is 549.0, B02 is 332.0 B04 is B02 is 32']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 549.0, B03 is 698.0, DOY is 211.0, PID is 7767.0, B02 is']\n",
      "prompt: B04 is 549.0, B03 is 698.0, DOY is 211.0, PID is 7767.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '4', '9', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '7', '6', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '4', '9', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '7', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'B04', 'is', '', '5', '4']]\n",
      "decoded_data: ['B04 is 549.0, B03 is 698.0, DOY is 211.0, PID is 7767.0, B02 is 332.0 B03 is B04 is 54']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7767.0, B03 is 698.0, B04 is 549.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 7767.0, B03 is 698.0, B04 is 549.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '7', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '7', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '3', '2', '9', '2', '9', '8', 'PID', 'is']]\n",
      "decoded_data: ['PID is 7767.0, B03 is 698.0, B04 is 549.0, DOY is 211.0, B02 is 332.0 329298PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7767.0, DOY is 211.0, B04 is 549.0, B03 is 698.0, B02 is']\n",
      "prompt: PID is 7767.0, DOY is 211.0, B04 is 549.0, B03 is 698.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '7', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '9', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '8', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '7', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '9', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B02', 'is', '', 'B03', 'is', '', '3', '2']]\n",
      "decoded_data: ['PID is 7767.0, DOY is 211.0, B04 is 549.0, B03 is 698.0, B02 is 332.0 B02 is B03 is 32']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7767.0, B04 is 549.0, B03 is 698.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 7767.0, B04 is 549.0, B03 is 698.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '7', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '9', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '7', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '9', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '3', '2', '9', '.', '0']]\n",
      "decoded_data: ['PID is 7767.0, B04 is 549.0, B03 is 698.0, DOY is 211.0, B02 is 332.0 B04 is 329.0']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 549.0, PID is 7767.0, B03 is 698.0, B02 is']\n",
      "prompt: DOY is 211.0, B04 is 549.0, PID is 7767.0, B03 is 698.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '9', '.', '0', ',', '', 'PID', 'is', '', '7', '7', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '8', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '9', '.', '0', ',', '', 'PID', 'is', '', '7', '7', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '3', '2', '0', ',', '', 'B03', 'is', '']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 549.0, PID is 7767.0, B03 is 698.0, B02 is 332.0 320, B03 is ']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7767.0, DOY is 211.0, B03 is 698.0, B04 is 549.0, B02 is']\n",
      "prompt: PID is 7767.0, DOY is 211.0, B03 is 698.0, B04 is 549.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '7', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '9', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '7', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '5', '3']]\n",
      "decoded_data: ['PID is 7767.0, DOY is 211.0, B03 is 698.0, B04 is 549.0, B02 is 332.0 B04 is PID is 53']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 698.0, DOY is 211.0, PID is 7767.0, B04 is 549.0, B02 is']\n",
      "prompt: B03 is 698.0, DOY is 211.0, PID is 7767.0, B04 is 549.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '9', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '7', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '9', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '6', '9', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '7', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '3', '2', '.', '0', ',', '', 'PID', 'is', '']]\n",
      "decoded_data: ['B03 is 698.0, DOY is 211.0, PID is 7767.0, B04 is 549.0, B02 is 332.032.0, PID is ']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 698.0, B04 is 549.0, PID is 7767.0, DOY is 211.0, B02 is']\n",
      "prompt: B03 is 698.0, B04 is 549.0, PID is 7767.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '9', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '9', '.', '0', ',', '', 'PID', 'is', '', '7', '7', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 17%|        | 140/829 [04:12<20:17,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B03', 'is', '', '6', '9', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '9', '.', '0', ',', '', 'PID', 'is', '', '7', '7', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '3', '2', '2', '9', '9']]\n",
      "decoded_data: ['B03 is 698.0, B04 is 549.0, PID is 7767.0, DOY is 211.0, B02 is 332.0 PID is 32299']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7867.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 7867.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '8', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '8', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '0', '1', '0', '4']]\n",
      "decoded_data: ['PID is 7867.0, DOY is 211.0, B02 is 327.0, B03 is 728.0, B04 is 537.0 PID is 50104']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7867.0, DOY is 211.0, B03 is 728.0, B02 is 327.0, B04 is']\n",
      "prompt: PID is 7867.0, DOY is 211.0, B03 is 728.0, B02 is 327.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '8', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '8', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '3', '7', '7', '0']]\n",
      "decoded_data: ['PID is 7867.0, DOY is 211.0, B03 is 728.0, B02 is 327.0, B04 is 537.0 PID is 53770']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7867.0, DOY is 211.0, B03 is 728.0, B02 is 327.0, B04 is']\n",
      "prompt: PID is 7867.0, DOY is 211.0, B03 is 728.0, B02 is 327.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '8', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '8', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '3', '7', '0', '5']]\n",
      "decoded_data: ['PID is 7867.0, DOY is 211.0, B03 is 728.0, B02 is 327.0, B04 is 537.0 PID is 53705']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 327.0, PID is 7867.0, B03 is 728.0, B04 is']\n",
      "prompt: DOY is 211.0, B02 is 327.0, PID is 7867.0, B03 is 728.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '7', '.', '0', ',', '', 'PID', 'is', '', '7', '8', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '8', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '7', '.', '0', ',', '', 'PID', 'is', '', '7', '8', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '6', '1', '9', '2']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 327.0, PID is 7867.0, B03 is 728.0, B04 is 537.0 PID is 56192']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 728.0, PID is 7867.0, B02 is 327.0, DOY is 211.0, B04 is']\n",
      "prompt: B03 is 728.0, PID is 7867.0, B02 is 327.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '2', '8', '.', '0', ',', '', 'PID', 'is', '', '7', '8', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '2', '8', '.', '0', ',', '', 'PID', 'is', '', '7', '8', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '3', '7', '8', '5']]\n",
      "decoded_data: ['B03 is 728.0, PID is 7867.0, B02 is 327.0, DOY is 211.0, B04 is 537.0 PID is 53785']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7867.0, B03 is 728.0, B02 is 327.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 7867.0, B03 is 728.0, B02 is 327.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '8', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '8', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '3', '7', '0', '8']]\n",
      "decoded_data: ['PID is 7867.0, B03 is 728.0, B02 is 327.0, DOY is 211.0, B04 is 537.0 PID is 53708']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7867.0, DOY is 211.0, B03 is 728.0, B02 is 327.0, B04 is']\n",
      "prompt: PID is 7867.0, DOY is 211.0, B03 is 728.0, B02 is 327.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '8', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '8', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '3', '7', '7', '0']]\n",
      "decoded_data: ['PID is 7867.0, DOY is 211.0, B03 is 728.0, B02 is 327.0, B04 is 537.0 PID is 53770']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7867.0, B02 is 327.0, B03 is 728.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 7867.0, B02 is 327.0, B03 is 728.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '8', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '8', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '6', '1', '.', '0']]\n",
      "decoded_data: ['PID is 7867.0, B02 is 327.0, B03 is 728.0, DOY is 211.0, B04 is 537.0 B04 is 561.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 728.0, PID is 7867.0, DOY is 211.0, B02 is 327.0, B04 is']\n",
      "prompt: B03 is 728.0, PID is 7867.0, DOY is 211.0, B02 is 327.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '2', '8', '.', '0', ',', '', 'PID', 'is', '', '7', '8', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '2', '8', '.', '0', ',', '', 'PID', 'is', '', '7', '8', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '3', '7', '0', '4', '5', '3', '7']]\n",
      "decoded_data: ['B03 is 728.0, PID is 7867.0, DOY is 211.0, B02 is 327.0, B04 is 537.0 53704537']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 728.0, DOY is 211.0, PID is 7867.0, B02 is 327.0, B04 is']\n",
      "prompt: B03 is 728.0, DOY is 211.0, PID is 7867.0, B02 is 327.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '2', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '8', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '2', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '8', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '3', '7', '0', '.', '0', '7', '0']]\n",
      "decoded_data: ['B03 is 728.0, DOY is 211.0, PID is 7867.0, B02 is 327.0, B04 is 537.0 5370.070']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 327.0, DOY is 211.0, B03 is 728.0, PID is 7867.0, B04 is']\n",
      "prompt: B02 is 327.0, DOY is 211.0, B03 is 728.0, PID is 7867.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '2', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '8', '.', '0', ',', '', 'PID', 'is', '', '7', '8', '6', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '2', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '8', '.', '0', ',', '', 'PID', 'is', '', '7', '8', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '5', '8', '5', '3']]\n",
      "decoded_data: ['B02 is 327.0, DOY is 211.0, B03 is 728.0, PID is 7867.0, B04 is 537.0 PID is 75853']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 327.0, PID is 7867.0, B03 is 728.0, DOY is 211.0, B04 is']\n",
      "prompt: B02 is 327.0, PID is 7867.0, B03 is 728.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '2', '7', '.', '0', ',', '', 'PID', 'is', '', '7', '8', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '2', '7', '.', '0', ',', '', 'PID', 'is', '', '7', '8', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '3', '7', '0', '7', '0', '7', '0']]\n",
      "decoded_data: ['B02 is 327.0, PID is 7867.0, B03 is 728.0, DOY is 211.0, B04 is 537.0 53707070']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 327.0, PID is 7867.0, DOY is 211.0, B03 is 728.0, B04 is']\n",
      "prompt: B02 is 327.0, PID is 7867.0, DOY is 211.0, B03 is 728.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '2', '7', '.', '0', ',', '', 'PID', 'is', '', '7', '8', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '8', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '2', '7', '.', '0', ',', '', 'PID', 'is', '', '7', '8', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'PID', 'is', '', '7', '7']]\n",
      "decoded_data: ['B02 is 327.0, PID is 7867.0, DOY is 211.0, B03 is 728.0, B04 is 537.0 PID is PID is 77']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7867.0, B03 is 728.0, B02 is 327.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 7867.0, B03 is 728.0, B02 is 327.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '8', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '8', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '3', '7', '9', '7']]\n",
      "decoded_data: ['PID is 7867.0, B03 is 728.0, B02 is 327.0, DOY is 211.0, B04 is 537.0 PID is 53797']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 728.0, B02 is 327.0, PID is 7867.0, DOY is 211.0, B04 is']\n",
      "prompt: B03 is 728.0, B02 is 327.0, PID is 7867.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '2', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '7', '.', '0', ',', '', 'PID', 'is', '', '7', '8', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 17%|        | 141/829 [04:15<21:59,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B03', 'is', '', '7', '2', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '7', '.', '0', ',', '', 'PID', 'is', '', '7', '8', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '3', '7', '0', '.', '0', '7', '0']]\n",
      "decoded_data: ['B03 is 728.0, B02 is 327.0, PID is 7867.0, DOY is 211.0, B04 is 537.0 5370.070']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7967.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 7967.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '9', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '9', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '3', '3', '9', '2']]\n",
      "decoded_data: ['PID is 7967.0, DOY is 211.0, B04 is 561.0, B03 is 729.0, B02 is 339.0 B04 is 53392']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 729.0, PID is 7967.0, B04 is 561.0, DOY is 211.0, B02 is']\n",
      "prompt: B03 is 729.0, PID is 7967.0, B04 is 561.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '2', '9', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '2', '9', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '3', '3', '9', '2', '9', 'DOY', 'is', '', 'B04']]\n",
      "decoded_data: ['B03 is 729.0, PID is 7967.0, B04 is 561.0, DOY is 211.0, B02 is 339.033929DOY is B04']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 729.0, PID is 7967.0, B04 is 561.0, DOY is 211.0, B02 is']\n",
      "prompt: B03 is 729.0, PID is 7967.0, B04 is 561.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '2', '9', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '2', '9', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['B03 is 729.0, PID is 7967.0, B04 is 561.0, DOY is 211.0, B02 is 333.0 B04 is PID is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7967.0, DOY is 211.0, B03 is 729.0, B04 is 561.0, B02 is']\n",
      "prompt: PID is 7967.0, DOY is 211.0, B03 is 729.0, B04 is 561.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '9', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '9', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '3', '3', '3', '3', '3', '3', '9', '0']]\n",
      "decoded_data: ['PID is 7967.0, DOY is 211.0, B03 is 729.0, B04 is 561.0, B02 is 339.0 33333390']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 561.0, DOY is 211.0, PID is 7967.0, B03 is 729.0, B02 is']\n",
      "prompt: B04 is 561.0, DOY is 211.0, PID is 7967.0, B03 is 729.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '6', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '9', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '6', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '3', '9', '0', '1', '0']]\n",
      "decoded_data: ['B04 is 561.0, DOY is 211.0, PID is 7967.0, B03 is 729.0, B02 is 339.0 PID is 39010']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 561.0, DOY is 211.0, PID is 7967.0, B03 is 729.0, B02 is']\n",
      "prompt: B04 is 561.0, DOY is 211.0, PID is 7967.0, B03 is 729.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '6', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '9', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '6', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['B04 is 561.0, DOY is 211.0, PID is 7967.0, B03 is 729.0, B02 is 333.0 PID is B04 is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 561.0, DOY is 211.0, B03 is 729.0, PID is 7967.0, B02 is']\n",
      "prompt: B04 is 561.0, DOY is 211.0, B03 is 729.0, PID is 7967.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '6', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '9', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '6', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '9', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '3', '9', '0', '.', '0', '1', '0', '.']]\n",
      "decoded_data: ['B04 is 561.0, DOY is 211.0, B03 is 729.0, PID is 7967.0, B02 is 339.0 390.010.']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 561.0, B03 is 729.0, PID is 7967.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 561.0, B03 is 729.0, PID is 7967.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '6', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '9', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '6', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '9', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '3', '9', '5', '9', '0']]\n",
      "decoded_data: ['B04 is 561.0, B03 is 729.0, PID is 7967.0, DOY is 211.0, B02 is 339.0 PID is 39590']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 561.0, PID is 7967.0, B03 is 729.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 561.0, PID is 7967.0, B03 is 729.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '6', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '6', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '3', '9', '2', '9', '2']]\n",
      "decoded_data: ['B04 is 561.0, PID is 7967.0, B03 is 729.0, DOY is 211.0, B02 is 333.0 PID is 39292']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7967.0, B03 is 729.0, DOY is 211.0, B04 is 561.0, B02 is']\n",
      "prompt: PID is 7967.0, B03 is 729.0, DOY is 211.0, B04 is 561.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '9', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '9', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '3', '3', '9', '2', '.', '0', '3', '9']]\n",
      "decoded_data: ['PID is 7967.0, B03 is 729.0, DOY is 211.0, B04 is 561.0, B02 is 333.0 3392.039']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 729.0, PID is 7967.0, B04 is 561.0, B02 is']\n",
      "prompt: DOY is 211.0, B03 is 729.0, PID is 7967.0, B04 is 561.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '9', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '9', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B02', 'is', '', '3', '3']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 729.0, PID is 7967.0, B04 is 561.0, B02 is 339.0 PID is B02 is 33']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 729.0, B04 is 561.0, PID is 7967.0, B02 is']\n",
      "prompt: DOY is 211.0, B03 is 729.0, B04 is 561.0, PID is 7967.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '3', '9', '2', '7', '.', '0', ',', '']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 729.0, B04 is 561.0, PID is 7967.0, B02 is 339.0 3927.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 561.0, DOY is 211.0, B03 is 729.0, PID is 7967.0, B02 is']\n",
      "prompt: B04 is 561.0, DOY is 211.0, B03 is 729.0, PID is 7967.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '6', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '9', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '6', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '9', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '3', '3', '3', '3', '3', '.', '0', ',', '']]\n",
      "decoded_data: ['B04 is 561.0, DOY is 211.0, B03 is 729.0, PID is 7967.0, B02 is 339.033333.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 561.0, PID is 7967.0, B03 is 729.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 561.0, PID is 7967.0, B03 is 729.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '6', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '6', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '5', '9']]\n",
      "decoded_data: ['B04 is 561.0, PID is 7967.0, B03 is 729.0, DOY is 211.0, B02 is 333.0 B04 is PID is 59']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 729.0, B04 is 561.0, DOY is 211.0, PID is 7967.0, B02 is']\n",
      "prompt: B03 is 729.0, B04 is 561.0, DOY is 211.0, PID is 7967.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '2', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '7', '.', '0', ',', '', 'B02', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 17%|        | 142/829 [04:17<23:18,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B03', 'is', '', '7', '2', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '3', '9']]\n",
      "decoded_data: ['B03 is 729.0, B04 is 561.0, DOY is 211.0, PID is 7967.0, B02 is 339.0 PID is B04 is 39']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5068.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 5068.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '6', '8', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '8', '4', '0', '.', '0', ',', '', 'B02', 'is', '', '5', '3', '9', '.', '0', ',', '', 'B03', 'is', '', '8', '2', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '8', '2', '6', '2', '6', '.', '0', ',', '']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5068.0, B04 is 840.0, B02 is 539.0, B03 is 826.082626.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 840.0, B02 is 539.0, PID is 5068.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 840.0, B02 is 539.0, PID is 5068.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '8', '4', '0', '.', '0', ',', '', 'B02', 'is', '', '5', '3', '9', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '8', '4', '0', '.', '0', ',', '', 'B02', 'is', '', '5', '3', '9', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '8', '2', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '8', '2', '6', '3', '.']]\n",
      "decoded_data: ['B04 is 840.0, B02 is 539.0, PID is 5068.0, DOY is 211.0, B03 is 826.0 B04 is 8263.']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 539.0, B04 is 840.0, DOY is 211.0, PID is 5068.0, B03 is']\n",
      "prompt: B02 is 539.0, B04 is 840.0, DOY is 211.0, PID is 5068.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '5', '3', '9', '.', '0', ',', '', 'B04', 'is', '', '8', '4', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '6', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '5', '3', '9', '.', '0', ',', '', 'B04', 'is', '', '8', '4', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '8', '2', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '8', '2', '6', '2', '6']]\n",
      "decoded_data: ['B02 is 539.0, B04 is 840.0, DOY is 211.0, PID is 5068.0, B03 is 826.0 B04 is 82626']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 840.0, DOY is 211.0, PID is 5068.0, B02 is 539.0, B03 is']\n",
      "prompt: B04 is 840.0, DOY is 211.0, PID is 5068.0, B02 is 539.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '8', '4', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '5', '3', '9', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '8', '4', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '5', '3', '9', '.', '0', ',', '', 'B03', 'is', '', '8', '2', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '8', '2', '6', '2', '6']]\n",
      "decoded_data: ['B04 is 840.0, DOY is 211.0, PID is 5068.0, B02 is 539.0, B03 is 826.0 PID is 82626']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 840.0, DOY is 211.0, PID is 5068.0, B02 is 539.0, B03 is']\n",
      "prompt: B04 is 840.0, DOY is 211.0, PID is 5068.0, B02 is 539.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '8', '4', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '5', '3', '9', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '8', '4', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '5', '3', '9', '.', '0', ',', '', 'B03', 'is', '', '8', '2', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '8', '2', '6', '2', '6']]\n",
      "decoded_data: ['B04 is 840.0, DOY is 211.0, PID is 5068.0, B02 is 539.0, B03 is 826.0 PID is 82626']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5068.0, B04 is 840.0, DOY is 211.0, B02 is 539.0, B03 is']\n",
      "prompt: PID is 5068.0, B04 is 840.0, DOY is 211.0, B02 is 539.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '0', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '8', '4', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '5', '3', '9', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '0', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '8', '4', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '5', '3', '9', '.', '0', ',', '', 'B03', 'is', '', '8', '2', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['PID is 5068.0, B04 is 840.0, DOY is 211.0, B02 is 539.0, B03 is 826.0 PID is B04 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5068.0, DOY is 211.0, B04 is 840.0, B02 is 539.0, B03 is']\n",
      "prompt: PID is 5068.0, DOY is 211.0, B04 is 840.0, B02 is 539.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '0', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '8', '4', '0', '.', '0', ',', '', 'B02', 'is', '', '5', '3', '9', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '0', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '8', '4', '0', '.', '0', ',', '', 'B02', 'is', '', '5', '3', '9', '.', '0', ',', '', 'B03', 'is', '', '8', '2', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '8', '2']]\n",
      "decoded_data: ['PID is 5068.0, DOY is 211.0, B04 is 840.0, B02 is 539.0, B03 is 826.0 B04 is PID is 82']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 840.0, B02 is 539.0, PID is 5068.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 840.0, B02 is 539.0, PID is 5068.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '8', '4', '0', '.', '0', ',', '', 'B02', 'is', '', '5', '3', '9', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '8', '4', '0', '.', '0', ',', '', 'B02', 'is', '', '5', '3', '9', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '8', '2', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '8', '2', '6', '.', '0', ',', '', 'B04', 'is']]\n",
      "decoded_data: ['B04 is 840.0, B02 is 539.0, PID is 5068.0, DOY is 211.0, B03 is 826.0826.0, B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5068.0, B04 is 840.0, B02 is 539.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 5068.0, B04 is 840.0, B02 is 539.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '8', '4', '0', '.', '0', ',', '', 'B02', 'is', '', '5', '3', '9', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '8', '4', '0', '.', '0', ',', '', 'B02', 'is', '', '5', '3', '9', '.', '0', ',', '', 'B03', 'is', '', '8', '2', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '8', '2']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5068.0, B04 is 840.0, B02 is 539.0, B03 is 826.0 B04 is PID is 82']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 840.0, B02 is 539.0, DOY is 211.0, PID is 5068.0, B03 is']\n",
      "prompt: B04 is 840.0, B02 is 539.0, DOY is 211.0, PID is 5068.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '8', '4', '0', '.', '0', ',', '', 'B02', 'is', '', '5', '3', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '6', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '8', '4', '0', '.', '0', ',', '', 'B02', 'is', '', '5', '3', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '8', '2', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '8', '2']]\n",
      "decoded_data: ['B04 is 840.0, B02 is 539.0, DOY is 211.0, PID is 5068.0, B03 is 826.0 PID is B04 is 82']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 539.0, B04 is 840.0, PID is 5068.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 539.0, B04 is 840.0, PID is 5068.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '5', '3', '9', '.', '0', ',', '', 'B04', 'is', '', '8', '4', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '6', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '5', '3', '9', '.', '0', ',', '', 'B04', 'is', '', '8', '4', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '8', '2', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 539.0, B04 is 840.0, PID is 5068.0, B03 is 826.0 PID is B04 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 539.0, PID is 5068.0, B04 is 840.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 539.0, PID is 5068.0, B04 is 840.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '5', '3', '9', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '8', '4', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '5', '3', '9', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '8', '4', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '8', '2', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '8', '2', '6', '2', '6']]\n",
      "decoded_data: ['B02 is 539.0, PID is 5068.0, B04 is 840.0, DOY is 211.0, B03 is 826.0 B04 is 82626']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5068.0, DOY is 211.0, B04 is 840.0, B02 is 539.0, B03 is']\n",
      "prompt: PID is 5068.0, DOY is 211.0, B04 is 840.0, B02 is 539.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '0', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '8', '4', '0', '.', '0', ',', '', 'B02', 'is', '', '5', '3', '9', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '0', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '8', '4', '0', '.', '0', ',', '', 'B02', 'is', '', '5', '3', '9', '.', '0', ',', '', 'B03', 'is', '', '8', '2', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '8', '2']]\n",
      "decoded_data: ['PID is 5068.0, DOY is 211.0, B04 is 840.0, B02 is 539.0, B03 is 826.0 B04 is PID is 82']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 539.0, PID is 5068.0, DOY is 211.0, B04 is 840.0, B03 is']\n",
      "prompt: B02 is 539.0, PID is 5068.0, DOY is 211.0, B04 is 840.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '5', '3', '9', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '8', '4', '0', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '5', '3', '9', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '8', '4', '0', '.', '0', ',', '', 'B03', 'is', '', '8', '2', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '8', '2']]\n",
      "decoded_data: ['B02 is 539.0, PID is 5068.0, DOY is 211.0, B04 is 840.0, B03 is 826.0 B04 is PID is 82']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5068.0, B02 is 539.0, B04 is 840.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 5068.0, B02 is 539.0, B04 is 840.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '5', '3', '9', '.', '0', ',', '', 'B04', 'is', '', '8', '4', '0', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 17%|        | 143/829 [04:19<24:28,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '5', '3', '9', '.', '0', ',', '', 'B04', 'is', '', '8', '4', '0', '.', '0', ',', '', 'B03', 'is', '', '8', '2', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5068.0, B02 is 539.0, B04 is 840.0, B03 is 826.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5168.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 5168.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '6', '8', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '4', '9', '8', '.', '0', ',', '', 'B04', 'is', '', '8', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '8', '1', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '8', '1', '3', '.', '0', ',', '', 'B04']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5168.0, B02 is 498.0, B04 is 811.0, B03 is 813.0 813.0, B04']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 811.0, DOY is 211.0, B02 is 498.0, PID is 5168.0, B03 is']\n",
      "prompt: B04 is 811.0, DOY is 211.0, B02 is 498.0, PID is 5168.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '8', '1', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '4', '9', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '6', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '8', '1', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '4', '9', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '8', '1', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '8', '1', '3', '8', '1']]\n",
      "decoded_data: ['B04 is 811.0, DOY is 211.0, B02 is 498.0, PID is 5168.0, B03 is 813.0 PID is 81381']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 498.0, DOY is 211.0, B04 is 811.0, PID is 5168.0, B03 is']\n",
      "prompt: B02 is 498.0, DOY is 211.0, B04 is 811.0, PID is 5168.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '4', '9', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '8', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '6', '8', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|        | 144/829 [04:20<19:07,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B02', 'is', '', '4', '9', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '8', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '8', '1', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '8', '0', ',', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['B02 is 498.0, DOY is 211.0, B04 is 811.0, PID is 5168.0, B03 is 813.080, PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5268.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 5268.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '8', '.', '0', ',', '', 'B04', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|        | 145/829 [04:20<14:52,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B02', 'is', '', '4', '1', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '8', '4', '7', '8', '4', '7', '7', '8', '.']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5268.0, B04 is 700.0, B02 is 413.0, B03 is 778.084784778.']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 700.0, B02 is 413.0, PID is 5268.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 700.0, B02 is 413.0, PID is 5268.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B02', 'is', '', '4', '1', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B02', 'is', '', '4', '1', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '8', '4', '7', '8', '4', '7', '8', '4', '7']]\n",
      "decoded_data: ['B04 is 700.0, B02 is 413.0, PID is 5268.0, DOY is 211.0, B03 is 778.0847847847']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5368.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 5368.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '3', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '3', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '3', '6', '5', '8']]\n",
      "decoded_data: ['PID is 5368.0, DOY is 211.0, B02 is 337.0, B04 is 588.0, B03 is 784.0 B04 is 53658']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 588.0, DOY is 211.0, PID is 5368.0, B02 is 337.0, B03 is']\n",
      "prompt: B04 is 588.0, DOY is 211.0, PID is 5368.0, B02 is 337.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '8', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '8', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '7', '8', '4', '3', '.', '0', '4', '.']]\n",
      "decoded_data: ['B04 is 588.0, DOY is 211.0, PID is 5368.0, B02 is 337.0, B03 is 784.0 7843.04.']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 337.0, B04 is 588.0, PID is 5368.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 337.0, B04 is 588.0, PID is 5368.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '3', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '3', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '8', '4', '3', '6', '8', '4', '3', '5', '.']]\n",
      "decoded_data: ['B02 is 337.0, B04 is 588.0, PID is 5368.0, DOY is 211.0, B03 is 784.084368435.']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 588.0, PID is 5368.0, DOY is 211.0, B02 is 337.0, B03 is']\n",
      "prompt: B04 is 588.0, PID is 5368.0, DOY is 211.0, B02 is 337.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '8', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '8', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '7', '8', '4', '3', '.']]\n",
      "decoded_data: ['B04 is 588.0, PID is 5368.0, DOY is 211.0, B02 is 337.0, B03 is 784.0 B04 is 7843.']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 588.0, DOY is 211.0, PID is 5368.0, B02 is 337.0, B03 is']\n",
      "prompt: B04 is 588.0, DOY is 211.0, PID is 5368.0, B02 is 337.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '8', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '8', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', '5']]\n",
      "decoded_data: ['B04 is 588.0, DOY is 211.0, PID is 5368.0, B02 is 337.0, B03 is 784.0 B04 is B04 is 5']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 588.0, B02 is 337.0, DOY is 211.0, PID is 5368.0, B03 is']\n",
      "prompt: B04 is 588.0, B02 is 337.0, DOY is 211.0, PID is 5368.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '8', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '8', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '8', '4', '3', '5']]\n",
      "decoded_data: ['B04 is 588.0, B02 is 337.0, DOY is 211.0, PID is 5368.0, B03 is 784.0 PID is 78435']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 337.0, PID is 5368.0, B04 is 588.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 337.0, PID is 5368.0, B04 is 588.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '8', '4', '.', '0', '4', '3', '.', '0']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 337.0, PID is 5368.0, B04 is 588.0, B03 is 784.0784.043.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 588.0, DOY is 211.0, B02 is 337.0, PID is 5368.0, B03 is']\n",
      "prompt: B04 is 588.0, DOY is 211.0, B02 is 337.0, PID is 5368.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '8', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '8', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '2', '7', '.', '0', ',', '', 'B04', 'is']]\n",
      "decoded_data: ['B04 is 588.0, DOY is 211.0, B02 is 337.0, PID is 5368.0, B03 is 784.0727.0, B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5368.0, B04 is 588.0, DOY is 211.0, B02 is 337.0, B03 is']\n",
      "prompt: PID is 5368.0, B04 is 588.0, DOY is 211.0, B02 is 337.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '3', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '3', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', 'B03', 'is']]\n",
      "decoded_data: ['PID is 5368.0, B04 is 588.0, DOY is 211.0, B02 is 337.0, B03 is 784.0 PID is B04 is B03 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 588.0, PID is 5368.0, B02 is 337.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 588.0, PID is 5368.0, B02 is 337.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '8', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '8', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '8', '4', '3', '5']]\n",
      "decoded_data: ['B04 is 588.0, PID is 5368.0, B02 is 337.0, DOY is 211.0, B03 is 784.0 PID is 78435']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 588.0, PID is 5368.0, B02 is 337.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 588.0, PID is 5368.0, B02 is 337.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '8', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '8', '8', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '8', '4', '3', '1', '.', '0', ',', '']]\n",
      "decoded_data: ['B04 is 588.0, PID is 5368.0, B02 is 337.0, DOY is 211.0, B03 is 784.078431.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 337.0, DOY is 211.0, PID is 5368.0, B04 is 588.0, B03 is']\n",
      "prompt: B02 is 337.0, DOY is 211.0, PID is 5368.0, B04 is 588.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '3', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '3', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '5', '3']]\n",
      "decoded_data: ['B02 is 337.0, DOY is 211.0, PID is 5368.0, B04 is 588.0, B03 is 784.0 B04 is PID is 53']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 588.0, B02 is 337.0, DOY is 211.0, PID is 5368.0, B03 is']\n",
      "prompt: B04 is 588.0, B02 is 337.0, DOY is 211.0, PID is 5368.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '8', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '8', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '7', '8']]\n",
      "decoded_data: ['B04 is 588.0, B02 is 337.0, DOY is 211.0, PID is 5368.0, B03 is 784.0 PID is B04 is 78']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5368.0, B02 is 337.0, B04 is 588.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5368.0, B02 is 337.0, B04 is 588.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '3', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '3', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', '5', '8']]\n",
      "decoded_data: ['PID is 5368.0, B02 is 337.0, B04 is 588.0, DOY is 211.0, B03 is 784.0 B04 is B04 is 58']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5368.0, B02 is 337.0, B04 is 588.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5368.0, B02 is 337.0, B04 is 588.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '3', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 18%|        | 146/829 [04:23<18:07,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '5', '3', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '8', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '7', '8']]\n",
      "decoded_data: ['PID is 5368.0, B02 is 337.0, B04 is 588.0, DOY is 211.0, B03 is 784.0 PID is B04 is 78']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5468.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5468.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '4', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '4', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '9', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '3', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '3', '1', '3', '.', '0', '6', '6', '4', '3']]\n",
      "decoded_data: ['PID is 5468.0, DOY is 211.0, B03 is 791.0, B04 is 553.0, B02 is 306.0313.06643']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 791.0, PID is 5468.0, DOY is 211.0, B04 is 553.0, B02 is']\n",
      "prompt: B03 is 791.0, PID is 5468.0, DOY is 211.0, B04 is 553.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '9', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '3', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '9', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '3', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '3', '6', '3', '.']]\n",
      "decoded_data: ['B03 is 791.0, PID is 5468.0, DOY is 211.0, B04 is 553.0, B02 is 306.0 B04 is 5363.']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 791.0, B04 is 553.0, PID is 5468.0, B02 is']\n",
      "prompt: DOY is 211.0, B03 is 791.0, B04 is 553.0, PID is 5468.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '9', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '8', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '9', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '3', '.', '0', ',', '', 'B04', 'is', '', 'PID']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 791.0, B04 is 553.0, PID is 5468.0, B02 is 306.03.0, B04 is PID']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 553.0, PID is 5468.0, B03 is 791.0, B02 is']\n",
      "prompt: DOY is 211.0, B04 is 553.0, PID is 5468.0, B03 is 791.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '9', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '9', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '3', '1', '3', '7', '3']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 553.0, PID is 5468.0, B03 is 791.0, B02 is 306.0 PID is 31373']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5468.0, B04 is 553.0, B03 is 791.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 5468.0, B04 is 553.0, B03 is 791.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '4', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '9', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|        | 147/829 [04:23<15:30,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '5', '4', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '9', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '3', '1', '3', '7', '3', '7', '5', '3', '1']]\n",
      "decoded_data: ['PID is 5468.0, B04 is 553.0, B03 is 791.0, DOY is 211.0, B02 is 306.0313737531']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5568.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 5568.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '8', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '6', '3']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5568.0, B02 is 340.0, B04 is 551.0, B03 is 697.0 B04 is PID is 63']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5568.0, DOY is 211.0, B02 is 340.0, B04 is 551.0, B03 is']\n",
      "prompt: PID is 5568.0, DOY is 211.0, B02 is 340.0, B04 is 551.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '5', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '5', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['PID is 5568.0, DOY is 211.0, B02 is 340.0, B04 is 551.0, B03 is 696.0 PID is B04 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 340.0, DOY is 211.0, B04 is 551.0, PID is 5568.0, B03 is']\n",
      "prompt: B02 is 340.0, DOY is 211.0, B04 is 551.0, PID is 5568.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '4', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '4', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '1', '0', '.', '0', '.', '0', ',', '']]\n",
      "decoded_data: ['B02 is 340.0, DOY is 211.0, B04 is 551.0, PID is 5568.0, B03 is 694.0610.0.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5568.0, B04 is 551.0, B02 is 340.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5568.0, B04 is 551.0, B02 is 340.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '5', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '5', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['PID is 5568.0, B04 is 551.0, B02 is 340.0, DOY is 211.0, B03 is 697.0 B04 is PID is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 340.0, PID is 5568.0, B04 is 551.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 340.0, PID is 5568.0, B04 is 551.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '4', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|        | 148/829 [04:24<13:51,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B02', 'is', '', '3', '4', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '3', '4', '0', '2', '9', '7', '3', '2']]\n",
      "decoded_data: ['B02 is 340.0, PID is 5568.0, B04 is 551.0, DOY is 211.0, B03 is 694.0734029732']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5668.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 5668.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '6', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '6', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'B03', 'is', '', '5', '1', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', '5', '1', '9', '0', '1']]\n",
      "decoded_data: ['PID is 5668.0, DOY is 211.0, B04 is 434.0, B02 is 280.0, B03 is 519.0 B03 is 51901']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 280.0, B04 is 434.0, DOY is 211.0, PID is 5668.0, B03 is']\n",
      "prompt: B02 is 280.0, B04 is 434.0, DOY is 211.0, PID is 5668.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '5', '1', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '5', '3']]\n",
      "decoded_data: ['B02 is 280.0, B04 is 434.0, DOY is 211.0, PID is 5668.0, B03 is 519.0 B04 is PID is 53']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 434.0, DOY is 211.0, PID is 5668.0, B02 is 280.0, B03 is']\n",
      "prompt: B04 is 434.0, DOY is 211.0, PID is 5668.0, B02 is 280.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '3', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '3', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'B03', 'is', '', '5', '1', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '1', '9', '5', '1', '9', '5', '1']]\n",
      "decoded_data: ['B04 is 434.0, DOY is 211.0, PID is 5668.0, B02 is 280.0, B03 is 519.0 51951951']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 280.0, DOY is 211.0, B04 is 434.0, PID is 5668.0, B03 is']\n",
      "prompt: B02 is 280.0, DOY is 211.0, B04 is 434.0, PID is 5668.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '5', '1', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', '5', '0', '8', '3', '2']]\n",
      "decoded_data: ['B02 is 280.0, DOY is 211.0, B04 is 434.0, PID is 5668.0, B03 is 519.0 B03 is 50832']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 280.0, PID is 5668.0, B04 is 434.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 280.0, PID is 5668.0, B04 is 434.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '5', '1', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '1', '9', '0', '8']]\n",
      "decoded_data: ['B02 is 280.0, PID is 5668.0, B04 is 434.0, DOY is 211.0, B03 is 519.0 B04 is 51908']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5668.0, DOY is 211.0, B02 is 280.0, B04 is 434.0, B03 is']\n",
      "prompt: PID is 5668.0, DOY is 211.0, B02 is 280.0, B04 is 434.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '6', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '6', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '4', '.', '0', ',', '', 'B03', 'is', '', '5', '1', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '0', '8', '3', '4']]\n",
      "decoded_data: ['PID is 5668.0, DOY is 211.0, B02 is 280.0, B04 is 434.0, B03 is 519.0 B04 is 50834']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5668.0, DOY is 211.0, B04 is 434.0, B02 is 280.0, B03 is']\n",
      "prompt: PID is 5668.0, DOY is 211.0, B04 is 434.0, B02 is 280.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '6', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '6', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'B03', 'is', '', '5', '1', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B03', 'is', '', '5', '1']]\n",
      "decoded_data: ['PID is 5668.0, DOY is 211.0, B04 is 434.0, B02 is 280.0, B03 is 519.0 B04 is B03 is 51']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5668.0, B04 is 434.0, B02 is 280.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5668.0, B04 is 434.0, B02 is 280.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '6', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '6', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '5', '1', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '5', '1']]\n",
      "decoded_data: ['PID is 5668.0, B04 is 434.0, B02 is 280.0, DOY is 211.0, B03 is 519.0 B04 is PID is 51']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 434.0, B02 is 280.0, PID is 5668.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 434.0, B02 is 280.0, PID is 5668.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '3', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '3', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '5', '1', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B03', 'is']]\n",
      "decoded_data: ['B04 is 434.0, B02 is 280.0, PID is 5668.0, DOY is 211.0, B03 is 519.0 B04 is PID is B03 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 434.0, PID is 5668.0, B02 is 280.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 434.0, PID is 5668.0, B02 is 280.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '3', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '3', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '5', '1', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '5', '0']]\n",
      "decoded_data: ['B04 is 434.0, PID is 5668.0, B02 is 280.0, DOY is 211.0, B03 is 519.0 B04 is PID is 50']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 280.0, B04 is 434.0, PID is 5668.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 280.0, B04 is 434.0, PID is 5668.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '5', '1', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '0', '1', '9', '5', '1', '0', '.']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 280.0, B04 is 434.0, PID is 5668.0, B03 is 519.0 5019510.']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 280.0, B04 is 434.0, PID is 5668.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 280.0, B04 is 434.0, PID is 5668.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '5', '1', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '9', '.', '0', ',', '', 'PID', 'is', '']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 280.0, B04 is 434.0, PID is 5668.0, B03 is 519.059.0, PID is ']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 280.0, B04 is 434.0, PID is 5668.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 280.0, B04 is 434.0, PID is 5668.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '5', '1', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '1', '9', '6', '4', '.', '0', ',']]\n",
      "decoded_data: ['B02 is 280.0, B04 is 434.0, PID is 5668.0, DOY is 211.0, B03 is 519.0 51964.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 434.0, DOY is 211.0, PID is 5668.0, B02 is 280.0, B03 is']\n",
      "prompt: B04 is 434.0, DOY is 211.0, PID is 5668.0, B02 is 280.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '3', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '3', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'B03', 'is', '', '5', '1', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '5', '0']]\n",
      "decoded_data: ['B04 is 434.0, DOY is 211.0, PID is 5668.0, B02 is 280.0, B03 is 519.0 B04 is PID is 50']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5668.0, DOY is 211.0, B04 is 434.0, B02 is 280.0, B03 is']\n",
      "prompt: PID is 5668.0, DOY is 211.0, B04 is 434.0, B02 is 280.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '6', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 18%|        | 149/829 [04:27<17:32,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '5', '6', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '0', '.', '0', ',', '', 'B03', 'is', '', '5', '1', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '1', '9', '6', '9']]\n",
      "decoded_data: ['PID is 5668.0, DOY is 211.0, B04 is 434.0, B02 is 280.0, B03 is 519.0 B04 is 51969']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5768.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5768.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '7', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '7', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '5', '2', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B03', 'is', '', 'B03', 'is']]\n",
      "decoded_data: ['PID is 5768.0, DOY is 211.0, B03 is 527.0, B04 is 491.0, B02 is 310.0 PID is B03 is B03 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5768.0, B03 is 527.0, B04 is 491.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 5768.0, B03 is 527.0, B04 is 491.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '5', '2', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '5', '2', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '3', '2', '1', '0', '1', '0', '1', '0']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5768.0, B03 is 527.0, B04 is 491.0, B02 is 310.0 32101010']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 527.0, PID is 5768.0, DOY is 211.0, B04 is 491.0, B02 is']\n",
      "prompt: B03 is 527.0, PID is 5768.0, DOY is 211.0, B04 is 491.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '5', '2', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '5', '2', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', '3', '0', '1', '0', '1']]\n",
      "decoded_data: ['B03 is 527.0, PID is 5768.0, DOY is 211.0, B04 is 491.0, B02 is 310.0 B03 is 30101']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 491.0, B03 is 527.0, PID is 5768.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 491.0, B03 is 527.0, PID is 5768.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '9', '1', '.', '0', ',', '', 'B03', 'is', '', '5', '2', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '9', '1', '.', '0', ',', '', 'B03', 'is', '', '5', '2', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '3', '1', '0', '0', '2']]\n",
      "decoded_data: ['B04 is 491.0, B03 is 527.0, PID is 5768.0, DOY is 211.0, B02 is 310.0 PID is 31002']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5768.0, B04 is 491.0, B03 is 527.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 5768.0, B04 is 491.0, B03 is 527.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '1', '.', '0', ',', '', 'B03', 'is', '', '5', '2', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '1', '.', '0', ',', '', 'B03', 'is', '', '5', '2', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'B04', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5768.0, B04 is 491.0, B03 is 527.0, B02 is 310.0 B03 is B04 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 491.0, PID is 5768.0, DOY is 211.0, B03 is 527.0, B02 is']\n",
      "prompt: B04 is 491.0, PID is 5768.0, DOY is 211.0, B03 is 527.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '9', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '5', '2', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '9', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '5', '2', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '3', '0', '1', '0', '1']]\n",
      "decoded_data: ['B04 is 491.0, PID is 5768.0, DOY is 211.0, B03 is 527.0, B02 is 310.0 PID is 30101']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 491.0, PID is 5768.0, B03 is 527.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 491.0, PID is 5768.0, B03 is 527.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '9', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '5', '2', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '9', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '5', '2', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B03', 'is', '', '3', '2']]\n",
      "decoded_data: ['B04 is 491.0, PID is 5768.0, B03 is 527.0, DOY is 211.0, B02 is 310.0 PID is B03 is 32']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 491.0, PID is 5768.0, B03 is 527.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 491.0, PID is 5768.0, B03 is 527.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '9', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '5', '2', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '9', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '5', '2', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '3', '2', '1', '0', '1']]\n",
      "decoded_data: ['B04 is 491.0, PID is 5768.0, B03 is 527.0, DOY is 211.0, B02 is 310.0 PID is 32101']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 527.0, B04 is 491.0, DOY is 211.0, PID is 5768.0, B02 is']\n",
      "prompt: B03 is 527.0, B04 is 491.0, DOY is 211.0, PID is 5768.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '5', '2', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '8', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '5', '2', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '3', '2', '4', '5', '5']]\n",
      "decoded_data: ['B03 is 527.0, B04 is 491.0, DOY is 211.0, PID is 5768.0, B02 is 310.0 PID is 32455']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 527.0, B04 is 491.0, DOY is 211.0, PID is 5768.0, B02 is']\n",
      "prompt: B03 is 527.0, B04 is 491.0, DOY is 211.0, PID is 5768.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '5', '2', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '8', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '5', '2', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B03', 'is', '', 'B03', 'is']]\n",
      "decoded_data: ['B03 is 527.0, B04 is 491.0, DOY is 211.0, PID is 5768.0, B02 is 310.0 PID is B03 is B03 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5768.0, B03 is 527.0, B04 is 491.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 5768.0, B03 is 527.0, B04 is 491.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '5', '2', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '5', '2', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '4', '5']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5768.0, B03 is 527.0, B04 is 491.0, B02 is 310.0 B04 is PID is 45']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 527.0, B04 is 491.0, PID is 5768.0, B02 is']\n",
      "prompt: DOY is 211.0, B03 is 527.0, B04 is 491.0, PID is 5768.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '5', '2', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '8', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '5', '2', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '3', '1', '0', '7', '0']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 527.0, B04 is 491.0, PID is 5768.0, B02 is 310.0 PID is 31070']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 527.0, PID is 5768.0, DOY is 211.0, B04 is 491.0, B02 is']\n",
      "prompt: B03 is 527.0, PID is 5768.0, DOY is 211.0, B04 is 491.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '5', '2', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '5', '2', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '4', '5', '0', '1', '0']]\n",
      "decoded_data: ['B03 is 527.0, PID is 5768.0, DOY is 211.0, B04 is 491.0, B02 is 310.0 B04 is 45010']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 527.0, B04 is 491.0, PID is 5768.0, DOY is 211.0, B02 is']\n",
      "prompt: B03 is 527.0, B04 is 491.0, PID is 5768.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '5', '2', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '5', '2', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '4', '5', '0', '.', '0']]\n",
      "decoded_data: ['B03 is 527.0, B04 is 491.0, PID is 5768.0, DOY is 211.0, B02 is 310.0 B04 is 450.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 491.0, PID is 5768.0, B03 is 527.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 491.0, PID is 5768.0, B03 is 527.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '9', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '5', '2', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 18%|        | 150/829 [04:29<20:16,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B04', 'is', '', '4', '9', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '5', '2', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '5', '9']]\n",
      "decoded_data: ['B04 is 491.0, PID is 5768.0, B03 is 527.0, DOY is 211.0, B02 is 310.0 B04 is PID is 59']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5868.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 5868.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '8', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '8', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '3', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '8', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B03', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['PID is 5868.0, DOY is 211.0, B04 is 601.0, B03 is 635.0, B02 is 387.0 PID is B03 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5868.0, B03 is 635.0, B04 is 601.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 5868.0, B03 is 635.0, B04 is 601.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '6', '3', '5', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '6', '3', '5', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '8', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'PID', 'is', '', 'B03', 'is']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5868.0, B03 is 635.0, B04 is 601.0, B02 is 387.0 B03 is PID is B03 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 635.0, DOY is 211.0, B04 is 601.0, PID is 5868.0, B02 is']\n",
      "prompt: B03 is 635.0, DOY is 211.0, B04 is 601.0, PID is 5868.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '3', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '8', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '6', '3', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '8', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B03', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['B03 is 635.0, DOY is 211.0, B04 is 601.0, PID is 5868.0, B02 is 387.0 B04 is B03 is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 635.0, PID is 5868.0, B04 is 601.0, B02 is']\n",
      "prompt: DOY is 211.0, B03 is 635.0, PID is 5868.0, B04 is 601.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '3', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '3', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '8', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '8', '7', '0', '.', '0', ',', '', 'PID', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 635.0, PID is 5868.0, B04 is 601.0, B02 is 387.0870.0, PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 635.0, B04 is 601.0, PID is 5868.0, B02 is']\n",
      "prompt: DOY is 211.0, B03 is 635.0, B04 is 601.0, PID is 5868.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '3', '5', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '8', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '3', '5', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '8', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '3', '.', '0', ',', '', 'B04', 'is', '', 'PID']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 635.0, B04 is 601.0, PID is 5868.0, B02 is 387.03.0, B04 is PID']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 635.0, PID is 5868.0, B04 is 601.0, B02 is']\n",
      "prompt: DOY is 211.0, B03 is 635.0, PID is 5868.0, B04 is 601.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '3', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '3', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '8', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '3', '8', '7', '0', '7']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 635.0, PID is 5868.0, B04 is 601.0, B02 is 387.0 PID is 38707']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 601.0, B03 is 635.0, PID is 5868.0, B02 is']\n",
      "prompt: DOY is 211.0, B04 is 601.0, B03 is 635.0, PID is 5868.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '3', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '8', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '3', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '8', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '3', '5', '1', '0', '.', '0', ',', '', 'PID']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 601.0, B03 is 635.0, PID is 5868.0, B02 is 387.03510.0, PID']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 601.0, PID is 5868.0, B03 is 635.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 601.0, PID is 5868.0, B03 is 635.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '6', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '6', '3', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '6', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '6', '3', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '8', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['B04 is 601.0, PID is 5868.0, B03 is 635.0, DOY is 211.0, B02 is 387.0 B03 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 635.0, PID is 5868.0, B04 is 601.0, DOY is 211.0, B02 is']\n",
      "prompt: B03 is 635.0, PID is 5868.0, B04 is 601.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '3', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '6', '3', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '8', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'DOY', 'is', '', '2', '3']]\n",
      "decoded_data: ['B03 is 635.0, PID is 5868.0, B04 is 601.0, DOY is 211.0, B02 is 387.0 PID is DOY is 23']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5868.0, B04 is 601.0, B03 is 635.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 5868.0, B04 is 601.0, B03 is 635.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '3', '5', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '3', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '8', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'B04', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5868.0, B04 is 601.0, B03 is 635.0, B02 is 387.0 B03 is B04 is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 601.0, B03 is 635.0, PID is 5868.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 601.0, B03 is 635.0, PID is 5868.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '6', '0', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '3', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '6', '0', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '3', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '8', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '3', '5', '7', '0', '.', '0', ',', '', 'B02']]\n",
      "decoded_data: ['B04 is 601.0, B03 is 635.0, PID is 5868.0, DOY is 211.0, B02 is 387.03570.0, B02']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 635.0, PID is 5868.0, B04 is 601.0, B02 is']\n",
      "prompt: DOY is 211.0, B03 is 635.0, PID is 5868.0, B04 is 601.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '3', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '3', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '8', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '6', '0', '7', '0', '7']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 635.0, PID is 5868.0, B04 is 601.0, B02 is 387.0 B04 is 60707']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 601.0, B03 is 635.0, DOY is 211.0, PID is 5868.0, B02 is']\n",
      "prompt: B04 is 601.0, B03 is 635.0, DOY is 211.0, PID is 5868.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '6', '0', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '3', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '8', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '6', '0', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '3', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '8', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '3', '.', '0', ',', '', 'B03', 'is', '', 'PID']]\n",
      "decoded_data: ['B04 is 601.0, B03 is 635.0, DOY is 211.0, PID is 5868.0, B02 is 387.03.0, B03 is PID']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 601.0, PID is 5868.0, B03 is 635.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 601.0, PID is 5868.0, B03 is 635.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '6', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '6', '3', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '6', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '6', '3', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '8', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '3', '5', '7', '0', '7', '0', '.', '0', '.']]\n",
      "decoded_data: ['B04 is 601.0, PID is 5868.0, B03 is 635.0, DOY is 211.0, B02 is 387.0357070.0.']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 635.0, PID is 5868.0, B04 is 601.0, DOY is 211.0, B02 is']\n",
      "prompt: B03 is 635.0, PID is 5868.0, B04 is 601.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '3', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|        | 151/829 [04:31<22:04,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B03', 'is', '', '6', '3', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '8', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '3', '4', '0', '7', '4', '0', '7', '3', '1']]\n",
      "decoded_data: ['B03 is 635.0, PID is 5868.0, B04 is 601.0, DOY is 211.0, B02 is 387.0340740731']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5968.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 5968.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '6', '1', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'DOY', 'is', '', 'B02', 'is', '', '6', '7']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5968.0, B03 is 725.0, B02 is 367.0, B04 is 616.0 DOY is B02 is 67']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5968.0, B03 is 725.0, B02 is 367.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 5968.0, B03 is 725.0, B02 is 367.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '9', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '9', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '1', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'DOY', 'is', '', '2', '6', '7', '1', '6']]\n",
      "decoded_data: ['PID is 5968.0, B03 is 725.0, B02 is 367.0, DOY is 211.0, B04 is 616.0 DOY is 26716']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5968.0, B03 is 725.0, B02 is 367.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 5968.0, B03 is 725.0, B02 is 367.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '6', '1', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '6', '6', '7', '1', '6', '.', '0', ',']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5968.0, B03 is 725.0, B02 is 367.0, B04 is 616.0 66716.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5968.0, B03 is 725.0, B02 is 367.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 5968.0, B03 is 725.0, B02 is 367.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '9', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '9', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '1', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '6', '1', '6', '5', '3']]\n",
      "decoded_data: ['PID is 5968.0, B03 is 725.0, B02 is 367.0, DOY is 211.0, B04 is 616.0 PID is 61653']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 367.0, DOY is 211.0, B03 is 725.0, PID is 5968.0, B04 is']\n",
      "prompt: B02 is 367.0, DOY is 211.0, B03 is 725.0, PID is 5968.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '8', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '6', '1', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'DOY', 'is', '', 'B02', 'is', '', '3', '4']]\n",
      "decoded_data: ['B02 is 367.0, DOY is 211.0, B03 is 725.0, PID is 5968.0, B04 is 616.0 DOY is B02 is 34']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 367.0, PID is 5968.0, DOY is 211.0, B03 is 725.0, B04 is']\n",
      "prompt: B02 is 367.0, PID is 5968.0, DOY is 211.0, B03 is 725.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '6', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '5', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '6', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '5', '.', '0', ',', '', 'B04', 'is', '', '6', '1', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '6', '1', '1', '6', '5']]\n",
      "decoded_data: ['B02 is 367.0, PID is 5968.0, DOY is 211.0, B03 is 725.0, B04 is 616.0 PID is 61165']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 367.0, PID is 5968.0, B03 is 725.0, B04 is']\n",
      "prompt: DOY is 211.0, B02 is 367.0, PID is 5968.0, B03 is 725.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '5', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '5', '.', '0', ',', '', 'B04', 'is', '', '6', '1', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '6', '6', '.', '0', ',', '', 'PID', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 367.0, PID is 5968.0, B03 is 725.0, B04 is 616.0 66.0, PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5968.0, DOY is 211.0, B02 is 367.0, B03 is 725.0, B04 is']\n",
      "prompt: PID is 5968.0, DOY is 211.0, B02 is 367.0, B03 is 725.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '9', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '5', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '9', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '5', '.', '0', ',', '', 'B04', 'is', '', '6', '1', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '6', '6', '.', '0', '1', '6', '5', '.']]\n",
      "decoded_data: ['PID is 5968.0, DOY is 211.0, B02 is 367.0, B03 is 725.0, B04 is 616.0 66.0165.']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 725.0, PID is 5968.0, DOY is 211.0, B02 is 367.0, B04 is']\n",
      "prompt: B03 is 725.0, PID is 5968.0, DOY is 211.0, B02 is 367.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '2', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '2', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '6', '1', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '6', '5', '3', '2', '.', '0', ',', '']]\n",
      "decoded_data: ['B03 is 725.0, PID is 5968.0, DOY is 211.0, B02 is 367.0, B04 is 616.0 6532.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 725.0, DOY is 211.0, B02 is 367.0, PID is 5968.0, B04 is']\n",
      "prompt: B03 is 725.0, DOY is 211.0, B02 is 367.0, PID is 5968.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '2', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '8', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '2', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '6', '1', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '6', '6', '.', '0', '1']]\n",
      "decoded_data: ['B03 is 725.0, DOY is 211.0, B02 is 367.0, PID is 5968.0, B04 is 616.0 PID is 66.01']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 367.0, PID is 5968.0, B03 is 725.0, B04 is']\n",
      "prompt: DOY is 211.0, B02 is 367.0, PID is 5968.0, B03 is 725.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '5', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '5', '.', '0', ',', '', 'B04', 'is', '', '6', '1', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '6', '9', '4', '3', '.', '0', '.', '0']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 367.0, PID is 5968.0, B03 is 725.0, B04 is 616.0 6943.0.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 367.0, B03 is 725.0, PID is 5968.0, DOY is 211.0, B04 is']\n",
      "prompt: B02 is 367.0, B03 is 725.0, PID is 5968.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '6', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '5', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '1', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '6', '1', '6', '.', '0', '.', '0', '.']]\n",
      "decoded_data: ['B02 is 367.0, B03 is 725.0, PID is 5968.0, DOY is 211.0, B04 is 616.0 616.0.0.']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5968.0, B03 is 725.0, B02 is 367.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 5968.0, B03 is 725.0, B02 is 367.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '9', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '9', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '1', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '6', '4', '9', '2', '6', '.', '0', '.']]\n",
      "decoded_data: ['PID is 5968.0, B03 is 725.0, B02 is 367.0, DOY is 211.0, B04 is 616.0 64926.0.']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5968.0, B03 is 725.0, B02 is 367.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 5968.0, B03 is 725.0, B02 is 367.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '9', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '9', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '1', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '6', '6', '.', '0', '1', '.', '0', '.']]\n",
      "decoded_data: ['PID is 5968.0, B03 is 725.0, B02 is 367.0, DOY is 211.0, B04 is 616.0 66.01.0.']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5968.0, DOY is 211.0, B03 is 725.0, B02 is 367.0, B04 is']\n",
      "prompt: PID is 5968.0, DOY is 211.0, B03 is 725.0, B02 is 367.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '9', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '7', '.', '0', ',', '', 'B04', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 18%|        | 152/829 [04:34<23:06,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '5', '9', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '6', '1', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '6', '6', '7', '6', '.', '0', '1', '.']]\n",
      "decoded_data: ['PID is 5968.0, DOY is 211.0, B03 is 725.0, B02 is 367.0, B04 is 616.0 6676.01.']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6068.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 6068.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '0', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '0', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '8', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '9', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['PID is 6068.0, DOY is 211.0, B02 is 387.0, B03 is 746.0, B04 is 597.0 B03 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 746.0, PID is 6068.0, B02 is 387.0, B04 is']\n",
      "prompt: DOY is 211.0, B03 is 746.0, PID is 6068.0, B02 is 387.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '8', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '8', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '9', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'DOY', 'is', '', 'PID', 'is', '', '2', '3']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 746.0, PID is 6068.0, B02 is 387.0, B04 is 597.0 DOY is PID is 23']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 387.0, PID is 6068.0, B03 is 746.0, DOY is 211.0, B04 is']\n",
      "prompt: B02 is 387.0, PID is 6068.0, B03 is 746.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '8', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '8', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '9', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B03', 'is', '', '5', '8']]\n",
      "decoded_data: ['B02 is 387.0, PID is 6068.0, B03 is 746.0, DOY is 211.0, B04 is 597.0 PID is B03 is 58']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 387.0, DOY is 211.0, PID is 6068.0, B03 is 746.0, B04 is']\n",
      "prompt: B02 is 387.0, DOY is 211.0, PID is 6068.0, B03 is 746.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '8', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '6', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '8', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '9', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '8', '7', '3', '8']]\n",
      "decoded_data: ['B02 is 387.0, DOY is 211.0, PID is 6068.0, B03 is 746.0, B04 is 597.0 PID is 58738']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6068.0, DOY is 211.0, B02 is 387.0, B03 is 746.0, B04 is']\n",
      "prompt: PID is 6068.0, DOY is 211.0, B02 is 387.0, B03 is 746.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '0', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '8', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '6', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '0', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '8', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '9', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '1', '7', '3', '6', '4', '7', '3', '.']]\n",
      "decoded_data: ['PID is 6068.0, DOY is 211.0, B02 is 387.0, B03 is 746.0, B04 is 597.061736473.']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 387.0, B03 is 746.0, PID is 6068.0, B04 is']\n",
      "prompt: DOY is 211.0, B02 is 387.0, B03 is 746.0, PID is 6068.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '8', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '8', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '8', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '9', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'PID', 'is', '', 'DOY', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 387.0, B03 is 746.0, PID is 6068.0, B04 is 597.0 B03 is PID is DOY is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6068.0, DOY is 211.0, B03 is 746.0, B02 is 387.0, B04 is']\n",
      "prompt: PID is 6068.0, DOY is 211.0, B03 is 746.0, B02 is 387.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '0', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '8', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '0', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '8', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '9', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'PID', 'is', '', 'B03', 'is']]\n",
      "decoded_data: ['PID is 6068.0, DOY is 211.0, B03 is 746.0, B02 is 387.0, B04 is 597.0 B03 is PID is B03 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 746.0, PID is 6068.0, DOY is 211.0, B02 is 387.0, B04 is']\n",
      "prompt: B03 is 746.0, PID is 6068.0, DOY is 211.0, B02 is 387.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '4', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '8', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '4', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '8', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '9', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '.', '0', ',', '', 'B03', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['B03 is 746.0, PID is 6068.0, DOY is 211.0, B02 is 387.0, B04 is 597.0.0, B03 is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 387.0, B03 is 746.0, PID is 6068.0, DOY is 211.0, B04 is']\n",
      "prompt: B02 is 387.0, B03 is 746.0, PID is 6068.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '8', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '8', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '9', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '8', '7', '3', '9']]\n",
      "decoded_data: ['B02 is 387.0, B03 is 746.0, PID is 6068.0, DOY is 211.0, B04 is 597.0 PID is 58739']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 387.0, DOY is 211.0, B03 is 746.0, PID is 6068.0, B04 is']\n",
      "prompt: B02 is 387.0, DOY is 211.0, B03 is 746.0, PID is 6068.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '8', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '8', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '8', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '6', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '9', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'DOY', 'is', '', 'PID', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['B02 is 387.0, DOY is 211.0, B03 is 746.0, PID is 6068.0, B04 is 597.0 DOY is PID is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6068.0, B02 is 387.0, DOY is 211.0, B03 is 746.0, B04 is']\n",
      "prompt: PID is 6068.0, B02 is 387.0, DOY is 211.0, B03 is 746.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '0', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '8', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '6', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '0', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '8', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '9', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'B04', 'is', '', '5', '3']]\n",
      "decoded_data: ['PID is 6068.0, B02 is 387.0, DOY is 211.0, B03 is 746.0, B04 is 597.0 B03 is B04 is 53']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6068.0, B02 is 387.0, B03 is 746.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 6068.0, B02 is 387.0, B03 is 746.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '8', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '6', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '8', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '9', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '1', '.', '0', ',', '', 'B03', 'is', '', 'PID']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6068.0, B02 is 387.0, B03 is 746.0, B04 is 597.01.0, B03 is PID']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6068.0, B02 is 387.0, B03 is 746.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 6068.0, B02 is 387.0, B03 is 746.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '0', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '8', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '0', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '8', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '9', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '8', '7', '3', '8']]\n",
      "decoded_data: ['PID is 6068.0, B02 is 387.0, B03 is 746.0, DOY is 211.0, B04 is 597.0 PID is 58738']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6068.0, B03 is 746.0, B02 is 387.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 6068.0, B03 is 746.0, B02 is 387.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '0', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '8', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '0', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '8', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '9', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '', 'B02', 'is', '', 'DOY', 'is', '', '2']]\n",
      "decoded_data: ['PID is 6068.0, B03 is 746.0, B02 is 387.0, DOY is 211.0, B04 is 597.0 B02 is DOY is 2']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6068.0, B02 is 387.0, DOY is 211.0, B03 is 746.0, B04 is']\n",
      "prompt: PID is 6068.0, B02 is 387.0, DOY is 211.0, B03 is 746.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '0', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '8', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '6', '.', '0', ',', '', 'B04', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 18%|        | 153/829 [04:36<23:58,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '6', '0', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '8', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '9', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '8', '9', '7', '5', '3', '8', '.']]\n",
      "decoded_data: ['PID is 6068.0, B02 is 387.0, DOY is 211.0, B03 is 746.0, B04 is 597.0 5897538.']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6168.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 6168.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '1', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '1', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '2', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '.', '0', ',', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['PID is 6168.0, DOY is 211.0, B03 is 742.0, B04 is 589.0, B02 is 354.0.0, PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 589.0, B03 is 742.0, PID is 6168.0, B02 is']\n",
      "prompt: DOY is 211.0, B04 is 589.0, B03 is 742.0, PID is 6168.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '2', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '8', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '2', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 589.0, B03 is 742.0, PID is 6168.0, B02 is 354.0 B03 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6168.0, B04 is 589.0, DOY is 211.0, B03 is 742.0, B02 is']\n",
      "prompt: PID is 6168.0, B04 is 589.0, DOY is 211.0, B03 is 742.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '1', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '2', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '1', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '2', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['PID is 6168.0, B04 is 589.0, DOY is 211.0, B03 is 742.0, B02 is 354.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 589.0, B03 is 742.0, DOY is 211.0, PID is 6168.0, B02 is']\n",
      "prompt: B04 is 589.0, B03 is 742.0, DOY is 211.0, PID is 6168.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '8', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '8', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '8', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '4', '1', '0', '0', '0', '1', '.', '0', ',']]\n",
      "decoded_data: ['B04 is 589.0, B03 is 742.0, DOY is 211.0, PID is 6168.0, B02 is 354.0410001.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 589.0, DOY is 211.0, B03 is 742.0, PID is 6168.0, B02 is']\n",
      "prompt: B04 is 589.0, DOY is 211.0, B03 is 742.0, PID is 6168.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '8', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '2', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '8', '.', '0', ',', '', 'B02', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|        | 154/829 [04:37<19:42,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B04', 'is', '', '5', '8', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '2', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '4', '3', '0', ',', '', 'B03', 'is', '', 'PID']]\n",
      "decoded_data: ['B04 is 589.0, DOY is 211.0, B03 is 742.0, PID is 6168.0, B02 is 354.0430, B03 is PID']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6268.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 6268.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '2', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '2', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B03', 'is', '', '7', '3']]\n",
      "decoded_data: ['PID is 6268.0, DOY is 211.0, B04 is 573.0, B03 is 748.0, B02 is 330.0 B04 is B03 is 73']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6268.0, DOY is 211.0, B03 is 748.0, B04 is 573.0, B02 is']\n",
      "prompt: PID is 6268.0, DOY is 211.0, B03 is 748.0, B04 is 573.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '2', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '2', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '4', '3', '8', '0']]\n",
      "decoded_data: ['PID is 6268.0, DOY is 211.0, B03 is 748.0, B04 is 573.0, B02 is 330.0 B04 is 54380']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 748.0, PID is 6268.0, DOY is 211.0, B04 is 573.0, B02 is']\n",
      "prompt: B03 is 748.0, PID is 6268.0, DOY is 211.0, B04 is 573.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '4', '8', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '4', '8', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '3', '0', '6', '4', '3']]\n",
      "decoded_data: ['B03 is 748.0, PID is 6268.0, DOY is 211.0, B04 is 573.0, B02 is 330.0 PID is 30643']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6268.0, B03 is 748.0, B04 is 573.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 6268.0, B03 is 748.0, B04 is 573.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'B04', 'is', '', '5', '4']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6268.0, B03 is 748.0, B04 is 573.0, B02 is 330.0 B03 is B04 is 54']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 573.0, PID is 6268.0, DOY is 211.0, B03 is 748.0, B02 is']\n",
      "prompt: B04 is 573.0, PID is 6268.0, DOY is 211.0, B03 is 748.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '8', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '3', '0', '6', '6', '4', '3', '0', '6', '.']]\n",
      "decoded_data: ['B04 is 573.0, PID is 6268.0, DOY is 211.0, B03 is 748.0, B02 is 330.030664306.']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 748.0, PID is 6268.0, DOY is 211.0, B04 is 573.0, B02 is']\n",
      "prompt: B03 is 748.0, PID is 6268.0, DOY is 211.0, B04 is 573.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '4', '8', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '4', '8', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '3', '0', '5', '4', '5', '4', '6', '6', '.']]\n",
      "decoded_data: ['B03 is 748.0, PID is 6268.0, DOY is 211.0, B04 is 573.0, B02 is 330.030545466.']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 573.0, DOY is 211.0, PID is 6268.0, B03 is 748.0, B02 is']\n",
      "prompt: B04 is 573.0, DOY is 211.0, PID is 6268.0, B03 is 748.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '8', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', '7', '3', '8', '3', '0']]\n",
      "decoded_data: ['B04 is 573.0, DOY is 211.0, PID is 6268.0, B03 is 748.0, B02 is 330.0 B03 is 73830']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6268.0, B04 is 573.0, B03 is 748.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 6268.0, B04 is 573.0, B03 is 748.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '8', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'B03', 'is', '', '7', '4']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6268.0, B04 is 573.0, B03 is 748.0, B02 is 330.0 B03 is B03 is 74']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 573.0, PID is 6268.0, B03 is 748.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 573.0, PID is 6268.0, B03 is 748.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '1', '.', '0', '8', '7', '3', '0', '5', '4']]\n",
      "decoded_data: ['B04 is 573.0, PID is 6268.0, B03 is 748.0, DOY is 211.0, B02 is 330.01.0873054']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 748.0, DOY is 211.0, PID is 6268.0, B04 is 573.0, B02 is']\n",
      "prompt: B03 is 748.0, DOY is 211.0, PID is 6268.0, B04 is 573.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '4', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '4', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'B03', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['B03 is 748.0, DOY is 211.0, PID is 6268.0, B04 is 573.0, B02 is 330.0 B03 is B03 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 748.0, B04 is 573.0, DOY is 211.0, PID is 6268.0, B02 is']\n",
      "prompt: B03 is 748.0, B04 is 573.0, DOY is 211.0, PID is 6268.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '4', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '8', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '4', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'B04', 'is', '', 'DOY', 'is']]\n",
      "decoded_data: ['B03 is 748.0, B04 is 573.0, DOY is 211.0, PID is 6268.0, B02 is 330.0 B03 is B04 is DOY is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6268.0, DOY is 211.0, B03 is 748.0, B04 is 573.0, B02 is']\n",
      "prompt: PID is 6268.0, DOY is 211.0, B03 is 748.0, B04 is 573.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '2', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '2', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'PID', 'is', '', '3', '0']]\n",
      "decoded_data: ['PID is 6268.0, DOY is 211.0, B03 is 748.0, B04 is 573.0, B02 is 330.0 B03 is PID is 30']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 573.0, PID is 6268.0, B03 is 748.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 573.0, PID is 6268.0, B03 is 748.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['B04 is 573.0, PID is 6268.0, B03 is 748.0, DOY is 211.0, B02 is 330.0 B03 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 748.0, PID is 6268.0, DOY is 211.0, B04 is 573.0, B02 is']\n",
      "prompt: B03 is 748.0, PID is 6268.0, DOY is 211.0, B04 is 573.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '4', '8', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '4', '8', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '3', '0', '5', '4', '3', '0', '.', '0', '6']]\n",
      "decoded_data: ['B03 is 748.0, PID is 6268.0, DOY is 211.0, B04 is 573.0, B02 is 330.0305430.06']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6268.0, DOY is 211.0, B03 is 748.0, B04 is 573.0, B02 is']\n",
      "prompt: PID is 6268.0, DOY is 211.0, B03 is 748.0, B04 is 573.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '2', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'B02', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 19%|        | 155/829 [04:39<21:37,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '6', '2', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'B04', 'is', '', '3', '0']]\n",
      "decoded_data: ['PID is 6268.0, DOY is 211.0, B03 is 748.0, B04 is 573.0, B02 is 330.0 B03 is B04 is 30']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6368.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 6368.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '3', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '3', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '3', '.', '0', ',', '']]\n",
      "decoded_data: ['PID is 6368.0, DOY is 211.0, B04 is 540.0, B03 is 714.0, B02 is 310.0 B04 is 3.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 540.0, PID is 6368.0, B03 is 714.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 540.0, PID is 6368.0, B03 is 714.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '4', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '4', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '3', '0', '0', '2', '8', '0', '0', ',']]\n",
      "decoded_data: ['B04 is 540.0, PID is 6368.0, B03 is 714.0, DOY is 211.0, B02 is 310.0 3002800,']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 714.0, PID is 6368.0, B04 is 540.0, B02 is']\n",
      "prompt: DOY is 211.0, B03 is 714.0, PID is 6368.0, B04 is 540.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '4', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '0', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '4', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '5', '9']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 714.0, PID is 6368.0, B04 is 540.0, B02 is 310.0 PID is B04 is 59']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 714.0, B04 is 540.0, PID is 6368.0, DOY is 211.0, B02 is']\n",
      "prompt: B03 is 714.0, B04 is 540.0, PID is 6368.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '1', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '1', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '3', '0', '2', '3', '0']]\n",
      "decoded_data: ['B03 is 714.0, B04 is 540.0, PID is 6368.0, DOY is 211.0, B02 is 310.0 PID is 30230']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 714.0, PID is 6368.0, B04 is 540.0, DOY is 211.0, B02 is']\n",
      "prompt: B03 is 714.0, PID is 6368.0, B04 is 540.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '1', '4', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '1', '4', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '3', '0', '2', '3', '0']]\n",
      "decoded_data: ['B03 is 714.0, PID is 6368.0, B04 is 540.0, DOY is 211.0, B02 is 310.0 B04 is 30230']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 714.0, PID is 6368.0, B04 is 540.0, B02 is']\n",
      "prompt: DOY is 211.0, B03 is 714.0, PID is 6368.0, B04 is 540.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '4', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '0', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '4', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '3', '0', '2', 'B03', 'is', '', 'PID', 'is', '']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 714.0, PID is 6368.0, B04 is 540.0, B02 is 310.0302B03 is PID is ']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 540.0, PID is 6368.0, DOY is 211.0, B03 is 714.0, B02 is']\n",
      "prompt: B04 is 540.0, PID is 6368.0, DOY is 211.0, B03 is 714.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '4', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '4', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '4', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '3', '0', '0', ',', '']]\n",
      "decoded_data: ['B04 is 540.0, PID is 6368.0, DOY is 211.0, B03 is 714.0, B02 is 310.0 PID is 300, ']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 714.0, B04 is 540.0, PID is 6368.0, DOY is 211.0, B02 is']\n",
      "prompt: B03 is 714.0, B04 is 540.0, PID is 6368.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '1', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '1', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '3', '0', ',', '', 'B04', 'is', '', '3']]\n",
      "decoded_data: ['B03 is 714.0, B04 is 540.0, PID is 6368.0, DOY is 211.0, B02 is 310.0 30, B04 is 3']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 540.0, PID is 6368.0, B03 is 714.0, B02 is']\n",
      "prompt: DOY is 211.0, B04 is 540.0, PID is 6368.0, B03 is 714.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '4', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '3', '0']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 540.0, PID is 6368.0, B03 is 714.0, B02 is 310.0 PID is B04 is 30']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 540.0, B03 is 714.0, PID is 6368.0, B02 is']\n",
      "prompt: DOY is 211.0, B04 is 540.0, B03 is 714.0, PID is 6368.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '4', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '8', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '4', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'PID', 'is', '', '7', '6']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 540.0, B03 is 714.0, PID is 6368.0, B02 is 310.0 B03 is PID is 76']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 540.0, DOY is 211.0, PID is 6368.0, B03 is 714.0, B02 is']\n",
      "prompt: B04 is 540.0, DOY is 211.0, PID is 6368.0, B03 is 714.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '4', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '4', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '4', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', '3', '0', '2', '6', '4']]\n",
      "decoded_data: ['B04 is 540.0, DOY is 211.0, PID is 6368.0, B03 is 714.0, B02 is 310.0 B03 is 30264']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 540.0, PID is 6368.0, B03 is 714.0, B02 is']\n",
      "prompt: DOY is 211.0, B04 is 540.0, PID is 6368.0, B03 is 714.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '4', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B03', 'is', '', '7', '6']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 540.0, PID is 6368.0, B03 is 714.0, B02 is 310.0 PID is B03 is 76']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 540.0, PID is 6368.0, B03 is 714.0, B02 is']\n",
      "prompt: DOY is 211.0, B04 is 540.0, PID is 6368.0, B03 is 714.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '4', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', 'B03', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 540.0, PID is 6368.0, B03 is 714.0, B02 is 310.0 PID is B04 is B03 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6368.0, B04 is 540.0, DOY is 211.0, B03 is 714.0, B02 is']\n",
      "prompt: PID is 6368.0, B04 is 540.0, DOY is 211.0, B03 is 714.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '3', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '4', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '3', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B03', 'is', '', '3', '1']]\n",
      "decoded_data: ['PID is 6368.0, B04 is 540.0, DOY is 211.0, B03 is 714.0, B02 is 310.0 B04 is B03 is 31']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6368.0, B03 is 714.0, B04 is 540.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 6368.0, B03 is 714.0, B04 is 540.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '0', '.', '0', ',', '', 'B02', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 19%|        | 156/829 [04:42<23:07,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '3', '1', '0', '2', '3', '.', '0', ',']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6368.0, B03 is 714.0, B04 is 540.0, B02 is 310.0 31023.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6468.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 6468.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '3', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '3', '2', '3', '2', '3', '2', '3', '2', '.']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6468.0, B03 is 676.0, B04 is 503.0, B02 is 300.032323232.']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6468.0, DOY is 211.0, B03 is 676.0, B04 is 503.0, B02 is']\n",
      "prompt: PID is 6468.0, DOY is 211.0, B03 is 676.0, B04 is 503.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '4', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '3', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '4', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '3', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '3', '0', '0', '6', '.', '0', '0', '0', '0']]\n",
      "decoded_data: ['PID is 6468.0, DOY is 211.0, B03 is 676.0, B04 is 503.0, B02 is 300.03006.0000']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6468.0, B04 is 503.0, DOY is 211.0, B03 is 676.0, B02 is']\n",
      "prompt: PID is 6468.0, B04 is 503.0, DOY is 211.0, B03 is 676.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '4', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '6', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '4', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B03', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['PID is 6468.0, B04 is 503.0, DOY is 211.0, B03 is 676.0, B02 is 300.0 B04 is B03 is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 676.0, B04 is 503.0, PID is 6468.0, DOY is 211.0, B02 is']\n",
      "prompt: B03 is 676.0, B04 is 503.0, PID is 6468.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '7', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '3', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '6', '7', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '3', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B03', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['B03 is 676.0, B04 is 503.0, PID is 6468.0, DOY is 211.0, B02 is 300.0 B04 is B03 is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 503.0, PID is 6468.0, B03 is 676.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 503.0, PID is 6468.0, B03 is 676.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '0', '3', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '0', '3', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'B04', 'is', '', 'B03', 'is']]\n",
      "decoded_data: ['B04 is 503.0, PID is 6468.0, B03 is 676.0, DOY is 211.0, B02 is 300.0 B03 is B04 is B03 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 503.0, DOY is 211.0, PID is 6468.0, B03 is 676.0, B02 is']\n",
      "prompt: B04 is 503.0, DOY is 211.0, PID is 6468.0, B03 is 676.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '0', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '6', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '0', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '3', '0', '0', '0', '0']]\n",
      "decoded_data: ['B04 is 503.0, DOY is 211.0, PID is 6468.0, B03 is 676.0, B02 is 300.0 PID is 30000']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 503.0, PID is 6468.0, B03 is 676.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 503.0, PID is 6468.0, B03 is 676.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '0', '3', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|        | 157/829 [04:43<20:13,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B04', 'is', '', '5', '0', '3', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '3', '0', '0', '0', '0', '0', '0', '0', '0']]\n",
      "decoded_data: ['B04 is 503.0, PID is 6468.0, B03 is 676.0, DOY is 211.0, B02 is 300.0300000000']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6568.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 6568.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '5', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '5', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '9', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '2', '0', '0', '1', '0', '1', '0', '1']]\n",
      "decoded_data: ['PID is 6568.0, DOY is 211.0, B04 is 459.0, B03 is 699.0, B02 is 301.0 20010101']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 459.0, DOY is 211.0, B03 is 699.0, PID is 6568.0, B02 is']\n",
      "prompt: B04 is 459.0, DOY is 211.0, B03 is 699.0, PID is 6568.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '5', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '8', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '5', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '3', '0', '1', '4', '0']]\n",
      "decoded_data: ['B04 is 459.0, DOY is 211.0, B03 is 699.0, PID is 6568.0, B02 is 301.0 PID is 30140']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 699.0, PID is 6568.0, B04 is 459.0, B02 is']\n",
      "prompt: DOY is 211.0, B03 is 699.0, PID is 6568.0, B04 is 459.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '9', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '4', '8', '0', '1', '.', '0', ',', '', 'PID']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 699.0, PID is 6568.0, B04 is 459.0, B02 is 301.04801.0, PID']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 699.0, B04 is 459.0, PID is 6568.0, B02 is']\n",
      "prompt: DOY is 211.0, B03 is 699.0, B04 is 459.0, PID is 6568.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '9', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '8', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '9', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'DOY', 'is', '', '3', '0']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 699.0, B04 is 459.0, PID is 6568.0, B02 is 301.0 B04 is DOY is 30']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 699.0, DOY is 211.0, B04 is 459.0, PID is 6568.0, B02 is']\n",
      "prompt: B03 is 699.0, DOY is 211.0, B04 is 459.0, PID is 6568.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '9', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '8', '.', '0', ',', '', 'B02', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|        | 158/829 [04:44<17:41,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B03', 'is', '', '6', '9', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '5', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '0', '1', '4', '0', '1', '.', '0', '2', '0']]\n",
      "decoded_data: ['B03 is 699.0, DOY is 211.0, B04 is 459.0, PID is 6568.0, B02 is 305.001401.020']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 459.0, DOY is 211.0, B03 is 699.0, PID is 6568.0, B02 is']\n",
      "prompt: B04 is 459.0, DOY is 211.0, B03 is 699.0, PID is 6568.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '5', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '8', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '5', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '8', '0', ',', '', 'B03', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['B04 is 459.0, DOY is 211.0, B03 is 699.0, PID is 6568.0, B02 is 301.080, B03 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6668.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 6668.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '8', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '2', '3', '.', '0', '3', '.', '0', ',']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6668.0, B04 is 508.0, B02 is 315.0, B03 is 723.0723.03.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 508.0, DOY is 211.0, PID is 6668.0, B02 is 315.0, B03 is']\n",
      "prompt: B04 is 508.0, DOY is 211.0, PID is 6668.0, B02 is 315.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '0', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '5', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '0', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '2', '3', '.', '0']]\n",
      "decoded_data: ['B04 is 508.0, DOY is 211.0, PID is 6668.0, B02 is 315.0, B03 is 723.0 PID is 723.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 315.0, PID is 6668.0, DOY is 211.0, B04 is 508.0, B03 is']\n",
      "prompt: B02 is 315.0, PID is 6668.0, DOY is 211.0, B04 is 508.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '1', '5', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '1', '5', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '2', '3', '4', '3', '.', '0', ',', '']]\n",
      "decoded_data: ['B02 is 315.0, PID is 6668.0, DOY is 211.0, B04 is 508.0, B03 is 723.072343.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 315.0, B04 is 508.0, DOY is 211.0, PID is 6668.0, B03 is']\n",
      "prompt: B02 is 315.0, B04 is 508.0, DOY is 211.0, PID is 6668.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '1', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '1', '5', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '0', '1', '2', '3', '.', '0', ',', '']]\n",
      "decoded_data: ['B02 is 315.0, B04 is 508.0, DOY is 211.0, PID is 6668.0, B03 is 723.070123.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 508.0, PID is 6668.0, B02 is 315.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 508.0, PID is 6668.0, B02 is 315.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '0', '8', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|        | 159/829 [04:45<15:27,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B04', 'is', '', '5', '0', '8', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '6', '0', '3', '0', '0', '3', '9', '2']]\n",
      "decoded_data: ['B04 is 508.0, PID is 6668.0, B02 is 315.0, DOY is 211.0, B03 is 723.0760300392']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6768.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 6768.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '8', '.', '0', ',', '', 'B04', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|        | 160/829 [04:45<12:17,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '3', '0']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6768.0, B04 is 580.0, B03 is 720.0, B02 is 330.0 B04 is PID is 30']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 720.0, PID is 6768.0, B04 is 580.0, DOY is 211.0, B02 is']\n",
      "prompt: B03 is 720.0, PID is 6768.0, B04 is 580.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '2', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '2', '0', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '3', '0', '1', '0', '0', '1', '0', '2', '3']]\n",
      "decoded_data: ['B03 is 720.0, PID is 6768.0, B04 is 580.0, DOY is 211.0, B02 is 330.0301001023']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6868.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 6868.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '8', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '8', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B03', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['PID is 6868.0, DOY is 211.0, B04 is 557.0, B03 is 697.0, B02 is 317.0 B04 is B03 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 697.0, B04 is 557.0, DOY is 211.0, PID is 6868.0, B02 is']\n",
      "prompt: B03 is 697.0, B04 is 557.0, DOY is 211.0, PID is 6868.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '9', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '8', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '6', '9', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '3', '4']]\n",
      "decoded_data: ['B03 is 697.0, B04 is 557.0, DOY is 211.0, PID is 6868.0, B02 is 317.0 B04 is PID is 34']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 697.0, PID is 6868.0, B04 is 557.0, B02 is']\n",
      "prompt: DOY is 211.0, B03 is 697.0, PID is 6868.0, B04 is 557.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '5', '1']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 697.0, PID is 6868.0, B04 is 557.0, B02 is 317.0 PID is B04 is 51']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 557.0, DOY is 211.0, B03 is 697.0, PID is 6868.0, B02 is']\n",
      "prompt: B04 is 557.0, DOY is 211.0, B03 is 697.0, PID is 6868.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '5', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '8', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '5', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '3', '1', '7', '4', '3']]\n",
      "decoded_data: ['B04 is 557.0, DOY is 211.0, B03 is 697.0, PID is 6868.0, B02 is 317.0 PID is 31743']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6868.0, B04 is 557.0, B03 is 697.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 6868.0, B04 is 557.0, B03 is 697.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '3', '1', '7', '4', '1', '.', '0', ',']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6868.0, B04 is 557.0, B03 is 697.0, B02 is 317.0 31741.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 697.0, B04 is 557.0, DOY is 211.0, PID is 6868.0, B02 is']\n",
      "prompt: B03 is 697.0, B04 is 557.0, DOY is 211.0, PID is 6868.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '9', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '8', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '6', '9', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '1', '7', '4', '3']]\n",
      "decoded_data: ['B03 is 697.0, B04 is 557.0, DOY is 211.0, PID is 6868.0, B02 is 317.0 B04 is 51743']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 557.0, B03 is 697.0, PID is 6868.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 557.0, B03 is 697.0, PID is 6868.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '5', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '5', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '3', '4', '3', '1', '7']]\n",
      "decoded_data: ['B04 is 557.0, B03 is 697.0, PID is 6868.0, DOY is 211.0, B02 is 317.0 PID is 34317']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6868.0, DOY is 211.0, B03 is 697.0, B04 is 557.0, B02 is']\n",
      "prompt: PID is 6868.0, DOY is 211.0, B03 is 697.0, B04 is 557.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '8', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '8', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B02', 'is', '', '3', '.']]\n",
      "decoded_data: ['PID is 6868.0, DOY is 211.0, B03 is 697.0, B04 is 557.0, B02 is 317.0 B04 is B02 is 3.']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 557.0, PID is 6868.0, B03 is 697.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 557.0, PID is 6868.0, B03 is 697.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '5', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '5', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '3', '1', '7', '4', '3', '.', '0', '7']]\n",
      "decoded_data: ['B04 is 557.0, PID is 6868.0, B03 is 697.0, DOY is 211.0, B02 is 317.0 31743.07']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6868.0, B04 is 557.0, DOY is 211.0, B03 is 697.0, B02 is']\n",
      "prompt: PID is 6868.0, B04 is 557.0, DOY is 211.0, B03 is 697.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '8', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '8', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B03', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['PID is 6868.0, B04 is 557.0, DOY is 211.0, B03 is 697.0, B02 is 317.0 B04 is B03 is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 697.0, PID is 6868.0, B04 is 557.0, B02 is']\n",
      "prompt: DOY is 211.0, B03 is 697.0, PID is 6868.0, B04 is 557.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '5', '1']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 697.0, PID is 6868.0, B04 is 557.0, B02 is 317.0 PID is B04 is 51']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 557.0, B03 is 697.0, PID is 6868.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 557.0, B03 is 697.0, PID is 6868.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '5', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '5', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '7', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '3', '.', '0', ',', '', 'PID', 'is', '']]\n",
      "decoded_data: ['B04 is 557.0, B03 is 697.0, PID is 6868.0, DOY is 211.0, B02 is 317.0 3.0, PID is ']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6868.0, B03 is 697.0, DOY is 211.0, B04 is 557.0, B02 is']\n",
      "prompt: PID is 6868.0, B03 is 697.0, DOY is 211.0, B04 is 557.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '8', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '8', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '5', '5']]\n",
      "decoded_data: ['PID is 6868.0, B03 is 697.0, DOY is 211.0, B04 is 557.0, B02 is 317.0 PID is B04 is 55']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6868.0, DOY is 211.0, B03 is 697.0, B04 is 557.0, B02 is']\n",
      "prompt: PID is 6868.0, DOY is 211.0, B03 is 697.0, B04 is 557.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '8', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '8', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '1', '7', '4', '3']]\n",
      "decoded_data: ['PID is 6868.0, DOY is 211.0, B03 is 697.0, B04 is 557.0, B02 is 317.0 B04 is 51743']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6868.0, B04 is 557.0, B03 is 697.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 6868.0, B04 is 557.0, B03 is 697.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '7', '.', '0', ',', '', 'B02', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 19%|        | 161/829 [04:47<16:12,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '7', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '3', '1']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6868.0, B04 is 557.0, B03 is 697.0, B02 is 317.0 B04 is PID is 31']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6968.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 6968.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '9', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '9', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'DOY', 'is', '', 'PID', 'is', '', '5', '3']]\n",
      "decoded_data: ['PID is 6968.0, DOY is 211.0, B02 is 311.0, B03 is 691.0, B04 is 525.0 DOY is PID is 53']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6968.0, B02 is 311.0, DOY is 211.0, B03 is 691.0, B04 is']\n",
      "prompt: PID is 6968.0, B02 is 311.0, DOY is 211.0, B03 is 691.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '9', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '9', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B03', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['PID is 6968.0, B02 is 311.0, DOY is 211.0, B03 is 691.0, B04 is 525.0 PID is B03 is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 691.0, B02 is 311.0, PID is 6968.0, DOY is 211.0, B04 is']\n",
      "prompt: B03 is 691.0, B02 is 311.0, PID is 6968.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '3', '9', '5', '5']]\n",
      "decoded_data: ['B03 is 691.0, B02 is 311.0, PID is 6968.0, DOY is 211.0, B04 is 525.0 PID is 53955']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 691.0, DOY is 211.0, B02 is 311.0, PID is 6968.0, B04 is']\n",
      "prompt: B03 is 691.0, DOY is 211.0, B02 is 311.0, PID is 6968.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '8', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'DOY', 'is', '', '5', '3']]\n",
      "decoded_data: ['B03 is 691.0, DOY is 211.0, B02 is 311.0, PID is 6968.0, B04 is 525.0 PID is DOY is 53']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 311.0, B03 is 691.0, PID is 6968.0, DOY is 211.0, B04 is']\n",
      "prompt: B02 is 311.0, B03 is 691.0, PID is 6968.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '3', '0', '5', '2', '5', '3', '0']]\n",
      "decoded_data: ['B02 is 311.0, B03 is 691.0, PID is 6968.0, DOY is 211.0, B04 is 525.0 53052530']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6968.0, B03 is 691.0, B02 is 311.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 6968.0, B03 is 691.0, B02 is 311.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '9', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '9', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '2', '5', '2', '5']]\n",
      "decoded_data: ['PID is 6968.0, B03 is 691.0, B02 is 311.0, DOY is 211.0, B04 is 525.0 PID is 52525']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6968.0, B02 is 311.0, DOY is 211.0, B03 is 691.0, B04 is']\n",
      "prompt: PID is 6968.0, B02 is 311.0, DOY is 211.0, B03 is 691.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '9', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '9', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '6', '9', '2', '5', '6', '9', '2']]\n",
      "decoded_data: ['PID is 6968.0, B02 is 311.0, DOY is 211.0, B03 is 691.0, B04 is 525.0 56925692']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 311.0, B03 is 691.0, PID is 6968.0, B04 is']\n",
      "prompt: DOY is 211.0, B02 is 311.0, B03 is 691.0, PID is 6968.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '8', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B02', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 311.0, B03 is 691.0, PID is 6968.0, B04 is 525.0 PID is B02 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6968.0, DOY is 211.0, B02 is 311.0, B03 is 691.0, B04 is']\n",
      "prompt: PID is 6968.0, DOY is 211.0, B02 is 311.0, B03 is 691.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '9', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '9', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '3', '4', '0', '9']]\n",
      "decoded_data: ['PID is 6968.0, DOY is 211.0, B02 is 311.0, B03 is 691.0, B04 is 525.0 PID is 53409']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 691.0, PID is 6968.0, B02 is 311.0, B04 is']\n",
      "prompt: DOY is 211.0, B03 is 691.0, PID is 6968.0, B02 is 311.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '2', '5', '3', '5']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 691.0, PID is 6968.0, B02 is 311.0, B04 is 525.0 PID is 52535']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 691.0, B02 is 311.0, PID is 6968.0, DOY is 211.0, B04 is']\n",
      "prompt: B03 is 691.0, B02 is 311.0, PID is 6968.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '5', '3', '4', '0']]\n",
      "decoded_data: ['B03 is 691.0, B02 is 311.0, PID is 6968.0, DOY is 211.0, B04 is 525.0 PID is 55340']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 691.0, B02 is 311.0, DOY is 211.0, PID is 6968.0, B04 is']\n",
      "prompt: B03 is 691.0, B02 is 311.0, DOY is 211.0, PID is 6968.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '8', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B02', 'is', '', 'DOY', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['B03 is 691.0, B02 is 311.0, DOY is 211.0, PID is 6968.0, B04 is 525.0 B02 is DOY is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 691.0, B02 is 311.0, PID is 6968.0, DOY is 211.0, B04 is']\n",
      "prompt: B03 is 691.0, B02 is 311.0, PID is 6968.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B02', 'is', '', '5', '8']]\n",
      "decoded_data: ['B03 is 691.0, B02 is 311.0, PID is 6968.0, DOY is 211.0, B04 is 525.0 PID is B02 is 58']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 691.0, PID is 6968.0, DOY is 211.0, B02 is 311.0, B04 is']\n",
      "prompt: B03 is 691.0, PID is 6968.0, DOY is 211.0, B02 is 311.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '9', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '2', '5', '8', '5']]\n",
      "decoded_data: ['B03 is 691.0, PID is 6968.0, DOY is 211.0, B02 is 311.0, B04 is 525.0 PID is 52585']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6968.0, B03 is 691.0, DOY is 211.0, B02 is 311.0, B04 is']\n",
      "prompt: PID is 6968.0, B03 is 691.0, DOY is 211.0, B02 is 311.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '9', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '1', '.', '0', ',', '', 'B04', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 20%|        | 162/829 [04:50<18:52,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '6', '9', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '8', '5', '3', '5', '8', '5', '8']]\n",
      "decoded_data: ['PID is 6968.0, B03 is 691.0, DOY is 211.0, B02 is 311.0, B04 is 525.0 58535858']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7068.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 7068.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '0', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '0', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '0', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '5', '9']]\n",
      "decoded_data: ['PID is 7068.0, DOY is 211.0, B02 is 331.0, B04 is 560.0, B03 is 693.0 PID is B04 is 59']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7068.0, B02 is 331.0, DOY is 211.0, B04 is 560.0, B03 is']\n",
      "prompt: PID is 7068.0, B02 is 331.0, DOY is 211.0, B04 is 560.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '0', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '0', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '0', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '0', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', '6', '4', '4', '4', '4']]\n",
      "decoded_data: ['PID is 7068.0, B02 is 331.0, DOY is 211.0, B04 is 560.0, B03 is 693.0 B03 is 64444']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 331.0, PID is 7068.0, DOY is 211.0, B04 is 560.0, B03 is']\n",
      "prompt: B02 is 331.0, PID is 7068.0, DOY is 211.0, B04 is 560.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '0', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '0', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'DOY', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['B02 is 331.0, PID is 7068.0, DOY is 211.0, B04 is 560.0, B03 is 693.0 B04 is DOY is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 560.0, PID is 7068.0, DOY is 211.0, B02 is 331.0, B03 is']\n",
      "prompt: B04 is 560.0, PID is 7068.0, DOY is 211.0, B02 is 331.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '6', '0', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '6', '0', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '6', '4']]\n",
      "decoded_data: ['B04 is 560.0, PID is 7068.0, DOY is 211.0, B02 is 331.0, B03 is 693.0 B04 is PID is 64']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 560.0, B02 is 331.0, PID is 7068.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 560.0, B02 is 331.0, PID is 7068.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', '6', '4', '4', '4', '.']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 560.0, B02 is 331.0, PID is 7068.0, B03 is 693.0 B03 is 6444.']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 560.0, B02 is 331.0, DOY is 211.0, PID is 7068.0, B03 is']\n",
      "prompt: B04 is 560.0, B02 is 331.0, DOY is 211.0, PID is 7068.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '6', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '6', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '3', '8', '9', '3']]\n",
      "decoded_data: ['B04 is 560.0, B02 is 331.0, DOY is 211.0, PID is 7068.0, B03 is 693.0 B04 is 53893']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 560.0, PID is 7068.0, B02 is 331.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 560.0, PID is 7068.0, B02 is 331.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '0', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '0', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '6', '4', '4', '4', '4', '4', '4', '4']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 560.0, PID is 7068.0, B02 is 331.0, B03 is 693.0 64444444']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 331.0, DOY is 211.0, B04 is 560.0, PID is 7068.0, B03 is']\n",
      "prompt: B02 is 331.0, DOY is 211.0, B04 is 560.0, PID is 7068.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '0', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '0', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', '6', '4', '4', '4', '4']]\n",
      "decoded_data: ['B02 is 331.0, DOY is 211.0, B04 is 560.0, PID is 7068.0, B03 is 693.0 B03 is 64444']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 560.0, B02 is 331.0, PID is 7068.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 560.0, B02 is 331.0, PID is 7068.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B03', 'is', '', '6', '9']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 560.0, B02 is 331.0, PID is 7068.0, B03 is 693.0 PID is B03 is 69']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 331.0, B04 is 560.0, PID is 7068.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 331.0, B04 is 560.0, PID is 7068.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '0', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '0', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '6', '4']]\n",
      "decoded_data: ['B02 is 331.0, B04 is 560.0, PID is 7068.0, DOY is 211.0, B03 is 693.0 B04 is PID is 64']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7068.0, B02 is 331.0, DOY is 211.0, B04 is 560.0, B03 is']\n",
      "prompt: PID is 7068.0, B02 is 331.0, DOY is 211.0, B04 is 560.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '0', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '0', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 163/829 [04:52<19:26,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '7', '0', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '0', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '1', '4', '4', '4', '4', '4', '4', '4']]\n",
      "decoded_data: ['PID is 7068.0, B02 is 331.0, DOY is 211.0, B04 is 560.0, B03 is 693.0714444444']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 7168.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 7168.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '8', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '9', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '6', '4']]\n",
      "decoded_data: ['DOY is 211.0, PID is 7168.0, B02 is 330.0, B04 is 539.0, B03 is 687.0 PID is B04 is 64']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 539.0, DOY is 211.0, B02 is 330.0, PID is 7168.0, B03 is']\n",
      "prompt: B04 is 539.0, DOY is 211.0, B02 is 330.0, PID is 7168.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '3', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '0', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '3', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '0', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '2', '8', '7', '3']]\n",
      "decoded_data: ['B04 is 539.0, DOY is 211.0, B02 is 330.0, PID is 7168.0, B03 is 687.0 PID is 72873']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 539.0, B02 is 330.0, PID is 7168.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 539.0, B02 is 330.0, PID is 7168.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '0', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '0', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '6', '2', '3', '8', '7']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 539.0, B02 is 330.0, PID is 7168.0, B03 is 687.0 PID is 62387']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7168.0, DOY is 211.0, B02 is 330.0, B04 is 539.0, B03 is']\n",
      "prompt: PID is 7168.0, DOY is 211.0, B02 is 330.0, B04 is 539.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '1', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '9', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '1', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '9', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '6', '2']]\n",
      "decoded_data: ['PID is 7168.0, DOY is 211.0, B02 is 330.0, B04 is 539.0, B03 is 687.0 PID is B04 is 62']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7168.0, B04 is 539.0, B02 is 330.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 7168.0, B04 is 539.0, B02 is 330.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '1', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '1', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '6', '2', '.', '0', '5', '3', '2', '3']]\n",
      "decoded_data: ['PID is 7168.0, B04 is 539.0, B02 is 330.0, DOY is 211.0, B03 is 687.0 62.05323']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 330.0, B04 is 539.0, PID is 7168.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 330.0, B04 is 539.0, PID is 7168.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '3', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '9', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '3', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '9', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '6', '2', '3', '8', '7']]\n",
      "decoded_data: ['B02 is 330.0, B04 is 539.0, PID is 7168.0, DOY is 211.0, B03 is 687.0 PID is 62387']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 539.0, PID is 7168.0, B02 is 330.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 539.0, PID is 7168.0, B02 is 330.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '3', '9', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '3', '9', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '6', '4']]\n",
      "decoded_data: ['B04 is 539.0, PID is 7168.0, B02 is 330.0, DOY is 211.0, B03 is 687.0 PID is B04 is 64']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7168.0, DOY is 211.0, B02 is 330.0, B04 is 539.0, B03 is']\n",
      "prompt: PID is 7168.0, DOY is 211.0, B02 is 330.0, B04 is 539.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '1', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '9', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '1', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '9', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '6', '0', '5', '3', '8']]\n",
      "decoded_data: ['PID is 7168.0, DOY is 211.0, B02 is 330.0, B04 is 539.0, B03 is 687.0 PID is 60538']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 330.0, PID is 7168.0, B04 is 539.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 330.0, PID is 7168.0, B04 is 539.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '3', '0', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '3', '0', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '4']]\n",
      "decoded_data: ['B02 is 330.0, PID is 7168.0, B04 is 539.0, DOY is 211.0, B03 is 687.0 B04 is PID is 74']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7168.0, DOY is 211.0, B04 is 539.0, B02 is 330.0, B03 is']\n",
      "prompt: PID is 7168.0, DOY is 211.0, B04 is 539.0, B02 is 330.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '1', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '0', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '1', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '0', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '6', '2', '.', '0', '5']]\n",
      "decoded_data: ['PID is 7168.0, DOY is 211.0, B04 is 539.0, B02 is 330.0, B03 is 687.0 B04 is 62.05']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 330.0, DOY is 211.0, PID is 7168.0, B04 is 539.0, B03 is']\n",
      "prompt: B02 is 330.0, DOY is 211.0, PID is 7168.0, B04 is 539.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '3', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '9', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '3', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '9', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '4', '7', '4', '7']]\n",
      "decoded_data: ['B02 is 330.0, DOY is 211.0, PID is 7168.0, B04 is 539.0, B03 is 687.0 PID is 74747']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7168.0, B04 is 539.0, B02 is 330.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 7168.0, B04 is 539.0, B02 is 330.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '1', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '1', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['PID is 7168.0, B04 is 539.0, B02 is 330.0, DOY is 211.0, B03 is 687.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 330.0, PID is 7168.0, B04 is 539.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 330.0, PID is 7168.0, B04 is 539.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '3', '0', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '3', '0', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '6', '8']]\n",
      "decoded_data: ['B02 is 330.0, PID is 7168.0, B04 is 539.0, DOY is 211.0, B03 is 687.0 B04 is PID is 68']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 7168.0, B02 is 330.0, B04 is 539.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 7168.0, B02 is 330.0, B04 is 539.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '9', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '9', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '5', '3']]\n",
      "decoded_data: ['DOY is 211.0, PID is 7168.0, B02 is 330.0, B04 is 539.0, B03 is 687.0 PID is B04 is 53']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 539.0, B02 is 330.0, DOY is 211.0, PID is 7168.0, B03 is']\n",
      "prompt: B04 is 539.0, B02 is 330.0, DOY is 211.0, PID is 7168.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '3', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '8', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 20%|        | 164/829 [04:54<21:31,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B04', 'is', '', '5', '3', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['B04 is 539.0, B02 is 330.0, DOY is 211.0, PID is 7168.0, B03 is 687.0 B04 is PID is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 7268.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 7268.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '2', '6', '8', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '2', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '2', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '5', '4']]\n",
      "decoded_data: ['DOY is 211.0, PID is 7268.0, B02 is 342.0, B04 is 554.0, B03 is 701.0 B04 is PID is 54']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 554.0, PID is 7268.0, B02 is 342.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 554.0, PID is 7268.0, B02 is 342.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '5', '4', '.', '0', ',', '', 'PID', 'is', '', '7', '2', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '5', '4', '.', '0', ',', '', 'PID', 'is', '', '7', '2', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '7', '0']]\n",
      "decoded_data: ['B04 is 554.0, PID is 7268.0, B02 is 342.0, DOY is 211.0, B03 is 701.0 PID is B04 is 70']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7268.0, DOY is 211.0, B04 is 554.0, B02 is 342.0, B03 is']\n",
      "prompt: PID is 7268.0, DOY is 211.0, B04 is 554.0, B02 is 342.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '2', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '2', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['PID is 7268.0, DOY is 211.0, B04 is 554.0, B02 is 342.0, B03 is 701.0 B04 is B04 is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 554.0, DOY is 211.0, B02 is 342.0, PID is 7268.0, B03 is']\n",
      "prompt: B04 is 554.0, DOY is 211.0, B02 is 342.0, PID is 7268.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '2', '6', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '2', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B02', 'is', '', 'B04', 'is', '', 'DOY', 'is']]\n",
      "decoded_data: ['B04 is 554.0, DOY is 211.0, B02 is 342.0, PID is 7268.0, B03 is 701.0 B02 is B04 is DOY is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 7268.0, B04 is 554.0, B02 is 342.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 7268.0, B04 is 554.0, B02 is 342.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '2', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '2', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['DOY is 211.0, PID is 7268.0, B04 is 554.0, B02 is 342.0, B03 is 701.0 B04 is B04 is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7268.0, B04 is 554.0, DOY is 211.0, B02 is 342.0, B03 is']\n",
      "prompt: PID is 7268.0, B04 is 554.0, DOY is 211.0, B02 is 342.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '2', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '2', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', '5', '4']]\n",
      "decoded_data: ['PID is 7268.0, B04 is 554.0, DOY is 211.0, B02 is 342.0, B03 is 701.0 B04 is B04 is 54']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 554.0, DOY is 211.0, B02 is 342.0, PID is 7268.0, B03 is']\n",
      "prompt: B04 is 554.0, DOY is 211.0, B02 is 342.0, PID is 7268.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '2', '6', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '2', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '7', '0']]\n",
      "decoded_data: ['B04 is 554.0, DOY is 211.0, B02 is 342.0, PID is 7268.0, B03 is 701.0 PID is B04 is 70']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 342.0, B04 is 554.0, PID is 7268.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 342.0, B04 is 554.0, PID is 7268.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '4', '2', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '4', '.', '0', ',', '', 'PID', 'is', '', '7', '2', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '4', '2', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '4', '.', '0', ',', '', 'PID', 'is', '', '7', '2', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '0', '1', '7', '1']]\n",
      "decoded_data: ['B02 is 342.0, B04 is 554.0, PID is 7268.0, DOY is 211.0, B03 is 701.0 PID is 70171']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7268.0, B04 is 554.0, B02 is 342.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 7268.0, B04 is 554.0, B02 is 342.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '2', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '2', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '0']]\n",
      "decoded_data: ['PID is 7268.0, B04 is 554.0, B02 is 342.0, DOY is 211.0, B03 is 701.0 B04 is PID is 70']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 554.0, B02 is 342.0, PID is 7268.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 554.0, B02 is 342.0, PID is 7268.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '5', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '2', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '5', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '2', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '7', '0', '1', '.', '0']]\n",
      "decoded_data: ['B04 is 554.0, B02 is 342.0, PID is 7268.0, DOY is 211.0, B03 is 701.0 B04 is 701.0']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 342.0, PID is 7268.0, B04 is 554.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 342.0, PID is 7268.0, B04 is 554.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '2', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '2', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '4', '2', '2', '.']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 342.0, PID is 7268.0, B04 is 554.0, B03 is 701.0 B04 is 5422.']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 342.0, B04 is 554.0, PID is 7268.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 342.0, B04 is 554.0, PID is 7268.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '2', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '4', '.', '0', ',', '', 'PID', 'is', '', '7', '2', '6', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '2', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '4', '.', '0', ',', '', 'PID', 'is', '', '7', '2', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '7', '0', '1', '1', '4', '9', '0', '1']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 342.0, B04 is 554.0, PID is 7268.0, B03 is 701.0 70114901']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 342.0, B04 is 554.0, DOY is 211.0, PID is 7268.0, B03 is']\n",
      "prompt: B02 is 342.0, B04 is 554.0, DOY is 211.0, PID is 7268.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '4', '2', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '2', '6', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '4', '2', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '2', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '0']]\n",
      "decoded_data: ['B02 is 342.0, B04 is 554.0, DOY is 211.0, PID is 7268.0, B03 is 701.0 B04 is PID is 70']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7268.0, DOY is 211.0, B02 is 342.0, B04 is 554.0, B03 is']\n",
      "prompt: PID is 7268.0, DOY is 211.0, B02 is 342.0, B04 is 554.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '2', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '2', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '2', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '2', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '7', '1', '7', '0', '1', '1', '1', '1']]\n",
      "decoded_data: ['PID is 7268.0, DOY is 211.0, B02 is 342.0, B04 is 554.0, B03 is 701.0 71701111']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 554.0, B02 is 342.0, PID is 7268.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 554.0, B02 is 342.0, PID is 7268.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '5', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '2', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 20%|        | 165/829 [04:56<23:00,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B04', 'is', '', '5', '5', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '2', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '0', '1', '1', '1']]\n",
      "decoded_data: ['B04 is 554.0, B02 is 342.0, PID is 7268.0, DOY is 211.0, B03 is 701.0 PID is 70111']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7368.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 7368.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '3', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 166/829 [04:57<17:12,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '7', '3', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '7', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '3', '2', '4', '4', '4', '4', '4', '2']]\n",
      "decoded_data: ['PID is 7368.0, DOY is 211.0, B03 is 717.0, B04 is 609.0, B02 is 364.032444442']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 7468.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 7468.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '4', '6', '8', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '4', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '7', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '2', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '6', '2', '6', '.', '0', ',', '', 'B03']]\n",
      "decoded_data: ['DOY is 211.0, PID is 7468.0, B02 is 373.0, B03 is 731.0, B04 is 626.0 626.0, B03']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7468.0, B02 is 373.0, B03 is 731.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 7468.0, B02 is 373.0, B03 is 731.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '4', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '7', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '4', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '7', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '2', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '6', '2', '6', '2', '6', '.', '0', '9']]\n",
      "decoded_data: ['PID is 7468.0, B02 is 373.0, B03 is 731.0, DOY is 211.0, B04 is 626.0 62626.09']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7468.0, B03 is 731.0, B02 is 373.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 7468.0, B03 is 731.0, B02 is 373.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '4', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '7', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '4', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '7', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '2', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '6', '2', '6', '2', '6']]\n",
      "decoded_data: ['PID is 7468.0, B03 is 731.0, B02 is 373.0, DOY is 211.0, B04 is 626.0 PID is 62626']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 373.0, PID is 7468.0, DOY is 211.0, B03 is 731.0, B04 is']\n",
      "prompt: B02 is 373.0, PID is 7468.0, DOY is 211.0, B03 is 731.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '7', '3', '.', '0', ',', '', 'PID', 'is', '', '7', '4', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '7', '3', '.', '0', ',', '', 'PID', 'is', '', '7', '4', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '2', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '6', '2', '6', '2', '6', '.', '0', '.']]\n",
      "decoded_data: ['B02 is 373.0, PID is 7468.0, DOY is 211.0, B03 is 731.0, B04 is 626.0 62626.0.']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7468.0, DOY is 211.0, B02 is 373.0, B03 is 731.0, B04 is']\n",
      "prompt: PID is 7468.0, DOY is 211.0, B02 is 373.0, B03 is 731.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '4', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '7', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '4', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '7', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '2', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '6', '2', '6', '2', '6', '.', '0', 'is']]\n",
      "decoded_data: ['PID is 7468.0, DOY is 211.0, B02 is 373.0, B03 is 731.0, B04 is 626.0 62626.0 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 373.0, DOY is 211.0, PID is 7468.0, B03 is 731.0, B04 is']\n",
      "prompt: B02 is 373.0, DOY is 211.0, PID is 7468.0, B03 is 731.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '7', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '4', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '7', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '4', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '2', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '6', '.', '0', '1', '.', '0', ',', '']]\n",
      "decoded_data: ['B02 is 373.0, DOY is 211.0, PID is 7468.0, B03 is 731.0, B04 is 626.0 6.01.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 373.0, DOY is 211.0, B03 is 731.0, PID is 7468.0, B04 is']\n",
      "prompt: B02 is 373.0, DOY is 211.0, B03 is 731.0, PID is 7468.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '7', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '4', '6', '8', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '7', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '4', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '6', '2', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '6', '.', '0', 'is', '', '6', '5', '1']]\n",
      "decoded_data: ['B02 is 373.0, DOY is 211.0, B03 is 731.0, PID is 7468.0, B04 is 626.0 6.0 is 651']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 373.0, B03 is 731.0, PID is 7468.0, DOY is 211.0, B04 is']\n",
      "prompt: B02 is 373.0, B03 is 731.0, PID is 7468.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '7', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '4', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '7', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '4', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '2', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '6', '2', '6', '2', '6', '.', '0', '.']]\n",
      "decoded_data: ['B02 is 373.0, B03 is 731.0, PID is 7468.0, DOY is 211.0, B04 is 626.0 62626.0.']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 731.0, PID is 7468.0, DOY is 211.0, B02 is 373.0, B04 is']\n",
      "prompt: B03 is 731.0, PID is 7468.0, DOY is 211.0, B02 is 373.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '3', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '4', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '7', '3', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '3', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '4', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '7', '3', '.', '0', ',', '', 'B04', 'is', '', '6', '2', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '2', '6', '.', '0', '1', '.', '0', '.']]\n",
      "decoded_data: ['B03 is 731.0, PID is 7468.0, DOY is 211.0, B02 is 373.0, B04 is 626.0626.01.0.']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 373.0, B03 is 731.0, PID is 7468.0, B04 is']\n",
      "prompt: DOY is 211.0, B02 is 373.0, B03 is 731.0, PID is 7468.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '7', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '4', '6', '8', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '7', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '4', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '6', '2', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '6', '.', '0', '.', '0', ',', '', 'B03']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 373.0, B03 is 731.0, PID is 7468.0, B04 is 626.0 6.0.0, B03']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7468.0, DOY is 211.0, B02 is 373.0, B03 is 731.0, B04 is']\n",
      "prompt: PID is 7468.0, DOY is 211.0, B02 is 373.0, B03 is 731.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '4', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '7', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '4', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '7', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '2', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '6', '2', '6', '.', '0', '9', '5', '.']]\n",
      "decoded_data: ['PID is 7468.0, DOY is 211.0, B02 is 373.0, B03 is 731.0, B04 is 626.0 626.095.']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 731.0, PID is 7468.0, B02 is 373.0, DOY is 211.0, B04 is']\n",
      "prompt: B03 is 731.0, PID is 7468.0, B02 is 373.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '3', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '4', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '7', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '3', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '4', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '7', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '2', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '6', '.', '0', '9', '5', '2', '6', '.']]\n",
      "decoded_data: ['B03 is 731.0, PID is 7468.0, B02 is 373.0, DOY is 211.0, B04 is 626.0 6.09526.']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7468.0, B02 is 373.0, B03 is 731.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 7468.0, B02 is 373.0, B03 is 731.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '4', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '7', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 167/829 [04:59<18:43,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '7', '4', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '7', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '2', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '8', '5', '9', '5', '9', '5', '3', '5']]\n",
      "decoded_data: ['PID is 7468.0, B02 is 373.0, B03 is 731.0, DOY is 211.0, B04 is 626.0785959535']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7568.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 7568.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '5', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '5', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '9', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '9', '2', '1', '0', '.', '0', ',', '', 'B04']]\n",
      "decoded_data: ['PID is 7568.0, DOY is 211.0, B04 is 599.0, B02 is 359.0, B03 is 721.09210.0, B04']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 599.0, B02 is 359.0, PID is 7568.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 599.0, B02 is 359.0, PID is 7568.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '9', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '9', '.', '0', ',', '', 'PID', 'is', '', '7', '5', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '9', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '9', '.', '0', ',', '', 'PID', 'is', '', '7', '5', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '9']]\n",
      "decoded_data: ['B04 is 599.0, B02 is 359.0, PID is 7568.0, DOY is 211.0, B03 is 721.0 B04 is PID is 79']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7568.0, DOY is 211.0, B02 is 359.0, B04 is 599.0, B03 is']\n",
      "prompt: PID is 7568.0, DOY is 211.0, B02 is 359.0, B04 is 599.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '5', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '9', '9', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '5', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '9', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '7', '0', '0', '0', '0', '0', '8', '2']]\n",
      "decoded_data: ['PID is 7568.0, DOY is 211.0, B02 is 359.0, B04 is 599.0, B03 is 721.0 70000082']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 599.0, DOY is 211.0, PID is 7568.0, B02 is 359.0, B03 is']\n",
      "prompt: B04 is 599.0, DOY is 211.0, PID is 7568.0, B02 is 359.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '9', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '5', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '9', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '9', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '5', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'DOY', 'is', '', '7', '0', '0', '0', '0']]\n",
      "decoded_data: ['B04 is 599.0, DOY is 211.0, PID is 7568.0, B02 is 359.0, B03 is 721.0 DOY is 70000']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7568.0, DOY is 211.0, B02 is 359.0, B04 is 599.0, B03 is']\n",
      "prompt: PID is 7568.0, DOY is 211.0, B02 is 359.0, B04 is 599.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '5', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '9', '9', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '5', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '9', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '5', '9']]\n",
      "decoded_data: ['PID is 7568.0, DOY is 211.0, B02 is 359.0, B04 is 599.0, B03 is 721.0 PID is B04 is 59']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7568.0, DOY is 211.0, B04 is 599.0, B02 is 359.0, B03 is']\n",
      "prompt: PID is 7568.0, DOY is 211.0, B04 is 599.0, B02 is 359.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '5', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '9', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '9', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '5', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '9', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '7', '0', '3', '2', '1']]\n",
      "decoded_data: ['PID is 7568.0, DOY is 211.0, B04 is 599.0, B02 is 359.0, B03 is 721.0 B04 is 70321']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7568.0, B02 is 359.0, B04 is 599.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 7568.0, B02 is 359.0, B04 is 599.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '5', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '9', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 168/829 [05:00<17:01,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '7', '5', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '9', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '0', '8', '2', '1', '9', '0', '8', '2']]\n",
      "decoded_data: ['PID is 7568.0, B02 is 359.0, B04 is 599.0, DOY is 211.0, B03 is 721.0708219082']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 7668.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 7668.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '6', '6', '8', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '6', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '8', '2', '3', '1']]\n",
      "decoded_data: ['DOY is 211.0, PID is 7668.0, B02 is 343.0, B04 is 566.0, B03 is 703.0 B04 is 58231']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 566.0, B02 is 343.0, DOY is 211.0, PID is 7668.0, B03 is']\n",
      "prompt: B04 is 566.0, B02 is 343.0, DOY is 211.0, PID is 7668.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '6', '6', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '6', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '7', '9', '0', '3', '.', '0', ',', '']]\n",
      "decoded_data: ['B04 is 566.0, B02 is 343.0, DOY is 211.0, PID is 7668.0, B03 is 703.0 7903.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 566.0, B02 is 343.0, PID is 7668.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 566.0, B02 is 343.0, PID is 7668.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '3', '.', '0', ',', '', 'PID', 'is', '', '7', '6', '6', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '3', '.', '0', ',', '', 'PID', 'is', '', '7', '6', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 566.0, B02 is 343.0, PID is 7668.0, B03 is 703.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 343.0, B04 is 566.0, PID is 7668.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 343.0, B04 is 566.0, PID is 7668.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '4', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '7', '6', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '4', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '7', '6', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '7', '9', '0', '3', '.']]\n",
      "decoded_data: ['B02 is 343.0, B04 is 566.0, PID is 7668.0, DOY is 211.0, B03 is 703.0 B04 is 7903.']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 7668.0, B02 is 343.0, B04 is 566.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 7668.0, B02 is 343.0, B04 is 566.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '6', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '6', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '2', '3', '3', '.']]\n",
      "decoded_data: ['DOY is 211.0, PID is 7668.0, B02 is 343.0, B04 is 566.0, B03 is 703.0 B04 is 5233.']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 7668.0, B02 is 343.0, B04 is 566.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 7668.0, B02 is 343.0, B04 is 566.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '6', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '6', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '8', '2', '3', '4']]\n",
      "decoded_data: ['DOY is 211.0, PID is 7668.0, B02 is 343.0, B04 is 566.0, B03 is 703.0 B04 is 58234']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 343.0, PID is 7668.0, B04 is 566.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 343.0, PID is 7668.0, B04 is 566.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '3', '.', '0', ',', '', 'PID', 'is', '', '7', '6', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '3', '.', '0', ',', '', 'PID', 'is', '', '7', '6', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'DOY', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 343.0, PID is 7668.0, B04 is 566.0, B03 is 703.0 B04 is DOY is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 343.0, DOY is 211.0, B04 is 566.0, PID is 7668.0, B03 is']\n",
      "prompt: B02 is 343.0, DOY is 211.0, B04 is 566.0, PID is 7668.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '4', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '7', '6', '6', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '4', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '7', '6', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'DOY', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['B02 is 343.0, DOY is 211.0, B04 is 566.0, PID is 7668.0, B03 is 703.0 B04 is DOY is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 343.0, PID is 7668.0, DOY is 211.0, B04 is 566.0, B03 is']\n",
      "prompt: B02 is 343.0, PID is 7668.0, DOY is 211.0, B04 is 566.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '4', '3', '.', '0', ',', '', 'PID', 'is', '', '7', '6', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '4', '3', '.', '0', ',', '', 'PID', 'is', '', '7', '6', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '6', '6', '4', '3']]\n",
      "decoded_data: ['B02 is 343.0, PID is 7668.0, DOY is 211.0, B04 is 566.0, B03 is 703.0 B04 is 56643']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 566.0, PID is 7668.0, B02 is 343.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 566.0, PID is 7668.0, B02 is 343.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '7', '6', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '7', '6', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '7']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 566.0, PID is 7668.0, B02 is 343.0, B03 is 703.0 PID is B04 is 7']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 566.0, DOY is 211.0, B02 is 343.0, PID is 7668.0, B03 is']\n",
      "prompt: B04 is 566.0, DOY is 211.0, B02 is 343.0, PID is 7668.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '3', '.', '0', ',', '', 'PID', 'is', '', '7', '6', '6', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '3', '.', '0', ',', '', 'PID', 'is', '', '7', '6', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'DOY', 'is', '', '2', '1']]\n",
      "decoded_data: ['B04 is 566.0, DOY is 211.0, B02 is 343.0, PID is 7668.0, B03 is 703.0 B04 is DOY is 21']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7668.0, B02 is 343.0, DOY is 211.0, B04 is 566.0, B03 is']\n",
      "prompt: PID is 7668.0, B02 is 343.0, DOY is 211.0, B04 is 566.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '6', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '6', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '4', '3', '1', '9']]\n",
      "decoded_data: ['PID is 7668.0, B02 is 343.0, DOY is 211.0, B04 is 566.0, B03 is 703.0 B04 is 54319']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 566.0, PID is 7668.0, B02 is 343.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 566.0, PID is 7668.0, B02 is 343.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '7', '6', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '7', '6', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B03', 'is', '', '7', '0']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 566.0, PID is 7668.0, B02 is 343.0, B03 is 703.0 PID is B03 is 70']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 566.0, PID is 7668.0, DOY is 211.0, B02 is 343.0, B03 is']\n",
      "prompt: B04 is 566.0, PID is 7668.0, DOY is 211.0, B02 is 343.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '7', '6', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'PID', 'is', '', '7', '6', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'DOY', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['B04 is 566.0, PID is 7668.0, DOY is 211.0, B02 is 343.0, B03 is 703.0 B04 is DOY is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 566.0, B02 is 343.0, DOY is 211.0, PID is 7668.0, B03 is']\n",
      "prompt: B04 is 566.0, B02 is 343.0, DOY is 211.0, PID is 7668.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '6', '6', '8', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 20%|        | 169/829 [05:02<19:50,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B04', 'is', '', '5', '6', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '6', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '7', '9', '0', '3', '.']]\n",
      "decoded_data: ['B04 is 566.0, B02 is 343.0, DOY is 211.0, PID is 7668.0, B03 is 703.0 B04 is 7903.']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 7768.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 7768.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '7', '6', '8', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '7', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '2', '.', '0', ',', '', 'B04', 'is', '', '6', '5', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '6', '5', '8', '.', '0']]\n",
      "decoded_data: ['DOY is 211.0, PID is 7768.0, B02 is 392.0, B04 is 657.0, B03 is 738.0 B04 is 658.0']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7768.0, DOY is 211.0, B04 is 657.0, B02 is 392.0, B03 is']\n",
      "prompt: PID is 7768.0, DOY is 211.0, B04 is 657.0, B02 is 392.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '7', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '5', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '7', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '5', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['PID is 7768.0, DOY is 211.0, B04 is 657.0, B02 is 392.0, B03 is 738.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7768.0, DOY is 211.0, B02 is 392.0, B04 is 657.0, B03 is']\n",
      "prompt: PID is 7768.0, DOY is 211.0, B02 is 392.0, B04 is 657.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '7', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '2', '.', '0', ',', '', 'B04', 'is', '', '6', '5', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '7', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '2', '.', '0', ',', '', 'B04', 'is', '', '6', '5', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '6', '5', '1', '.', '0']]\n",
      "decoded_data: ['PID is 7768.0, DOY is 211.0, B02 is 392.0, B04 is 657.0, B03 is 738.0 B04 is 651.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 657.0, DOY is 211.0, B02 is 392.0, PID is 7768.0, B03 is']\n",
      "prompt: B04 is 657.0, DOY is 211.0, B02 is 392.0, PID is 7768.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '6', '5', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '7', '6', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '6', '5', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '7', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '7', '.', '0', ',', '', 'B04', 'is', '']]\n",
      "decoded_data: ['B04 is 657.0, DOY is 211.0, B02 is 392.0, PID is 7768.0, B03 is 737.0 7.0, B04 is ']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 392.0, B04 is 657.0, DOY is 211.0, PID is 7768.0, B03 is']\n",
      "prompt: B02 is 392.0, B04 is 657.0, DOY is 211.0, PID is 7768.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '9', '2', '.', '0', ',', '', 'B04', 'is', '', '6', '5', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '7', '6', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '9', '2', '.', '0', ',', '', 'B04', 'is', '', '6', '5', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '7', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '7', '9', '1', '.', '0', ',', '', 'B04']]\n",
      "decoded_data: ['B02 is 392.0, B04 is 657.0, DOY is 211.0, PID is 7768.0, B03 is 738.0 791.0, B04']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 7768.0, B02 is 392.0, B04 is 657.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 7768.0, B02 is 392.0, B04 is 657.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '7', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '2', '.', '0', ',', '', 'B04', 'is', '', '6', '5', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '7', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '2', '.', '0', ',', '', 'B04', 'is', '', '6', '5', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '6', '5', '1', '4', '9']]\n",
      "decoded_data: ['DOY is 211.0, PID is 7768.0, B02 is 392.0, B04 is 657.0, B03 is 738.0 B04 is 65149']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 392.0, PID is 7768.0, B04 is 657.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 392.0, PID is 7768.0, B04 is 657.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '7', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '6', '5', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '7', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '6', '5', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '6', '9', '2', '1', '1']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 392.0, PID is 7768.0, B04 is 657.0, B03 is 738.0 B04 is 69211']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 657.0, B02 is 392.0, PID is 7768.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 657.0, B02 is 392.0, PID is 7768.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '6', '5', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '7', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '6', '5', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '7', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', '6', '5']]\n",
      "decoded_data: ['B04 is 657.0, B02 is 392.0, PID is 7768.0, DOY is 211.0, B03 is 738.0 B04 is B04 is 65']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 657.0, B02 is 392.0, DOY is 211.0, PID is 7768.0, B03 is']\n",
      "prompt: B04 is 657.0, B02 is 392.0, DOY is 211.0, PID is 7768.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '6', '5', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '7', '6', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '6', '5', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '7', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '7', '9', '1', '.', '0', '2', '1', '6']]\n",
      "decoded_data: ['B04 is 657.0, B02 is 392.0, DOY is 211.0, PID is 7768.0, B03 is 738.0 791.0216']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 392.0, B04 is 657.0, PID is 7768.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 392.0, B04 is 657.0, PID is 7768.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '2', '.', '0', ',', '', 'B04', 'is', '', '6', '5', '7', '.', '0', ',', '', 'PID', 'is', '', '7', '7', '6', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '2', '.', '0', ',', '', 'B04', 'is', '', '6', '5', '7', '.', '0', ',', '', 'PID', 'is', '', '7', '7', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '3', '8', '5', '1', '.', '0', ',', '', 'B04']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 392.0, B04 is 657.0, PID is 7768.0, B03 is 738.03851.0, B04']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 392.0, PID is 7768.0, B04 is 657.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 392.0, PID is 7768.0, B04 is 657.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '7', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '6', '5', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '7', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '6', '5', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '6', '6', '5', '3', '5']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 392.0, PID is 7768.0, B04 is 657.0, B03 is 738.0 B04 is 66535']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 392.0, PID is 7768.0, B04 is 657.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 392.0, PID is 7768.0, B04 is 657.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '7', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '6', '5', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '7', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '6', '5', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '1']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 392.0, PID is 7768.0, B04 is 657.0, B03 is 738.0 B04 is PID is 71']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 657.0, PID is 7768.0, B02 is 392.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 657.0, PID is 7768.0, B02 is 392.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '5', '7', '.', '0', ',', '', 'PID', 'is', '', '7', '7', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '5', '7', '.', '0', ',', '', 'PID', 'is', '', '7', '7', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '6', '5', '1', '6']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 657.0, PID is 7768.0, B02 is 392.0, B03 is 731.0 PID is 76516']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 657.0, PID is 7768.0, DOY is 211.0, B02 is 392.0, B03 is']\n",
      "prompt: B04 is 657.0, PID is 7768.0, DOY is 211.0, B02 is 392.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '6', '5', '7', '.', '0', ',', '', 'PID', 'is', '', '7', '7', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '6', '5', '7', '.', '0', ',', '', 'PID', 'is', '', '7', '7', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '3', '7', '5', '1', '.', '0', '3', '1', '6']]\n",
      "decoded_data: ['B04 is 657.0, PID is 7768.0, DOY is 211.0, B02 is 392.0, B03 is 731.03751.0316']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7768.0, DOY is 211.0, B02 is 392.0, B04 is 657.0, B03 is']\n",
      "prompt: PID is 7768.0, DOY is 211.0, B02 is 392.0, B04 is 657.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '7', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '2', '.', '0', ',', '', 'B04', 'is', '', '6', '5', '7', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 21%|        | 170/829 [05:05<21:45,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '7', '7', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '2', '.', '0', ',', '', 'B04', 'is', '', '6', '5', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '7', '1', '6', '5', '1']]\n",
      "decoded_data: ['PID is 7768.0, DOY is 211.0, B02 is 392.0, B04 is 657.0, B03 is 738.0 B04 is 71651']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 7868.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 7868.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '8', '6', '8', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '8', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '4', '7', '2', '8', '8', '8', '8', '.']]\n",
      "decoded_data: ['DOY is 211.0, PID is 7868.0, B04 is 539.0, B02 is 334.0, B03 is 728.074728888.']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7868.0, B04 is 539.0, DOY is 211.0, B02 is 334.0, B03 is']\n",
      "prompt: PID is 7868.0, B04 is 539.0, DOY is 211.0, B02 is 334.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '8', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '8', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '2', '8', '8', '8', '8', '8', '.', '0']]\n",
      "decoded_data: ['PID is 7868.0, B04 is 539.0, DOY is 211.0, B02 is 334.0, B03 is 728.07288888.0']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 539.0, PID is 7868.0, B02 is 334.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 539.0, PID is 7868.0, B02 is 334.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '9', '.', '0', ',', '', 'PID', 'is', '', '7', '8', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '9', '.', '0', ',', '', 'PID', 'is', '', '7', '8', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '2', '8', '8', '8', '8', '.', '0', ',']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 539.0, PID is 7868.0, B02 is 334.0, B03 is 728.0728888.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 539.0, B02 is 334.0, DOY is 211.0, PID is 7868.0, B03 is']\n",
      "prompt: B04 is 539.0, B02 is 334.0, DOY is 211.0, PID is 7868.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '3', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '8', '6', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '3', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '8', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '2', '8', '8', '8', '.', '0', ',', '']]\n",
      "decoded_data: ['B04 is 539.0, B02 is 334.0, DOY is 211.0, PID is 7868.0, B03 is 728.072888.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 334.0, DOY is 211.0, B04 is 539.0, PID is 7868.0, B03 is']\n",
      "prompt: B02 is 334.0, DOY is 211.0, B04 is 539.0, PID is 7868.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '3', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '9', '.', '0', ',', '', 'PID', 'is', '', '7', '8', '6', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '3', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '9', '.', '0', ',', '', 'PID', 'is', '', '7', '8', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '4', '7', '4', '7', '0', '.', '0', '0']]\n",
      "decoded_data: ['B02 is 334.0, DOY is 211.0, B04 is 539.0, PID is 7868.0, B03 is 728.0747470.00']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 539.0, B02 is 334.0, PID is 7868.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 539.0, B02 is 334.0, PID is 7868.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '4', '.', '0', ',', '', 'PID', 'is', '', '7', '8', '6', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '4', '.', '0', ',', '', 'PID', 'is', '', '7', '8', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '2', '8', '8', '8']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 539.0, B02 is 334.0, PID is 7868.0, B03 is 728.0 PID is 72888']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 539.0, DOY is 211.0, B02 is 334.0, PID is 7868.0, B03 is']\n",
      "prompt: B04 is 539.0, DOY is 211.0, B02 is 334.0, PID is 7868.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '3', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '4', '.', '0', ',', '', 'PID', 'is', '', '7', '8', '6', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '3', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '4', '.', '0', ',', '', 'PID', 'is', '', '7', '8', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '4']]\n",
      "decoded_data: ['B04 is 539.0, DOY is 211.0, B02 is 334.0, PID is 7868.0, B03 is 728.0 B04 is PID is 74']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7868.0, B02 is 334.0, B04 is 539.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 7868.0, B02 is 334.0, B04 is 539.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '8', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '8', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '4']]\n",
      "decoded_data: ['PID is 7868.0, B02 is 334.0, B04 is 539.0, DOY is 211.0, B03 is 728.0 B04 is PID is 74']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7868.0, DOY is 211.0, B04 is 539.0, B02 is 334.0, B03 is']\n",
      "prompt: PID is 7868.0, DOY is 211.0, B04 is 539.0, B02 is 334.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '8', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '8', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '7', '2', '8', '8', '8', '8', '.', '0']]\n",
      "decoded_data: ['PID is 7868.0, DOY is 211.0, B04 is 539.0, B02 is 334.0, B03 is 728.0 728888.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 334.0, B04 is 539.0, DOY is 211.0, PID is 7868.0, B03 is']\n",
      "prompt: B02 is 334.0, B04 is 539.0, DOY is 211.0, PID is 7868.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '3', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '8', '6', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '3', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '8', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '7', '4', '9', '2', '8']]\n",
      "decoded_data: ['B02 is 334.0, B04 is 539.0, DOY is 211.0, PID is 7868.0, B03 is 728.0 B04 is 74928']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7868.0, DOY is 211.0, B02 is 334.0, B04 is 539.0, B03 is']\n",
      "prompt: PID is 7868.0, DOY is 211.0, B02 is 334.0, B04 is 539.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '8', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '9', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '8', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '5', '7']]\n",
      "decoded_data: ['PID is 7868.0, DOY is 211.0, B02 is 334.0, B04 is 539.0, B03 is 728.0 B04 is PID is 57']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7868.0, B02 is 334.0, DOY is 211.0, B04 is 539.0, B03 is']\n",
      "prompt: PID is 7868.0, B02 is 334.0, DOY is 211.0, B04 is 539.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '8', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '9', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '8', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '2', '8', '8', '8']]\n",
      "decoded_data: ['PID is 7868.0, B02 is 334.0, DOY is 211.0, B04 is 539.0, B03 is 728.0 B04 is 52888']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7868.0, B02 is 334.0, B04 is 539.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 7868.0, B02 is 334.0, B04 is 539.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '8', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|        | 171/829 [05:07<21:45,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '7', '8', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '2', '8', '8', '8', '8', '8', '7', '8']]\n",
      "decoded_data: ['PID is 7868.0, B02 is 334.0, B04 is 539.0, DOY is 211.0, B03 is 728.0728888878']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 7968.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 7968.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '8', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '7', '9', '4', '4', '7']]\n",
      "decoded_data: ['DOY is 211.0, PID is 7968.0, B02 is 307.0, B04 is 545.0, B03 is 709.0 B04 is 79447']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 307.0, B04 is 545.0, PID is 7968.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 307.0, B04 is 545.0, PID is 7968.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '5', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '5', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 307.0, B04 is 545.0, PID is 7968.0, B03 is 709.0 PID is B04 is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 307.0, B04 is 545.0, PID is 7968.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 307.0, B04 is 545.0, PID is 7968.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '0', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '5', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '0', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '5', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['B02 is 307.0, B04 is 545.0, PID is 7968.0, DOY is 211.0, B03 is 709.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 545.0, B02 is 307.0, PID is 7968.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 545.0, B02 is 307.0, PID is 7968.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '4', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '7', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '4', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '7', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '9', '9', '9', '9']]\n",
      "decoded_data: ['B04 is 545.0, B02 is 307.0, PID is 7968.0, DOY is 211.0, B03 is 709.0 PID is 79999']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 545.0, DOY is 211.0, B02 is 307.0, PID is 7968.0, B03 is']\n",
      "prompt: B04 is 545.0, DOY is 211.0, B02 is 307.0, PID is 7968.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '4', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '7', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '4', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '7', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['B04 is 545.0, DOY is 211.0, B02 is 307.0, PID is 7968.0, B03 is 709.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7968.0, DOY is 211.0, B04 is 545.0, B02 is 307.0, B03 is']\n",
      "prompt: PID is 7968.0, DOY is 211.0, B04 is 545.0, B02 is 307.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '9', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '9', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '7', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['PID is 7968.0, DOY is 211.0, B04 is 545.0, B02 is 307.0, B03 is 709.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 307.0, B04 is 545.0, PID is 7968.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 307.0, B04 is 545.0, PID is 7968.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '0', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '5', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '0', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '5', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B02', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['B02 is 307.0, B04 is 545.0, PID is 7968.0, DOY is 211.0, B03 is 709.0 B04 is B02 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 545.0, B02 is 307.0, PID is 7968.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 545.0, B02 is 307.0, PID is 7968.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '7', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '7', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '7', '9']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 545.0, B02 is 307.0, PID is 7968.0, B03 is 709.0 PID is B04 is 79']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 307.0, PID is 7968.0, B04 is 545.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 307.0, PID is 7968.0, B04 is 545.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '0', '7', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|        | 172/829 [05:08<19:53,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B02', 'is', '', '3', '0', '7', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '4', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '9', '9', '7', '7', '9', '9', '9', '9']]\n",
      "decoded_data: ['B02 is 307.0, PID is 7968.0, B04 is 545.0, DOY is 211.0, B03 is 709.0799779999']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 8068.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 8068.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '8', '0', '6', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '8', '0', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '2', '.', '0', ',', '', 'B04', 'is', '', '5']]\n",
      "decoded_data: ['DOY is 211.0, PID is 8068.0, B03 is 686.0, B04 is 512.0, B02 is 291.02.0, B04 is 5']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 512.0, DOY is 211.0, B03 is 686.0, PID is 8068.0, B02 is']\n",
      "prompt: B04 is 512.0, DOY is 211.0, B03 is 686.0, PID is 8068.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '1', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '6', '.', '0', ',', '', 'PID', 'is', '', '8', '0', '6', '8', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '1', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '6', '.', '0', ',', '', 'PID', 'is', '', '8', '0', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '2', '.', '0', ',', '', 'B03', 'is', '', 'B02']]\n",
      "decoded_data: ['B04 is 512.0, DOY is 211.0, B03 is 686.0, PID is 8068.0, B02 is 291.02.0, B03 is B02']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 686.0, PID is 8068.0, B04 is 512.0, B02 is']\n",
      "prompt: DOY is 211.0, B03 is 686.0, PID is 8068.0, B04 is 512.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '6', '.', '0', ',', '', 'PID', 'is', '', '8', '0', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '2', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '6', '.', '0', ',', '', 'PID', 'is', '', '8', '0', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '3', '4', '2', '1', '2', '.', '0', ',', '']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 686.0, PID is 8068.0, B04 is 512.0, B02 is 291.034212.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 686.0, B04 is 512.0, DOY is 211.0, PID is 8068.0, B02 is']\n",
      "prompt: B03 is 686.0, B04 is 512.0, DOY is 211.0, PID is 8068.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '8', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '8', '0', '6', '8', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '6', '8', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '8', '0', '6', '8', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '.', '0', ',', '', '3', '7', '4', '4', '1']]\n",
      "decoded_data: ['B03 is 686.0, B04 is 512.0, DOY is 211.0, PID is 8068.0, B02 is 291.0.0, 37441']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 686.0, PID is 8068.0, B04 is 512.0, B02 is']\n",
      "prompt: DOY is 211.0, B03 is 686.0, PID is 8068.0, B04 is 512.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '6', '.', '0', ',', '', 'PID', 'is', '', '8', '0', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '2', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '6', '.', '0', ',', '', 'PID', 'is', '', '8', '0', '6', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '2', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '2', '9', '1', '7', '1']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 686.0, PID is 8068.0, B04 is 512.0, B02 is 291.0 PID is 29171']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 512.0, DOY is 211.0, PID is 8068.0, B03 is 686.0, B02 is']\n",
      "prompt: B04 is 512.0, DOY is 211.0, PID is 8068.0, B03 is 686.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '1', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '8', '0', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '6', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '1', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '8', '0', '6', '8', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '6', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '3', '1', '2', '9', '1']]\n",
      "decoded_data: ['B04 is 512.0, DOY is 211.0, PID is 8068.0, B03 is 686.0, B02 is 291.0 PID is 31291']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 512.0, B03 is 686.0, PID is 8068.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 512.0, B03 is 686.0, PID is 8068.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '1', '2', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '6', '.', '0', ',', '', 'PID', 'is', '', '8', '0', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|        | 173/829 [05:09<17:49,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B04', 'is', '', '5', '1', '2', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '6', '.', '0', ',', '', 'PID', 'is', '', '8', '0', '6', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '9', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '0', ',', '', 'PID', 'is', '', 'B04', 'is', '']]\n",
      "decoded_data: ['B04 is 512.0, B03 is 686.0, PID is 8068.0, DOY is 211.0, B02 is 291.00, PID is B04 is ']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5069.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 5069.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '0', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|        | 174/829 [05:10<13:25,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '5', '0', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '5', '7', '3', '.', '0', ',', '', 'B04', 'is', '', '8', '7', '3', '.', '0', ',', '', 'B03', 'is', '', '8', '5', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '4', '9', '6', '0', ',', '', 'B04', 'is', '']]\n",
      "decoded_data: ['PID is 5069.0, DOY is 211.0, B02 is 573.0, B04 is 873.0, B03 is 855.04960, B04 is ']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5169.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 5169.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '6', '9', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '5', '3', '2', '.', '0', ',', '', 'B04', 'is', '', '8', '3', '0', '.', '0', ',', '', 'B03', 'is', '', '8', '3', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '8', '3', '2', '6', '5', '0', '3', '2', '.']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5169.0, B02 is 532.0, B04 is 830.0, B03 is 832.083265032.']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 830.0, B02 is 532.0, DOY is 211.0, PID is 5169.0, B03 is']\n",
      "prompt: B04 is 830.0, B02 is 532.0, DOY is 211.0, PID is 5169.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '8', '3', '0', '.', '0', ',', '', 'B02', 'is', '', '5', '3', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '6', '9', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '8', '3', '0', '.', '0', ',', '', 'B02', 'is', '', '5', '3', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '8', '3', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '8', '3', '2', '.', '0', ',', '', 'PID', 'is']]\n",
      "decoded_data: ['B04 is 830.0, B02 is 532.0, DOY is 211.0, PID is 5169.0, B03 is 832.0832.0, PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5169.0, DOY is 211.0, B02 is 532.0, B04 is 830.0, B03 is']\n",
      "prompt: PID is 5169.0, DOY is 211.0, B02 is 532.0, B04 is 830.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '1', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '5', '3', '2', '.', '0', ',', '', 'B04', 'is', '', '8', '3', '0', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '1', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '5', '3', '2', '.', '0', ',', '', 'B04', 'is', '', '8', '3', '0', '.', '0', ',', '', 'B03', 'is', '', '8', '3', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '8', '3', '2', '6', '3']]\n",
      "decoded_data: ['PID is 5169.0, DOY is 211.0, B02 is 532.0, B04 is 830.0, B03 is 832.0 B04 is 83263']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 830.0, B02 is 532.0, PID is 5169.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 830.0, B02 is 532.0, PID is 5169.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '8', '3', '0', '.', '0', ',', '', 'B02', 'is', '', '5', '3', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '6', '9', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '8', '3', '0', '.', '0', ',', '', 'B02', 'is', '', '5', '3', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '8', '3', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '8', '3', '2', '6', '7']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 830.0, B02 is 532.0, PID is 5169.0, B03 is 832.0 PID is 83267']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5169.0, B02 is 532.0, B04 is 830.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 5169.0, B02 is 532.0, B04 is 830.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '5', '3', '2', '.', '0', ',', '', 'B04', 'is', '', '8', '3', '0', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|        | 175/829 [05:11<12:10,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '5', '3', '2', '.', '0', ',', '', 'B04', 'is', '', '8', '3', '0', '.', '0', ',', '', 'B03', 'is', '', '8', '3', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '8', '3', '2', '7', '2', '6', '3', '2', '7']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5169.0, B02 is 532.0, B04 is 830.0, B03 is 832.0832726327']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5269.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 5269.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '2', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|        | 176/829 [05:11<10:04,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '5', '2', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '9', '7', '.', '0', ',', '', 'B02', 'is', '', '4', '2', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '7', '9', '7', '9', '7']]\n",
      "decoded_data: ['PID is 5269.0, DOY is 211.0, B04 is 697.0, B02 is 423.0, B03 is 779.0 B04 is 79797']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 697.0, PID is 5269.0, B02 is 423.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 697.0, PID is 5269.0, B02 is 423.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '6', '9', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '4', '2', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '6', '9', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '4', '2', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '7', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '9', '7', '9', '7', '9', '9', '7', '9']]\n",
      "decoded_data: ['B04 is 697.0, PID is 5269.0, B02 is 423.0, DOY is 211.0, B03 is 779.0797979979']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5369.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 5369.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '9', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '1', '9', '8', '8', '8', '9', '0']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5369.0, B02 is 303.0, B03 is 689.0, B04 is 519.0 51988890']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 689.0, PID is 5369.0, B02 is 303.0, B04 is']\n",
      "prompt: DOY is 211.0, B03 is 689.0, PID is 5369.0, B02 is 303.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '9', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '9', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '0', '7', '.', '0', ',', '', 'PID']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 689.0, PID is 5369.0, B02 is 303.0, B04 is 519.0 507.0, PID']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5369.0, B03 is 689.0, B02 is 303.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 5369.0, B03 is 689.0, B02 is 303.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '0', '9', '1', '9']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5369.0, B03 is 689.0, B02 is 303.0, B04 is 519.0 PID is 50919']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5369.0, DOY is 211.0, B02 is 303.0, B03 is 689.0, B04 is']\n",
      "prompt: PID is 5369.0, DOY is 211.0, B02 is 303.0, B03 is 689.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '3', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '3', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '1', '9', '2', '.', '0', '.', '0']]\n",
      "decoded_data: ['PID is 5369.0, DOY is 211.0, B02 is 303.0, B03 is 689.0, B04 is 519.0 5192.0.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 689.0, B02 is 303.0, PID is 5369.0, DOY is 211.0, B04 is']\n",
      "prompt: B03 is 689.0, B02 is 303.0, PID is 5369.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '8', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '6', '8', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '2', '4', '5', '9']]\n",
      "decoded_data: ['B03 is 689.0, B02 is 303.0, PID is 5369.0, DOY is 211.0, B04 is 519.0 PID is 52459']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5369.0, DOY is 211.0, B03 is 689.0, B02 is 303.0, B04 is']\n",
      "prompt: PID is 5369.0, DOY is 211.0, B03 is 689.0, B02 is 303.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '3', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '3', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '7', '3', '6', '6', '5', '0', '3']]\n",
      "decoded_data: ['PID is 5369.0, DOY is 211.0, B03 is 689.0, B02 is 303.0, B04 is 519.0 57366503']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5369.0, DOY is 211.0, B03 is 689.0, B02 is 303.0, B04 is']\n",
      "prompt: PID is 5369.0, DOY is 211.0, B03 is 689.0, B02 is 303.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '3', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '3', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '3', '4', '3', '2', '1', '.', '0']]\n",
      "decoded_data: ['PID is 5369.0, DOY is 211.0, B03 is 689.0, B02 is 303.0, B04 is 519.0 534321.0']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 303.0, PID is 5369.0, B03 is 689.0, B04 is']\n",
      "prompt: DOY is 211.0, B02 is 303.0, PID is 5369.0, B03 is 689.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '7', '3', '4', '.', '0', '.', '0']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 303.0, PID is 5369.0, B03 is 689.0, B04 is 519.0 5734.0.0']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5369.0, B02 is 303.0, B03 is 689.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 5369.0, B02 is 303.0, B03 is 689.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '0', '5', '0', '3', '2', '.', '0']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5369.0, B02 is 303.0, B03 is 689.0, B04 is 519.0 505032.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 689.0, PID is 5369.0, B02 is 303.0, DOY is 211.0, B04 is']\n",
      "prompt: B03 is 689.0, PID is 5369.0, B02 is 303.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '8', '9', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '6', '8', '9', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '0', '7', '3', '4', '4', '.', '0']]\n",
      "decoded_data: ['B03 is 689.0, PID is 5369.0, B02 is 303.0, DOY is 211.0, B04 is 519.0 507344.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 303.0, PID is 5369.0, DOY is 211.0, B03 is 689.0, B04 is']\n",
      "prompt: B02 is 303.0, PID is 5369.0, DOY is 211.0, B03 is 689.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '1', '9', '0', '4', '4', '4', '6']]\n",
      "decoded_data: ['B02 is 303.0, PID is 5369.0, DOY is 211.0, B03 is 689.0, B04 is 519.0 51904446']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5369.0, B02 is 303.0, B03 is 689.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 5369.0, B02 is 303.0, B03 is 689.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '3', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '3', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '0', '3', '2', '4', '6', '8', '8']]\n",
      "decoded_data: ['PID is 5369.0, B02 is 303.0, B03 is 689.0, DOY is 211.0, B04 is 519.0 50324688']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 303.0, B03 is 689.0, DOY is 211.0, PID is 5369.0, B04 is']\n",
      "prompt: B02 is 303.0, B03 is 689.0, DOY is 211.0, PID is 5369.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '9', '2', '.', '0']]\n",
      "decoded_data: ['B02 is 303.0, B03 is 689.0, DOY is 211.0, PID is 5369.0, B04 is 519.0 PID is 592.0']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5369.0, B03 is 689.0, B02 is 303.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 5369.0, B03 is 689.0, B02 is 303.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '3', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '3', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '0', '9', '0', '8']]\n",
      "decoded_data: ['PID is 5369.0, B03 is 689.0, B02 is 303.0, DOY is 211.0, B04 is 519.0 PID is 50908']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 689.0, DOY is 211.0, B02 is 303.0, PID is 5369.0, B04 is']\n",
      "prompt: B03 is 689.0, DOY is 211.0, B02 is 303.0, PID is 5369.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '8', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '9', '.', '0', ',', '', 'B04', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 21%|       | 177/829 [05:13<15:02,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B03', 'is', '', '6', '8', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '0', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '0', '5', '9', '0']]\n",
      "decoded_data: ['B03 is 689.0, DOY is 211.0, B02 is 303.0, PID is 5369.0, B04 is 519.0 PID is 50590']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5469.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 5469.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '9', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '7', '.', '0', ',', '', 'B04', 'is', '', '3', '4', '3', '.', '0', ',', '', 'B03', 'is', '', '5', '1', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '7', '1', '.', '0', ',', '', 'B04']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5469.0, B02 is 247.0, B04 is 343.0, B03 is 517.0 571.0, B04']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 343.0, B02 is 247.0, PID is 5469.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 343.0, B02 is 247.0, PID is 5469.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '3', '4', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '3', '4', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '5', '1', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '7', '1', '7', '1']]\n",
      "decoded_data: ['B04 is 343.0, B02 is 247.0, PID is 5469.0, DOY is 211.0, B03 is 517.0 PID is 57171']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5469.0, B04 is 343.0, B02 is 247.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5469.0, B04 is 343.0, B02 is 247.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '4', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '3', '4', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '4', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '3', '4', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '5', '1', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'DOY', 'is', '', '2', '1', '9', '0', '7']]\n",
      "decoded_data: ['PID is 5469.0, B04 is 343.0, B02 is 247.0, DOY is 211.0, B03 is 517.0 DOY is 21907']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 343.0, B02 is 247.0, PID is 5469.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 343.0, B02 is 247.0, PID is 5469.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '3', '4', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '9', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '3', '4', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '5', '1', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '7', '1', '7', '1']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 343.0, B02 is 247.0, PID is 5469.0, B03 is 517.0 PID is 57171']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 247.0, DOY is 211.0, B04 is 343.0, PID is 5469.0, B03 is']\n",
      "prompt: B02 is 247.0, DOY is 211.0, B04 is 343.0, PID is 5469.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '3', '4', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '9', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '3', '4', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '5', '1', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B02', 'is', '', '5', '7']]\n",
      "decoded_data: ['B02 is 247.0, DOY is 211.0, B04 is 343.0, PID is 5469.0, B03 is 517.0 PID is B02 is 57']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5469.0, B04 is 343.0, DOY is 211.0, B02 is 247.0, B03 is']\n",
      "prompt: PID is 5469.0, B04 is 343.0, DOY is 211.0, B02 is 247.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '4', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '3', '4', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '4', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '3', '4', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '7', '.', '0', ',', '', 'B03', 'is', '', '5', '1', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '1', '7', '1', '7']]\n",
      "decoded_data: ['PID is 5469.0, B04 is 343.0, DOY is 211.0, B02 is 247.0, B03 is 517.0 PID is 51717']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 343.0, PID is 5469.0, B02 is 247.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 343.0, PID is 5469.0, B02 is 247.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '3', '4', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '3', '4', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '5', '1', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', '5', '1', '7', '1', '.']]\n",
      "decoded_data: ['B04 is 343.0, PID is 5469.0, B02 is 247.0, DOY is 211.0, B03 is 517.0 B03 is 5171.']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5469.0, B04 is 343.0, B02 is 247.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5469.0, B04 is 343.0, B02 is 247.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '4', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '3', '4', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '4', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '3', '4', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '5', '1', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '5', '1']]\n",
      "decoded_data: ['PID is 5469.0, B04 is 343.0, B02 is 247.0, DOY is 211.0, B03 is 517.0 PID is B04 is 51']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 343.0, B02 is 247.0, DOY is 211.0, PID is 5469.0, B03 is']\n",
      "prompt: B04 is 343.0, B02 is 247.0, DOY is 211.0, PID is 5469.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '3', '4', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '9', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '3', '4', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '5', '1', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B02', 'is', '', '5', '1', '7', '1', '7']]\n",
      "decoded_data: ['B04 is 343.0, B02 is 247.0, DOY is 211.0, PID is 5469.0, B03 is 517.0 B02 is 51717']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 343.0, PID is 5469.0, B02 is 247.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 343.0, PID is 5469.0, B02 is 247.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '3', '4', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '3', '4', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '5', '1', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B02', 'is', '', 'DOY', 'is']]\n",
      "decoded_data: ['B04 is 343.0, PID is 5469.0, B02 is 247.0, DOY is 211.0, B03 is 517.0 B04 is B02 is DOY is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 247.0, PID is 5469.0, B04 is 343.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 247.0, PID is 5469.0, B04 is 343.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '3', '4', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '3', '4', '3', '.', '0', ',', '', 'B03', 'is', '', '5', '1', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '1', '7', '1', '7']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 247.0, PID is 5469.0, B04 is 343.0, B03 is 517.0 PID is 51717']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5469.0, DOY is 211.0, B04 is 343.0, B02 is 247.0, B03 is']\n",
      "prompt: PID is 5469.0, DOY is 211.0, B04 is 343.0, B02 is 247.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '4', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '3', '4', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '4', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '3', '4', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '7', '.', '0', ',', '', 'B03', 'is', '', '5', '1', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B02', 'is', '', '5', '7', '1', '7', '1']]\n",
      "decoded_data: ['PID is 5469.0, DOY is 211.0, B04 is 343.0, B02 is 247.0, B03 is 517.0 B02 is 57171']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5469.0, DOY is 211.0, B04 is 343.0, B02 is 247.0, B03 is']\n",
      "prompt: PID is 5469.0, DOY is 211.0, B04 is 343.0, B02 is 247.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '4', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '3', '4', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '4', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '3', '4', '3', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '7', '.', '0', ',', '', 'B03', 'is', '', '5', '1', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '7', '9', '6', '1']]\n",
      "decoded_data: ['PID is 5469.0, DOY is 211.0, B04 is 343.0, B02 is 247.0, B03 is 517.0 PID is 57961']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 247.0, DOY is 211.0, B04 is 343.0, PID is 5469.0, B03 is']\n",
      "prompt: B02 is 247.0, DOY is 211.0, B04 is 343.0, PID is 5469.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '3', '4', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '9', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '4', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '3', '4', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '5', '1', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '1', '7', '1', '.', '0', ',', '', 'B02']]\n",
      "decoded_data: ['B02 is 247.0, DOY is 211.0, B04 is 343.0, PID is 5469.0, B03 is 517.05171.0, B02']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5469.0, B04 is 343.0, DOY is 211.0, B02 is 247.0, B03 is']\n",
      "prompt: PID is 5469.0, B04 is 343.0, DOY is 211.0, B02 is 247.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '4', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '3', '4', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '7', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 21%|       | 178/829 [05:16<18:40,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '5', '4', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '3', '4', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '4', '7', '.', '0', ',', '', 'B03', 'is', '', '5', '1', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '7', '1', '.', '0']]\n",
      "decoded_data: ['PID is 5469.0, B04 is 343.0, DOY is 211.0, B02 is 247.0, B03 is 517.0 B04 is 571.0']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5569.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 5569.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '3', '7', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'B03', 'is', '', '4', '7', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '4', '8', '4', '0', '.', '0', '.', '0', ',']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5569.0, B04 is 374.0, B02 is 277.0, B03 is 472.04840.0.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 374.0, PID is 5569.0, B02 is 277.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 374.0, PID is 5569.0, B02 is 277.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '3', '7', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '3', '7', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '4', '7', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '4', '7', '7', '3', '.']]\n",
      "decoded_data: ['B04 is 374.0, PID is 5569.0, B02 is 277.0, DOY is 211.0, B03 is 472.0 B04 is 4773.']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 277.0, DOY is 211.0, PID is 5569.0, B04 is 374.0, B03 is']\n",
      "prompt: B02 is 277.0, DOY is 211.0, PID is 5569.0, B04 is 374.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '3', '7', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '3', '7', '4', '.', '0', ',', '', 'B03', 'is', '', '4', '7', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '4', '0', '.', '0', '.', '0', ',', '', 'B04']]\n",
      "decoded_data: ['B02 is 277.0, DOY is 211.0, PID is 5569.0, B04 is 374.0, B03 is 472.040.0.0, B04']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5569.0, B02 is 277.0, DOY is 211.0, B04 is 374.0, B03 is']\n",
      "prompt: PID is 5569.0, B02 is 277.0, DOY is 211.0, B04 is 374.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '5', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '3', '7', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '5', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '3', '7', '4', '.', '0', ',', '', 'B03', 'is', '', '4', '7', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '4', '0', '.', '0', '.', '0', ',', '', 'PID']]\n",
      "decoded_data: ['PID is 5569.0, B02 is 277.0, DOY is 211.0, B04 is 374.0, B03 is 472.040.0.0, PID']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 277.0, B04 is 374.0, PID is 5569.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 277.0, B04 is 374.0, PID is 5569.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'B04', 'is', '', '3', '7', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'B04', 'is', '', '3', '7', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '4', '7', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '4', '7', '7', '3', '.']]\n",
      "decoded_data: ['B02 is 277.0, B04 is 374.0, PID is 5569.0, DOY is 211.0, B03 is 472.0 B04 is 4773.']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5569.0, DOY is 211.0, B02 is 277.0, B04 is 374.0, B03 is']\n",
      "prompt: PID is 5569.0, DOY is 211.0, B02 is 277.0, B04 is 374.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '5', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'B04', 'is', '', '3', '7', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '5', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'B04', 'is', '', '3', '7', '4', '.', '0', ',', '', 'B03', 'is', '', '4', '7', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '4', '7', '2', '.', '0', '.', '0', '.', '0']]\n",
      "decoded_data: ['PID is 5569.0, DOY is 211.0, B02 is 277.0, B04 is 374.0, B03 is 472.0472.0.0.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 277.0, PID is 5569.0, DOY is 211.0, B04 is 374.0, B03 is']\n",
      "prompt: B02 is 277.0, PID is 5569.0, DOY is 211.0, B04 is 374.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '3', '7', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '3', '7', '4', '.', '0', ',', '', 'B03', 'is', '', '4', '7', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', '3', '7']]\n",
      "decoded_data: ['B02 is 277.0, PID is 5569.0, DOY is 211.0, B04 is 374.0, B03 is 472.0 B04 is B04 is 37']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5569.0, B02 is 277.0, B04 is 374.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5569.0, B02 is 277.0, B04 is 374.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '5', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'B04', 'is', '', '3', '7', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '5', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'B04', 'is', '', '3', '7', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '4', '7', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '8', '4', '7', '7']]\n",
      "decoded_data: ['PID is 5569.0, B02 is 277.0, B04 is 374.0, DOY is 211.0, B03 is 472.0 B04 is 58477']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5569.0, B02 is 277.0, B04 is 374.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 5569.0, B02 is 277.0, B04 is 374.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'B04', 'is', '', '3', '7', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'B04', 'is', '', '3', '7', '4', '.', '0', ',', '', 'B03', 'is', '', '4', '7', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '4', '7', '4', '0', '.']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5569.0, B02 is 277.0, B04 is 374.0, B03 is 472.0 B04 is 4740.']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 374.0, B02 is 277.0, DOY is 211.0, PID is 5569.0, B03 is']\n",
      "prompt: B04 is 374.0, B02 is 277.0, DOY is 211.0, PID is 5569.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '3', '7', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '9', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '3', '7', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '4', '7', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', '3', '7']]\n",
      "decoded_data: ['B04 is 374.0, B02 is 277.0, DOY is 211.0, PID is 5569.0, B03 is 472.0 B04 is B04 is 37']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 374.0, PID is 5569.0, B02 is 277.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 374.0, PID is 5569.0, B02 is 277.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '3', '7', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '3', '7', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '4', '7', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B02', 'is', '', 'B04', 'is', '', 'DOY', 'is']]\n",
      "decoded_data: ['B04 is 374.0, PID is 5569.0, B02 is 277.0, DOY is 211.0, B03 is 472.0 B02 is B04 is DOY is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5569.0, DOY is 211.0, B02 is 277.0, B04 is 374.0, B03 is']\n",
      "prompt: PID is 5569.0, DOY is 211.0, B02 is 277.0, B04 is 374.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '5', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'B04', 'is', '', '3', '7', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '5', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'B04', 'is', '', '3', '7', '4', '.', '0', ',', '', 'B03', 'is', '', '4', '7', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '4', '7', '2', '2', '.', '0', '.', '0', ',']]\n",
      "decoded_data: ['PID is 5569.0, DOY is 211.0, B02 is 277.0, B04 is 374.0, B03 is 472.04722.0.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5569.0, DOY is 211.0, B04 is 374.0, B02 is 277.0, B03 is']\n",
      "prompt: PID is 5569.0, DOY is 211.0, B04 is 374.0, B02 is 277.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '5', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '3', '7', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '5', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '3', '7', '4', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'B03', 'is', '', '4', '7', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B02', 'is', '', 'B03', 'is', '', '4', '7']]\n",
      "decoded_data: ['PID is 5569.0, DOY is 211.0, B04 is 374.0, B02 is 277.0, B03 is 472.0 B02 is B03 is 47']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 277.0, B04 is 374.0, DOY is 211.0, PID is 5569.0, B03 is']\n",
      "prompt: B02 is 277.0, B04 is 374.0, DOY is 211.0, PID is 5569.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'B04', 'is', '', '3', '7', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '9', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'B04', 'is', '', '3', '7', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '4', '7', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', '3', '8']]\n",
      "decoded_data: ['B02 is 277.0, B04 is 374.0, DOY is 211.0, PID is 5569.0, B03 is 472.0 B04 is B04 is 38']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 374.0, PID is 5569.0, DOY is 211.0, B02 is 277.0, B03 is']\n",
      "prompt: B04 is 374.0, PID is 5569.0, DOY is 211.0, B02 is 277.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '3', '7', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 22%|       | 179/829 [05:18<21:00,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B04', 'is', '', '3', '7', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '7', '7', '.', '0', ',', '', 'B03', 'is', '', '4', '7', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['B04 is 374.0, PID is 5569.0, DOY is 211.0, B02 is 277.0, B03 is 472.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5669.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5669.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '6', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|       | 180/829 [05:19<15:43,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '5', '6', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '5', '2', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '7', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '4', '6', '1', '2', '8', '7', '4', '6', '1']]\n",
      "decoded_data: ['PID is 5669.0, DOY is 211.0, B03 is 525.0, B02 is 287.0, B04 is 461.0461287461']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5769.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 5769.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '9', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '4', '0', '0', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '8', '7', '8', '7', '8', '9', '0', '.']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5769.0, B02 is 400.0, B04 is 601.0, B03 is 678.068787890.']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 400.0, B04 is 601.0, PID is 5769.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 400.0, B04 is 601.0, PID is 5769.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '4', '0', '0', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '9', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '4', '0', '0', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '6', '8']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 400.0, B04 is 601.0, PID is 5769.0, B03 is 678.0 B04 is PID is 68']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 601.0, B02 is 400.0, PID is 5769.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 601.0, B02 is 400.0, PID is 5769.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '6', '0', '1', '.', '0', ',', '', 'B02', 'is', '', '4', '0', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '6', '0', '1', '.', '0', ',', '', 'B02', 'is', '', '4', '0', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '6', '5', '8', '7', '8']]\n",
      "decoded_data: ['B04 is 601.0, B02 is 400.0, PID is 5769.0, DOY is 211.0, B03 is 678.0 B04 is 65878']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 601.0, PID is 5769.0, B02 is 400.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 601.0, PID is 5769.0, B02 is 400.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '6', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '4', '0', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '6', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '4', '0', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['B04 is 601.0, PID is 5769.0, B02 is 400.0, DOY is 211.0, B03 is 678.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 400.0, B04 is 601.0, PID is 5769.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 400.0, B04 is 601.0, PID is 5769.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '4', '0', '0', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '4', '0', '0', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '6', '8']]\n",
      "decoded_data: ['B02 is 400.0, B04 is 601.0, PID is 5769.0, DOY is 211.0, B03 is 678.0 PID is B04 is 68']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 601.0, DOY is 211.0, PID is 5769.0, B02 is 400.0, B03 is']\n",
      "prompt: B04 is 601.0, DOY is 211.0, PID is 5769.0, B02 is 400.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '6', '0', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '4', '0', '0', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '6', '0', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '4', '0', '0', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '5', '8', '7', '8', '7', '5', '8', '.']]\n",
      "decoded_data: ['B04 is 601.0, DOY is 211.0, PID is 5769.0, B02 is 400.0, B03 is 678.065878758.']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5769.0, B04 is 601.0, DOY is 211.0, B02 is 400.0, B03 is']\n",
      "prompt: PID is 5769.0, B04 is 601.0, DOY is 211.0, B02 is 400.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '7', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '4', '0', '0', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '7', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '4', '0', '0', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '6', '7', '8', '7', '8']]\n",
      "decoded_data: ['PID is 5769.0, B04 is 601.0, DOY is 211.0, B02 is 400.0, B03 is 678.0 PID is 67878']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 601.0, PID is 5769.0, B02 is 400.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 601.0, PID is 5769.0, B02 is 400.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '4', '0', '0', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '4', '0', '0', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', 'DOY', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 601.0, PID is 5769.0, B02 is 400.0, B03 is 678.0 PID is B04 is DOY is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5769.0, B02 is 400.0, DOY is 211.0, B04 is 601.0, B03 is']\n",
      "prompt: PID is 5769.0, B02 is 400.0, DOY is 211.0, B04 is 601.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '7', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '4', '0', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '7', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '4', '0', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'DOY', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['PID is 5769.0, B02 is 400.0, DOY is 211.0, B04 is 601.0, B03 is 678.0 B04 is DOY is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 601.0, B02 is 400.0, PID is 5769.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 601.0, B02 is 400.0, PID is 5769.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '6', '0', '1', '.', '0', ',', '', 'B02', 'is', '', '4', '0', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '6', '0', '1', '.', '0', ',', '', 'B02', 'is', '', '4', '0', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '8', '7', '8', '9', '.', '0', ',', '']]\n",
      "decoded_data: ['B04 is 601.0, B02 is 400.0, PID is 5769.0, DOY is 211.0, B03 is 678.078789.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5769.0, B02 is 400.0, B04 is 601.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5769.0, B02 is 400.0, B04 is 601.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '7', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '4', '0', '0', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '7', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '4', '0', '0', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '6', '7']]\n",
      "decoded_data: ['PID is 5769.0, B02 is 400.0, B04 is 601.0, DOY is 211.0, B03 is 678.0 B04 is PID is 67']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5769.0, B02 is 400.0, B04 is 601.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5769.0, B02 is 400.0, B04 is 601.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '7', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '4', '0', '0', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '7', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '4', '0', '0', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['PID is 5769.0, B02 is 400.0, B04 is 601.0, DOY is 211.0, B03 is 678.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 400.0, B04 is 601.0, PID is 5769.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 400.0, B04 is 601.0, PID is 5769.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '4', '0', '0', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '9', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '4', '0', '0', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '6', '8', '7', '8', '7']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 400.0, B04 is 601.0, PID is 5769.0, B03 is 678.0 PID is 68787']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 400.0, B04 is 601.0, PID is 5769.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 400.0, B04 is 601.0, PID is 5769.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '4', '0', '0', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '4', '0', '0', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '6', '8', '9', '2', '5', '8', '7', '.']]\n",
      "decoded_data: ['B02 is 400.0, B04 is 601.0, PID is 5769.0, DOY is 211.0, B03 is 678.0 6892587.']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 400.0, DOY is 211.0, B04 is 601.0, PID is 5769.0, B03 is']\n",
      "prompt: B02 is 400.0, DOY is 211.0, B04 is 601.0, PID is 5769.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '4', '0', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '9', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 22%|       | 181/829 [05:21<18:43,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B02', 'is', '', '4', '0', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '6', '7', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'DOY', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['B02 is 400.0, DOY is 211.0, B04 is 601.0, PID is 5769.0, B03 is 678.0 B04 is DOY is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5869.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 5869.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '9', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|       | 182/829 [05:21<14:10,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '3', '2', '4', '3', '7', '3', '7', '6', '9']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5869.0, B03 is 687.0, B04 is 550.0, B02 is 341.0324373769']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5969.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5969.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '9', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|       | 183/829 [05:22<10:55,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '5', '9', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '8', '.', '0', ',', '', 'B04', 'is', '', '6', '1', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '5', '7', '9', '2', '8', '7', '9', '4']]\n",
      "decoded_data: ['PID is 5969.0, DOY is 211.0, B03 is 745.0, B02 is 348.0, B04 is 611.0657928794']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6069.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 6069.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '9', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '9', '.', '0', ',', '', 'B04', 'is', '', '6', '3', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '7', '3']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6069.0, B02 is 359.0, B04 is 635.0, B03 is 759.0 PID is B04 is 73']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6069.0, B04 is 635.0, B02 is 359.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 6069.0, B04 is 635.0, B02 is 359.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '0', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '6', '3', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '0', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '6', '3', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '6', '5']]\n",
      "decoded_data: ['PID is 6069.0, B04 is 635.0, B02 is 359.0, DOY is 211.0, B03 is 759.0 B04 is PID is 65']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 635.0, PID is 6069.0, B02 is 359.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 635.0, PID is 6069.0, B02 is 359.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '6', '3', '5', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '6', '3', '5', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '2', '9', '8', '9']]\n",
      "decoded_data: ['B04 is 635.0, PID is 6069.0, B02 is 359.0, DOY is 211.0, B03 is 759.0 PID is 72989']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 359.0, PID is 6069.0, B04 is 635.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 359.0, PID is 6069.0, B04 is 635.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '5', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '6', '3', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '5', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '6', '3', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '7', '2', '9', '8', '9']]\n",
      "decoded_data: ['B02 is 359.0, PID is 6069.0, B04 is 635.0, DOY is 211.0, B03 is 759.0 B04 is 72989']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 359.0, PID is 6069.0, B04 is 635.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 359.0, PID is 6069.0, B04 is 635.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '5', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '6', '3', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '5', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '6', '3', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '3', '6', '5', '9', '8', '.', '0', ',']]\n",
      "decoded_data: ['B02 is 359.0, PID is 6069.0, B04 is 635.0, DOY is 211.0, B03 is 759.0736598.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 635.0, B02 is 359.0, PID is 6069.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 635.0, B02 is 359.0, PID is 6069.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '6', '3', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '6', '3', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '9', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '3', '4', '1', '.', '0', ',', '', 'B02']]\n",
      "decoded_data: ['B04 is 635.0, B02 is 359.0, PID is 6069.0, DOY is 211.0, B03 is 759.07341.0, B02']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 359.0, B04 is 635.0, PID is 6069.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 359.0, B04 is 635.0, PID is 6069.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '5', '9', '.', '0', ',', '', 'B04', 'is', '', '6', '3', '5', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '5', '9', '.', '0', ',', '', 'B04', 'is', '', '6', '3', '5', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '6', '7', '3', '5', '9']]\n",
      "decoded_data: ['B02 is 359.0, B04 is 635.0, PID is 6069.0, DOY is 211.0, B03 is 759.0 B04 is 67359']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6069.0, B04 is 635.0, DOY is 211.0, B02 is 359.0, B03 is']\n",
      "prompt: PID is 6069.0, B04 is 635.0, DOY is 211.0, B02 is 359.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '0', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '6', '3', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '9', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '0', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '6', '3', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '2', '9', '8', '9']]\n",
      "decoded_data: ['PID is 6069.0, B04 is 635.0, DOY is 211.0, B02 is 359.0, B03 is 759.0 PID is 72989']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6069.0, DOY is 211.0, B04 is 635.0, B02 is 359.0, B03 is']\n",
      "prompt: PID is 6069.0, DOY is 211.0, B04 is 635.0, B02 is 359.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '0', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '3', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '9', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '0', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '3', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '3', '6', '5', '9', '.', '0', ',', '']]\n",
      "decoded_data: ['PID is 6069.0, DOY is 211.0, B04 is 635.0, B02 is 359.0, B03 is 759.073659.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6069.0, B04 is 635.0, B02 is 359.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 6069.0, B04 is 635.0, B02 is 359.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '6', '3', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '9', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '6', '3', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '3', '6', '5', '9', '.', '0', ',', '']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6069.0, B04 is 635.0, B02 is 359.0, B03 is 759.073659.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 635.0, DOY is 211.0, PID is 6069.0, B02 is 359.0, B03 is']\n",
      "prompt: B04 is 635.0, DOY is 211.0, PID is 6069.0, B02 is 359.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '6', '3', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '9', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '6', '3', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '3', '5', '9', '.', '0', ',', '', 'PID']]\n",
      "decoded_data: ['B04 is 635.0, DOY is 211.0, PID is 6069.0, B02 is 359.0, B03 is 759.07359.0, PID']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 359.0, B04 is 635.0, PID is 6069.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 359.0, B04 is 635.0, PID is 6069.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '5', '9', '.', '0', ',', '', 'B04', 'is', '', '6', '3', '5', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '5', '9', '.', '0', ',', '', 'B04', 'is', '', '6', '3', '5', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '3', '4', '7', '5', '9', '.', '0', ',']]\n",
      "decoded_data: ['B02 is 359.0, B04 is 635.0, PID is 6069.0, DOY is 211.0, B03 is 759.0734759.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 635.0, PID is 6069.0, DOY is 211.0, B02 is 359.0, B03 is']\n",
      "prompt: B04 is 635.0, PID is 6069.0, DOY is 211.0, B02 is 359.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '6', '3', '5', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '9', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '6', '3', '5', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '2', '9', '8', '9']]\n",
      "decoded_data: ['B04 is 635.0, PID is 6069.0, DOY is 211.0, B02 is 359.0, B03 is 759.0 PID is 72989']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 635.0, PID is 6069.0, DOY is 211.0, B02 is 359.0, B03 is']\n",
      "prompt: B04 is 635.0, PID is 6069.0, DOY is 211.0, B02 is 359.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '6', '3', '5', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '9', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '6', '3', '5', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '3']]\n",
      "decoded_data: ['B04 is 635.0, PID is 6069.0, DOY is 211.0, B02 is 359.0, B03 is 759.0 B04 is PID is 73']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 635.0, DOY is 211.0, PID is 6069.0, B02 is 359.0, B03 is']\n",
      "prompt: B04 is 635.0, DOY is 211.0, PID is 6069.0, B02 is 359.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '6', '3', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '9', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 22%|       | 184/829 [05:24<15:24,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B04', 'is', '', '6', '3', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '0', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '2', '9', '8', '7', '.', '0', ',', '']]\n",
      "decoded_data: ['B04 is 635.0, DOY is 211.0, PID is 6069.0, B02 is 359.0, B03 is 759.072987.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6169.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 6169.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '6', '1', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '7', '1', '.', '0', ',', '', 'B04', 'is']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6169.0, B04 is 612.0, B03 is 754.0, B02 is 357.0571.0, B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6169.0, B03 is 754.0, B04 is 612.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 6169.0, B03 is 754.0, B04 is 612.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '1', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '6', '1', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '1', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '6', '1', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '2', '1', '9', '1', '9', '3', '.', '0']]\n",
      "decoded_data: ['PID is 6169.0, B03 is 754.0, B04 is 612.0, DOY is 211.0, B02 is 357.06219193.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 754.0, PID is 6169.0, DOY is 211.0, B04 is 612.0, B02 is']\n",
      "prompt: B03 is 754.0, PID is 6169.0, DOY is 211.0, B04 is 612.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '5', '4', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '1', '2', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '5', '4', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '1', '2', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '3', '2', '1', '9', '1', '.', '0', '1', '.']]\n",
      "decoded_data: ['B03 is 754.0, PID is 6169.0, DOY is 211.0, B04 is 612.0, B02 is 357.032191.01.']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 612.0, PID is 6169.0, B03 is 754.0, B02 is']\n",
      "prompt: DOY is 211.0, B04 is 612.0, PID is 6169.0, B03 is 754.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '1', '2', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '4', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '1', '2', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B03', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 612.0, PID is 6169.0, B03 is 754.0, B02 is 357.0 PID is B03 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 612.0, DOY is 211.0, PID is 6169.0, B03 is 754.0, B02 is']\n",
      "prompt: B04 is 612.0, DOY is 211.0, PID is 6169.0, B03 is 754.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '6', '1', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '4', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '6', '1', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '3', '6']]\n",
      "decoded_data: ['B04 is 612.0, DOY is 211.0, PID is 6169.0, B03 is 754.0, B02 is 357.0 PID is B04 is 36']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 754.0, PID is 6169.0, DOY is 211.0, B04 is 612.0, B02 is']\n",
      "prompt: B03 is 754.0, PID is 6169.0, DOY is 211.0, B04 is 612.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '5', '4', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '1', '2', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '5', '4', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '1', '2', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '5', '7', '1', '7', '1', '7', '1', '.']]\n",
      "decoded_data: ['B03 is 754.0, PID is 6169.0, DOY is 211.0, B04 is 612.0, B02 is 357.065717171.']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 754.0, B04 is 612.0, PID is 6169.0, DOY is 211.0, B02 is']\n",
      "prompt: B03 is 754.0, B04 is 612.0, PID is 6169.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '6', '1', '2', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '6', '1', '2', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '3', '5']]\n",
      "decoded_data: ['B03 is 754.0, B04 is 612.0, PID is 6169.0, DOY is 211.0, B02 is 357.0 PID is B04 is 35']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6169.0, B04 is 612.0, DOY is 211.0, B03 is 754.0, B02 is']\n",
      "prompt: PID is 6169.0, B04 is 612.0, DOY is 211.0, B03 is 754.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '1', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '6', '1', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '4', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '1', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '6', '1', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '3', '6']]\n",
      "decoded_data: ['PID is 6169.0, B04 is 612.0, DOY is 211.0, B03 is 754.0, B02 is 357.0 B04 is PID is 36']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 612.0, B03 is 754.0, PID is 6169.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 612.0, B03 is 754.0, PID is 6169.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '6', '1', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '4', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '6', '1', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '4', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '5', '7', '1', '.', '0', '1', '.', '0']]\n",
      "decoded_data: ['B04 is 612.0, B03 is 754.0, PID is 6169.0, DOY is 211.0, B02 is 357.06571.01.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 612.0, B03 is 754.0, DOY is 211.0, PID is 6169.0, B02 is']\n",
      "prompt: B04 is 612.0, B03 is 754.0, DOY is 211.0, PID is 6169.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '6', '1', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '9', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '6', '1', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '6', '1']]\n",
      "decoded_data: ['B04 is 612.0, B03 is 754.0, DOY is 211.0, PID is 6169.0, B02 is 357.0 PID is B04 is 61']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 612.0, DOY is 211.0, PID is 6169.0, B03 is 754.0, B02 is']\n",
      "prompt: B04 is 612.0, DOY is 211.0, PID is 6169.0, B03 is 754.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '6', '1', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '4', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '6', '1', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '7', '1', '7', '1', '.', '0', ',', '']]\n",
      "decoded_data: ['B04 is 612.0, DOY is 211.0, PID is 6169.0, B03 is 754.0, B02 is 357.057171.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 754.0, B04 is 612.0, PID is 6169.0, B02 is']\n",
      "prompt: DOY is 211.0, B03 is 754.0, B04 is 612.0, PID is 6169.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '6', '1', '2', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '9', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '6', '1', '2', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B02', 'is', '', '3', '5']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 754.0, B04 is 612.0, PID is 6169.0, B02 is 357.0 PID is B02 is 35']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 612.0, B03 is 754.0, PID is 6169.0, B02 is']\n",
      "prompt: DOY is 211.0, B04 is 612.0, B03 is 754.0, PID is 6169.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '1', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '4', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '9', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '1', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '4', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '3', '2', '1', '.', '0', ',', '', 'PID']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 612.0, B03 is 754.0, PID is 6169.0, B02 is 357.0 321.0, PID']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 754.0, B04 is 612.0, PID is 6169.0, B02 is']\n",
      "prompt: DOY is 211.0, B03 is 754.0, B04 is 612.0, PID is 6169.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '6', '1', '2', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '9', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '6', '1', '2', '.', '0', ',', '', 'PID', 'is', '', '6', '1', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B03', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 754.0, B04 is 612.0, PID is 6169.0, B02 is 357.0 B04 is B03 is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6169.0, DOY is 211.0, B03 is 754.0, B04 is 612.0, B02 is']\n",
      "prompt: PID is 6169.0, DOY is 211.0, B03 is 754.0, B04 is 612.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '1', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '6', '1', '2', '.', '0', ',', '', 'B02', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 22%|       | 185/829 [05:26<18:14,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '6', '1', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '6', '1', '2', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['PID is 6169.0, DOY is 211.0, B03 is 754.0, B04 is 612.0, B02 is 357.0 B03 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6269.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 6269.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '9', '.', '0', ',', '', 'B02', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|       | 186/829 [05:27<13:44,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '2', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '6', '.', '0', ',', '', 'B04', 'is', '', '6', '1', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '4', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '3', '4', '7', '3', '8', 'is', '', 'B04']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6269.0, B02 is 366.0, B04 is 616.0, B03 is 747.0734738 is B04']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6369.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 6369.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '9', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '3', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '3', '0', '3', '0', '5', '9', '.', '0']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6369.0, B04 is 592.0, B03 is 713.0, B02 is 359.0 303059.0']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6369.0, B04 is 592.0, B03 is 713.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 6369.0, B04 is 592.0, B03 is 713.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '3', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '9', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '3', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '9', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '9', '2', '1', '9', '3', '.', '0', 'is', '']]\n",
      "decoded_data: ['PID is 6369.0, B04 is 592.0, B03 is 713.0, DOY is 211.0, B02 is 359.092193.0 is ']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 713.0, B04 is 592.0, DOY is 211.0, PID is 6369.0, B02 is']\n",
      "prompt: B03 is 713.0, B04 is 592.0, DOY is 211.0, PID is 6369.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '1', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '9', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '9', '.', '0', ',', '', 'B02', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|       | 187/829 [05:28<11:55,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B03', 'is', '', '7', '1', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '9', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '9', '2', '.', '0', ',', '', 'PID', 'is', '']]\n",
      "decoded_data: ['B03 is 713.0, B04 is 592.0, DOY is 211.0, PID is 6369.0, B02 is 359.092.0, PID is ']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 713.0, B04 is 592.0, PID is 6369.0, B02 is']\n",
      "prompt: DOY is 211.0, B03 is 713.0, B04 is 592.0, PID is 6369.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '9', '2', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '9', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '9', '2', '.', '0', ',', '', 'PID', 'is', '', '6', '3', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '9', '2', '1', '9', 'is', '', 'PID', 'is', '']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 713.0, B04 is 592.0, PID is 6369.0, B02 is 359.09219 is PID is ']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6469.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 6469.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '9', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '5', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '7', '6', '7', '6', '8', '3', '.', '0']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6469.0, B02 is 320.0, B04 is 505.0, B03 is 683.06767683.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 505.0, PID is 6469.0, B02 is 320.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 505.0, PID is 6469.0, B02 is 320.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '0', '5', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '0', '5', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '8', '3', '8', '3', '2', '.', '0', ',']]\n",
      "decoded_data: ['B04 is 505.0, PID is 6469.0, B02 is 320.0, DOY is 211.0, B03 is 683.0683832.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 320.0, B04 is 505.0, PID is 6469.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 320.0, B04 is 505.0, PID is 6469.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '5', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '9', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|       | 188/829 [05:28<10:34,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '5', '.', '0', ',', '', 'PID', 'is', '', '6', '4', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '2', '8', '3', '.', '0', '.', '0', ',']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 320.0, B04 is 505.0, PID is 6469.0, B03 is 683.06283.0.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6469.0, B02 is 320.0, B04 is 505.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 6469.0, B02 is 320.0, B04 is 505.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '4', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '4', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '0', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '7', '8', '3', '4', '6', '7', '3', '4']]\n",
      "decoded_data: ['PID is 6469.0, B02 is 320.0, B04 is 505.0, DOY is 211.0, B03 is 683.0678346734']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6569.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 6569.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '9', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '2', '2', '4', '2', '.', '0', '2', '.', '0']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6569.0, B03 is 721.0, B04 is 425.0, B02 is 252.02242.02.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 425.0, PID is 6569.0, B03 is 721.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 425.0, PID is 6569.0, B03 is 721.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '2', '5', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '2', '5', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '2', '9', '2', '9', '2', '5', '2', '4']]\n",
      "decoded_data: ['B04 is 425.0, PID is 6569.0, B03 is 721.0, DOY is 211.0, B02 is 252.0 29292524']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6569.0, B03 is 721.0, B04 is 425.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 6569.0, B03 is 721.0, B04 is 425.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '5', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '2', '5', '2', '.', '0', '2', '9', '2', '.']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6569.0, B03 is 721.0, B04 is 425.0, B02 is 252.0252.0292.']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 721.0, PID is 6569.0, B04 is 425.0, B02 is']\n",
      "prompt: DOY is 211.0, B03 is 721.0, PID is 6569.0, B04 is 425.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '5', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '2', '4', '8', '0', '2', '5', '2', '.']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 721.0, PID is 6569.0, B04 is 425.0, B02 is 252.0 2480252.']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6569.0, B03 is 721.0, B04 is 425.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 6569.0, B03 is 721.0, B04 is 425.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '5', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '2', '5', '2', '9', '2']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6569.0, B03 is 721.0, B04 is 425.0, B02 is 252.0 PID is 25292']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6569.0, B03 is 721.0, DOY is 211.0, B04 is 425.0, B02 is']\n",
      "prompt: PID is 6569.0, B03 is 721.0, DOY is 211.0, B04 is 425.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '5', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '5', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '5', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '3', '2']]\n",
      "decoded_data: ['PID is 6569.0, B03 is 721.0, DOY is 211.0, B04 is 425.0, B02 is 252.0 PID is B04 is 32']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 425.0, PID is 6569.0, DOY is 211.0, B03 is 721.0, B02 is']\n",
      "prompt: B04 is 425.0, PID is 6569.0, DOY is 211.0, B03 is 721.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '2', '5', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '2', '5', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '8', '0', '2', '.', '0', '2', '9', '2', '.']]\n",
      "decoded_data: ['B04 is 425.0, PID is 6569.0, DOY is 211.0, B03 is 721.0, B02 is 252.0802.0292.']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 425.0, DOY is 211.0, PID is 6569.0, B03 is 721.0, B02 is']\n",
      "prompt: B04 is 425.0, DOY is 211.0, PID is 6569.0, B03 is 721.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '2', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '2', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '6', '1', '8', '0', '2']]\n",
      "decoded_data: ['B04 is 425.0, DOY is 211.0, PID is 6569.0, B03 is 721.0, B02 is 252.0 PID is 61802']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 721.0, DOY is 211.0, PID is 6569.0, B04 is 425.0, B02 is']\n",
      "prompt: B03 is 721.0, DOY is 211.0, PID is 6569.0, B04 is 425.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '2', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '5', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '2', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '2', '9', '2', '5', '2']]\n",
      "decoded_data: ['B03 is 721.0, DOY is 211.0, PID is 6569.0, B04 is 425.0, B02 is 252.0 PID is 29252']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 721.0, B04 is 425.0, PID is 6569.0, B02 is']\n",
      "prompt: DOY is 211.0, B03 is 721.0, B04 is 425.0, PID is 6569.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '5', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '9', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '5', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'DOY', 'is', '', '2', '2']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 721.0, B04 is 425.0, PID is 6569.0, B02 is 251.0 B04 is DOY is 22']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 721.0, PID is 6569.0, B04 is 425.0, B02 is']\n",
      "prompt: DOY is 211.0, B03 is 721.0, PID is 6569.0, B04 is 425.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '5', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '2', '5', '1', '2', '.', '0', '2', '.']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 721.0, PID is 6569.0, B04 is 425.0, B02 is 252.0 2512.02.']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 425.0, DOY is 211.0, B03 is 721.0, PID is 6569.0, B02 is']\n",
      "prompt: B04 is 425.0, DOY is 211.0, B03 is 721.0, PID is 6569.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '4', '2', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '9', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '4', '2', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '2', '2', '9', '2', '.', '0', '.', '0']]\n",
      "decoded_data: ['B04 is 425.0, DOY is 211.0, B03 is 721.0, PID is 6569.0, B02 is 251.0 2292.0.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 721.0, DOY is 211.0, B04 is 425.0, PID is 6569.0, B02 is']\n",
      "prompt: B03 is 721.0, DOY is 211.0, B04 is 425.0, PID is 6569.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '2', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '5', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '9', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '2', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '5', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '2', '.', '0', '0', '.', '0', ',', '']]\n",
      "decoded_data: ['B03 is 721.0, DOY is 211.0, B04 is 425.0, PID is 6569.0, B02 is 252.0 2.00.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6569.0, B03 is 721.0, B04 is 425.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 6569.0, B03 is 721.0, B04 is 425.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '5', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '5', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '2', '9', '2', '9', '2']]\n",
      "decoded_data: ['PID is 6569.0, B03 is 721.0, B04 is 425.0, DOY is 211.0, B02 is 252.0 B04 is 29292']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 721.0, DOY is 211.0, PID is 6569.0, B04 is 425.0, B02 is']\n",
      "prompt: B03 is 721.0, DOY is 211.0, PID is 6569.0, B04 is 425.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '2', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '5', '.', '0', ',', '', 'B02', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 23%|       | 189/829 [05:31<14:56,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B03', 'is', '', '7', '2', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '5', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '4', '2', '5', '.', '0', ',', '', 'B02', 'is', '', '2', '5', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '2', '.', '0', '2', '5', '2', '.', '0', '.']]\n",
      "decoded_data: ['B03 is 721.0, DOY is 211.0, PID is 6569.0, B04 is 425.0, B02 is 252.02.0252.0.']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6669.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 6669.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '9', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '3', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '6', '3', '1', '.', '0', 'is', '', 'B03']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6669.0, B03 is 733.0, B02 is 341.0, B04 is 531.05631.0 is B03']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 733.0, PID is 6669.0, DOY is 211.0, B02 is 341.0, B04 is']\n",
      "prompt: B03 is 733.0, PID is 6669.0, DOY is 211.0, B02 is 341.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '3', '3', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '3', '3', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '2', '3', '1', '.', '0', '1', '.', '0']]\n",
      "decoded_data: ['B03 is 733.0, PID is 6669.0, DOY is 211.0, B02 is 341.0, B04 is 531.05231.01.0']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6669.0, B02 is 341.0, B03 is 733.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 6669.0, B02 is 341.0, B03 is 733.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '3', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', '7', '2', '3', '6', '1']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6669.0, B02 is 341.0, B03 is 733.0, B04 is 531.0 B03 is 72361']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 733.0, B02 is 341.0, PID is 6669.0, DOY is 211.0, B04 is']\n",
      "prompt: B03 is 733.0, B02 is 341.0, PID is 6669.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '3', '3', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '3', '3', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '7', '2', '3', '1', '9', '2', '.', '0']]\n",
      "decoded_data: ['B03 is 733.0, B02 is 341.0, PID is 6669.0, DOY is 211.0, B04 is 531.05723192.0']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6669.0, DOY is 211.0, B02 is 341.0, B03 is 733.0, B04 is']\n",
      "prompt: PID is 6669.0, DOY is 211.0, B02 is 341.0, B03 is 733.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '6', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '3', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '6', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '3', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', '6', '7', '2', '3', '1']]\n",
      "decoded_data: ['PID is 6669.0, DOY is 211.0, B02 is 341.0, B03 is 733.0, B04 is 531.0 B03 is 67231']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 733.0, PID is 6669.0, B02 is 341.0, DOY is 211.0, B04 is']\n",
      "prompt: B03 is 733.0, PID is 6669.0, B02 is 341.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '3', '3', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '3', '3', '.', '0', ',', '', 'PID', 'is', '', '6', '6', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '6', '7', '2', '3', '1', '.', '0', '0']]\n",
      "decoded_data: ['B03 is 733.0, PID is 6669.0, B02 is 341.0, DOY is 211.0, B04 is 531.0567231.00']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6669.0, B02 is 341.0, B03 is 733.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 6669.0, B02 is 341.0, B03 is 733.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '6', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|       | 190/829 [05:32<14:03,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '6', '6', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '3', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '2', '3', '1', '9', '2', '3', '1', '0']]\n",
      "decoded_data: ['PID is 6669.0, B02 is 341.0, B03 is 733.0, DOY is 211.0, B04 is 531.0523192310']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6769.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 6769.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '7', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '7', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '3', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '6', '3', '1', '9', '2']]\n",
      "decoded_data: ['PID is 6769.0, DOY is 211.0, B02 is 353.0, B04 is 602.0, B03 is 719.0 B04 is 63192']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6769.0, DOY is 211.0, B04 is 602.0, B02 is 353.0, B03 is']\n",
      "prompt: PID is 6769.0, DOY is 211.0, B04 is 602.0, B02 is 353.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '7', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '2', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '6', '7', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '2', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', '6', '2']]\n",
      "decoded_data: ['PID is 6769.0, DOY is 211.0, B04 is 602.0, B02 is 353.0, B03 is 719.0 B04 is B04 is 62']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6769.0, B04 is 602.0, B02 is 353.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 6769.0, B04 is 602.0, B02 is 353.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '2', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '3', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|       | 191/829 [05:32<11:39,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '7', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '2', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '8', '3', '0', '0', ',', '', 'B04', 'is', '']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6769.0, B04 is 602.0, B02 is 353.0, B03 is 719.08300, B04 is ']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 6869.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 6869.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '9', '.', '0', ',', '', 'B02', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|       | 192/829 [05:33<09:05,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '6', '8', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '3', '0', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '8', '8', '8', '8', '8', '8', '8', '8']]\n",
      "decoded_data: ['DOY is 211.0, PID is 6869.0, B02 is 320.0, B04 is 530.0, B03 is 688.0688888888']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 6969.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 6969.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '6', '9', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|       | 193/829 [05:33<07:17,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '6', '9', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '4', '6', '.', '0', ',', '', 'B04', 'is', '', '4', '8', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '8', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '2', '8', '8', '8', '8', '8', '8', '8', '8']]\n",
      "decoded_data: ['PID is 6969.0, DOY is 211.0, B03 is 646.0, B04 is 481.0, B02 is 288.0288888888']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 7069.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 7069.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '9', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '3', '.', '0', ',', '', 'B04', 'is', '', '6', '2', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '4', '7', '3', '.', '0', ',', '', 'B04']]\n",
      "decoded_data: ['DOY is 211.0, PID is 7069.0, B02 is 363.0, B04 is 620.0, B03 is 711.07473.0, B04']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 620.0, B02 is 363.0, PID is 7069.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 620.0, B02 is 363.0, PID is 7069.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '2', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '3', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '9', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '2', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '3', '.', '0', ',', '', 'PID', 'is', '', '7', '0', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '7', '0', 'B02', 'is', '', 'B04', 'is', '']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 620.0, B02 is 363.0, PID is 7069.0, B03 is 711.0 70B02 is B04 is ']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7069.0, B04 is 620.0, DOY is 211.0, B02 is 363.0, B03 is']\n",
      "prompt: PID is 7069.0, B04 is 620.0, DOY is 211.0, B02 is 363.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '0', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '6', '2', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '3', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|       | 194/829 [05:33<06:53,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '7', '0', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '6', '2', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '2', '2', '1', '4', '7', '1', '9', '4']]\n",
      "decoded_data: ['PID is 7069.0, B04 is 620.0, DOY is 211.0, B02 is 363.0, B03 is 711.0622147194']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 7169.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 7169.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '9', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '7', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '6', '0', '1', '2', '9', '0', '1', '.']]\n",
      "decoded_data: ['DOY is 211.0, PID is 7169.0, B02 is 362.0, B03 is 707.0, B04 is 601.0 6012901.']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 362.0, PID is 7169.0, DOY is 211.0, B03 is 707.0, B04 is']\n",
      "prompt: B02 is 362.0, PID is 7169.0, DOY is 211.0, B03 is 707.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '6', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '6', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '7', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'PID', 'is', '', '6', '0']]\n",
      "decoded_data: ['B02 is 362.0, PID is 7169.0, DOY is 211.0, B03 is 707.0, B04 is 601.0 PID is PID is 60']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 707.0, DOY is 211.0, PID is 7169.0, B02 is 362.0, B04 is']\n",
      "prompt: B03 is 707.0, DOY is 211.0, PID is 7169.0, B02 is 362.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '0', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '2', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '0', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '2', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '6', '6', '5', '3', '.', '0', ',', '']]\n",
      "decoded_data: ['B03 is 707.0, DOY is 211.0, PID is 7169.0, B02 is 362.0, B04 is 601.0 6653.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 362.0, B03 is 707.0, DOY is 211.0, PID is 7169.0, B04 is']\n",
      "prompt: B02 is 362.0, B03 is 707.0, DOY is 211.0, PID is 7169.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '6', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '6', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '6', '2', '.', '0', '3', '0', '2', '.']]\n",
      "decoded_data: ['B02 is 362.0, B03 is 707.0, DOY is 211.0, PID is 7169.0, B04 is 601.0 62.0302.']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 362.0, B03 is 707.0, DOY is 211.0, PID is 7169.0, B04 is']\n",
      "prompt: B02 is 362.0, B03 is 707.0, DOY is 211.0, PID is 7169.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '6', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '6', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '6', '4', '.', '0', '.', '0', ',', '']]\n",
      "decoded_data: ['B02 is 362.0, B03 is 707.0, DOY is 211.0, PID is 7169.0, B04 is 601.0 64.0.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 362.0, B03 is 707.0, PID is 7169.0, DOY is 211.0, B04 is']\n",
      "prompt: B02 is 362.0, B03 is 707.0, PID is 7169.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '6', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '7', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '6', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '7', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '6', '2', '0', '1', '9']]\n",
      "decoded_data: ['B02 is 362.0, B03 is 707.0, PID is 7169.0, DOY is 211.0, B04 is 601.0 PID is 62019']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 362.0, B03 is 707.0, PID is 7169.0, B04 is']\n",
      "prompt: DOY is 211.0, B02 is 362.0, B03 is 707.0, PID is 7169.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '7', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '7', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '6', '4', '0', '1', '2']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 362.0, B03 is 707.0, PID is 7169.0, B04 is 601.0 B04 is 64012']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 362.0, PID is 7169.0, B03 is 707.0, DOY is 211.0, B04 is']\n",
      "prompt: B02 is 362.0, PID is 7169.0, B03 is 707.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '6', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '6', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '6', '4', '8', '0', '1']]\n",
      "decoded_data: ['B02 is 362.0, PID is 7169.0, B03 is 707.0, DOY is 211.0, B04 is 601.0 PID is 64801']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 707.0, B02 is 362.0, PID is 7169.0, DOY is 211.0, B04 is']\n",
      "prompt: B03 is 707.0, B02 is 362.0, PID is 7169.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '0', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '0', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '6', '0', '1', '2', '0']]\n",
      "decoded_data: ['B03 is 707.0, B02 is 362.0, PID is 7169.0, DOY is 211.0, B04 is 601.0 PID is 60120']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 362.0, PID is 7169.0, B03 is 707.0, DOY is 211.0, B04 is']\n",
      "prompt: B02 is 362.0, PID is 7169.0, B03 is 707.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '6', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '6', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '6', '2', '4', '8', '0', '1', '.', '0']]\n",
      "decoded_data: ['B02 is 362.0, PID is 7169.0, B03 is 707.0, DOY is 211.0, B04 is 601.0 624801.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 362.0, DOY is 211.0, B03 is 707.0, PID is 7169.0, B04 is']\n",
      "prompt: B02 is 362.0, DOY is 211.0, B03 is 707.0, PID is 7169.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '6', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '7', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '6', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '7', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '4', '0', '1', '.', '0', ',', '', 'B03']]\n",
      "decoded_data: ['B02 is 362.0, DOY is 211.0, B03 is 707.0, PID is 7169.0, B04 is 601.06401.0, B03']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7169.0, DOY is 211.0, B02 is 362.0, B03 is 707.0, B04 is']\n",
      "prompt: PID is 7169.0, DOY is 211.0, B02 is 362.0, B03 is 707.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '1', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '1', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '2', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '7', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B03', 'is', '', '6', '0']]\n",
      "decoded_data: ['PID is 7169.0, DOY is 211.0, B02 is 362.0, B03 is 707.0, B04 is 601.0 PID is B03 is 60']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 707.0, B02 is 362.0, PID is 7169.0, B04 is']\n",
      "prompt: DOY is 211.0, B03 is 707.0, B02 is 362.0, PID is 7169.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '6', '4', '0', '1', '.', '0', '1', '.']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 707.0, B02 is 362.0, PID is 7169.0, B04 is 601.0 6401.01.']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 707.0, DOY is 211.0, B02 is 362.0, PID is 7169.0, B04 is']\n",
      "prompt: B03 is 707.0, DOY is 211.0, B02 is 362.0, PID is 7169.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '0', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '0', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '1', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'DOY', 'is', '', 'PID', 'is', '', '2', '0']]\n",
      "decoded_data: ['B03 is 707.0, DOY is 211.0, B02 is 362.0, PID is 7169.0, B04 is 601.0 DOY is PID is 20']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7169.0, B02 is 362.0, DOY is 211.0, B03 is 707.0, B04 is']\n",
      "prompt: PID is 7169.0, B02 is 362.0, DOY is 211.0, B03 is 707.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '1', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '7', '.', '0', ',', '', 'B04', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 24%|       | 195/829 [05:36<12:03,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '7', '1', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '7', '.', '0', ',', '', 'B04', 'is', '', '6', '0', '1', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '6', '0', '1', '2', '9', '0', '1', '.']]\n",
      "decoded_data: ['PID is 7169.0, B02 is 362.0, DOY is 211.0, B03 is 707.0, B04 is 601.0 6012901.']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7269.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 7269.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '2', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '2', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '9']]\n",
      "decoded_data: ['PID is 7269.0, DOY is 211.0, B04 is 561.0, B02 is 346.0, B03 is 709.0 B04 is PID is 79']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 561.0, PID is 7269.0, B02 is 346.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 561.0, PID is 7269.0, B02 is 346.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '6', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '2', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '6', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '2', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['B04 is 561.0, PID is 7269.0, B02 is 346.0, DOY is 211.0, B03 is 709.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7269.0, B04 is 561.0, DOY is 211.0, B02 is 346.0, B03 is']\n",
      "prompt: PID is 7269.0, B04 is 561.0, DOY is 211.0, B02 is 346.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '2', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '2', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'DOY', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['PID is 7269.0, B04 is 561.0, DOY is 211.0, B02 is 346.0, B03 is 709.0 B04 is DOY is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7269.0, B02 is 346.0, B04 is 561.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 7269.0, B02 is 346.0, B04 is 561.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '2', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '2', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', '5', '6']]\n",
      "decoded_data: ['PID is 7269.0, B02 is 346.0, B04 is 561.0, DOY is 211.0, B03 is 709.0 B04 is B04 is 56']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 561.0, PID is 7269.0, B02 is 346.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 561.0, PID is 7269.0, B02 is 346.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '2', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '2', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '0']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 561.0, PID is 7269.0, B02 is 346.0, B03 is 709.0 B04 is PID is 70']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7269.0, DOY is 211.0, B02 is 346.0, B04 is 561.0, B03 is']\n",
      "prompt: PID is 7269.0, DOY is 211.0, B02 is 346.0, B04 is 561.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '2', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '2', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'DOY', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['PID is 7269.0, DOY is 211.0, B02 is 346.0, B04 is 561.0, B03 is 709.0 B04 is DOY is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 561.0, DOY is 211.0, PID is 7269.0, B02 is 346.0, B03 is']\n",
      "prompt: B04 is 561.0, DOY is 211.0, PID is 7269.0, B02 is 346.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '6', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '2', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '6', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '2', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '9', '0', '9', '0']]\n",
      "decoded_data: ['B04 is 561.0, DOY is 211.0, PID is 7269.0, B02 is 346.0, B03 is 709.0 PID is 79090']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7269.0, B04 is 561.0, B02 is 346.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 7269.0, B04 is 561.0, B02 is 346.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '2', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '2', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '7', '0', '9', '0', '9']]\n",
      "decoded_data: ['PID is 7269.0, B04 is 561.0, B02 is 346.0, DOY is 211.0, B03 is 709.0 B04 is 70909']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 7269.0, B04 is 561.0, B02 is 346.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 7269.0, B04 is 561.0, B02 is 346.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '2', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '2', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['DOY is 211.0, PID is 7269.0, B04 is 561.0, B02 is 346.0, B03 is 709.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 561.0, B02 is 346.0, PID is 7269.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 561.0, B02 is 346.0, PID is 7269.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '6', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '6', '.', '0', ',', '', 'PID', 'is', '', '7', '2', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '6', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '6', '.', '0', ',', '', 'PID', 'is', '', '7', '2', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '2', '0', '9', '0']]\n",
      "decoded_data: ['B04 is 561.0, B02 is 346.0, PID is 7269.0, DOY is 211.0, B03 is 709.0 PID is 72090']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7269.0, B04 is 561.0, DOY is 211.0, B02 is 346.0, B03 is']\n",
      "prompt: PID is 7269.0, B04 is 561.0, DOY is 211.0, B02 is 346.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '2', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '6', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '2', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '6', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', '5', '6']]\n",
      "decoded_data: ['PID is 7269.0, B04 is 561.0, DOY is 211.0, B02 is 346.0, B03 is 709.0 B04 is B04 is 56']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 561.0, B02 is 346.0, PID is 7269.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 561.0, B02 is 346.0, PID is 7269.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '6', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '6', '.', '0', ',', '', 'PID', 'is', '', '7', '2', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '6', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '6', '.', '0', ',', '', 'PID', 'is', '', '7', '2', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '2']]\n",
      "decoded_data: ['B04 is 561.0, B02 is 346.0, PID is 7269.0, DOY is 211.0, B03 is 709.0 B04 is PID is 72']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7269.0, DOY is 211.0, B02 is 346.0, B04 is 561.0, B03 is']\n",
      "prompt: PID is 7269.0, DOY is 211.0, B02 is 346.0, B04 is 561.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '2', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '1', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|       | 196/829 [05:38<14:43,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '7', '2', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '6', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '9', '0', '9', '0', ',', '', 'B04', 'is', '']]\n",
      "decoded_data: ['PID is 7269.0, DOY is 211.0, B02 is 346.0, B04 is 561.0, B03 is 709.09090, B04 is ']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 7369.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 7369.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '3', '6', '9', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '3', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '9', '3', '4', '9', '0', '3', '.']]\n",
      "decoded_data: ['DOY is 211.0, PID is 7369.0, B03 is 710.0, B02 is 344.0, B04 is 560.0 5934903.']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7369.0, B03 is 710.0, B02 is 344.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 7369.0, B03 is 710.0, B02 is 344.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '3', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '3', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '6', '0', '7', '3']]\n",
      "decoded_data: ['PID is 7369.0, B03 is 710.0, B02 is 344.0, DOY is 211.0, B04 is 560.0 PID is 56073']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7369.0, B02 is 344.0, B03 is 710.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 7369.0, B02 is 344.0, B03 is 710.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '3', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '3', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '6', '0', '4', '9', '4', '.', '0']]\n",
      "decoded_data: ['PID is 7369.0, B02 is 344.0, B03 is 710.0, DOY is 211.0, B04 is 560.0 560494.0']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 7369.0, B02 is 344.0, B03 is 710.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 7369.0, B02 is 344.0, B03 is 710.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '3', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '3', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '4', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'DOY', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['DOY is 211.0, PID is 7369.0, B02 is 344.0, B03 is 710.0, B04 is 560.0 PID is DOY is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 344.0, PID is 7369.0, B03 is 710.0, B04 is']\n",
      "prompt: DOY is 211.0, B02 is 344.0, PID is 7369.0, B03 is 710.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '4', '.', '0', ',', '', 'PID', 'is', '', '7', '3', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '4', '.', '0', ',', '', 'PID', 'is', '', '7', '3', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B03', 'is', '', '7', '4']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 344.0, PID is 7369.0, B03 is 710.0, B04 is 560.0 PID is B03 is 74']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 710.0, DOY is 211.0, B02 is 344.0, PID is 7369.0, B04 is']\n",
      "prompt: B03 is 710.0, DOY is 211.0, B02 is 344.0, PID is 7369.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '1', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '4', '.', '0', ',', '', 'PID', 'is', '', '7', '3', '6', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '1', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '4', '.', '0', ',', '', 'PID', 'is', '', '7', '3', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '6', '0', '1', '0']]\n",
      "decoded_data: ['B03 is 710.0, DOY is 211.0, B02 is 344.0, PID is 7369.0, B04 is 560.0 PID is 56010']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 344.0, DOY is 211.0, B03 is 710.0, PID is 7369.0, B04 is']\n",
      "prompt: B02 is 344.0, DOY is 211.0, B03 is 710.0, PID is 7369.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '4', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '0', '.', '0', ',', '', 'PID', 'is', '', '7', '3', '6', '9', '.', '0', ',', '', 'B04', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|       | 197/829 [05:39<13:56,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B02', 'is', '', '3', '4', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '0', '.', '0', ',', '', 'PID', 'is', '', '7', '3', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '6', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '6', '0', '7', '0', 'is', '', 'DOY', 'is']]\n",
      "decoded_data: ['B02 is 344.0, DOY is 211.0, B03 is 710.0, PID is 7369.0, B04 is 560.056070 is DOY is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 7469.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 7469.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '4', '6', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '4', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '5', '5', '5', '5']]\n",
      "decoded_data: ['DOY is 211.0, PID is 7469.0, B04 is 585.0, B03 is 717.0, B02 is 355.0 B04 is 55555']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 717.0, PID is 7469.0, B04 is 585.0, B02 is']\n",
      "prompt: DOY is 211.0, B03 is 717.0, PID is 7469.0, B04 is 585.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '7', '.', '0', ',', '', 'PID', 'is', '', '7', '4', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '5', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '7', '.', '0', ',', '', 'PID', 'is', '', '7', '4', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '3', '5', '5', '.', '0', '.', '0', ',']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 717.0, PID is 7469.0, B04 is 585.0, B02 is 355.07355.0.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 585.0, B03 is 717.0, PID is 7469.0, B02 is']\n",
      "prompt: DOY is 211.0, B04 is 585.0, B03 is 717.0, PID is 7469.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '7', '.', '0', ',', '', 'PID', 'is', '', '7', '4', '6', '9', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '7', '.', '0', ',', '', 'PID', 'is', '', '7', '4', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', 'DOY', 'is', '', 'B04', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 585.0, B03 is 717.0, PID is 7469.0, B02 is 355.07DOY is B04 is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 7469.0, B04 is 585.0, B03 is 717.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 7469.0, B04 is 585.0, B03 is 717.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '4', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '4', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '3', '8', '7', '.', '0', ',', '', 'B04']]\n",
      "decoded_data: ['DOY is 211.0, PID is 7469.0, B04 is 585.0, B03 is 717.0, B02 is 355.0 387.0, B04']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 717.0, B04 is 585.0, PID is 7469.0, B02 is']\n",
      "prompt: DOY is 211.0, B03 is 717.0, B04 is 585.0, PID is 7469.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '5', '.', '0', ',', '', 'PID', 'is', '', '7', '4', '6', '9', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '5', '.', '0', ',', '', 'PID', 'is', '', '7', '4', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '3', '7', '.', '0', ',', '', 'PID', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 717.0, B04 is 585.0, PID is 7469.0, B02 is 355.0737.0, PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7469.0, DOY is 211.0, B04 is 585.0, B03 is 717.0, B02 is']\n",
      "prompt: PID is 7469.0, DOY is 211.0, B04 is 585.0, B03 is 717.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '4', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '4', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['PID is 7469.0, DOY is 211.0, B04 is 585.0, B03 is 717.0, B02 is 355.0 PID is B04 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 717.0, B04 is 585.0, PID is 7469.0, DOY is 211.0, B02 is']\n",
      "prompt: B03 is 717.0, B04 is 585.0, PID is 7469.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '1', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '5', '.', '0', ',', '', 'PID', 'is', '', '7', '4', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '1', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '5', '.', '0', ',', '', 'PID', 'is', '', '7', '4', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '2', '7', '6', '2', '.', '0', ',', '']]\n",
      "decoded_data: ['B03 is 717.0, B04 is 585.0, PID is 7469.0, DOY is 211.0, B02 is 355.072762.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 585.0, DOY is 211.0, B03 is 717.0, PID is 7469.0, B02 is']\n",
      "prompt: B04 is 585.0, DOY is 211.0, B03 is 717.0, PID is 7469.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '8', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '7', '.', '0', ',', '', 'PID', 'is', '', '7', '4', '6', '9', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '8', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '7', '.', '0', ',', '', 'PID', 'is', '', '7', '4', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'PID', 'is', '', '7', '8']]\n",
      "decoded_data: ['B04 is 585.0, DOY is 211.0, B03 is 717.0, PID is 7469.0, B02 is 355.0 PID is PID is 78']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7469.0, B03 is 717.0, DOY is 211.0, B04 is 585.0, B02 is']\n",
      "prompt: PID is 7469.0, B03 is 717.0, DOY is 211.0, B04 is 585.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '4', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '5', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '4', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '3', '2', '.', '0', ',', '', 'PID', 'is', '']]\n",
      "decoded_data: ['PID is 7469.0, B03 is 717.0, DOY is 211.0, B04 is 585.0, B02 is 355.032.0, PID is ']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 717.0, DOY is 211.0, B04 is 585.0, PID is 7469.0, B02 is']\n",
      "prompt: B03 is 717.0, DOY is 211.0, B04 is 585.0, PID is 7469.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '1', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '5', '.', '0', ',', '', 'PID', 'is', '', '7', '4', '6', '9', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '1', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '5', '.', '0', ',', '', 'PID', 'is', '', '7', '4', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '8', '7', '8', '0', '.', '0', ',', '']]\n",
      "decoded_data: ['B03 is 717.0, DOY is 211.0, B04 is 585.0, PID is 7469.0, B02 is 355.078780.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 717.0, PID is 7469.0, B04 is 585.0, DOY is 211.0, B02 is']\n",
      "prompt: B03 is 717.0, PID is 7469.0, B04 is 585.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '1', '7', '.', '0', ',', '', 'PID', 'is', '', '7', '4', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '1', '7', '.', '0', ',', '', 'PID', 'is', '', '7', '4', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '3', '5', '5', '5', '5', '5', '5', '5']]\n",
      "decoded_data: ['B03 is 717.0, PID is 7469.0, B04 is 585.0, DOY is 211.0, B02 is 355.0 35555555']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 585.0, PID is 7469.0, DOY is 211.0, B03 is 717.0, B02 is']\n",
      "prompt: B04 is 585.0, PID is 7469.0, DOY is 211.0, B03 is 717.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '8', '5', '.', '0', ',', '', 'PID', 'is', '', '7', '4', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '7', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '8', '5', '.', '0', ',', '', 'PID', 'is', '', '7', '4', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '3', '8', '7', '3', '5', '5', '5', '5']]\n",
      "decoded_data: ['B04 is 585.0, PID is 7469.0, DOY is 211.0, B03 is 717.0, B02 is 355.0 38735555']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 717.0, B04 is 585.0, DOY is 211.0, PID is 7469.0, B02 is']\n",
      "prompt: B03 is 717.0, B04 is 585.0, DOY is 211.0, PID is 7469.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '1', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '4', '6', '9', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '1', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '4', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '5', '5', '5', '5']]\n",
      "decoded_data: ['B03 is 717.0, B04 is 585.0, DOY is 211.0, PID is 7469.0, B02 is 355.0 PID is 55555']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 717.0, B04 is 585.0, PID is 7469.0, DOY is 211.0, B02 is']\n",
      "prompt: B03 is 717.0, B04 is 585.0, PID is 7469.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '1', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '5', '.', '0', ',', '', 'PID', 'is', '', '7', '4', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '1', '7', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '5', '.', '0', ',', '', 'PID', 'is', '', '7', '4', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '9', '7', 'B02', 'is', '', '3', '.', '0']]\n",
      "decoded_data: ['B03 is 717.0, B04 is 585.0, PID is 7469.0, DOY is 211.0, B02 is 355.0797B02 is 3.0']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7469.0, DOY is 211.0, B04 is 585.0, B03 is 717.0, B02 is']\n",
      "prompt: PID is 7469.0, DOY is 211.0, B04 is 585.0, B03 is 717.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '4', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '7', '.', '0', ',', '', 'B02', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 24%|       | 198/829 [05:41<16:58,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '7', '4', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '8', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '7', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '3', '7', '3', '5', '5', '5', '5', '.']]\n",
      "decoded_data: ['PID is 7469.0, DOY is 211.0, B04 is 585.0, B03 is 717.0, B02 is 355.0 3735555.']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7569.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 7569.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '5', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '5', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '9', '9', '9', '9', '9', '0', '.', '0', ',']]\n",
      "decoded_data: ['PID is 7569.0, DOY is 211.0, B02 is 348.0, B04 is 573.0, B03 is 710.0999990.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 573.0, PID is 7569.0, DOY is 211.0, B02 is 348.0, B03 is']\n",
      "prompt: B04 is 573.0, PID is 7569.0, DOY is 211.0, B02 is 348.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'PID', 'is', '', '7', '5', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'PID', 'is', '', '7', '5', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '1', '0', '7', '8', '2', '.', '0', ',']]\n",
      "decoded_data: ['B04 is 573.0, PID is 7569.0, DOY is 211.0, B02 is 348.0, B03 is 710.0710782.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 348.0, PID is 7569.0, B04 is 573.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 348.0, PID is 7569.0, B04 is 573.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '8', '.', '0', ',', '', 'PID', 'is', '', '7', '5', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '8', '.', '0', ',', '', 'PID', 'is', '', '7', '5', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '7', '8', '7', '8']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 348.0, PID is 7569.0, B04 is 573.0, B03 is 710.0 B04 is 57878']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 348.0, PID is 7569.0, B04 is 573.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 348.0, PID is 7569.0, B04 is 573.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '4', '8', '.', '0', ',', '', 'PID', 'is', '', '7', '5', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '4', '8', '.', '0', ',', '', 'PID', 'is', '', '7', '5', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '9']]\n",
      "decoded_data: ['B02 is 348.0, PID is 7569.0, B04 is 573.0, DOY is 211.0, B03 is 710.0 B04 is PID is 79']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7569.0, B04 is 573.0, DOY is 211.0, B02 is 348.0, B03 is']\n",
      "prompt: PID is 7569.0, B04 is 573.0, DOY is 211.0, B02 is 348.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '5', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '5', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '7', '1', '0', '7', '8', '4', '8', '4']]\n",
      "decoded_data: ['PID is 7569.0, B04 is 573.0, DOY is 211.0, B02 is 348.0, B03 is 710.0 71078484']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 348.0, B04 is 573.0, PID is 7569.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 348.0, B04 is 573.0, PID is 7569.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'PID', 'is', '', '7', '5', '6', '9', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'PID', 'is', '', '7', '5', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '9', '6', '9', '5']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 348.0, B04 is 573.0, PID is 7569.0, B03 is 710.0 PID is 79695']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7569.0, B04 is 573.0, B02 is 348.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 7569.0, B04 is 573.0, B02 is 348.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '5', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '5', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['PID is 7569.0, B04 is 573.0, B02 is 348.0, DOY is 211.0, B03 is 710.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 348.0, PID is 7569.0, B04 is 573.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 348.0, PID is 7569.0, B04 is 573.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '8', '.', '0', ',', '', 'PID', 'is', '', '7', '5', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '8', '.', '0', ',', '', 'PID', 'is', '', '7', '5', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '1', '0', '.', '0', ',', '', 'B04', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 348.0, PID is 7569.0, B04 is 573.0, B03 is 710.0710.0, B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 348.0, PID is 7569.0, B04 is 573.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 348.0, PID is 7569.0, B04 is 573.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '4', '8', '.', '0', ',', '', 'PID', 'is', '', '7', '5', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '4', '8', '.', '0', ',', '', 'PID', 'is', '', '7', '5', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '8', '1', '9', '6', '5', '9', '0', '.']]\n",
      "decoded_data: ['B02 is 348.0, PID is 7569.0, B04 is 573.0, DOY is 211.0, B03 is 710.078196590.']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7569.0, B02 is 348.0, B04 is 573.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 7569.0, B02 is 348.0, B04 is 573.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '5', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '5', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['PID is 7569.0, B02 is 348.0, B04 is 573.0, DOY is 211.0, B03 is 710.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 7569.0, B02 is 348.0, B04 is 573.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 7569.0, B02 is 348.0, B04 is 573.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '5', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '5', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '8', '8', '4', '8', '1', '.', '0', '7']]\n",
      "decoded_data: ['DOY is 211.0, PID is 7569.0, B02 is 348.0, B04 is 573.0, B03 is 710.0788481.07']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 348.0, PID is 7569.0, B04 is 573.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 348.0, PID is 7569.0, B04 is 573.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '8', '.', '0', ',', '', 'PID', 'is', '', '7', '5', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '8', '.', '0', ',', '', 'PID', 'is', '', '7', '5', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'DOY', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 348.0, PID is 7569.0, B04 is 573.0, B03 is 710.0 B04 is DOY is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 348.0, PID is 7569.0, DOY is 211.0, B04 is 573.0, B03 is']\n",
      "prompt: B02 is 348.0, PID is 7569.0, DOY is 211.0, B04 is 573.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '4', '8', '.', '0', ',', '', 'PID', 'is', '', '7', '5', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '4', '8', '.', '0', ',', '', 'PID', 'is', '', '7', '5', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'DOY', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['B02 is 348.0, PID is 7569.0, DOY is 211.0, B04 is 573.0, B03 is 710.0 B04 is DOY is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 573.0, PID is 7569.0, DOY is 211.0, B02 is 348.0, B03 is']\n",
      "prompt: B04 is 573.0, PID is 7569.0, DOY is 211.0, B02 is 348.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'PID', 'is', '', '7', '5', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'PID', 'is', '', '7', '5', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '4', '8', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '1']]\n",
      "decoded_data: ['B04 is 573.0, PID is 7569.0, DOY is 211.0, B02 is 348.0, B03 is 710.0 B04 is PID is 71']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 348.0, B04 is 573.0, DOY is 211.0, PID is 7569.0, B03 is']\n",
      "prompt: B02 is 348.0, B04 is 573.0, DOY is 211.0, PID is 7569.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '4', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '5', '6', '9', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 24%|       | 199/829 [05:44<19:16,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B02', 'is', '', '3', '4', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '5', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'B04', 'is', '', '5', '2']]\n",
      "decoded_data: ['B02 is 348.0, B04 is 573.0, DOY is 211.0, PID is 7569.0, B03 is 710.0 B04 is B04 is 52']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 7669.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 7669.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '6', '6', '9', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '6', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '3', '1', '.', '0']]\n",
      "decoded_data: ['DOY is 211.0, PID is 7669.0, B03 is 700.0, B02 is 339.0, B04 is 553.0 B04 is 531.0']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 339.0, PID is 7669.0, B03 is 700.0, B04 is']\n",
      "prompt: DOY is 211.0, B02 is 339.0, PID is 7669.0, B03 is 700.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '9', '.', '0', ',', '', 'PID', 'is', '', '7', '6', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '9', '.', '0', ',', '', 'PID', 'is', '', '7', '6', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '3', '1', '3', '1']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 339.0, PID is 7669.0, B03 is 700.0, B04 is 553.0 PID is 53131']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 339.0, DOY is 211.0, PID is 7669.0, B03 is 700.0, B04 is']\n",
      "prompt: B02 is 339.0, DOY is 211.0, PID is 7669.0, B03 is 700.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '3', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '6', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '3', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '6', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'DOY', 'is', '', 'DOY', 'is', '', '2', '3']]\n",
      "decoded_data: ['B02 is 339.0, DOY is 211.0, PID is 7669.0, B03 is 700.0, B04 is 553.0 DOY is DOY is 23']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 700.0, B02 is 339.0, PID is 7669.0, B04 is']\n",
      "prompt: DOY is 211.0, B03 is 700.0, B02 is 339.0, PID is 7669.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '9', '.', '0', ',', '', 'PID', 'is', '', '7', '6', '6', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '9', '.', '0', ',', '', 'PID', 'is', '', '7', '6', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '3', '1', '.', '0', 'is', '', 'PID']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 700.0, B02 is 339.0, PID is 7669.0, B04 is 553.0 531.0 is PID']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 7669.0, B02 is 339.0, B03 is 700.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 7669.0, B02 is 339.0, B03 is 700.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '6', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '6', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '3', '1', '9', '5']]\n",
      "decoded_data: ['DOY is 211.0, PID is 7669.0, B02 is 339.0, B03 is 700.0, B04 is 553.0 PID is 53195']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7669.0, B03 is 700.0, B02 is 339.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 7669.0, B03 is 700.0, B02 is 339.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '6', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '6', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '3', '6', '4', '2', '3', '1', '.']]\n",
      "decoded_data: ['PID is 7669.0, B03 is 700.0, B02 is 339.0, DOY is 211.0, B04 is 553.0 5364231.']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 339.0, B03 is 700.0, DOY is 211.0, PID is 7669.0, B04 is']\n",
      "prompt: B02 is 339.0, B03 is 700.0, DOY is 211.0, PID is 7669.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '3', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '6', '6', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '3', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '6', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '3', '1', '3', '5']]\n",
      "decoded_data: ['B02 is 339.0, B03 is 700.0, DOY is 211.0, PID is 7669.0, B04 is 553.0 PID is 53135']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 7669.0, B03 is 700.0, B02 is 339.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 7669.0, B03 is 700.0, B02 is 339.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '6', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '6', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '3', '1', '8', '3', '6', '6', '.', '0']]\n",
      "decoded_data: ['DOY is 211.0, PID is 7669.0, B03 is 700.0, B02 is 339.0, B04 is 553.05318366.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 339.0, PID is 7669.0, B03 is 700.0, DOY is 211.0, B04 is']\n",
      "prompt: B02 is 339.0, PID is 7669.0, B03 is 700.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '3', '9', '.', '0', ',', '', 'PID', 'is', '', '7', '6', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '3', '9', '.', '0', ',', '', 'PID', 'is', '', '7', '6', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'DOY', 'is', '', 'B02', 'is', '', '2', '3']]\n",
      "decoded_data: ['B02 is 339.0, PID is 7669.0, B03 is 700.0, DOY is 211.0, B04 is 553.0 DOY is B02 is 23']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 339.0, DOY is 211.0, B03 is 700.0, PID is 7669.0, B04 is']\n",
      "prompt: B02 is 339.0, DOY is 211.0, B03 is 700.0, PID is 7669.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '3', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'PID', 'is', '', '7', '6', '6', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '3', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'PID', 'is', '', '7', '6', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'DOY', 'is', '', 'B02', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['B02 is 339.0, DOY is 211.0, B03 is 700.0, PID is 7669.0, B04 is 553.0 DOY is B02 is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 700.0, PID is 7669.0, B02 is 339.0, DOY is 211.0, B04 is']\n",
      "prompt: B03 is 700.0, PID is 7669.0, B02 is 339.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'PID', 'is', '', '7', '6', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'PID', 'is', '', '7', '6', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '3', '1', '9', '9']]\n",
      "decoded_data: ['B03 is 700.0, PID is 7669.0, B02 is 339.0, DOY is 211.0, B04 is 553.0 PID is 53199']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 700.0, PID is 7669.0, B02 is 339.0, DOY is 211.0, B04 is']\n",
      "prompt: B03 is 700.0, PID is 7669.0, B02 is 339.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'PID', 'is', '', '7', '6', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'PID', 'is', '', '7', '6', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '3', '1', '3', '1']]\n",
      "decoded_data: ['B03 is 700.0, PID is 7669.0, B02 is 339.0, DOY is 211.0, B04 is 553.0 PID is 53131']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 339.0, DOY is 211.0, PID is 7669.0, B03 is 700.0, B04 is']\n",
      "prompt: B02 is 339.0, DOY is 211.0, PID is 7669.0, B03 is 700.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '3', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '6', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '3', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '6', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '3', '1', '7', '3', '1', '0', 'is']]\n",
      "decoded_data: ['B02 is 339.0, DOY is 211.0, PID is 7669.0, B03 is 700.0, B04 is 553.0 5317310 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7669.0, B02 is 339.0, DOY is 211.0, B03 is 700.0, B04 is']\n",
      "prompt: PID is 7669.0, B02 is 339.0, DOY is 211.0, B03 is 700.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '6', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '6', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', '5', '3', '1', 'is', '']]\n",
      "decoded_data: ['PID is 7669.0, B02 is 339.0, DOY is 211.0, B03 is 700.0, B04 is 553.0 B03 is 531 is ']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 339.0, PID is 7669.0, B03 is 700.0, DOY is 211.0, B04 is']\n",
      "prompt: B02 is 339.0, PID is 7669.0, B03 is 700.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '3', '9', '.', '0', ',', '', 'PID', 'is', '', '7', '6', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 24%|       | 200/829 [05:46<20:51,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B02', 'is', '', '3', '3', '9', '.', '0', ',', '', 'PID', 'is', '', '7', '6', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '0', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '5', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '3', '1', '3', '6']]\n",
      "decoded_data: ['B02 is 339.0, PID is 7669.0, B03 is 700.0, DOY is 211.0, B04 is 553.0 PID is 53136']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 7769.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 7769.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '7', '6', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '7', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '6', '5', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '2', '.', '0', ',', '', 'B02', 'is', '', '3', '8', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '3', '9', '2', '.', '0']]\n",
      "decoded_data: ['DOY is 211.0, PID is 7769.0, B04 is 655.0, B03 is 712.0, B02 is 387.0 B04 is 392.0']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 7769.0, B03 is 712.0, B04 is 655.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 7769.0, B03 is 712.0, B04 is 655.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '7', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '2', '.', '0', ',', '', 'B04', 'is', '', '6', '5', '5', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '7', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '2', '.', '0', ',', '', 'B04', 'is', '', '6', '5', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '4', '9', '5', '0']]\n",
      "decoded_data: ['DOY is 211.0, PID is 7769.0, B03 is 712.0, B04 is 655.0, B02 is 350.0 B04 is 54950']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 655.0, DOY is 211.0, B03 is 712.0, PID is 7769.0, B02 is']\n",
      "prompt: B04 is 655.0, DOY is 211.0, B03 is 712.0, PID is 7769.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '6', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '7', '6', '9', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '6', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '7', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B03', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['B04 is 655.0, DOY is 211.0, B03 is 712.0, PID is 7769.0, B02 is 350.0 PID is B03 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 7769.0, B04 is 655.0, B03 is 712.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 7769.0, B04 is 655.0, B03 is 712.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '7', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '6', '5', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '2', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '7', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '6', '5', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '2', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '5', '0']]\n",
      "decoded_data: ['DOY is 211.0, PID is 7769.0, B04 is 655.0, B03 is 712.0, B02 is 354.0 B04 is PID is 50']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7769.0, DOY is 211.0, B03 is 712.0, B04 is 655.0, B02 is']\n",
      "prompt: PID is 7769.0, DOY is 211.0, B03 is 712.0, B04 is 655.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '7', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '2', '.', '0', ',', '', 'B04', 'is', '', '6', '5', '5', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '7', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '2', '.', '0', ',', '', 'B04', 'is', '', '6', '5', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '5', '4']]\n",
      "decoded_data: ['PID is 7769.0, DOY is 211.0, B03 is 712.0, B04 is 655.0, B02 is 354.0 PID is B04 is 54']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7769.0, DOY is 211.0, B04 is 655.0, B03 is 712.0, B02 is']\n",
      "prompt: PID is 7769.0, DOY is 211.0, B04 is 655.0, B03 is 712.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '7', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '5', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '2', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '7', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '5', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '2', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '3', '9']]\n",
      "decoded_data: ['PID is 7769.0, DOY is 211.0, B04 is 655.0, B03 is 712.0, B02 is 350.0 B04 is PID is 39']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 712.0, DOY is 211.0, PID is 7769.0, B04 is 655.0, B02 is']\n",
      "prompt: B03 is 712.0, DOY is 211.0, PID is 7769.0, B04 is 655.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '1', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '7', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '6', '5', '5', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '1', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '7', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '6', '5', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '3', '9', '2', '9', '0']]\n",
      "decoded_data: ['B03 is 712.0, DOY is 211.0, PID is 7769.0, B04 is 655.0, B02 is 354.0 PID is 39290']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 712.0, PID is 7769.0, B04 is 655.0, B02 is']\n",
      "prompt: DOY is 211.0, B03 is 712.0, PID is 7769.0, B04 is 655.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '7', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '6', '5', '5', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '7', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '6', '5', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '5', '4']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 712.0, PID is 7769.0, B04 is 655.0, B02 is 354.0 PID is B04 is 54']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 655.0, PID is 7769.0, DOY is 211.0, B03 is 712.0, B02 is']\n",
      "prompt: B04 is 655.0, PID is 7769.0, DOY is 211.0, B03 is 712.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '6', '5', '5', '.', '0', ',', '', 'PID', 'is', '', '7', '7', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '2', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '6', '5', '5', '.', '0', ',', '', 'PID', 'is', '', '7', '7', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '2', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '3', '5']]\n",
      "decoded_data: ['B04 is 655.0, PID is 7769.0, DOY is 211.0, B03 is 712.0, B02 is 358.0 PID is B04 is 35']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 712.0, PID is 7769.0, B04 is 655.0, B02 is']\n",
      "prompt: DOY is 211.0, B03 is 712.0, PID is 7769.0, B04 is 655.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '7', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '6', '5', '5', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '7', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '6', '5', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '4', '8', '7', '5', '4', '.', '0', ',', '']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 712.0, PID is 7769.0, B04 is 655.0, B02 is 354.048754.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 655.0, DOY is 211.0, B03 is 712.0, PID is 7769.0, B02 is']\n",
      "prompt: B04 is 655.0, DOY is 211.0, B03 is 712.0, PID is 7769.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '6', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '7', '6', '9', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '6', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '7', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '8', '7']]\n",
      "decoded_data: ['B04 is 655.0, DOY is 211.0, B03 is 712.0, PID is 7769.0, B02 is 354.0 PID is B04 is 87']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 655.0, DOY is 211.0, B03 is 712.0, PID is 7769.0, B02 is']\n",
      "prompt: B04 is 655.0, DOY is 211.0, B03 is 712.0, PID is 7769.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '6', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '7', '6', '9', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '6', '5', '5', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '7', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '8', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['B04 is 655.0, DOY is 211.0, B03 is 712.0, PID is 7769.0, B02 is 383.0 PID is B04 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 712.0, PID is 7769.0, DOY is 211.0, B04 is 655.0, B02 is']\n",
      "prompt: B03 is 712.0, PID is 7769.0, DOY is 211.0, B04 is 655.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '1', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '7', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '5', '5', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '1', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '7', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '5', '5', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '4', '8', '7', '5']]\n",
      "decoded_data: ['B03 is 712.0, PID is 7769.0, DOY is 211.0, B04 is 655.0, B02 is 354.0 B04 is 54875']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 655.0, B03 is 712.0, PID is 7769.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 655.0, B03 is 712.0, PID is 7769.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '6', '5', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '7', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|       | 201/829 [05:48<21:50,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B04', 'is', '', '6', '5', '5', '.', '0', ',', '', 'B03', 'is', '', '7', '1', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '7', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '9', '0', '5', '0', '8', '3', '9', '0', ',']]\n",
      "decoded_data: ['B04 is 655.0, B03 is 712.0, PID is 7769.0, DOY is 211.0, B02 is 354.090508390,']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 7869.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 7869.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '8', '6', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '8', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '2', '0', '8', '2', '.', '0', ',', '']]\n",
      "decoded_data: ['DOY is 211.0, PID is 7869.0, B04 is 510.0, B02 is 322.0, B03 is 682.062082.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 510.0, DOY is 211.0, PID is 7869.0, B02 is 322.0, B03 is']\n",
      "prompt: B04 is 510.0, DOY is 211.0, PID is 7869.0, B02 is 322.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '1', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '8', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '1', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '8', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '8', '2', '.', '0', ',', '', 'B04', 'is']]\n",
      "decoded_data: ['B04 is 510.0, DOY is 211.0, PID is 7869.0, B02 is 322.0, B03 is 682.0682.0, B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 322.0, PID is 7869.0, B04 is 510.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 322.0, PID is 7869.0, B04 is 510.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '8', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '8', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '8', '2', '8', '2', '8', '2', '.', '0']]\n",
      "decoded_data: ['B02 is 322.0, PID is 7869.0, B04 is 510.0, DOY is 211.0, B03 is 682.06828282.0']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 322.0, B04 is 510.0, PID is 7869.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 322.0, B04 is 510.0, PID is 7869.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '0', '.', '0', ',', '', 'PID', 'is', '', '7', '8', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '0', '.', '0', ',', '', 'PID', 'is', '', '7', '8', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '2', '8', '2', '.', '0', ',', '', 'B04']]\n",
      "decoded_data: ['B02 is 322.0, B04 is 510.0, PID is 7869.0, DOY is 211.0, B03 is 682.06282.0, B04']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 322.0, B04 is 510.0, PID is 7869.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 322.0, B04 is 510.0, PID is 7869.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '0', '.', '0', ',', '', 'PID', 'is', '', '7', '8', '6', '9', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '0', '.', '0', ',', '', 'PID', 'is', '', '7', '8', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '6', '5']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 322.0, B04 is 510.0, PID is 7869.0, B03 is 682.0 B04 is PID is 65']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 322.0, B04 is 510.0, PID is 7869.0, B03 is']\n",
      "prompt: DOY is 211.0, B02 is 322.0, B04 is 510.0, PID is 7869.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '0', '.', '0', ',', '', 'PID', 'is', '', '7', '8', '6', '9', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '0', '.', '0', ',', '', 'PID', 'is', '', '7', '8', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 322.0, B04 is 510.0, PID is 7869.0, B03 is 682.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 510.0, PID is 7869.0, DOY is 211.0, B02 is 322.0, B03 is']\n",
      "prompt: B04 is 510.0, PID is 7869.0, DOY is 211.0, B02 is 322.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '1', '0', '.', '0', ',', '', 'PID', 'is', '', '7', '8', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '1', '0', '.', '0', ',', '', 'PID', 'is', '', '7', '8', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '6', '8', '2', '8', '2', '.', '0', ',']]\n",
      "decoded_data: ['B04 is 510.0, PID is 7869.0, DOY is 211.0, B02 is 322.0, B03 is 682.0 68282.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 322.0, B04 is 510.0, PID is 7869.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 322.0, B04 is 510.0, PID is 7869.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '0', '.', '0', ',', '', 'PID', 'is', '', '7', '8', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '0', '.', '0', ',', '', 'PID', 'is', '', '7', '8', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '4']]\n",
      "decoded_data: ['B02 is 322.0, B04 is 510.0, PID is 7869.0, DOY is 211.0, B03 is 682.0 B04 is PID is 74']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 322.0, PID is 7869.0, DOY is 211.0, B04 is 510.0, B03 is']\n",
      "prompt: B02 is 322.0, PID is 7869.0, DOY is 211.0, B04 is 510.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '8', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '0', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '8', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '0', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'DOY', 'is', '', '6', '5']]\n",
      "decoded_data: ['B02 is 322.0, PID is 7869.0, DOY is 211.0, B04 is 510.0, B03 is 682.0 B04 is DOY is 65']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7869.0, B02 is 322.0, B04 is 510.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 7869.0, B02 is 322.0, B04 is 510.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '8', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '8', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '6', '8', '2', '1', '0', '2', '8', '2']]\n",
      "decoded_data: ['PID is 7869.0, B02 is 322.0, B04 is 510.0, DOY is 211.0, B03 is 682.0 68210282']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 7869.0, B04 is 510.0, B02 is 322.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 7869.0, B04 is 510.0, B02 is 322.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '8', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '8', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '6', '8']]\n",
      "decoded_data: ['DOY is 211.0, PID is 7869.0, B04 is 510.0, B02 is 322.0, B03 is 682.0 B04 is PID is 68']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 510.0, B02 is 322.0, PID is 7869.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 510.0, B02 is 322.0, PID is 7869.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '1', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '8', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '1', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '8', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '6', '5', '4', '5', '4']]\n",
      "decoded_data: ['B04 is 510.0, B02 is 322.0, PID is 7869.0, DOY is 211.0, B03 is 682.0 B04 is 65454']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7869.0, B04 is 510.0, DOY is 211.0, B02 is 322.0, B03 is']\n",
      "prompt: PID is 7869.0, B04 is 510.0, DOY is 211.0, B02 is 322.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '8', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '8', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '6', '2', '0', '8', '2']]\n",
      "decoded_data: ['PID is 7869.0, B04 is 510.0, DOY is 211.0, B02 is 322.0, B03 is 682.0 B04 is 62082']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 322.0, PID is 7869.0, DOY is 211.0, B04 is 510.0, B03 is']\n",
      "prompt: B02 is 322.0, PID is 7869.0, DOY is 211.0, B04 is 510.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '8', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '0', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'PID', 'is', '', '7', '8', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '0', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '6', '2']]\n",
      "decoded_data: ['B02 is 322.0, PID is 7869.0, DOY is 211.0, B04 is 510.0, B03 is 682.0 PID is B04 is 62']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 322.0, B04 is 510.0, PID is 7869.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 322.0, B04 is 510.0, PID is 7869.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '0', '.', '0', ',', '', 'PID', 'is', '', '7', '8', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 24%|       | 202/829 [05:51<22:32,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B02', 'is', '', '3', '2', '2', '.', '0', ',', '', 'B04', 'is', '', '5', '1', '0', '.', '0', ',', '', 'PID', 'is', '', '7', '8', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '8', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '5', '8', '2', '.', '0', '0', ',', '']]\n",
      "decoded_data: ['B02 is 322.0, B04 is 510.0, PID is 7869.0, DOY is 211.0, B03 is 682.06582.00, ']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 7969.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 7969.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '9', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '4', '9', '0', '.', '0', '0', ',', '']]\n",
      "decoded_data: ['DOY is 211.0, PID is 7969.0, B02 is 351.0, B03 is 664.0, B04 is 490.07490.00, ']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7969.0, DOY is 211.0, B02 is 351.0, B03 is 664.0, B04 is']\n",
      "prompt: PID is 7969.0, DOY is 211.0, B02 is 351.0, B03 is 664.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '9', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '6', '4', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '9', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'DOY', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['PID is 7969.0, DOY is 211.0, B02 is 351.0, B03 is 664.0, B04 is 430.0 PID is DOY is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 664.0, B02 is 351.0, DOY is 211.0, PID is 7969.0, B04 is']\n",
      "prompt: B03 is 664.0, B02 is 351.0, DOY is 211.0, PID is 7969.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '6', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '4', '9', '0', '9', '6']]\n",
      "decoded_data: ['B03 is 664.0, B02 is 351.0, DOY is 211.0, PID is 7969.0, B04 is 430.0 B04 is 49096']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7969.0, B03 is 664.0, B02 is 351.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 7969.0, B03 is 664.0, B02 is 351.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '9', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '6', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '9', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '6', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B02', 'is', '', '4', '9', '6', '8', '2']]\n",
      "decoded_data: ['PID is 7969.0, B03 is 664.0, B02 is 351.0, DOY is 211.0, B04 is 430.0 B02 is 49682']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 664.0, B02 is 351.0, PID is 7969.0, DOY is 211.0, B04 is']\n",
      "prompt: B03 is 664.0, B02 is 351.0, PID is 7969.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '6', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '9', '0', '9', '0', '9', '0', '1']]\n",
      "decoded_data: ['B03 is 664.0, B02 is 351.0, PID is 7969.0, DOY is 211.0, B04 is 439.0 49090901']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 351.0, B03 is 664.0, DOY is 211.0, PID is 7969.0, B04 is']\n",
      "prompt: B02 is 351.0, B03 is 664.0, DOY is 211.0, PID is 7969.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '5', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '5', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'DOY', 'is', '', 'PID', 'is', '', '4', '9']]\n",
      "decoded_data: ['B02 is 351.0, B03 is 664.0, DOY is 211.0, PID is 7969.0, B04 is 430.0 DOY is PID is 49']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 351.0, DOY is 211.0, B03 is 664.0, PID is 7969.0, B04 is']\n",
      "prompt: B02 is 351.0, DOY is 211.0, B03 is 664.0, PID is 7969.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '6', '4', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '6', '4', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '4', '7', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'DOY', 'is', '', 'B03', 'is', '', 'DOY', 'is']]\n",
      "decoded_data: ['B02 is 351.0, DOY is 211.0, B03 is 664.0, PID is 7969.0, B04 is 474.0 DOY is B03 is DOY is']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 664.0, DOY is 211.0, PID is 7969.0, B02 is 351.0, B04 is']\n",
      "prompt: B03 is 664.0, DOY is 211.0, PID is 7969.0, B02 is 351.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '6', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'DOY', 'is', '', 'B02', 'is', '', '4', '9']]\n",
      "decoded_data: ['B03 is 664.0, DOY is 211.0, PID is 7969.0, B02 is 351.0, B04 is 430.0 DOY is B02 is 49']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 664.0, B02 is 351.0, PID is 7969.0, B04 is']\n",
      "prompt: DOY is 211.0, B03 is 664.0, B02 is 351.0, PID is 7969.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '4', '9', '0', '9', '9']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 664.0, B02 is 351.0, PID is 7969.0, B04 is 430.0 PID is 49099']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 351.0, PID is 7969.0, B03 is 664.0, DOY is 211.0, B04 is']\n",
      "prompt: B02 is 351.0, PID is 7969.0, B03 is 664.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '5', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '6', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '5', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '6', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '9', '0', '9', '0', '1', '0', '9']]\n",
      "decoded_data: ['B02 is 351.0, PID is 7969.0, B03 is 664.0, DOY is 211.0, B04 is 490.0 49090109']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 351.0, DOY is 211.0, B03 is 664.0, PID is 7969.0, B04 is']\n",
      "prompt: B02 is 351.0, DOY is 211.0, B03 is 664.0, PID is 7969.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '6', '4', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '6', '4', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '9', '0', '.', '0', ',', '', 'DOY', 'is', '']]\n",
      "decoded_data: ['B02 is 351.0, DOY is 211.0, B03 is 664.0, PID is 7969.0, B04 is 439.090.0, DOY is ']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 664.0, PID is 7969.0, DOY is 211.0, B02 is 351.0, B04 is']\n",
      "prompt: B03 is 664.0, PID is 7969.0, DOY is 211.0, B02 is 351.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '6', '4', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '6', '6', '4', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '9', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '9', '0', '9', '0', '.', '0', '.']]\n",
      "decoded_data: ['B03 is 664.0, PID is 7969.0, DOY is 211.0, B02 is 351.0, B04 is 490.0 49090.0.']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 351.0, PID is 7969.0, B03 is 664.0, DOY is 211.0, B04 is']\n",
      "prompt: B02 is 351.0, PID is 7969.0, B03 is 664.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '5', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '6', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '5', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '6', '6', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '4', '9', '0', '9', '0', '8', '7', '4', '.']]\n",
      "decoded_data: ['B02 is 351.0, PID is 7969.0, B03 is 664.0, DOY is 211.0, B04 is 439.049090874.']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 7969.0, B02 is 351.0, DOY is 211.0, B03 is 664.0, B04 is']\n",
      "prompt: PID is 7969.0, B02 is 351.0, DOY is 211.0, B03 is 664.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '7', '9', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '6', '4', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '7', '9', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '6', '4', '.', '0', ',', '', 'B04', 'is', '', '4', '3', '0', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B02', 'is', '', '4', '9', '0', '0', '0']]\n",
      "decoded_data: ['PID is 7969.0, B02 is 351.0, DOY is 211.0, B03 is 664.0, B04 is 430.0 B02 is 49000']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 664.0, B02 is 351.0, PID is 7969.0, B04 is']\n",
      "prompt: DOY is 211.0, B03 is 664.0, B02 is 351.0, PID is 7969.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '9', '.', '0', ',', '', 'B04', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 24%|       | 203/829 [05:53<23:14,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '6', '4', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '1', '.', '0', ',', '', 'PID', 'is', '', '7', '9', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '4', '7', '4', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '.', '0', ',', '', 'PID', 'is', '']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 664.0, B02 is 351.0, PID is 7969.0, B04 is 474.0 4.0, PID is ']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 8069.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 8069.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '8', '0', '6', '9', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '8', '0', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '2', '7', '8', '5']]\n",
      "decoded_data: ['DOY is 211.0, PID is 8069.0, B03 is 698.0, B02 is 329.0, B04 is 527.0 PID is 52785']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 8069.0, B03 is 698.0, DOY is 211.0, B02 is 329.0, B04 is']\n",
      "prompt: PID is 8069.0, B03 is 698.0, DOY is 211.0, B02 is 329.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '8', '0', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '8', '0', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '2', '9', '8', '5']]\n",
      "decoded_data: ['PID is 8069.0, B03 is 698.0, DOY is 211.0, B02 is 329.0, B04 is 527.0 PID is 52985']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 698.0, DOY is 211.0, PID is 8069.0, B02 is 329.0, B04 is']\n",
      "prompt: B03 is 698.0, DOY is 211.0, PID is 8069.0, B02 is 329.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '9', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '8', '0', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '6', '9', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '8', '0', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '2', '7', '4', '5']]\n",
      "decoded_data: ['B03 is 698.0, DOY is 211.0, PID is 8069.0, B02 is 329.0, B04 is 527.0 PID is 52745']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 329.0, PID is 8069.0, DOY is 211.0, B03 is 698.0, B04 is']\n",
      "prompt: B02 is 329.0, PID is 8069.0, DOY is 211.0, B03 is 698.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '2', '9', '.', '0', ',', '', 'PID', 'is', '', '8', '0', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '8', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '2', '9', '.', '0', ',', '', 'PID', 'is', '', '8', '0', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '2', '7', '8', '5']]\n",
      "decoded_data: ['B02 is 329.0, PID is 8069.0, DOY is 211.0, B03 is 698.0, B04 is 527.0 PID is 52785']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 8069.0, B03 is 698.0, B02 is 329.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 8069.0, B03 is 698.0, B02 is 329.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '8', '0', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '8', '0', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '2', '2', '2', '2', '2', '.', '0']]\n",
      "decoded_data: ['PID is 8069.0, B03 is 698.0, B02 is 329.0, DOY is 211.0, B04 is 527.0 522222.0']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 8069.0, B03 is 698.0, DOY is 211.0, B02 is 329.0, B04 is']\n",
      "prompt: PID is 8069.0, B03 is 698.0, DOY is 211.0, B02 is 329.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '8', '0', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '8', '0', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B03', 'is', '', '5', '2']]\n",
      "decoded_data: ['PID is 8069.0, B03 is 698.0, DOY is 211.0, B02 is 329.0, B04 is 527.0 PID is B03 is 52']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 8069.0, B03 is 698.0, DOY is 211.0, B02 is 329.0, B04 is']\n",
      "prompt: PID is 8069.0, B03 is 698.0, DOY is 211.0, B02 is 329.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '8', '0', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '8', '0', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '2', '7', '4', '3', '8', '.', '0']]\n",
      "decoded_data: ['PID is 8069.0, B03 is 698.0, DOY is 211.0, B02 is 329.0, B04 is 527.0 527438.0']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 8069.0, B03 is 698.0, DOY is 211.0, B02 is 329.0, B04 is']\n",
      "prompt: PID is 8069.0, B03 is 698.0, DOY is 211.0, B02 is 329.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '8', '0', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '8', '0', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '2', '7', '9', '8']]\n",
      "decoded_data: ['PID is 8069.0, B03 is 698.0, DOY is 211.0, B02 is 329.0, B04 is 527.0 PID is 52798']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 329.0, DOY is 211.0, PID is 8069.0, B03 is 698.0, B04 is']\n",
      "prompt: B02 is 329.0, DOY is 211.0, PID is 8069.0, B03 is 698.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '2', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '8', '0', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '8', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '2', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '8', '0', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'DOY', 'is', '', 'B03', 'is']]\n",
      "decoded_data: ['B02 is 329.0, DOY is 211.0, PID is 8069.0, B03 is 698.0, B04 is 527.0 PID is DOY is B03 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 8069.0, B02 is 329.0, DOY is 211.0, B03 is 698.0, B04 is']\n",
      "prompt: PID is 8069.0, B02 is 329.0, DOY is 211.0, B03 is 698.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '8', '0', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '8', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '8', '0', '6', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '2', '7', '8', '5']]\n",
      "decoded_data: ['PID is 8069.0, B02 is 329.0, DOY is 211.0, B03 is 698.0, B04 is 527.0 PID is 52785']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 329.0, B03 is 698.0, PID is 8069.0, B04 is']\n",
      "prompt: DOY is 211.0, B02 is 329.0, B03 is 698.0, PID is 8069.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '9', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '8', '.', '0', ',', '', 'PID', 'is', '', '8', '0', '6', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '9', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '8', '.', '0', ',', '', 'PID', 'is', '', '8', '0', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '5', '.', '0', ',', '']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 329.0, B03 is 698.0, PID is 8069.0, B04 is 527.0 B04 is 5.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 698.0, B02 is 329.0, PID is 8069.0, DOY is 211.0, B04 is']\n",
      "prompt: B03 is 698.0, B02 is 329.0, PID is 8069.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '6', '9', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '9', '.', '0', ',', '', 'PID', 'is', '', '8', '0', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '6', '9', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '9', '.', '0', ',', '', 'PID', 'is', '', '8', '0', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '2', '7', '.', '0', ',', '', 'PID']]\n",
      "decoded_data: ['B03 is 698.0, B02 is 329.0, PID is 8069.0, DOY is 211.0, B04 is 527.0 527.0, PID']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 329.0, PID is 8069.0, DOY is 211.0, B03 is 698.0, B04 is']\n",
      "prompt: B02 is 329.0, PID is 8069.0, DOY is 211.0, B03 is 698.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '2', '9', '.', '0', ',', '', 'PID', 'is', '', '8', '0', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '8', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '2', '9', '.', '0', ',', '', 'PID', 'is', '', '8', '0', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '2', '7', '4', '5']]\n",
      "decoded_data: ['B02 is 329.0, PID is 8069.0, DOY is 211.0, B03 is 698.0, B04 is 527.0 PID is 52745']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 329.0, DOY is 211.0, B03 is 698.0, PID is 8069.0, B04 is']\n",
      "prompt: B02 is 329.0, DOY is 211.0, B03 is 698.0, PID is 8069.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '2', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '8', '.', '0', ',', '', 'PID', 'is', '', '8', '0', '6', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '2', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '8', '.', '0', ',', '', 'PID', 'is', '', '8', '0', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '2', '7', '.', '0', '5', '2', '2']]\n",
      "decoded_data: ['B02 is 329.0, DOY is 211.0, B03 is 698.0, PID is 8069.0, B04 is 527.0 527.0522']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 329.0, PID is 8069.0, B03 is 698.0, B04 is']\n",
      "prompt: DOY is 211.0, B02 is 329.0, PID is 8069.0, B03 is 698.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '9', '.', '0', ',', '', 'PID', 'is', '', '8', '0', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '8', '.', '0', ',', '', 'B04', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 25%|       | 204/829 [05:55<23:46,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '9', '.', '0', ',', '', 'PID', 'is', '', '8', '0', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '6', '9', '8', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '2', '7', '.', '0', ',', '', 'PID']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 329.0, PID is 8069.0, B03 is 698.0, B04 is 527.0 527.0, PID']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5070.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 5070.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '7', '0', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '7', '0', '.', '0', ',', '', 'B03', 'is', '', '8', '3', '4', '.', '0', ',', '', 'B04', 'is', '', '8', '1', '2', '.', '0', ',', '', 'B02', 'is', '', '5', '4', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B03', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5070.0, B03 is 834.0, B04 is 812.0, B02 is 548.0 PID is B03 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5070.0, B04 is 812.0, B03 is 834.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 5070.0, B04 is 812.0, B03 is 834.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '7', '0', '.', '0', ',', '', 'B04', 'is', '', '8', '1', '2', '.', '0', ',', '', 'B03', 'is', '', '8', '3', '4', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '7', '0', '.', '0', ',', '', 'B04', 'is', '', '8', '1', '2', '.', '0', ',', '', 'B03', 'is', '', '8', '3', '4', '.', '0', ',', '', 'B02', 'is', '', '5', '4', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'B04', 'is', '', '8', '2']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5070.0, B04 is 812.0, B03 is 834.0, B02 is 548.0 B03 is B04 is 82']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 834.0, PID is 5070.0, DOY is 211.0, B04 is 812.0, B02 is']\n",
      "prompt: B03 is 834.0, PID is 5070.0, DOY is 211.0, B04 is 812.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '8', '3', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '7', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '8', '1', '2', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '8', '3', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '7', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '8', '1', '2', '.', '0', ',', '', 'B02', 'is', '', '5', '4', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '4', '8', '9', '5', '8', '.', '0', '.']]\n",
      "decoded_data: ['B03 is 834.0, PID is 5070.0, DOY is 211.0, B04 is 812.0, B02 is 548.0548958.0.']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5070.0, DOY is 211.0, B04 is 812.0, B03 is 834.0, B02 is']\n",
      "prompt: PID is 5070.0, DOY is 211.0, B04 is 812.0, B03 is 834.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '0', '7', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '8', '1', '2', '.', '0', ',', '', 'B03', 'is', '', '8', '3', '4', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '0', '7', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '8', '1', '2', '.', '0', ',', '', 'B03', 'is', '', '8', '3', '4', '.', '0', ',', '', 'B02', 'is', '', '5', '4', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '5', '2']]\n",
      "decoded_data: ['PID is 5070.0, DOY is 211.0, B04 is 812.0, B03 is 834.0, B02 is 548.0 PID is B04 is 52']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 834.0, PID is 5070.0, B04 is 812.0, B02 is']\n",
      "prompt: DOY is 211.0, B03 is 834.0, PID is 5070.0, B04 is 812.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '8', '3', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '7', '0', '.', '0', ',', '', 'B04', 'is', '', '8', '1', '2', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '8', '3', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '7', '0', '.', '0', ',', '', 'B04', 'is', '', '8', '1', '2', '.', '0', ',', '', 'B02', 'is', '', '5', '4', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '8', '9', '8', '9', '5', '2', '.', '0', ',']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 834.0, PID is 5070.0, B04 is 812.0, B02 is 548.0898952.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5070.0, B03 is 834.0, B04 is 812.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 5070.0, B03 is 834.0, B04 is 812.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '0', '7', '0', '.', '0', ',', '', 'B03', 'is', '', '8', '3', '4', '.', '0', ',', '', 'B04', 'is', '', '8', '1', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '0', '7', '0', '.', '0', ',', '', 'B03', 'is', '', '8', '3', '4', '.', '0', ',', '', 'B04', 'is', '', '8', '1', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '5', '4', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'DOY', 'is']]\n",
      "decoded_data: ['PID is 5070.0, B03 is 834.0, B04 is 812.0, DOY is 211.0, B02 is 548.0 B04 is PID is DOY is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5070.0, DOY is 211.0, B03 is 834.0, B04 is 812.0, B02 is']\n",
      "prompt: PID is 5070.0, DOY is 211.0, B03 is 834.0, B04 is 812.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '0', '7', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '8', '3', '4', '.', '0', ',', '', 'B04', 'is', '', '8', '1', '2', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '0', '7', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '8', '3', '4', '.', '0', ',', '', 'B04', 'is', '', '8', '1', '2', '.', '0', ',', '', 'B02', 'is', '', '5', '4', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B02', 'is', '', '5', '9', '0', '2', '4']]\n",
      "decoded_data: ['PID is 5070.0, DOY is 211.0, B03 is 834.0, B04 is 812.0, B02 is 548.0 B02 is 59024']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 834.0, B04 is 812.0, DOY is 211.0, PID is 5070.0, B02 is']\n",
      "prompt: B03 is 834.0, B04 is 812.0, DOY is 211.0, PID is 5070.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '8', '3', '4', '.', '0', ',', '', 'B04', 'is', '', '8', '1', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '7', '0', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '8', '3', '4', '.', '0', ',', '', 'B04', 'is', '', '8', '1', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '7', '0', '.', '0', ',', '', 'B02', 'is', '', '5', '4', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '1', '9', '0', '.', '0', '.', '0', ',', '']]\n",
      "decoded_data: ['B03 is 834.0, B04 is 812.0, DOY is 211.0, PID is 5070.0, B02 is 548.0190.0.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5070.0, B03 is 834.0, B04 is 812.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 5070.0, B03 is 834.0, B04 is 812.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '7', '0', '.', '0', ',', '', 'B03', 'is', '', '8', '3', '4', '.', '0', ',', '', 'B04', 'is', '', '8', '1', '2', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '7', '0', '.', '0', ',', '', 'B03', 'is', '', '8', '3', '4', '.', '0', ',', '', 'B04', 'is', '', '8', '1', '2', '.', '0', ',', '', 'B02', 'is', '', '5', '4', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B03', 'is', '', 'B03', 'is']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5070.0, B03 is 834.0, B04 is 812.0, B02 is 548.0 PID is B03 is B03 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 812.0, B03 is 834.0, PID is 5070.0, DOY is 211.0, B02 is']\n",
      "prompt: B04 is 812.0, B03 is 834.0, PID is 5070.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '8', '1', '2', '.', '0', ',', '', 'B03', 'is', '', '8', '3', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '7', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '8', '1', '2', '.', '0', ',', '', 'B03', 'is', '', '8', '3', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '7', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '5', '4', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '8', '9', '8', '8']]\n",
      "decoded_data: ['B04 is 812.0, B03 is 834.0, PID is 5070.0, DOY is 211.0, B02 is 548.0 PID is 58988']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 834.0, PID is 5070.0, B04 is 812.0, DOY is 211.0, B02 is']\n",
      "prompt: B03 is 834.0, PID is 5070.0, B04 is 812.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '8', '3', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '7', '0', '.', '0', ',', '', 'B04', 'is', '', '8', '1', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '8', '3', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '7', '0', '.', '0', ',', '', 'B04', 'is', '', '8', '1', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '5', '4', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '8', '9', '5', '4', '8', '9', '8', '.']]\n",
      "decoded_data: ['B03 is 834.0, PID is 5070.0, B04 is 812.0, DOY is 211.0, B02 is 548.058954898.']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 834.0, B04 is 812.0, DOY is 211.0, PID is 5070.0, B02 is']\n",
      "prompt: B03 is 834.0, B04 is 812.0, DOY is 211.0, PID is 5070.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '8', '3', '4', '.', '0', ',', '', 'B04', 'is', '', '8', '1', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '7', '0', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '8', '3', '4', '.', '0', ',', '', 'B04', 'is', '', '8', '1', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '7', '0', '.', '0', ',', '', 'B02', 'is', '', '5', '4', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['B03 is 834.0, B04 is 812.0, DOY is 211.0, PID is 5070.0, B02 is 548.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 834.0, PID is 5070.0, DOY is 211.0, B04 is 812.0, B02 is']\n",
      "prompt: B03 is 834.0, PID is 5070.0, DOY is 211.0, B04 is 812.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '8', '3', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '7', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '8', '1', '2', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '8', '3', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '7', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '8', '1', '2', '.', '0', ',', '', 'B02', 'is', '', '5', '4', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '8', '3']]\n",
      "decoded_data: ['B03 is 834.0, PID is 5070.0, DOY is 211.0, B04 is 812.0, B02 is 548.0 PID is B04 is 83']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 834.0, B04 is 812.0, DOY is 211.0, PID is 5070.0, B02 is']\n",
      "prompt: B03 is 834.0, B04 is 812.0, DOY is 211.0, PID is 5070.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '8', '3', '4', '.', '0', ',', '', 'B04', 'is', '', '8', '1', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '7', '0', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '8', '3', '4', '.', '0', ',', '', 'B04', 'is', '', '8', '1', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '7', '0', '.', '0', ',', '', 'B02', 'is', '', '5', '4', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '9', '3', '9', '3', '4', '8', '0', '.']]\n",
      "decoded_data: ['B03 is 834.0, B04 is 812.0, DOY is 211.0, PID is 5070.0, B02 is 548.059393480.']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 834.0, B04 is 812.0, PID is 5070.0, B02 is']\n",
      "prompt: DOY is 211.0, B03 is 834.0, B04 is 812.0, PID is 5070.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '8', '3', '4', '.', '0', ',', '', 'B04', 'is', '', '8', '1', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '7', '0', '.', '0', ',', '', 'B02', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 25%|       | 205/829 [05:58<24:08,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '8', '3', '4', '.', '0', ',', '', 'B04', 'is', '', '8', '1', '2', '.', '0', ',', '', 'PID', 'is', '', '5', '0', '7', '0', '.', '0', ',', '', 'B02', 'is', '', '5', '4', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 834.0, B04 is 812.0, PID is 5070.0, B02 is 548.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5170.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 5170.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '7', '0', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '7', '0', '.', '0', ',', '', 'B03', 'is', '', '8', '0', '0', '.', '0', ',', '', 'B02', 'is', '', '4', '8', '6', '.', '0', ',', '', 'B04', 'is', '', '7', '3', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5170.0, B03 is 800.0, B02 is 486.0, B04 is 733.0 B03 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 800.0, B02 is 486.0, DOY is 211.0, PID is 5170.0, B04 is']\n",
      "prompt: B03 is 800.0, B02 is 486.0, DOY is 211.0, PID is 5170.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '8', '0', '0', '.', '0', ',', '', 'B02', 'is', '', '4', '8', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '7', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '8', '0', '0', '.', '0', ',', '', 'B02', 'is', '', '4', '8', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '7', '0', '.', '0', ',', '', 'B04', 'is', '', '7', '3', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'PID', 'is', '', '7', '2']]\n",
      "decoded_data: ['B03 is 800.0, B02 is 486.0, DOY is 211.0, PID is 5170.0, B04 is 733.0 B03 is PID is 72']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 486.0, DOY is 211.0, B03 is 800.0, PID is 5170.0, B04 is']\n",
      "prompt: B02 is 486.0, DOY is 211.0, B03 is 800.0, PID is 5170.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '4', '8', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '8', '0', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '7', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '4', '8', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '8', '0', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '7', '0', '.', '0', ',', '', 'B04', 'is', '', '7', '3', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'PID', 'is', '', '7', '2']]\n",
      "decoded_data: ['B02 is 486.0, DOY is 211.0, B03 is 800.0, PID is 5170.0, B04 is 733.0 B03 is PID is 72']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 486.0, PID is 5170.0, DOY is 211.0, B03 is 800.0, B04 is']\n",
      "prompt: B02 is 486.0, PID is 5170.0, DOY is 211.0, B03 is 800.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '4', '8', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '7', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '8', '0', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '4', '8', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '7', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '8', '0', '0', '.', '0', ',', '', 'B04', 'is', '', '7', '3', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '9', '4', '4', '7']]\n",
      "decoded_data: ['B02 is 486.0, PID is 5170.0, DOY is 211.0, B03 is 800.0, B04 is 733.0 PID is 79447']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 486.0, B03 is 800.0, PID is 5170.0, B04 is']\n",
      "prompt: DOY is 211.0, B02 is 486.0, B03 is 800.0, PID is 5170.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '4', '8', '6', '.', '0', ',', '', 'B03', 'is', '', '8', '0', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '7', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '4', '8', '6', '.', '0', ',', '', 'B03', 'is', '', '8', '0', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '7', '0', '.', '0', ',', '', 'B04', 'is', '', '7', '3', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '3', '3', '3', '3']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 486.0, B03 is 800.0, PID is 5170.0, B04 is 733.0 PID is 73333']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 800.0, B02 is 486.0, DOY is 211.0, PID is 5170.0, B04 is']\n",
      "prompt: B03 is 800.0, B02 is 486.0, DOY is 211.0, PID is 5170.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '8', '0', '0', '.', '0', ',', '', 'B02', 'is', '', '4', '8', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '7', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '8', '0', '0', '.', '0', ',', '', 'B02', 'is', '', '4', '8', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '7', '0', '.', '0', ',', '', 'B04', 'is', '', '7', '3', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', '7', '3', '3', '3', '3']]\n",
      "decoded_data: ['B03 is 800.0, B02 is 486.0, DOY is 211.0, PID is 5170.0, B04 is 733.0 B03 is 73333']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5170.0, DOY is 211.0, B03 is 800.0, B02 is 486.0, B04 is']\n",
      "prompt: PID is 5170.0, DOY is 211.0, B03 is 800.0, B02 is 486.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '1', '7', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '8', '0', '0', '.', '0', ',', '', 'B02', 'is', '', '4', '8', '6', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '1', '7', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '8', '0', '0', '.', '0', ',', '', 'B02', 'is', '', '4', '8', '6', '.', '0', ',', '', 'B04', 'is', '', '7', '3', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '5', '0', '3', '3']]\n",
      "decoded_data: ['PID is 5170.0, DOY is 211.0, B03 is 800.0, B02 is 486.0, B04 is 733.0 PID is 75033']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 800.0, DOY is 211.0, B02 is 486.0, PID is 5170.0, B04 is']\n",
      "prompt: B03 is 800.0, DOY is 211.0, B02 is 486.0, PID is 5170.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '8', '0', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '4', '8', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '7', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '8', '0', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '4', '8', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '7', '0', '.', '0', ',', '', 'B04', 'is', '', '7', '3', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'PID', 'is', '', '7', '5']]\n",
      "decoded_data: ['B03 is 800.0, DOY is 211.0, B02 is 486.0, PID is 5170.0, B04 is 733.0 B03 is PID is 75']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5170.0, B02 is 486.0, DOY is 211.0, B03 is 800.0, B04 is']\n",
      "prompt: PID is 5170.0, B02 is 486.0, DOY is 211.0, B03 is 800.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '1', '7', '0', '.', '0', ',', '', 'B02', 'is', '', '4', '8', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '8', '0', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '1', '7', '0', '.', '0', ',', '', 'B02', 'is', '', '4', '8', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '8', '0', '0', '.', '0', ',', '', 'B04', 'is', '', '7', '3', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '3', '3', '3', '3']]\n",
      "decoded_data: ['PID is 5170.0, B02 is 486.0, DOY is 211.0, B03 is 800.0, B04 is 733.0 PID is 73333']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 486.0, B03 is 800.0, DOY is 211.0, PID is 5170.0, B04 is']\n",
      "prompt: B02 is 486.0, B03 is 800.0, DOY is 211.0, PID is 5170.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '4', '8', '6', '.', '0', ',', '', 'B03', 'is', '', '8', '0', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '7', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '4', '8', '6', '.', '0', ',', '', 'B03', 'is', '', '8', '0', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '7', '0', '.', '0', ',', '', 'B04', 'is', '', '7', '3', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', '7', '3', '3', '3', '3']]\n",
      "decoded_data: ['B02 is 486.0, B03 is 800.0, DOY is 211.0, PID is 5170.0, B04 is 733.0 B03 is 73333']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 800.0, PID is 5170.0, B02 is 486.0, DOY is 211.0, B04 is']\n",
      "prompt: B03 is 800.0, PID is 5170.0, B02 is 486.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '8', '0', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '7', '0', '.', '0', ',', '', 'B02', 'is', '', '4', '8', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '8', '0', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '7', '0', '.', '0', ',', '', 'B02', 'is', '', '4', '8', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '7', '3', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'DOY', 'is', '', '2', '1', '9', '3', '1']]\n",
      "decoded_data: ['B03 is 800.0, PID is 5170.0, B02 is 486.0, DOY is 211.0, B04 is 733.0 DOY is 21931']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 800.0, B02 is 486.0, PID is 5170.0, B04 is']\n",
      "prompt: DOY is 211.0, B03 is 800.0, B02 is 486.0, PID is 5170.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '8', '0', '0', '.', '0', ',', '', 'B02', 'is', '', '4', '8', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '7', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '8', '0', '0', '.', '0', ',', '', 'B02', 'is', '', '4', '8', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '7', '0', '.', '0', ',', '', 'B04', 'is', '', '7', '3', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'PID', 'is', '', '7', '5']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 800.0, B02 is 486.0, PID is 5170.0, B04 is 733.0 B03 is PID is 75']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 800.0, B02 is 486.0, PID is 5170.0, B04 is']\n",
      "prompt: DOY is 211.0, B03 is 800.0, B02 is 486.0, PID is 5170.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '8', '0', '0', '.', '0', ',', '', 'B02', 'is', '', '4', '8', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '7', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '8', '0', '0', '.', '0', ',', '', 'B02', 'is', '', '4', '8', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '7', '0', '.', '0', ',', '', 'B04', 'is', '', '7', '3', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '5', '2', '9', '4']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 800.0, B02 is 486.0, PID is 5170.0, B04 is 733.0 PID is 75294']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 486.0, PID is 5170.0, DOY is 211.0, B03 is 800.0, B04 is']\n",
      "prompt: B02 is 486.0, PID is 5170.0, DOY is 211.0, B03 is 800.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '4', '8', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '7', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '8', '0', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '4', '8', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '7', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '8', '0', '0', '.', '0', ',', '', 'B04', 'is', '', '7', '3', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B03', 'is', '', '8', '5']]\n",
      "decoded_data: ['B02 is 486.0, PID is 5170.0, DOY is 211.0, B03 is 800.0, B04 is 733.0 PID is B03 is 85']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 486.0, B03 is 800.0, DOY is 211.0, PID is 5170.0, B04 is']\n",
      "prompt: B02 is 486.0, B03 is 800.0, DOY is 211.0, PID is 5170.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '4', '8', '6', '.', '0', ',', '', 'B03', 'is', '', '8', '0', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '7', '0', '.', '0', ',', '', 'B04', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 25%|       | 206/829 [06:00<24:18,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B02', 'is', '', '4', '8', '6', '.', '0', ',', '', 'B03', 'is', '', '8', '0', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '1', '7', '0', '.', '0', ',', '', 'B04', 'is', '', '7', '3', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'PID', 'is', '', 'B03', 'is']]\n",
      "decoded_data: ['B02 is 486.0, B03 is 800.0, DOY is 211.0, PID is 5170.0, B04 is 733.0 B03 is PID is B03 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5270.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 5270.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '7', '0', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '7', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'B03', 'is', '', '6', '3', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '3', '2', '5', '3', '2', '9', '2', '.']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5270.0, B02 is 354.0, B04 is 528.0, B03 is 632.063253292.']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 528.0, B02 is 354.0, PID is 5270.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 528.0, B02 is 354.0, PID is 5270.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '7', '0', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '7', '0', '.', '0', ',', '', 'B03', 'is', '', '6', '3', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '6', '3', '2', '5', '3']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 528.0, B02 is 354.0, PID is 5270.0, B03 is 632.0 PID is 63253']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5270.0, DOY is 211.0, B04 is 528.0, B02 is 354.0, B03 is']\n",
      "prompt: PID is 5270.0, DOY is 211.0, B04 is 528.0, B02 is 354.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '2', '7', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '2', '7', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '4', '.', '0', ',', '', 'B03', 'is', '', '6', '3', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '5', '3', '2', '.', '0', '0', '5', '3']]\n",
      "decoded_data: ['PID is 5270.0, DOY is 211.0, B04 is 528.0, B02 is 354.0, B03 is 632.06532.0053']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 354.0, PID is 5270.0, B04 is 528.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 354.0, PID is 5270.0, B04 is 528.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '5', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '7', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '5', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '7', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '3', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '6', '3', '2', '8', '0']]\n",
      "decoded_data: ['B02 is 354.0, PID is 5270.0, B04 is 528.0, DOY is 211.0, B03 is 632.0 B04 is 63280']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5270.0, B02 is 354.0, B04 is 528.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5270.0, B02 is 354.0, B04 is 528.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '2', '7', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '2', '7', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '3', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '3', '2', '9', '8', '0', '0', '.', '0']]\n",
      "decoded_data: ['PID is 5270.0, B02 is 354.0, B04 is 528.0, DOY is 211.0, B03 is 632.06329800.0']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5270.0, B04 is 528.0, B02 is 354.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 5270.0, B04 is 528.0, B02 is 354.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '7', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '4', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '7', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '4', '.', '0', ',', '', 'B03', 'is', '', '6', '3', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '6', '3', '2', '5', '2', '.', '0', ',', '']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5270.0, B04 is 528.0, B02 is 354.0, B03 is 632.063252.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 354.0, DOY is 211.0, PID is 5270.0, B04 is 528.0, B03 is']\n",
      "prompt: B02 is 354.0, DOY is 211.0, PID is 5270.0, B04 is 528.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '7', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '5', '4', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '7', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'B03', 'is', '', '6', '3', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '3', '2']]\n",
      "decoded_data: ['B02 is 354.0, DOY is 211.0, PID is 5270.0, B04 is 528.0, B03 is 632.0 B04 is PID is 32']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 528.0, B02 is 354.0, PID is 5270.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 528.0, B02 is 354.0, PID is 5270.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '7', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'B02', 'is', '', '3', '5', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '7', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '3', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '6', '3', '2', '5', '3']]\n",
      "decoded_data: ['B04 is 528.0, B02 is 354.0, PID is 5270.0, DOY is 211.0, B03 is 632.0 B04 is 63253']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 354.0, PID is 5270.0, B04 is 528.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 354.0, PID is 5270.0, B04 is 528.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '5', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '7', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|       | 207/829 [06:02<21:31,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B02', 'is', '', '3', '5', '4', '.', '0', ',', '', 'PID', 'is', '', '5', '2', '7', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '2', '8', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '6', '3', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '3', '2', '5', '0', '0', '3', '2', '5', '3']]\n",
      "decoded_data: ['B02 is 354.0, PID is 5270.0, B04 is 528.0, DOY is 211.0, B03 is 632.0325003253']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5370.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 5370.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '7', '0', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '7', '0', '.', '0', ',', '', 'B03', 'is', '', '4', '7', '3', '.', '0', ',', '', 'B04', 'is', '', '2', '9', '2', '.', '0', ',', '', 'B02', 'is', '', '1', '9', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'B04', 'is', '', '2', '.']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5370.0, B03 is 473.0, B04 is 292.0, B02 is 197.0 B03 is B04 is 2.']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 292.0, DOY is 211.0, B03 is 473.0, PID is 5370.0, B02 is']\n",
      "prompt: B04 is 292.0, DOY is 211.0, B03 is 473.0, PID is 5370.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '2', '9', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '4', '7', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '7', '0', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '2', '9', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '4', '7', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '7', '0', '.', '0', ',', '', 'B02', 'is', '', '1', '9', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['B04 is 292.0, DOY is 211.0, B03 is 473.0, PID is 5370.0, B02 is 197.0 B03 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 292.0, DOY is 211.0, B03 is 473.0, PID is 5370.0, B02 is']\n",
      "prompt: B04 is 292.0, DOY is 211.0, B03 is 473.0, PID is 5370.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '2', '9', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '4', '7', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '7', '0', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '2', '9', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '4', '7', '3', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '7', '0', '.', '0', ',', '', 'B02', 'is', '', '1', '9', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'B04', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['B04 is 292.0, DOY is 211.0, B03 is 473.0, PID is 5370.0, B02 is 197.0 B03 is B04 is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5370.0, B04 is 292.0, B03 is 473.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 5370.0, B04 is 292.0, B03 is 473.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '7', '0', '.', '0', ',', '', 'B04', 'is', '', '2', '9', '2', '.', '0', ',', '', 'B03', 'is', '', '4', '7', '3', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '7', '0', '.', '0', ',', '', 'B04', 'is', '', '2', '9', '2', '.', '0', ',', '', 'B03', 'is', '', '4', '7', '3', '.', '0', ',', '', 'B02', 'is', '', '1', '9', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '2', '0', '1', '.', '0', ',', '', 'PID']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5370.0, B04 is 292.0, B03 is 473.0, B02 is 197.0 201.0, PID']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5370.0, B04 is 292.0, B03 is 473.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 5370.0, B04 is 292.0, B03 is 473.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '7', '0', '.', '0', ',', '', 'B04', 'is', '', '2', '9', '2', '.', '0', ',', '', 'B03', 'is', '', '4', '7', '3', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '7', '0', '.', '0', ',', '', 'B04', 'is', '', '2', '9', '2', '.', '0', ',', '', 'B03', 'is', '', '4', '7', '3', '.', '0', ',', '', 'B02', 'is', '', '1', '9', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '1', '4', '9', '7', '9', '7', '7', '1']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5370.0, B04 is 292.0, B03 is 473.0, B02 is 197.0 14979771']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 292.0, DOY is 211.0, PID is 5370.0, B03 is 473.0, B02 is']\n",
      "prompt: B04 is 292.0, DOY is 211.0, PID is 5370.0, B03 is 473.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '2', '9', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '7', '0', '.', '0', ',', '', 'B03', 'is', '', '4', '7', '3', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '2', '9', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '7', '0', '.', '0', ',', '', 'B03', 'is', '', '4', '7', '3', '.', '0', ',', '', 'B02', 'is', '', '1', '9', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '1', '1', '4', '9', '7']]\n",
      "decoded_data: ['B04 is 292.0, DOY is 211.0, PID is 5370.0, B03 is 473.0, B02 is 197.0 PID is 11497']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 292.0, DOY is 211.0, PID is 5370.0, B03 is 473.0, B02 is']\n",
      "prompt: B04 is 292.0, DOY is 211.0, PID is 5370.0, B03 is 473.0, B02 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '2', '9', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '7', '0', '.', '0', ',', '', 'B03', 'is', '', '4', '7', '3', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B04', 'is', '', '2', '9', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '7', '0', '.', '0', ',', '', 'B03', 'is', '', '4', '7', '3', '.', '0', ',', '', 'B02', 'is', '', '1', '9', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'B04', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['B04 is 292.0, DOY is 211.0, PID is 5370.0, B03 is 473.0, B02 is 197.0 B03 is B04 is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 473.0, B04 is 292.0, DOY is 211.0, PID is 5370.0, B02 is']\n",
      "prompt: B03 is 473.0, B04 is 292.0, DOY is 211.0, PID is 5370.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '4', '7', '3', '.', '0', ',', '', 'B04', 'is', '', '2', '9', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '7', '0', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['B03', 'is', '', '4', '7', '3', '.', '0', ',', '', 'B04', 'is', '', '2', '9', '2', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '3', '7', '0', '.', '0', ',', '', 'B02', 'is', '', '1', '4', '9', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', '1', '.', '0', '.', '0']]\n",
      "decoded_data: ['B03 is 473.0, B04 is 292.0, DOY is 211.0, PID is 5370.0, B02 is 149.0 B03 is 1.0.0']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5370.0, DOY is 211.0, B04 is 292.0, B03 is 473.0, B02 is']\n",
      "prompt: PID is 5370.0, DOY is 211.0, B04 is 292.0, B03 is 473.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '3', '7', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '2', '9', '2', '.', '0', ',', '', 'B03', 'is', '', '4', '7', '3', '.', '0', ',', '', 'B02', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|       | 208/829 [06:03<20:04,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '5', '3', '7', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '2', '9', '2', '.', '0', ',', '', 'B03', 'is', '', '4', '7', '3', '.', '0', ',', '', 'B02', 'is', '', '1', '9', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'B04', 'is', '', '4', '0']]\n",
      "decoded_data: ['PID is 5370.0, DOY is 211.0, B04 is 292.0, B03 is 473.0, B02 is 197.0 B03 is B04 is 40']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5370.0, DOY is 211.0, B03 is 473.0, B04 is 292.0, B02 is']\n",
      "prompt: PID is 5370.0, DOY is 211.0, B03 is 473.0, B04 is 292.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '3', '7', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '4', '7', '3', '.', '0', ',', '', 'B04', 'is', '', '2', '9', '2', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '3', '7', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '4', '7', '3', '.', '0', ',', '', 'B04', 'is', '', '2', '9', '2', '.', '0', ',', '', 'B02', 'is', '', '1', '9', '7', '.', '0', '<|endoftext|>', '<|endoftext|>', '1', '4', '0', ',', '', '2', '8', '5', '7']]\n",
      "decoded_data: ['PID is 5370.0, DOY is 211.0, B03 is 473.0, B04 is 292.0, B02 is 197.0140, 2857']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5470.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5470.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '4', '7', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '4', '7', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '3', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '1', '6', '.', '0', ',', '', 'B04', 'is', '', '2', '6', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '2', '8', '8', '9', '2', '.', '0', ',']]\n",
      "decoded_data: ['PID is 5470.0, DOY is 211.0, B03 is 367.0, B02 is 216.0, B04 is 262.0 28892.0,']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 367.0, B02 is 216.0, PID is 5470.0, B04 is']\n",
      "prompt: DOY is 211.0, B03 is 367.0, B02 is 216.0, PID is 5470.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '3', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '1', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '7', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '3', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '1', '6', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '7', '0', '.', '0', ',', '', 'B04', 'is', '', '2', '6', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '2', '8', '5', '4', '8', '5', '4', '.']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 367.0, B02 is 216.0, PID is 5470.0, B04 is 262.0 2854854.']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 367.0, B02 is 216.0, DOY is 211.0, PID is 5470.0, B04 is']\n",
      "prompt: B03 is 367.0, B02 is 216.0, DOY is 211.0, PID is 5470.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '3', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '1', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '7', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '3', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '1', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '7', '0', '.', '0', ',', '', 'B04', 'is', '', '2', '6', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'DOY', 'is', '', 'B02', 'is', '', 'B02', 'is']]\n",
      "decoded_data: ['B03 is 367.0, B02 is 216.0, DOY is 211.0, PID is 5470.0, B04 is 262.0 DOY is B02 is B02 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 216.0, B03 is 367.0, DOY is 211.0, PID is 5470.0, B04 is']\n",
      "prompt: B02 is 216.0, B03 is 367.0, DOY is 211.0, PID is 5470.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '1', '6', '.', '0', ',', '', 'B03', 'is', '', '3', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '7', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '1', '6', '.', '0', ',', '', 'B03', 'is', '', '3', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '7', '0', '.', '0', ',', '', 'B04', 'is', '', '2', '6', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '2', '6', '2', '8', '5', '.', '0', ',', '']]\n",
      "decoded_data: ['B02 is 216.0, B03 is 367.0, DOY is 211.0, PID is 5470.0, B04 is 262.026285.0, ']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 216.0, DOY is 211.0, B03 is 367.0, PID is 5470.0, B04 is']\n",
      "prompt: B02 is 216.0, DOY is 211.0, B03 is 367.0, PID is 5470.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '1', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '3', '6', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '7', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '1', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '3', '6', '7', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '7', '0', '.', '0', ',', '', 'B04', 'is', '', '2', '6', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '1', '6', '2', '8', '8', '8', '5', '.', '0']]\n",
      "decoded_data: ['B02 is 216.0, DOY is 211.0, B03 is 367.0, PID is 5470.0, B04 is 262.01628885.0']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5470.0, DOY is 211.0, B03 is 367.0, B02 is 216.0, B04 is']\n",
      "prompt: PID is 5470.0, DOY is 211.0, B03 is 367.0, B02 is 216.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '4', '7', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '3', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '1', '6', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '4', '7', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '3', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '1', '6', '.', '0', ',', '', 'B04', 'is', '', '2', '6', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '2', '8', '9', '2', '.', '0', ',', '', 'DOY']]\n",
      "decoded_data: ['PID is 5470.0, DOY is 211.0, B03 is 367.0, B02 is 216.0, B04 is 262.02892.0, DOY']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 367.0, DOY is 211.0, PID is 5470.0, B02 is 216.0, B04 is']\n",
      "prompt: B03 is 367.0, DOY is 211.0, PID is 5470.0, B02 is 216.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '3', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '7', '0', '.', '0', ',', '', 'B02', 'is', '', '2', '1', '6', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '3', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '7', '0', '.', '0', ',', '', 'B02', 'is', '', '2', '1', '6', '.', '0', ',', '', 'B04', 'is', '', '2', '6', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '2', '8', '9', '9', '2', '5', '.', '0']]\n",
      "decoded_data: ['B03 is 367.0, DOY is 211.0, PID is 5470.0, B02 is 216.0, B04 is 262.0 289925.0']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5470.0, B02 is 216.0, B03 is 367.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 5470.0, B02 is 216.0, B03 is 367.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '4', '7', '0', '.', '0', ',', '', 'B02', 'is', '', '2', '1', '6', '.', '0', ',', '', 'B03', 'is', '', '3', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '4', '7', '0', '.', '0', ',', '', 'B02', 'is', '', '2', '1', '6', '.', '0', ',', '', 'B03', 'is', '', '3', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '2', '6', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '2', '1', '6', '2', '8', '9', '2', '.']]\n",
      "decoded_data: ['PID is 5470.0, B02 is 216.0, B03 is 367.0, DOY is 211.0, B04 is 262.0 2162892.']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5470.0, DOY is 211.0, B03 is 367.0, B02 is 216.0, B04 is']\n",
      "prompt: PID is 5470.0, DOY is 211.0, B03 is 367.0, B02 is 216.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '4', '7', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '3', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '1', '6', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '4', '7', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '3', '6', '7', '.', '0', ',', '', 'B02', 'is', '', '2', '1', '6', '.', '0', ',', '', 'B04', 'is', '', '2', '6', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '2', '2', '8', '9', '9', '2', '.', '0', '3']]\n",
      "decoded_data: ['PID is 5470.0, DOY is 211.0, B03 is 367.0, B02 is 216.0, B04 is 262.0228992.03']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 216.0, DOY is 211.0, PID is 5470.0, B03 is 367.0, B04 is']\n",
      "prompt: B02 is 216.0, DOY is 211.0, PID is 5470.0, B03 is 367.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '2', '1', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '7', '0', '.', '0', ',', '', 'B03', 'is', '', '3', '6', '7', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '2', '1', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '7', '0', '.', '0', ',', '', 'B03', 'is', '', '3', '6', '7', '.', '0', ',', '', 'B04', 'is', '', '2', '6', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '2', '9', '9', '.', '0', ',', '', 'PID']]\n",
      "decoded_data: ['B02 is 216.0, DOY is 211.0, PID is 5470.0, B03 is 367.0, B04 is 262.0 299.0, PID']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 367.0, DOY is 211.0, PID is 5470.0, B02 is 216.0, B04 is']\n",
      "prompt: B03 is 367.0, DOY is 211.0, PID is 5470.0, B02 is 216.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '3', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '7', '0', '.', '0', ',', '', 'B02', 'is', '', '2', '1', '6', '.', '0', ',', '', 'B04', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|       | 209/829 [06:05<20:13,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B03', 'is', '', '3', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '4', '7', '0', '.', '0', ',', '', 'B02', 'is', '', '2', '1', '6', '.', '0', ',', '', 'B04', 'is', '', '2', '6', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '2', '2', '.', '0', ',', '', 'DOY', 'is']]\n",
      "decoded_data: ['B03 is 367.0, DOY is 211.0, PID is 5470.0, B02 is 216.0, B04 is 262.0 22.0, DOY is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5470.0, B03 is 367.0, DOY is 211.0, B02 is 216.0, B04 is']\n",
      "prompt: PID is 5470.0, B03 is 367.0, DOY is 211.0, B02 is 216.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '4', '7', '0', '.', '0', ',', '', 'B03', 'is', '', '3', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '1', '6', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '4', '7', '0', '.', '0', ',', '', 'B03', 'is', '', '3', '6', '7', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '2', '1', '6', '.', '0', ',', '', 'B04', 'is', '', '2', '6', '2', '.', '0', '<|endoftext|>', '<|endoftext|>', '2', '2', '8', '5', '6', '2', '8', '5', '6']]\n",
      "decoded_data: ['PID is 5470.0, B03 is 367.0, DOY is 211.0, B02 is 216.0, B04 is 262.0228562856']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5570.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 5570.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '7', '0', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '7', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '0', '.', '0', ',', '', 'B03', 'is', '', '5', '5', '9', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B03', 'is', '', 'B03', 'is']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5570.0, B02 is 330.0, B03 is 559.0, B04 is 468.0 PID is B03 is B03 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 330.0, DOY is 211.0, PID is 5570.0, B03 is 559.0, B04 is']\n",
      "prompt: B02 is 330.0, DOY is 211.0, PID is 5570.0, B03 is 559.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '3', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '7', '0', '.', '0', ',', '', 'B03', 'is', '', '5', '5', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '3', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '7', '0', '.', '0', ',', '', 'B03', 'is', '', '5', '5', '9', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B03', 'is', '', 'B04']]\n",
      "decoded_data: ['B02 is 330.0, DOY is 211.0, PID is 5570.0, B03 is 559.0, B04 is 468.0 PID is B03 is B04']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 330.0, PID is 5570.0, B03 is 559.0, B04 is']\n",
      "prompt: DOY is 211.0, B02 is 330.0, PID is 5570.0, B03 is 559.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '7', '0', '.', '0', ',', '', 'B03', 'is', '', '5', '5', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '7', '0', '.', '0', ',', '', 'B03', 'is', '', '5', '5', '9', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B03', 'is', '', 'B03', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 330.0, PID is 5570.0, B03 is 559.0, B04 is 468.0 PID is B03 is B03 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5570.0, B02 is 330.0, DOY is 211.0, B03 is 559.0, B04 is']\n",
      "prompt: PID is 5570.0, B02 is 330.0, DOY is 211.0, B03 is 559.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '5', '7', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '5', '5', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '5', '7', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '5', '5', '9', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '6', '8', '9', '8', '9', '8', '9']]\n",
      "decoded_data: ['PID is 5570.0, B02 is 330.0, DOY is 211.0, B03 is 559.0, B04 is 468.0 46898989']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 330.0, PID is 5570.0, DOY is 211.0, B03 is 559.0, B04 is']\n",
      "prompt: B02 is 330.0, PID is 5570.0, DOY is 211.0, B03 is 559.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '3', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '7', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '5', '5', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '3', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '7', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '5', '5', '9', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B03', 'is', '', 'PID', 'is']]\n",
      "decoded_data: ['B02 is 330.0, PID is 5570.0, DOY is 211.0, B03 is 559.0, B04 is 468.0 PID is B03 is PID is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 330.0, PID is 5570.0, B03 is 559.0, DOY is 211.0, B04 is']\n",
      "prompt: B02 is 330.0, PID is 5570.0, B03 is 559.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '3', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '7', '0', '.', '0', ',', '', 'B03', 'is', '', '5', '5', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '3', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '7', '0', '.', '0', ',', '', 'B03', 'is', '', '5', '5', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'PID', 'is', '', 'B03', 'is']]\n",
      "decoded_data: ['B02 is 330.0, PID is 5570.0, B03 is 559.0, DOY is 211.0, B04 is 468.0 B03 is PID is B03 is']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 559.0, B02 is 330.0, PID is 5570.0, B04 is']\n",
      "prompt: DOY is 211.0, B03 is 559.0, B02 is 330.0, PID is 5570.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '5', '5', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '7', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '5', '5', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '7', '0', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'PID', 'is', '', 'B03', 'is']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 559.0, B02 is 330.0, PID is 5570.0, B04 is 468.0 B03 is PID is B03 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 330.0, DOY is 211.0, B03 is 559.0, PID is 5570.0, B04 is']\n",
      "prompt: B02 is 330.0, DOY is 211.0, B03 is 559.0, PID is 5570.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '3', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '5', '5', '9', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '7', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '3', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '5', '5', '9', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '7', '0', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '4', '0', '0', '.', '0', '4', '.', '0']]\n",
      "decoded_data: ['B02 is 330.0, DOY is 211.0, B03 is 559.0, PID is 5570.0, B04 is 468.0 400.04.0']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5570.0, DOY is 211.0, B03 is 559.0, B02 is 330.0, B04 is']\n",
      "prompt: PID is 5570.0, DOY is 211.0, B03 is 559.0, B02 is 330.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '5', '7', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '5', '5', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '5', '7', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '5', '5', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '0', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'PID', 'is', '', '4', '5']]\n",
      "decoded_data: ['PID is 5570.0, DOY is 211.0, B03 is 559.0, B02 is 330.0, B04 is 468.0 B03 is PID is 45']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 559.0, PID is 5570.0, DOY is 211.0, B02 is 330.0, B04 is']\n",
      "prompt: B03 is 559.0, PID is 5570.0, DOY is 211.0, B02 is 330.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '5', '5', '9', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '7', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '5', '5', '9', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '7', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '0', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'PID', 'is', '', 'DOY', 'is']]\n",
      "decoded_data: ['B03 is 559.0, PID is 5570.0, DOY is 211.0, B02 is 330.0, B04 is 468.0 B03 is PID is DOY is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 330.0, B03 is 559.0, DOY is 211.0, PID is 5570.0, B04 is']\n",
      "prompt: B02 is 330.0, B03 is 559.0, DOY is 211.0, PID is 5570.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '3', '0', '.', '0', ',', '', 'B03', 'is', '', '5', '5', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '7', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '3', '0', '.', '0', ',', '', 'B03', 'is', '', '5', '5', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '7', '0', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B03', 'is', '', '4', '5']]\n",
      "decoded_data: ['B02 is 330.0, B03 is 559.0, DOY is 211.0, PID is 5570.0, B04 is 468.0 PID is B03 is 45']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 559.0, B02 is 330.0, PID is 5570.0, DOY is 211.0, B04 is']\n",
      "prompt: B03 is 559.0, B02 is 330.0, PID is 5570.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '5', '5', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '7', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '5', '5', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '7', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '4', '5', '5', '3', '2', '5', '5', '.', '0']]\n",
      "decoded_data: ['B03 is 559.0, B02 is 330.0, PID is 5570.0, DOY is 211.0, B04 is 468.04553255.0']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5570.0, B03 is 559.0, B02 is 330.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 5570.0, B03 is 559.0, B02 is 330.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '7', '0', '.', '0', ',', '', 'B03', 'is', '', '5', '5', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '7', '0', '.', '0', ',', '', 'B03', 'is', '', '5', '5', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '0', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B03', 'is', '', 'PID', 'is', '', 'DOY', 'is']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5570.0, B03 is 559.0, B02 is 330.0, B04 is 468.0 B03 is PID is DOY is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 330.0, PID is 5570.0, B03 is 559.0, DOY is 211.0, B04 is']\n",
      "prompt: B02 is 330.0, PID is 5570.0, B03 is 559.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '3', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '7', '0', '.', '0', ',', '', 'B03', 'is', '', '5', '5', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '3', '0', '.', '0', ',', '', 'PID', 'is', '', '5', '5', '7', '0', '.', '0', ',', '', 'B03', 'is', '', '5', '5', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B03', 'is', '', 'PID']]\n",
      "decoded_data: ['B02 is 330.0, PID is 5570.0, B03 is 559.0, DOY is 211.0, B04 is 468.0 PID is B03 is PID']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5570.0, B03 is 559.0, DOY is 211.0, B02 is 330.0, B04 is']\n",
      "prompt: PID is 5570.0, B03 is 559.0, DOY is 211.0, B02 is 330.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '5', '7', '0', '.', '0', ',', '', 'B03', 'is', '', '5', '5', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '0', '.', '0', ',', '', 'B04', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 25%|       | 210/829 [06:08<21:19,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['PID', 'is', '', '5', '5', '7', '0', '.', '0', ',', '', 'B03', 'is', '', '5', '5', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '3', '0', '.', '0', ',', '', 'B04', 'is', '', '4', '6', '8', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'DOY', 'is', '', 'PID', 'is', '', 'B03', 'is']]\n",
      "decoded_data: ['PID is 5570.0, B03 is 559.0, DOY is 211.0, B02 is 330.0, B04 is 468.0 DOY is PID is B03 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5670.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5670.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '6', '7', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '6', '7', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '9', '6', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '5', '9']]\n",
      "decoded_data: ['PID is 5670.0, DOY is 211.0, B03 is 724.0, B04 is 596.0, B02 is 395.0 PID is B04 is 59']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5670.0, B03 is 724.0, B04 is 596.0, DOY is 211.0, B02 is']\n",
      "prompt: PID is 5670.0, B03 is 724.0, B04 is 596.0, DOY is 211.0, B02 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '6', '7', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '9', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '6', '7', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '9', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '3', '9']]\n",
      "decoded_data: ['PID is 5670.0, B03 is 724.0, B04 is 596.0, DOY is 211.0, B02 is 395.0 PID is B04 is 39']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 724.0, B04 is 596.0, DOY is 211.0, PID is 5670.0, B02 is']\n",
      "prompt: B03 is 724.0, B04 is 596.0, DOY is 211.0, PID is 5670.0, B02 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '9', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '7', '0', '.', '0', ',', '', 'B02', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|       | 211/829 [06:08<16:49,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['B03', 'is', '', '7', '2', '4', '.', '0', ',', '', 'B04', 'is', '', '5', '9', '6', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '6', '7', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '9', '5', '.', '0', '<|endoftext|>', '<|endoftext|>', '4', '2', '2', '2', '2', '1', '9', '7', '3']]\n",
      "decoded_data: ['B03 is 724.0, B04 is 596.0, DOY is 211.0, PID is 5670.0, B02 is 395.0422221973']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5770.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 5770.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '7', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '7', '0', '.', '0', ',', '', 'B04', 'is', '', '6', '3', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5770.0, B04 is 631.0, B02 is 369.0, B03 is 756.0 PID is B04 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5770.0, B04 is 631.0, B02 is 369.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5770.0, B04 is 631.0, B02 is 369.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '7', '7', '0', '.', '0', ',', '', 'B04', 'is', '', '6', '3', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '7', '7', '0', '.', '0', ',', '', 'B04', 'is', '', '6', '3', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '8', '1', '6', '7']]\n",
      "decoded_data: ['PID is 5770.0, B04 is 631.0, B02 is 369.0, DOY is 211.0, B03 is 756.0 PID is 78167']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5770.0, B02 is 369.0, B04 is 631.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5770.0, B02 is 369.0, B04 is 631.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '7', '7', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '6', '3', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '7', '7', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '6', '3', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '5', '6', '7', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['PID is 5770.0, B02 is 369.0, B04 is 631.0, DOY is 211.0, B03 is 756.07567PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5770.0, DOY is 211.0, B04 is 631.0, B02 is 369.0, B03 is']\n",
      "prompt: PID is 5770.0, DOY is 211.0, B04 is 631.0, B02 is 369.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '7', '7', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '3', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '9', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '7', '7', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '3', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '7', '5', '6', '.', '0', ',', '', 'B04', 'is']]\n",
      "decoded_data: ['PID is 5770.0, DOY is 211.0, B04 is 631.0, B02 is 369.0, B03 is 756.0756.0, B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5770.0, B04 is 631.0, B02 is 369.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5770.0, B04 is 631.0, B02 is 369.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '7', '7', '0', '.', '0', ',', '', 'B04', 'is', '', '6', '3', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '7', '7', '0', '.', '0', ',', '', 'B04', 'is', '', '6', '3', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['PID is 5770.0, B04 is 631.0, B02 is 369.0, DOY is 211.0, B03 is 756.0 PID is B04 is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5770.0, B04 is 631.0, B02 is 369.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5770.0, B04 is 631.0, B02 is 369.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '7', '7', '0', '.', '0', ',', '', 'B04', 'is', '', '6', '3', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '7', '7', '0', '.', '0', ',', '', 'B04', 'is', '', '6', '3', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'B04', 'is', '', '7', '5']]\n",
      "decoded_data: ['PID is 5770.0, B04 is 631.0, B02 is 369.0, DOY is 211.0, B03 is 756.0 PID is B04 is 75']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 369.0, DOY is 211.0, B04 is 631.0, PID is 5770.0, B03 is']\n",
      "prompt: B02 is 369.0, DOY is 211.0, B04 is 631.0, PID is 5770.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '3', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '7', '0', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '3', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '7', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', 'B04', 'is']]\n",
      "decoded_data: ['B02 is 369.0, DOY is 211.0, B04 is 631.0, PID is 5770.0, B03 is 756.0 B04 is PID is B04 is']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 369.0, DOY is 211.0, PID is 5770.0, B04 is 631.0, B03 is']\n",
      "prompt: B02 is 369.0, DOY is 211.0, PID is 5770.0, B04 is 631.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '7', '0', '.', '0', ',', '', 'B04', 'is', '', '6', '3', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '7', '0', '.', '0', ',', '', 'B04', 'is', '', '6', '3', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '6', '7']]\n",
      "decoded_data: ['B02 is 369.0, DOY is 211.0, PID is 5770.0, B04 is 631.0, B03 is 756.0 B04 is PID is 67']\n",
      "------------------------------------\n",
      "loop_iter: ['B04 is 631.0, B02 is 369.0, PID is 5770.0, DOY is 211.0, B03 is']\n",
      "prompt: B04 is 631.0, B02 is 369.0, PID is 5770.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B04', 'is', '', '6', '3', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '9', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '7', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B04', 'is', '', '6', '3', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '9', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '7', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '5', '6', '9', '3']]\n",
      "decoded_data: ['B04 is 631.0, B02 is 369.0, PID is 5770.0, DOY is 211.0, B03 is 756.0 PID is 75693']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5770.0, B02 is 369.0, B04 is 631.0, DOY is 211.0, B03 is']\n",
      "prompt: PID is 5770.0, B02 is 369.0, B04 is 631.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '7', '7', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '6', '3', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '7', '7', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '6', '3', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '7', '5', '6', '7', '5']]\n",
      "decoded_data: ['PID is 5770.0, B02 is 369.0, B04 is 631.0, DOY is 211.0, B03 is 756.0 B04 is 75675']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 369.0, B04 is 631.0, PID is 5770.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 369.0, B04 is 631.0, PID is 5770.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '6', '3', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '7', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '6', '9', '.', '0', ',', '', 'B04', 'is', '', '6', '3', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '7', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '5']]\n",
      "decoded_data: ['B02 is 369.0, B04 is 631.0, PID is 5770.0, DOY is 211.0, B03 is 756.0 B04 is PID is 75']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5770.0, B04 is 631.0, B02 is 369.0, B03 is']\n",
      "prompt: DOY is 211.0, PID is 5770.0, B04 is 631.0, B02 is 369.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '7', '0', '.', '0', ',', '', 'B04', 'is', '', '6', '3', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '9', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '7', '0', '.', '0', ',', '', 'B04', 'is', '', '6', '3', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '1', '6', '7', '1']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5770.0, B04 is 631.0, B02 is 369.0, B03 is 756.0 PID is 71671']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 369.0, PID is 5770.0, B04 is 631.0, DOY is 211.0, B03 is']\n",
      "prompt: B02 is 369.0, PID is 5770.0, B04 is 631.0, DOY is 211.0, B03 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '6', '9', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '7', '0', '.', '0', ',', '', 'B04', 'is', '', '6', '3', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '6', '9', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '7', '0', '.', '0', ',', '', 'B04', 'is', '', '6', '3', '1', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', 'PID', 'is', '', '7', '5']]\n",
      "decoded_data: ['B02 is 369.0, PID is 5770.0, B04 is 631.0, DOY is 211.0, B03 is 756.0 B04 is PID is 75']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5770.0, B02 is 369.0, DOY is 211.0, B04 is 631.0, B03 is']\n",
      "prompt: PID is 5770.0, B02 is 369.0, DOY is 211.0, B04 is 631.0, B03 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '7', '7', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '3', '1', '.', '0', ',', '', 'B03', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '7', '7', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '3', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'B04', 'is', '', '6', '4', '1', '6', '.']]\n",
      "decoded_data: ['PID is 5770.0, B02 is 369.0, DOY is 211.0, B04 is 631.0, B03 is 756.0 B04 is 6416.']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B04 is 631.0, B02 is 369.0, PID is 5770.0, B03 is']\n",
      "prompt: DOY is 211.0, B04 is 631.0, B02 is 369.0, PID is 5770.0, B03 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '3', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '9', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '7', '0', '.', '0', ',', '', 'B03', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 26%|       | 212/829 [06:10<18:56,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '6', '3', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '6', '9', '.', '0', ',', '', 'PID', 'is', '', '5', '7', '7', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '5', '6', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '7', '5', '6', '7', '7']]\n",
      "decoded_data: ['DOY is 211.0, B04 is 631.0, B02 is 369.0, PID is 5770.0, B03 is 756.0 PID is 75677']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5870.0, B02 is']\n",
      "prompt: DOY is 211.0, PID is 5870.0, B02 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '7', '0', '.', '0', ',', '', 'B02', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '7', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '2', '9', '3', '.', '0', 'is', '']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5870.0, B02 is 329.0, B03 is 729.0, B04 is 573.0 5293.0 is ']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 729.0, PID is 5870.0, DOY is 211.0, B02 is 329.0, B04 is']\n",
      "prompt: B03 is 729.0, PID is 5870.0, DOY is 211.0, B02 is 329.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '2', '9', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '7', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '2', '9', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '7', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '5', '2', '9', '0', '.', '0', ',', '', 'PID']]\n",
      "decoded_data: ['B03 is 729.0, PID is 5870.0, DOY is 211.0, B02 is 329.0, B04 is 573.05290.0, PID']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5870.0, B03 is 729.0, B02 is 329.0, DOY is 211.0, B04 is']\n",
      "prompt: PID is 5870.0, B03 is 729.0, B02 is 329.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '8', '7', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '8', '7', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '8', '7', '3', '1', '0', '8', '6']]\n",
      "decoded_data: ['PID is 5870.0, B03 is 729.0, B02 is 329.0, DOY is 211.0, B04 is 573.0 58731086']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 729.0, B02 is 329.0, PID is 5870.0, DOY is 211.0, B04 is']\n",
      "prompt: B03 is 729.0, B02 is 329.0, PID is 5870.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '2', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '9', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '7', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '2', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '9', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '7', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '9', '1', '9', '3']]\n",
      "decoded_data: ['B03 is 729.0, B02 is 329.0, PID is 5870.0, DOY is 211.0, B04 is 573.0 PID is 59193']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 729.0, PID is 5870.0, DOY is 211.0, B02 is 329.0, B04 is']\n",
      "prompt: B03 is 729.0, PID is 5870.0, DOY is 211.0, B02 is 329.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '2', '9', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '7', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '2', '9', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '7', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', 'PID', 'is', '', '5', '7']]\n",
      "decoded_data: ['B03 is 729.0, PID is 5870.0, DOY is 211.0, B02 is 329.0, B04 is 573.0 PID is PID is 57']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 729.0, PID is 5870.0, B02 is 329.0, DOY is 211.0, B04 is']\n",
      "prompt: B03 is 729.0, PID is 5870.0, B02 is 329.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '2', '9', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '7', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '2', '9', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '7', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '8', '1', '9', '1']]\n",
      "decoded_data: ['B03 is 729.0, PID is 5870.0, B02 is 329.0, DOY is 211.0, B04 is 573.0 PID is 58191']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5870.0, DOY is 211.0, B03 is 729.0, B02 is 329.0, B04 is']\n",
      "prompt: PID is 5870.0, DOY is 211.0, B03 is 729.0, B02 is 329.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '8', '7', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '8', '7', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '8', '7', '3', '3']]\n",
      "decoded_data: ['PID is 5870.0, DOY is 211.0, B03 is 729.0, B02 is 329.0, B04 is 573.0 PID is 58733']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 329.0, B03 is 729.0, DOY is 211.0, PID is 5870.0, B04 is']\n",
      "prompt: B02 is 329.0, B03 is 729.0, DOY is 211.0, PID is 5870.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '2', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '7', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '2', '9', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '7', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '3', '3', '3', '3', '8', '7', '.', '0', '.']]\n",
      "decoded_data: ['B02 is 329.0, B03 is 729.0, DOY is 211.0, PID is 5870.0, B04 is 573.0333387.0.']\n",
      "------------------------------------\n",
      "loop_iter: ['B03 is 729.0, PID is 5870.0, B02 is 329.0, DOY is 211.0, B04 is']\n",
      "prompt: B03 is 729.0, PID is 5870.0, B02 is 329.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B03', 'is', '', '7', '2', '9', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '7', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B03', 'is', '', '7', '2', '9', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '7', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '8', '7', '3', '3']]\n",
      "decoded_data: ['B03 is 729.0, PID is 5870.0, B02 is 329.0, DOY is 211.0, B04 is 573.0 PID is 58733']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 329.0, PID is 5870.0, B03 is 729.0, DOY is 211.0, B04 is']\n",
      "prompt: B02 is 329.0, PID is 5870.0, B03 is 729.0, DOY is 211.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '2', '9', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '7', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '2', '9', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '7', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '3', '3', '3', '3']]\n",
      "decoded_data: ['B02 is 329.0, PID is 5870.0, B03 is 729.0, DOY is 211.0, B04 is 573.0 PID is 53333']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B03 is 729.0, B02 is 329.0, PID is 5870.0, B04 is']\n",
      "prompt: DOY is 211.0, B03 is 729.0, B02 is 329.0, PID is 5870.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '9', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '7', '0', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '9', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '7', '0', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '4', '2', '9', '3']]\n",
      "decoded_data: ['DOY is 211.0, B03 is 729.0, B02 is 329.0, PID is 5870.0, B04 is 573.0 PID is 54293']\n",
      "------------------------------------\n",
      "loop_iter: ['PID is 5870.0, B02 is 329.0, DOY is 211.0, B03 is 729.0, B04 is']\n",
      "prompt: PID is 5870.0, B02 is 329.0, DOY is 211.0, B03 is 729.0, B04 is\n",
      "tokenizer.tokenize: ['PID', 'is', '', '5', '8', '7', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['PID', 'is', '', '5', '8', '7', '0', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '9', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '8', '7', '3', '3']]\n",
      "decoded_data: ['PID is 5870.0, B02 is 329.0, DOY is 211.0, B03 is 729.0, B04 is 573.0 PID is 58733']\n",
      "------------------------------------\n",
      "loop_iter: ['B02 is 329.0, PID is 5870.0, DOY is 211.0, B03 is 729.0, B04 is']\n",
      "prompt: B02 is 329.0, PID is 5870.0, DOY is 211.0, B03 is 729.0, B04 is\n",
      "tokenizer.tokenize: ['B02', 'is', '', '3', '2', '9', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '7', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['B02', 'is', '', '3', '2', '9', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '7', '0', '.', '0', ',', '', 'DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', 'PID', 'is', '', '5', '7', '3', '3', '2']]\n",
      "decoded_data: ['B02 is 329.0, PID is 5870.0, DOY is 211.0, B03 is 729.0, B04 is 573.0 PID is 57332']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, B02 is 329.0, PID is 5870.0, B03 is 729.0, B04 is']\n",
      "prompt: DOY is 211.0, B02 is 329.0, PID is 5870.0, B03 is 729.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '9', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '7', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '9', '.', '0', ',', '', 'B04', 'is']\n",
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '9', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '7', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '8', '7', '3', '8', '7', '0', '.']]\n",
      "decoded_data: ['DOY is 211.0, B02 is 329.0, PID is 5870.0, B03 is 729.0, B04 is 573.0 5873870.']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5870.0, B03 is 729.0, B02 is 329.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 5870.0, B03 is 729.0, B02 is 329.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '7', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '9', '.', '0', ',', '', 'B04', 'is']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aispace/great.py:546: UserWarning: Max retries reached.\n",
      "  warnings.warn(\"Max retries reached.\")\n",
      " 26%|       | 213/829 [06:13<20:43,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen tokens: [['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '8', '7', '0', '.', '0', ',', '', 'B03', 'is', '', '7', '2', '9', '.', '0', ',', '', 'B02', 'is', '', '3', '2', '9', '.', '0', ',', '', 'B04', 'is', '', '5', '7', '3', '.', '0', '<|endoftext|>', '<|endoftext|>', '', '5', '8', '6', '.', '0', '8', '6', '6']]\n",
      "decoded_data: ['DOY is 211.0, PID is 5870.0, B03 is 729.0, B02 is 329.0, B04 is 573.0 586.0866']\n",
      "------------------------------------\n",
      "loop_iter: ['DOY is 211.0, PID is 5970.0, B04 is']\n",
      "prompt: DOY is 211.0, PID is 5970.0, B04 is\n",
      "tokenizer.tokenize: ['DOY', 'is', '', '2', '1', '1', '.', '0', ',', '', 'PID', 'is', '', '5', '9', '7', '0', '.', '0', ',', '', 'B04', 'is']\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "\n",
    "i_run = 1\n",
    "\n",
    "EXP_NAME = 'A0[RGB_TOK[ai]]'\n",
    "chkpt_list = [24000, 160000]\n",
    "\n",
    "# EXP_NAME = f'A0[RGB_TOK[distilgpt2]]'\n",
    "# chkpt_list = [22000, ]\n",
    "\n",
    "load_model_path_list = []\n",
    "experiment_dir_list  = []\n",
    "\n",
    "for i_run, chkpt in enumerate(chkpt_list):\n",
    "    experiment_dir_list.append(f'{EXP_NAME}/run[{i_run}]')\n",
    "    load_model_path_list.append(f'{EXP_NAME}/run[{i_run}]/checkpoint-{chkpt}')\n",
    "    # load_model_path_list.append(f'run[{i_run}]/model')\n",
    "\n",
    "print(load_model_path_list)\n",
    "\n",
    "print('i_run:', i_run, load_model_path_list[i_run])\n",
    "\n",
    "train_columns_list = ['B02', 'B03', 'B04', 'PID', 'DOY']\n",
    "\n",
    "# i_run = 0\n",
    "model = GetModel(train_data[train_columns_list], \n",
    "                 experiment_dir = experiment_dir_list[i_run], \n",
    "                 load_model_path = load_model_path_list[i_run], \n",
    "                 # tokenizer=load_model_path_list[i_run],)\n",
    "                 tokenizer=f\"{EXP_NAME}/aispace-tokenizer\")\n",
    "# model = []\n",
    "\n",
    "recovered_data = hls_data._impute(model=model, k=10000, max_length=60, temperature=0.01) #, device='cpu')\n",
    "\n",
    "imputed_file = f'{EXP_NAME}/recovered_output_run[{i_run}].csv'\n",
    "hls_data._save_recovered(imputed_file=imputed_file)\n",
    "\n",
    "imputed_file = f'{EXP_NAME}/imputed_output_run[{i_run}].csv'\n",
    "hls_data._save_imputed(imputed_file=imputed_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2391,
     "status": "ok",
     "timestamp": 1698374873218,
     "user": {
      "displayName": "Koyaua Uvarov",
      "userId": "04551130653342672393"
     },
     "user_tz": -180
    },
    "id": "52mz1GuEoAVH",
    "outputId": "d62911da-829e-4557-95c6-3617f24bb287",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "i_run=1\n",
    "\n",
    "# imputed_file = f'{experiment_dir}/imputed_output_run[{i_run}].csv'\n",
    "# imputed_data = hls_data._read_imputed(imputed_file)\n",
    "\n",
    "imputed_file = f'{EXP_NAME}/recovered_output_run[{i_run}].csv'\n",
    "recovered_data = hls_data._read_recovered(imputed_file)\n",
    "\n",
    "# display(imputed_data)\n",
    "print('recovered_data')\n",
    "display(recovered_data)\n",
    "\n",
    "hls_data._set_inference_recovered()\n",
    "hls_data._inference_imshow()\n",
    "\n",
    "\n",
    "# fn\n",
    "# experiment_dir = 'A0[shuf_sophia]'\n",
    "# experiment_dir = 'A0[great_sophia]'\n",
    "imputed_file = f'{EXP_NAME}/recovered_output_run[{i_run}].csv'\n",
    "for i_run in range(4,5):\n",
    "  imputed_file = f'{EXP_NAME}/recovered_output_run[{i_run}].csv'\n",
    "  recovered_data = hls_data._read_recovered(imputed_file)\n",
    "\n",
    "  hls_data._set_inference_recovered()\n",
    "  hls_data._inference_imshow()\n",
    "# display(recovered_data)\n",
    "# recovered_data = pd.read_csv(imputed_file)\n",
    "\n",
    "# display(recovered_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1698374782154,
     "user": {
      "displayName": "Koyaua Uvarov",
      "userId": "04551130653342672393"
     },
     "user_tz": -180
    },
    "id": "V87t1ZruBY5w"
   },
   "outputs": [],
   "source": [
    "# hls_data._imputed_data(recovered_data)\n",
    "\n",
    "hls_data._set_inference_recovered()\n",
    "\n",
    "# hls_data._inference_train_test_data()\n",
    "hls_data._inference_imshow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1698374782154,
     "user": {
      "displayName": "Koyaua Uvarov",
      "userId": "04551130653342672393"
     },
     "user_tz": -180
    },
    "id": "0ZfvhzTy5RU3"
   },
   "outputs": [],
   "source": [
    "fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1698374782154,
     "user": {
      "displayName": "Koyaua Uvarov",
      "userId": "04551130653342672393"
     },
     "user_tz": -180
    },
    "id": "tQxA80SIzte8"
   },
   "outputs": [],
   "source": [
    "# #### TEST METRICS ##################\n",
    "# nan_data = test_data.copy()\n",
    "# nan_data = nan_data.reset_index(drop=True)\n",
    "\n",
    "# print(nan_data.dtypes.tolist())\n",
    "\n",
    "# display(nan_data)\n",
    "# print(nan_data.columns)\n",
    "# # fn\n",
    "\n",
    "# print(f'NumPy version:{np.__version__}')\n",
    "# np.float = float\n",
    "\n",
    "# imputed_data = model.impute(nan_data, k=256, max_length=50000, temperature=0.01) #, device='cpu')\n",
    "# imputed_data.to_csv('test_imputed_output.csv')\n",
    "\n",
    "# # imputed_data = pd.read_csv('imputed_output.csv')\n",
    "# # ######### CLEAR UNNAMED COLUMNS FROM DATASETS #######################################\n",
    "# # imputed_data = imputed_data.loc[:, ~imputed_data.columns.str.contains('^Unnamed')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1698374782154,
     "user": {
      "displayName": "Koyaua Uvarov",
      "userId": "04551130653342672393"
     },
     "user_tz": -180
    },
    "id": "IcO1rdVyHI-b"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "impute = HLSInference(model, doy=211.0)\n",
    "\n",
    "impute._impute()\n",
    "\n",
    "imputed_file = f'{experiment_dir}/imputed_output.csv'\n",
    "impute._save_recovered(imputed_file = imputed_file)\n",
    "\n",
    "\n",
    "fn\n",
    "#### INFERENCE DATA #####################################\n",
    "# nan_data = test_data[test_data.isnull().any(axis=1)].astype('float64').copy()\n",
    "nan_data = to_impute.copy()\n",
    "# nan_data.astype('int16')\n",
    "# Reset the index to remove it\n",
    "#### for only one day processing ###########################\n",
    "nan_data_impute = nan_data.loc[(nan_data['DOY'] == 211.0)]\n",
    "nan_data_resid  = nan_data.loc[(nan_data['DOY'] != 211.0)]\n",
    "nan_data_impute = nan_data_impute.reset_index(drop=True)\n",
    "nan_data_resid  = nan_data_resid.reset_index(drop=True)\n",
    "\n",
    "print(nan_data.dtypes.tolist())\n",
    "\n",
    "display(nan_data_impute)\n",
    "print(nan_data_impute.columns)\n",
    "# fn\n",
    "\n",
    "print(f'NumPy version:{np.__version__}')\n",
    "np.float = float\n",
    "\n",
    "imputed_file = f'{experiment_dir}_imputed_output.csv'\n",
    "\n",
    "imputed_data = model.impute(nan_data_impute, k=256, max_length=50000, temperature=0.01) #, device='cpu')\n",
    "imputed_data.to_csv(imputed_file)\n",
    "\n",
    "# imputed_data = pd.read_csv('imputed_output.csv')\n",
    "# ######### CLEAR UNNAMED COLUMNS FROM DATASETS #######################################\n",
    "# imputed_data = imputed_data.loc[:, ~imputed_data.columns.str.contains('^Unnamed')]\n",
    "\n",
    "display(nan_data_impute)\n",
    "display(imputed_data)\n",
    "\n",
    "recovered_data = pd.concat([imputed_data, nan_data_resid], axis=0)\n",
    "recovered_data = recovered_data.reset_index(drop=True)\n",
    "\n",
    "hls_data._imputed_data(recovered_data)\n",
    "\n",
    "hls_data._inference_train_test_data()\n",
    "hls_data._inference_imshow()\n",
    "\n",
    "# imputed_data.to_csv('imputed_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "aborted",
     "timestamp": 1698374782154,
     "user": {
      "displayName": "Koyaua Uvarov",
      "userId": "04551130653342672393"
     },
     "user_tz": -180
    },
    "id": "wOHdGa4sQm2M"
   },
   "outputs": [],
   "source": [
    "imputed_data.to_csv(imputed_file)\n",
    "\n",
    "def _image_df2(input1, input2):\n",
    "    BND_LIST = ['B01', 'B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B09', 'B10', 'B11']\n",
    "    FMSK_LIST = ['cirrus', 'cloud', 'adj_cloud', 'cloud_shadow', 'snow_ice', 'water', 'aero' ]\n",
    "    ANG_LIST = ['SAA', 'SZA', 'VAA', 'VZA',]\n",
    "\n",
    "    input = input1\n",
    "\n",
    "    box_x_size = (input['X'].max() - input['X'].min() + 1).astype(int)\n",
    "    box_y_size = (input['Y'].max() - input['Y'].min() + 1).astype(int)\n",
    "\n",
    "    def _get_img_nan(input, bnd_list=['B04', 'B03', 'B02']):\n",
    "\n",
    "        print(input['DOY'].unique())\n",
    "\n",
    "        df = input[bnd_list].copy()\n",
    "\n",
    "        df[df > 0] = 0\n",
    "        df[df == -9999] = 1\n",
    "        df[df < 0] = 0\n",
    "\n",
    "        image = df.to_numpy()  # df[chanel_list]\n",
    "\n",
    "        image = image.transpose()\n",
    "        image = image.reshape(image.shape[0], box_x_size, box_y_size)\n",
    "\n",
    "        nans = np.dstack((image[0,:,:], image[1,:,:], image[2,:,:]))\n",
    "\n",
    "        return nans\n",
    "\n",
    "\n",
    "    def _get_img_rgb(input, bnd_list=['B04', 'B03', 'B02']):\n",
    "        df = input[bnd_list].copy()\n",
    "\n",
    "        # df[df > 0] = 0\n",
    "        df[df == -9999] = np.nan\n",
    "        # df[df < 0] = 0\n",
    "\n",
    "        image = df.to_numpy()\n",
    "\n",
    "        image = image.transpose()\n",
    "        image = image.reshape(image.shape[0], box_x_size, box_y_size)\n",
    "\n",
    "        # Convert the int16 array to int64\n",
    "        # image = image.astype(np.uint64)\n",
    "\n",
    "        r_ = (8200, 16000)\n",
    "        g_ = (8500, 14000)\n",
    "        b_ = (7500, 12000)\n",
    "\n",
    "\n",
    "        def generalized_normalization(band, rgb):\n",
    "            # Apply your normalization method here\n",
    "            # Example: Stretch and scale values to 0-255\n",
    "            band = np.ma.array (band, mask=np.isnan(band))\n",
    "\n",
    "            ### FOR HLS #################\n",
    "            band = 0.0001 * band\n",
    "            band = np.where(band > 0.3, 0.3, band)\n",
    "            min_val = -0.063\n",
    "            max_val = 0.3\n",
    "\n",
    "            # min_val = np.min(band)\n",
    "            # max_val = np.max(band)\n",
    "            # min_val = rgb[0]\n",
    "            # max_val = rgb[1]\n",
    "            # print(f'gn:{min_val}, {max_val}')\n",
    "            normalized_band = ((band - min_val) / (max_val - min_val) * 255).astype(np.uint8)\n",
    "            #\n",
    "            # Replace elements greater than 2000 with 1\n",
    "            # print('band:', band.min(), band.max())\n",
    "            normalized_band[normalized_band == np.nan] = 255\n",
    "            return normalized_band\n",
    "\n",
    "        # Scale the bands to 8-bit\n",
    "        scaled_red = generalized_normalization(image[2,:,:], r_)\n",
    "        scaled_green = generalized_normalization(image[1,:,:], g_)\n",
    "        scaled_blue = generalized_normalization(image[0,:,:], b_)\n",
    "\n",
    "        rgb = np.dstack((scaled_red, scaled_green, scaled_blue))\n",
    "\n",
    "        return rgb\n",
    "\n",
    "    def _get_img(input, bnd_list):\n",
    "        image = input[bnd_list].to_numpy()  # df[chanel_list]\n",
    "\n",
    "        image = image.transpose()\n",
    "        image = image.reshape(image.shape[0], box_x_size, box_y_size)\n",
    "\n",
    "        # Convert the int16 array to int64\n",
    "        image = image.astype(np.uint64)\n",
    "\n",
    "        return image[0,:,:]\n",
    "\n",
    "    # image_nan = _get_img_nan(input, bnd_list=['B02', 'B03', 'B04'])\n",
    "    image_rgb = _get_img_rgb(input1, bnd_list=['B02', 'B03', 'B04'])\n",
    "\n",
    "    image_rgb2 = _get_img_rgb(input2, bnd_list=['B02', 'B03', 'B04'])\n",
    "\n",
    "    image_rgb_list = [image_rgb, image_rgb2]\n",
    "\n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(1, len(image_rgb_list), figsize=(18, 22))\n",
    "    # Flatten the axes array to simplify indexing\n",
    "    axes = axes.ravel()\n",
    "    # print(image_rgb_list[0].shape)\n",
    "    axes[0].imshow(image_rgb_list[0])\n",
    "    # Loop through the images and plot them\n",
    "    for ii in range(1,len(image_rgb_list)):\n",
    "        axes[ii].imshow(image_rgb_list[ii], cmap='gray')  # You can specify a colormap\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1698374782155,
     "user": {
      "displayName": "Koyaua Uvarov",
      "userId": "04551130653342672393"
     },
     "user_tz": -180
    },
    "id": "QyYBcrVWHI-b"
   },
   "outputs": [],
   "source": [
    "clear_data = clear.copy()\n",
    "clear_data = clear_data.loc[(clear_data['DOY'] == 211.0)]\n",
    "test_data = pd.concat([imputed_data, clear_data], axis=0) #, ignore_index=True)\n",
    "\n",
    "display(test_data)\n",
    "\n",
    "# train_data = data\n",
    "\n",
    "# Sort the DataFrame by 'X', 'Y', and 'DOY'\n",
    "data = data.sort_values(by=['Y', 'X', 'DOY', ])\n",
    "test_data = test_data.sort_values(by=['Y', 'X', 'DOY'])\n",
    "\n",
    "\n",
    "doys = [171, 179, 187, 195, 203, 211, 219]\n",
    "doys = [203, 211, 219]\n",
    "doys = [211]\n",
    "# train_doys = [219]\n",
    "# train_data_list = []\n",
    "otput_data_list = []\n",
    "for doy in doys:\n",
    "    # data = _get_hls(doy)\n",
    "    # croped_data = _crop_data(data, doy)\n",
    "    tr_df = data[ data['DOY'] == float(doy)].copy()\n",
    "    tr_df2 = test_data[ test_data['DOY'] == float(doy)].copy()\n",
    "    # otput_data_list.append(tr_df)\n",
    "    _image_df2(tr_df, tr_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "aborted",
     "timestamp": 1698374782155,
     "user": {
      "displayName": "Koyaua Uvarov",
      "userId": "04551130653342672393"
     },
     "user_tz": -180
    },
    "id": "qQBC-ZXEHI-c"
   },
   "outputs": [],
   "source": [
    "fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "aborted",
     "timestamp": 1698374782155,
     "user": {
      "displayName": "Koyaua Uvarov",
      "userId": "04551130653342672393"
     },
     "user_tz": -180
    },
    "id": "AHzEWLYbB-IY"
   },
   "outputs": [],
   "source": [
    "data = clear.copy() #[0:1000]\n",
    "\n",
    "table_dtype = 'int16'\n",
    "\n",
    "data = data.astype(table_dtype)\n",
    "print(data.dtypes.tolist())\n",
    "# Reset the index to remove it\n",
    "data = data.reset_index(drop=True)\n",
    "# train_data.columns = final_columns_list\n",
    "# display(data)\n",
    "\n",
    "\n",
    "# Split the DataFrame into training and test DataFrames\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "display(train_data)\n",
    "test_data = test_data.reset_index(drop=True)\n",
    "display(test_data)\n",
    "\n",
    "# #### FOR CPU USABILITY, for 2 pixels #################################\n",
    "# epochs_steps = 1  # 250 #50\n",
    "# save_steps = 1   #250 #50 #9380  #2000   # FOR FIT THIS VALUE START TRAIN DATASET, EQUALS FOR STEPS IN FIRST START\n",
    "# logging_steps = 1 # 250 #25 #9380  #1000\n",
    "\n",
    "#### FOR T-4 GPU USABILITY################################\n",
    "epochs_steps = 200   # 250 #50\n",
    "save_steps = 100   #250 #50 #9380  #2000   # FOR FIT THIS VALUE START TRAIN DATASET, EQUALS FOR STEPS IN FIRST START\n",
    "logging_steps = 50 # 250 #25 #9380  #1000\n",
    "#### batch_size = 250 for T4\n",
    "batch_size = 200 #250 #312  # 224 # 250 #300 #164 for float64 # 112 # for float64 # 136 # 96   # 140# 400\n",
    "#######################################\n",
    "\n",
    "# #### FOR V-100 GPU USABILITY################################\n",
    "# epochs_steps = 200   # 250 #50\n",
    "# save_steps = 1000   #250 #50 #9380  #2000   # FOR FIT THIS VALUE START TRAIN DATASET, EQUALS FOR STEPS IN FIRST START\n",
    "# logging_steps = 200 # 250 #25 #9380  #1000\n",
    "# #### batch_size = 250 for T4\n",
    "# batch_size = 232 #250 #312  # 224 # 250 #300 #164 for float64 # 112 # for float64 # 136 # 96   # 140# 400\n",
    "# #######################################\n",
    "\n",
    "# #### FOR A-100 GPU USABILITY################################\n",
    "# epochs_steps = 800   # 250 #50\n",
    "# save_steps = 10000   #250 #50 #9380  #2000   # FOR FIT THIS VALUE START TRAIN DATASET, EQUALS FOR STEPS IN FIRST START\n",
    "# logging_steps = 500 # 250 #25 #9380  #1000\n",
    "# #### batch_size = 250 for T4\n",
    "# batch_size = 800 #250 #312  # 224 # 250 #300 #164 for float64 # 112 # for float64 # 136 # 96   # 140# 400\n",
    "# #######################################\n",
    "\n",
    "EXP_NAME = 'exp-A100'\n",
    "EXP_NAME = 'exp-V100'\n",
    "EXP_NAME = 'exp-T4'\n",
    "\n",
    "EXP_NAME = 'A0BASE'\n",
    "\n",
    "#### 1 ###########\n",
    "# learning_rate = 5e-5\n",
    "# lr_scheduler_type = 'constant' # constant_with_warmup\n",
    "\n",
    "step_checkpoint = 16000\n",
    "######### SET TRAINER_RUN ARGUMENTS ##########################\n",
    "learning_rate = 0.00001\n",
    "lr_scheduler_type = 'cosine_with_restarts'\n",
    "lr_scheduler_type = 'constant_with_warmup'\n",
    "lr_scheduler_type = 'cosine'\n",
    "lr_scheduler_type = 'linear'\n",
    "\n",
    "TRAINER_RUN = 0\n",
    "if TRAINER_RUN == 0:\n",
    "  load_model_path = 'distilgpt2'\n",
    "  experiment_dir = f\"{EXP_NAME}/run[{TRAINER_RUN}]\"\n",
    "elif TRAINER_RUN > 0:\n",
    "  before = pd.read_csv(f'{EXP_NAME}/run[{TRAINER_RUN-1}].csv')\n",
    "  load_model_path = before['experiment_dir'][0] + f'/checkpoint-{step_checkpoint}'\n",
    "  experiment_dir  = f\"{EXP_NAME}/run[{TRAINER_RUN}]\"\n",
    "\n",
    "TRAINER_DICT = pd.DataFrame({'EXP_NAME' : EXP_NAME}, index = [TRAINER_RUN])    # dict()\n",
    "\n",
    "\n",
    "TRAINER_DICT['TRAINER_RUN'] = TRAINER_RUN\n",
    "TRAINER_DICT['table_dtype'] = table_dtype\n",
    "TRAINER_DICT['epochs_steps'] = epochs_steps\n",
    "TRAINER_DICT['save_steps'] = save_steps\n",
    "TRAINER_DICT['logging_steps'] = logging_steps\n",
    "TRAINER_DICT['batch_size'] = batch_size\n",
    "TRAINER_DICT['learning_rate'] = learning_rate\n",
    "TRAINER_DICT['lr_scheduler_type'] = lr_scheduler_type\n",
    "TRAINER_DICT['experiment_dir'] = experiment_dir\n",
    "\n",
    "display(pd.DataFrame.from_dict(TRAINER_DICT))\n",
    "\n",
    "##### SET experiment_dir & efficient_finetuning #######################\n",
    "efficient_finetuning = ''  #'lora'\n",
    "if efficient_finetuning == 'lora':\n",
    "    experiment_dir = f\"{experiment_dir}_{efficient_finetuning}\"\n",
    "##### SET experiment_dir & efficient_finetuning #######################\n",
    "optimizer = 'adamw_torch'\n",
    "# optimizer = 'adamw_torch_fused'  #'adamw_torch'  #'adamw_torch_fused'\n",
    "if optimizer == 'adamw_torch_fused':\n",
    "    experiment_dir = f\"{experiment_dir}_{optimizer}\"\n",
    "#### SET model_save_dir through save_model #########################\n",
    "# model_save_dir = f'{EXP_NAME}/ZeroModel_{efficient_finetuning}'\n",
    "\n",
    "\n",
    "print('experiment_dir :', experiment_dir)\n",
    "print('load_model_path:', load_model_path)\n",
    "\n",
    "\n",
    "model = GReaT(llm=load_model_path,\n",
    "              batch_size=batch_size, epochs=epochs_steps, logging_steps=logging_steps, save_steps=save_steps,\n",
    "              # evaluation_strategy='steps',\n",
    "              # dataloader_num_workers=2, #fp16=True,\n",
    "              save_total_limit=2,\n",
    "              prediction_loss_only=True,\n",
    "              experiment_dir=f'{experiment_dir}',\n",
    "              dataloader_num_workers=2,\n",
    "              efficient_finetuning = efficient_finetuning,\n",
    "              learning_rate=learning_rate,\n",
    "              lr_scheduler_type=lr_scheduler_type,\n",
    "              warmup_ratio=0.1,\n",
    "              # optim=optimizer,\n",
    "              fp16 = True,\n",
    "              # torch_compile=True,   #### for Ampere\n",
    "              # bf16=True,            #### for Ampere\n",
    "              )\n",
    "\n",
    "print(f'----------- Model architecture, efficient_finetuning: {efficient_finetuning} -----------------------')\n",
    "print(model.model)\n",
    "print(f'----------------------------------------------------------------------------------------------------')\n",
    "# fn\n",
    "\n",
    "model.fit(data=train_data)\n",
    "# model.fit(data=train_data, test_data=test_data)\n",
    "\n",
    "TRAINER_DICT.to_csv(f'{experiment_dir}.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "aborted",
     "timestamp": 1698374782155,
     "user": {
      "displayName": "Koyaua Uvarov",
      "userId": "04551130653342672393"
     },
     "user_tz": -180
    },
    "id": "LV037qqBNdol"
   },
   "outputs": [],
   "source": [
    "from google.colab import runtime\n",
    "runtime.unassign()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "aborted",
     "timestamp": 1698374782155,
     "user": {
      "displayName": "Koyaua Uvarov",
      "userId": "04551130653342672393"
     },
     "user_tz": -180
    },
    "id": "695cBCyoBG3q"
   },
   "outputs": [],
   "source": [
    "fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "aborted",
     "timestamp": 1698374782155,
     "user": {
      "displayName": "Koyaua Uvarov",
      "userId": "04551130653342672393"
     },
     "user_tz": -180
    },
    "id": "f9v8lVF5Sayy"
   },
   "outputs": [],
   "source": [
    "fn"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
